{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13805409312248232,
      "exploration_ratio": 0.4545454545454545
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13806723833084106,
      "exploration_ratio": 0.6727272727272728
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1380913317203522,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1381505727767944,
      "exploration_ratio": 0.7545454545454546
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13804605841636658,
      "exploration_ratio": 0.890909090909091
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1380639922618866,
      "exploration_ratio": 0.9454545454545455
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13806076407432555,
      "exploration_ratio": 0.9454545454545455
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13798436403274533,
      "exploration_ratio": 0.9727272727272727
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 17.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.3,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13810608506202698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13807813167572022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.138188499212265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1381149733066559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13815503239631655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13817663788795473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13807546019554137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13812102675437926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13805676579475404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13810007214546202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13812368392944335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13812302470207213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13810468912124635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13797693371772765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13814672946929932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1380724823474884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1379516100883484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13805583834648133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13815696954727175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.13794001817703247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1380747890472412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1381057870388031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1381384265422821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31807370185852,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272453943888348,
      "backward_entropy": 0.1380776035785675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411940813064575,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 9.999999892897903e-05,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1827268918355306,
      "backward_entropy": 0.1380720889568329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.331005096435547,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.00020001306984340772,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18272884885470073,
      "backward_entropy": 0.13799630403518676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30230131149292,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.00030001032864674927,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18273022373517356,
      "backward_entropy": 0.1380089569091797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34959979057312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0003999900945927948,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1827307124932607,
      "backward_entropy": 0.13804492950439454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251442766189575,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0004999739758204669,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273115754127503,
      "backward_entropy": 0.13790454864501955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.298478078842162,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.000599932309705764,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273249268531797,
      "backward_entropy": 0.13781007766723632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.281526136398316,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0006998855387791991,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1827339311440786,
      "backward_entropy": 0.13783448934555054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.243175888061524,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0007998310087714344,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273554841677347,
      "backward_entropy": 0.13779167890548705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.095292806625366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0008997567521873862,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18273725112279257,
      "backward_entropy": 0.13779918551445008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219578552246094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0009996233158744872,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1827385644117991,
      "backward_entropy": 0.13781403899192807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.285581016540528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0010994920623488725,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18274041612943015,
      "backward_entropy": 0.13775618433952333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527983999252319,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0011993803083896637,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1827420393625895,
      "backward_entropy": 0.13782963871955872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295902967453003,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0012993616866879166,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18274313211441037,
      "backward_entropy": 0.1378661060333252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381620407104492,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.001399345404934138,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18274393081665039,
      "backward_entropy": 0.13769336104393004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30730767250061,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0014993505668826402,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1827448606491089,
      "backward_entropy": 0.1375870406627655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492208242416382,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0015993495704606175,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18274572292963662,
      "backward_entropy": 0.13782697319984435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.460567188262939,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0016994098899886013,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18274649182955424,
      "backward_entropy": 0.13767770171165467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439438152313233,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0017995067755691707,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18274694879849754,
      "backward_entropy": 0.1375706887245178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.284978866577148,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.001899634615983814,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18274737000465394,
      "backward_entropy": 0.13761595249176026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.681592512130738,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0019997191848233342,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18274769385655718,
      "backward_entropy": 0.13758110880851745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667942142486572,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0020999369444325566,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18274813095728554,
      "backward_entropy": 0.1376673126220703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.550422859191894,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.00220024436712265,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18274865945180258,
      "backward_entropy": 0.13770289778709413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.316625928878784,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.002300583012402058,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18274884223937987,
      "backward_entropy": 0.13738136768341064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389901781082154,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0024008645908907057,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18274854620297748,
      "backward_entropy": 0.13749914526939394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410749101638794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0025011188583448528,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18274827996889748,
      "backward_entropy": 0.1376034069061279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557601356506348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.002601352776400745,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18274791638056437,
      "backward_entropy": 0.13744494557380676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544804668426513,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0027016444830223916,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18274757663408916,
      "backward_entropy": 0.13746365189552306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.650802087783813,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0028019740944728254,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18274722099304197,
      "backward_entropy": 0.13742013692855834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55051941871643,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0029023877577856183,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1827469209829966,
      "backward_entropy": 0.1373487877845764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54866099357605,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0030028295004740357,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18274652560551957,
      "backward_entropy": 0.1374031400680542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.604417705535889,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.003103272314183414,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1827459990978241,
      "backward_entropy": 0.13715996980667117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420413303375245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0032037423690780996,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18274497787157695,
      "backward_entropy": 0.13731274008750916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524667358398437,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0033041740767657756,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18274369835853577,
      "backward_entropy": 0.13728380560874937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.712175035476685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0034046008251607416,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18274219433466596,
      "backward_entropy": 0.13699488043785096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.651596927642823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0035050993552431463,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18274059693018596,
      "backward_entropy": 0.13699340939521792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.781514406204224,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0036056518321856855,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273936112721761,
      "backward_entropy": 0.13695378780364992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371172666549683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0037062899442389607,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273800412813823,
      "backward_entropy": 0.13719644904136657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808435726165772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0038068417459726335,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18273676832516988,
      "backward_entropy": 0.13677477240562438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63784065246582,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.003907503210939467,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18273592591285706,
      "backward_entropy": 0.13677411556243896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.466166830062866,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0040081816259771585,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18273513515790302,
      "backward_entropy": 0.13684810876846315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531273651123048,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.004108799574896693,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18273453116416932,
      "backward_entropy": 0.13688727974891662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.504895734786988,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.004209410538896919,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18273375431696573,
      "backward_entropy": 0.13696174383163454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343900156021117,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.004309983970597386,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18273305296897888,
      "backward_entropy": 0.13667645454406738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33182635307312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00441044420003891,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18273176153500875,
      "backward_entropy": 0.13684804916381837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.236043548583984,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.004510799655690789,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18273041049639382,
      "backward_entropy": 0.13651416659355162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.464025735855103,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.004611025610938668,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1827290753523509,
      "backward_entropy": 0.1366055715084076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196845960617065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.004711253568530083,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272788524627687,
      "backward_entropy": 0.13681638836860657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.238258028030396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.004811344482004642,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272659977277123,
      "backward_entropy": 0.1363818347454071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.509751129150391,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.004911331180483103,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18272518912951152,
      "backward_entropy": 0.13661096930503847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.369722843170166,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.005011385260149837,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18272399107615153,
      "backward_entropy": 0.1360586714744568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.203228044509888,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.005111397290602326,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272269368171692,
      "backward_entropy": 0.1363831090927124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472453069686889,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.005211285362020135,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18272119164466857,
      "backward_entropy": 0.13594666719436643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14837737083435,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.005311216413974762,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18271957238515218,
      "backward_entropy": 0.13644655227661134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673105096817016,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.005411026580259204,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18271809021631874,
      "backward_entropy": 0.1361373782157898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559739112854004,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.005511001404374838,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18271657625834145,
      "backward_entropy": 0.13622547268867494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6794753074646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.005611049197614193,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18271543184916178,
      "backward_entropy": 0.13588718295097352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.174602746963501,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.005711226910352707,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18271436889966328,
      "backward_entropy": 0.1360741686820984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66305775642395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.005811259988695383,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18271275361378986,
      "backward_entropy": 0.13593194246292112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.562467288970947,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.005911438819020986,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18271127343177795,
      "backward_entropy": 0.13582107901573182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.108342599868774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0060116654261946675,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1827097276846568,
      "backward_entropy": 0.13587967872619627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.617327404022216,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.006111701158806682,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1827077845732371,
      "backward_entropy": 0.13577457070350646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.979717826843261,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00621183319017291,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18270582556724546,
      "backward_entropy": 0.13570290327072143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245736503601075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.006311732437461614,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18270378510157267,
      "backward_entropy": 0.13562430620193483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19035210609436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.006411577435210347,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18270187377929686,
      "backward_entropy": 0.13581014752388001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245153760910034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.00651133107021451,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18269978364308676,
      "backward_entropy": 0.13540371179580687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170033264160157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.006611031293869018,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18269808491071066,
      "backward_entropy": 0.13546634793281556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451866483688354,
      "terminal_state_reached": 1.0,
      "terminal_reward": 18.0,
      "log_Z": 0.006710646487772465,
      "trajectory_length": 7.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.18269620736440023,
      "backward_entropy": 0.1353512227535248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13290491104126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.006810341589152813,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18269473910331727,
      "backward_entropy": 0.13490673422813412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.200466775894165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.006909939367324114,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18269302845001223,
      "backward_entropy": 0.13507567524909975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050834846496581,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.007009473303332925,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18269100189208987,
      "backward_entropy": 0.1348074185848236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211551856994628,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.007108859112486243,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18268857200940453,
      "backward_entropy": 0.1350932276248932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177299356460571,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0072082155384123325,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18268583218256634,
      "backward_entropy": 0.13510428547859193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.084803247451783,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.007307518878951669,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18268291354179383,
      "backward_entropy": 0.13519002318382262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47479419708252,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.007406739750877023,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1826801637808482,
      "backward_entropy": 0.13509702801704407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472136211395263,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.007506089936941862,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.18267733454704285,
      "backward_entropy": 0.1346736943721771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.404883623123169,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.007605548156425357,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18267403841018676,
      "backward_entropy": 0.1339339518547058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.989463376998901,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.007705080602318048,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18267042438189188,
      "backward_entropy": 0.1343431043624878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995813083648682,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.007804453792050481,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18266650636990864,
      "backward_entropy": 0.1342723834514618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462061166763306,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.007903692498803138,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.182662832736969,
      "backward_entropy": 0.13382852435111997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.311563777923585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.00800305586308241,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18265921274820965,
      "backward_entropy": 0.13384000658988954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389601230621338,
      "terminal_state_reached": 1.0,
      "terminal_reward": 14.0,
      "log_Z": 0.008102465886622667,
      "trajectory_length": 7.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.18265579541524252,
      "backward_entropy": 0.13379067659378052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38036298751831,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0082019648514688,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18265231251716613,
      "backward_entropy": 0.13404609799385073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616733264923095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.008301547355949878,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18264837463696798,
      "backward_entropy": 0.13326555371284485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.297200107574463,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.008401323296129703,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18264458576838175,
      "backward_entropy": 0.13314575552940366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495435619354248,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.008501078654080629,
      "trajectory_length": 7.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.18264084060986835,
      "backward_entropy": 0.13341728687286375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86628246307373,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.008600917272269725,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18263672590255736,
      "backward_entropy": 0.13340472221374514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.310247039794922,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.008701040968298912,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18263227343559266,
      "backward_entropy": 0.13326104760169982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164716291427613,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.008801127411425113,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1826274613539378,
      "backward_entropy": 0.1339013493061066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34125714302063,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008901099301874637,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1826228360335032,
      "backward_entropy": 0.13281054735183714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.408551216125488,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.009001060388982296,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1826181908448537,
      "backward_entropy": 0.13279364943504332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329911518096925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.009101055003702641,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18261321783065795,
      "backward_entropy": 0.13298763751983642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.632625007629395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.009201035555452108,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18260829250017802,
      "backward_entropy": 0.13242076396942137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.155252075195312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00930118402466178,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1826033850510915,
      "backward_entropy": 0.13263813853263856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971444797515869,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.009401181153953076,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18259887695312502,
      "backward_entropy": 0.13268038034439086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279685926437377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.009500971902161837,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18259416619936625,
      "backward_entropy": 0.13261796116828917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396842575073242,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00960074607282877,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18258908589680992,
      "backward_entropy": 0.13161369681358337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.694296979904175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.009700538124889135,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18258346120516458,
      "backward_entropy": 0.13249868035316464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0993812084198,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.009800533205270768,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18257739146550495,
      "backward_entropy": 0.1321639978885651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.215981483459473,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.009900377970188856,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.18257072766621904,
      "backward_entropy": 0.13174623131752017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071000003814698,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.010000161081552505,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18256418506304423,
      "backward_entropy": 0.13217987298965456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646430587768554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.010099803563207388,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1825576901435852,
      "backward_entropy": 0.1311085593700409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.263958549499511,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0101996217854321,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18255082766215008,
      "backward_entropy": 0.13078715085983278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968987703323364,
      "terminal_state_reached": 1.0,
      "terminal_reward": 18.0,
      "log_Z": 0.01029939018189907,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1825435658295949,
      "backward_entropy": 0.13147143006324766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.108037090301513,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.010398962255567312,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1825357457002004,
      "backward_entropy": 0.13027503132820129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35642762184143,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.010498443711549043,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18252785205841066,
      "backward_entropy": 0.1306289279460907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010722017288208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.010597988311201335,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18251962860425314,
      "backward_entropy": 0.13099538087844848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.015125942230224,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.010697392839938402,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1825110673904419,
      "backward_entropy": 0.1299811828136444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360066318511963,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.010796671360731125,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18250314791997274,
      "backward_entropy": 0.1299362015724182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.072939109802245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.010896062199026346,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18249548673629762,
      "backward_entropy": 0.12952544569969177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225618314743041,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.010995382163673639,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18248746395111085,
      "backward_entropy": 0.1298927354812622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13650951385498,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.011094706505537033,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1824790934721629,
      "backward_entropy": 0.12949238896369936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.159972000122071,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.011193986423313618,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18247044881184898,
      "backward_entropy": 0.12942810177803038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183040618896484,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.011293229460716248,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.182461945215861,
      "backward_entropy": 0.12873512268066406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19883599281311,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.011392463929951191,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18245348532994587,
      "backward_entropy": 0.12846775770187377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314555168151855,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.011491712648421526,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18244448502858482,
      "backward_entropy": 0.12800718426704408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557043266296386,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.011591035593301057,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18243585030237836,
      "backward_entropy": 0.12821799993515018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983206653594971,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.011690545547753572,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1824263036251068,
      "backward_entropy": 0.12870053410530094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.121054458618165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.011789901368319988,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18241624832153322,
      "backward_entropy": 0.12826579809188843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.053781604766845,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.011889191344380379,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18240553736686707,
      "backward_entropy": 0.12756921052932738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841310453414917,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.011988397780805826,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18239473899205524,
      "backward_entropy": 0.1279083287715912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840808534622193,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.012087432481348515,
      "trajectory_length": 7.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.18238330682118734,
      "backward_entropy": 0.12733811259269714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.768422842025757,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.012186292745172977,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1823718210061391,
      "backward_entropy": 0.12733280062675478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.981579446792603,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.012284974940121174,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18236044645309446,
      "backward_entropy": 0.12688340663909914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.722075414657593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.012383599113672972,
      "trajectory_length": 7.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.18234924077987674,
      "backward_entropy": 0.12616377353668212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624949026107788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.012482024729251862,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18233833114306133,
      "backward_entropy": 0.1268029808998108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.367104196548462,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.012580229341983796,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1823281168937683,
      "backward_entropy": 0.1253975236415863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03184928894043,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.012678098026663065,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18231782714525857,
      "backward_entropy": 0.12658008217811587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.834149408340454,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.01277605602517724,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18230745196342468,
      "backward_entropy": 0.12485670447349548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.828263139724731,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.012873969413340092,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18229696551958718,
      "backward_entropy": 0.125756596326828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.768046474456787,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.012971854582428933,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.18228659828503926,
      "backward_entropy": 0.12476988911628724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.585138463973999,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.013069655746221542,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1822758913040161,
      "backward_entropy": 0.12569621086120605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.838181018829346,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.013167279493063688,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18226494789123532,
      "backward_entropy": 0.1257998502254486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.135627031326294,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.013264871295541525,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18225414355595906,
      "backward_entropy": 0.12350308299064636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060899209976196,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01336265066638589,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18224255641301473,
      "backward_entropy": 0.12383284449577332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091619157791138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.013460549339652062,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18222972949345909,
      "backward_entropy": 0.12339131355285644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843733644485473,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.013558562193065882,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18221686482429506,
      "backward_entropy": 0.12404149651527403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.183551549911499,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.013656522799283265,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18220342993736266,
      "backward_entropy": 0.12393800258636474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.471904945373535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.013754056021571159,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18219036459922794,
      "backward_entropy": 0.12289034008979798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.536436605453491,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01385140884667635,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.18217722773551942,
      "backward_entropy": 0.1211482357978821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0606873512268065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.01394861275330186,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1821642816066742,
      "backward_entropy": 0.12275405168533324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763679265975952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.014045390021055936,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18215150833129884,
      "backward_entropy": 0.12214564800262451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.866602802276612,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.014142219070345163,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18213850458463032,
      "backward_entropy": 0.12195006012916565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266149997711182,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.014239149168133736,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18212539951006573,
      "backward_entropy": 0.12067958474159242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.500092315673828,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.01433583553880453,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18211239178975425,
      "backward_entropy": 0.12051505684852601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.136618614196777,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.014432420395314694,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1820987602074941,
      "backward_entropy": 0.12150910735130312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.744068145751953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.01452870424836874,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18208565711975097,
      "backward_entropy": 0.11859464645385745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.630148792266846,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.014625085145235061,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1820723553498586,
      "backward_entropy": 0.11935325622558593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558948040008545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.014721476472914219,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18205856680870056,
      "backward_entropy": 0.1197106730937958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3979450225830075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.01481784824281931,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18204474250475566,
      "backward_entropy": 0.11864874839782716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.297490072250366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.014914123341441154,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18203169306119282,
      "backward_entropy": 0.11922307372093202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.52702260017395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.015010206867009402,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1820186217625936,
      "backward_entropy": 0.1171506369113922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458455801010132,
      "terminal_state_reached": 1.0,
      "terminal_reward": 16.0,
      "log_Z": 0.01510628154501319,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1820048987865448,
      "backward_entropy": 0.11843564748764038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.602962779998779,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.015202339086681605,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18199129899342853,
      "backward_entropy": 0.11836136698722836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6325235843658445,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.015298445336520671,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18197736740112305,
      "backward_entropy": 0.11573713541030883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.37546124458313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.015394603554159402,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18196307023366293,
      "backward_entropy": 0.11500236630439757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.478299570083618,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.015490671433508397,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1819489816824595,
      "backward_entropy": 0.11503593921661379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.084166812896728,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.015586712304502726,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18193377057711285,
      "backward_entropy": 0.11576649069786069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.009742259979248,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.015682493336498737,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18191820979118345,
      "backward_entropy": 0.11302375018596648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.229339551925659,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.015778014529496433,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18190275629361471,
      "backward_entropy": 0.1114584457874298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.878032445907593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.015873437840491535,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1818870464960734,
      "backward_entropy": 0.11506164789199828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.296196937561035,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.015968532115221024,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1818711002667745,
      "backward_entropy": 0.11452393054962158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.204550933837891,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.016063588671386242,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18185426394144694,
      "backward_entropy": 0.11366640448570253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.989158678054809,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01615855172276497,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1818376859029134,
      "backward_entropy": 0.11397345781326293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.095744180679321,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016253319196403028,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18182215491930642,
      "backward_entropy": 0.11131785213947296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.110114669799804,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.016347985342144968,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1818066895008087,
      "backward_entropy": 0.11301634907722473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.168491172790527,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.01644254717975855,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18179024855295817,
      "backward_entropy": 0.11047245144844056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.030090093612671,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016537065617740154,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1817740599314372,
      "backward_entropy": 0.11032869815826415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.017685604095459,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.016631470434367655,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18175827662150065,
      "backward_entropy": 0.10784908354282378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.794048070907593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.01672576479613781,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18174125750859577,
      "backward_entropy": 0.10906202077865601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.670641136169434,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.01681982111185789,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18172362049420673,
      "backward_entropy": 0.1084645050764084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.733300352096558,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.016913568414747716,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1817067305246989,
      "backward_entropy": 0.10828304648399353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.93543586730957,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01700708121061325,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18168943723042805,
      "backward_entropy": 0.10838022291660307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.882548904418945,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.017100533097982408,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1816713511943817,
      "backward_entropy": 0.10839055836200714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.318298244476319,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.017193849943578244,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18165346781412758,
      "backward_entropy": 0.10689958274364472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8554610252380375,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.017286719009280204,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1816357394059499,
      "backward_entropy": 0.1055507379770279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6316932201385494,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.01737952381372452,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.18161686658859252,
      "backward_entropy": 0.1057529479265213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.302269983291626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.017472155578434467,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1815976897875468,
      "backward_entropy": 0.1045882773399353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.111797237396241,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.017564405500888825,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1815780262152354,
      "backward_entropy": 0.10593737304210663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.743563604354859,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.017656843923032284,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18155673344930012,
      "backward_entropy": 0.10419851183891296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.424390697479248,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.017749177664518355,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.18153539101282753,
      "backward_entropy": 0.10203794896602629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.356100606918335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.01784123368561268,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18151324590047196,
      "backward_entropy": 0.10300186812877657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.686874675750732,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0179330101236701,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18149131933848064,
      "backward_entropy": 0.10443342983722688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.534424114227295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.018024734035134316,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18146966099739076,
      "backward_entropy": 0.10099371135234833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.439350652694702,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018116334825754164,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18144757548967996,
      "backward_entropy": 0.1023086041212082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.331204986572265,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.018207778595387934,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18142555952072145,
      "backward_entropy": 0.10170226275920868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.132959842681885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.01829900536686182,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.181404838959376,
      "backward_entropy": 0.09825372815132141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.561733675003052,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.01838987972587347,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18138509790102642,
      "backward_entropy": 0.0969990938901901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.581649351119995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.018480753153562547,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.181364776690801,
      "backward_entropy": 0.09771901190280914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.034318685531616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.01857161782681942,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18134283224741618,
      "backward_entropy": 0.09522652685642242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159775257110596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.018662135116755962,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18132052024205528,
      "backward_entropy": 0.09948930084705353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.235135412216186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.01875242590904236,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1812980731328328,
      "backward_entropy": 0.09653426289558412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0715607643127445,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.018842550367116927,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18127555449803673,
      "backward_entropy": 0.09681200027465821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.204874706268311,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01893236059695482,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18125139673550922,
      "backward_entropy": 0.09535093247890472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.156500291824341,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.01902204379439354,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18122650186220807,
      "backward_entropy": 0.09173563539981841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.91077151298523,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01911154091358185,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18120283285776773,
      "backward_entropy": 0.09815417885780334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.564424800872803,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01920070108026266,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18117860754330956,
      "backward_entropy": 0.0936003667116165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.760914850234985,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.019289328530430794,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18115570346514384,
      "backward_entropy": 0.09129092395305632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.800951838493347,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.01937762461602688,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1811323324839274,
      "backward_entropy": 0.0885747253894806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9568384170532225,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.019465652108192445,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18110866546630858,
      "backward_entropy": 0.09450770795345306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.650845623016357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.019553582184016705,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18108282486597696,
      "backward_entropy": 0.08808036983013154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8959578514099125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.019641152955591677,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1810567319393158,
      "backward_entropy": 0.09441760301589966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.569292163848877,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.019728617370128633,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.18102955023447673,
      "backward_entropy": 0.08861839056015015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3748143196105955,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.019815713353455066,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18100146651268006,
      "backward_entropy": 0.09028776049613953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.66690993309021,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.019902376644313335,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1809743424256643,
      "backward_entropy": 0.08544167995452881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2715202331542965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.01998884454369545,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18094570438067117,
      "backward_entropy": 0.0874188607931137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342882585525513,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02007483337074518,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18091715574264525,
      "backward_entropy": 0.086051607131958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598116755485535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.020160424895584582,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.18088928858439127,
      "backward_entropy": 0.08635236978530883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.131370615959168,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.020245883986353873,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1808591922124227,
      "backward_entropy": 0.08301327586174012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.486263227462769,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02033086437731981,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18082985281944275,
      "backward_entropy": 0.08505018770694733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.202841734886169,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.020415691286325456,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18079883257548018,
      "backward_entropy": 0.08630076110363005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.11551730632782,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02050016075372696,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18076652288436892,
      "backward_entropy": 0.08598877787590029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19904477596283,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.020584262907505035,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18073419531186422,
      "backward_entropy": 0.08155501663684844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.08142921924591,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.020668065175414085,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1807017683982849,
      "backward_entropy": 0.07978286445140838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.155653882026672,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.020751515962183477,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1806696097056071,
      "backward_entropy": 0.08073310911655426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.149937319755554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.020834706909954547,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.18063805301984154,
      "backward_entropy": 0.08191590905189514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.932086253166199,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0209177291020751,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1806059241294861,
      "backward_entropy": 0.07863471925258637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.967968249320984,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.021000366657972336,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18057317932446795,
      "backward_entropy": 0.08204856038093568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.663874912261963,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.021082731522619726,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18053940534591675,
      "backward_entropy": 0.07605605483055114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.731028509140015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.021164536103606225,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.18050530354181926,
      "backward_entropy": 0.07855878293514251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.942952680587768,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02124593500047922,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.18047152558962504,
      "backward_entropy": 0.07681785881519318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.776208472251892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.021327166818082333,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1804364999135335,
      "backward_entropy": 0.07392026156187056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.728516960144043,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.021408086642622948,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1804001450538635,
      "backward_entropy": 0.07477869272232054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.914627599716186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.021488687582314016,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.18036413192749023,
      "backward_entropy": 0.07479618221521378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.614857006072998,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.021569149941205977,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18032668232917787,
      "backward_entropy": 0.07632832825183869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.494612288475037,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02164923641830683,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18028865456581117,
      "backward_entropy": 0.07026044458150862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.638375186920166,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.021728893928229808,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18024967908859252,
      "backward_entropy": 0.07328922986984253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.411019229888916,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02180822044610977,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.18021112283070884,
      "backward_entropy": 0.06991719782352447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.49010705947876,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02188710179179907,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.18017353415489196,
      "backward_entropy": 0.0732046228647232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2300170183181764,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.021965700574219225,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.18013413747151694,
      "backward_entropy": 0.06964006125926972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.238545966148377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.022043794579803943,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.18009536663691203,
      "backward_entropy": 0.06892070412635803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.333673286437988,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.022121384926140308,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.18005727529525759,
      "backward_entropy": 0.06733273178339005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9201406240463257,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.022198693268001078,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1800168712933858,
      "backward_entropy": 0.06718870580196382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.937482976913452,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02227534744888544,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17997666994730632,
      "backward_entropy": 0.06706461191177368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.172374176979065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.022351466119289398,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17993638316790264,
      "backward_entropy": 0.06759852856397627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9980659008026125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022427315823733807,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17989490628242494,
      "backward_entropy": 0.06370630562305449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0957439661026,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.022502662800252437,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17985303004582723,
      "backward_entropy": 0.06866158306598664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9890915870666506,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02257773019373417,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17981019616127014,
      "backward_entropy": 0.061921061277389534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.735882878303528,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.022652452625334264,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17976702253023785,
      "backward_entropy": 0.0634317934513092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.779560923576355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.022726656682789326,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17972349325815837,
      "backward_entropy": 0.061784408092498765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.731112742424011,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02280042301863432,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17967888712882996,
      "backward_entropy": 0.06020503222942353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7489999532699585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.022873691096901894,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17963236769040428,
      "backward_entropy": 0.058952586054801935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6261957764625548,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02294649388641119,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17958565751711525,
      "backward_entropy": 0.0620405164361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.473639225959778,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.023018824122846126,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17953867912292482,
      "backward_entropy": 0.0620885843038559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.350715970993042,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.02309056222438812,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.17949174642562868,
      "backward_entropy": 0.06117741614580154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.516367292404175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02316171079874039,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17944416006406147,
      "backward_entropy": 0.05893607169389725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.428122580051422,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02323244623839855,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17939566175142926,
      "backward_entropy": 0.058609593808650974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2964476585388183,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.023302731290459632,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17934644023577373,
      "backward_entropy": 0.05745966881513596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1747074723243713,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02337241396307945,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17929729024569194,
      "backward_entropy": 0.05819709032773972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2756794810295107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 16.0,
      "log_Z": 0.02344147004187107,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1792470137278239,
      "backward_entropy": 0.05726899921894073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1869696259498594,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.023510074429214,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17919656236966452,
      "backward_entropy": 0.0574333679676056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1946470618247984,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.023578159138560296,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.17914515336354572,
      "backward_entropy": 0.056691797673702235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.138897478580475,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.023645798303186895,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17909393707911175,
      "backward_entropy": 0.058247183859348295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.980055105686188,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02371294479817152,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1790410081545512,
      "backward_entropy": 0.05616905272006989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.797186851501465,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.023779493756592274,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17898760040601094,
      "backward_entropy": 0.05531407207250595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0715267181396486,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.023845199123024942,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.17893505295117695,
      "backward_entropy": 0.05366012871265412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8769694924354554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02391064465045929,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17888010541598,
      "backward_entropy": 0.05111594468355178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9191755294799804,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.023975489474833012,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17882716655731204,
      "backward_entropy": 0.04942968189716339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.672203516960144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.024039900116622447,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17877257267634078,
      "backward_entropy": 0.050858242511749266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8133676171302797,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02410363331437111,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17871854503949486,
      "backward_entropy": 0.04909343957901001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8387503623962402,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02416686210781336,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17866381804148357,
      "backward_entropy": 0.05116349846124648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.574193596839905,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02422971446067095,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17860791087150577,
      "backward_entropy": 0.04895370662212371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.577876567840576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02429189682006836,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17855177521705629,
      "backward_entropy": 0.05221368700265885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5970418453216553,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.024353487603366374,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17849661111831666,
      "backward_entropy": 0.04454746693372726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4900782465934754,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.024414557963609695,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1784414033095042,
      "backward_entropy": 0.04741992622613907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3260882019996645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02447506971657276,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17838570674260457,
      "backward_entropy": 0.04503858178853989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.544560134410858,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.024534805119037627,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1783301293849945,
      "backward_entropy": 0.043734853565692906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3279347240924837,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.024594171904027462,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17827320297559104,
      "backward_entropy": 0.045752330422401434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.321962869167328,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.024652887880802155,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1782160480817159,
      "backward_entropy": 0.04574683368206024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.201295256614685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02471106145530939,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17815669377644855,
      "backward_entropy": 0.0445112943649292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4743886291980743,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.024768527783453464,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17809805671374002,
      "backward_entropy": 0.0431452290713787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.172458642721176,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.024825535528361798,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17803451816240948,
      "backward_entropy": 0.0441389349102974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.142328828573227,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.024881826341152193,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1779707610607147,
      "backward_entropy": 0.041448506712913516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1381612002849577,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.024937559850513935,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17790592710177103,
      "backward_entropy": 0.04198123380541801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2347153186798097,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.024992799572646617,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17784027059872945,
      "backward_entropy": 0.03982004776597022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0958431005477904,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02504769414663315,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17777079741160076,
      "backward_entropy": 0.041593525111675266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1662865459918974,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.025102006085217,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17770024935404458,
      "backward_entropy": 0.0404095521569252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9662639796733856,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.025155956111848354,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.17762736082077024,
      "backward_entropy": 0.04071337893605232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.886489713191986,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.025209279172122477,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.1775541921456655,
      "backward_entropy": 0.04067645817995071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7756442964076995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.025261824205517768,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17748083074887594,
      "backward_entropy": 0.038633085489273064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8313748776912688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.025313707813620568,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17740877866744995,
      "backward_entropy": 0.03992969006299972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7160447716712952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.025365000776946544,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17733809550603233,
      "backward_entropy": 0.040231921374797815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8303321421146392,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.025415629148483276,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.17726616859436034,
      "backward_entropy": 0.04118194967508316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7478298127651215,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.025465591996908187,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17719282905260722,
      "backward_entropy": 0.037807128578424457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7469715297222137,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025515059381723403,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17711917956670126,
      "backward_entropy": 0.03934851661324501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5987527966499329,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.025564051419496536,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17704491813977558,
      "backward_entropy": 0.03627670869231224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7279122948646546,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.025612445175647737,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1769708534081777,
      "backward_entropy": 0.034811892807483674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6328771233558654,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025660417415201663,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17689412633577983,
      "backward_entropy": 0.038060932755470275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6509011089801788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.025707748346030714,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17681511441866554,
      "backward_entropy": 0.03357135429978371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5324577271938324,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.025754686444997787,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.17673567136128743,
      "backward_entropy": 0.03652433201670646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.579465627670288,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.025801114924252033,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1766555150349935,
      "backward_entropy": 0.03293366014957429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5807720601558686,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.025847146473824977,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1765740116437276,
      "backward_entropy": 0.033877775520086285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4144944429397583,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02589268982410431,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17649072011311848,
      "backward_entropy": 0.036188671737909316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4415825009346008,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.025937564857304096,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1764068404833476,
      "backward_entropy": 0.03315828293561936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4547722429037093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.025981804914772512,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17632269263267517,
      "backward_entropy": 0.03213534817099571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4291176736354827,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026025544665753842,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17623702883720396,
      "backward_entropy": 0.033021344989538196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3628939032554626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.026068950071930885,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17614951729774472,
      "backward_entropy": 0.03394174575805664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3562659084796906,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.026111805625259877,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17606181403001148,
      "backward_entropy": 0.03074917539954185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3038766145706178,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026154127158224582,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17597487568855286,
      "backward_entropy": 0.032038076072931285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.337723621726036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026195903681218623,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1758872280518214,
      "backward_entropy": 0.032066847532987594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2669777929782868,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02623731903731823,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17579680879910786,
      "backward_entropy": 0.0311857570707798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.271266308426857,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.026278262585401536,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17570399145285293,
      "backward_entropy": 0.030185309797525407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0501278638839722,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026318654790520667,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17561070720354716,
      "backward_entropy": 0.029759895503520966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.074896977841854,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026358252763748168,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17551974356174468,
      "backward_entropy": 0.03228574171662331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1748403459787369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.026397121138870716,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1754289577404658,
      "backward_entropy": 0.0313523742556572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1490937769412994,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026435441337525845,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17533797224362693,
      "backward_entropy": 0.029404777586460113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0487954169511795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0264733012765646,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17524592677752177,
      "backward_entropy": 0.029204410314559937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1143286406993866,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026510515809059144,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17515283425649003,
      "backward_entropy": 0.028900863826274874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9721370905637741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026547310315072535,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1750589003165563,
      "backward_entropy": 0.029249403178691864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0482690572738647,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.026583510264754296,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.17496617237726847,
      "backward_entropy": 0.027813916504383092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9082187831401825,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.026619255356490613,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17487087845802304,
      "backward_entropy": 0.029208817631006245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8759881675243377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0266542699187994,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17477484146753947,
      "backward_entropy": 0.029891630858182906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9350310832262039,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026688629947602748,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17468003233273824,
      "backward_entropy": 0.026409585177898404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0011113852262497,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.026722414791584014,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1745843042929967,
      "backward_entropy": 0.027245333343744276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9235093027353287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02675600629299879,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1744860271612803,
      "backward_entropy": 0.026099688559770583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9319021046161652,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02678906377404928,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1743863642215729,
      "backward_entropy": 0.026567048728466037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.855632746219635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02682161144912243,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17428524295488995,
      "backward_entropy": 0.028609983325004577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8181493222713471,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026853526011109352,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.174183315038681,
      "backward_entropy": 0.02475284591317177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8562727451324463,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0268849216401577,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.17407952149709066,
      "backward_entropy": 0.024177935421466828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8516805395483971,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.026915894448757173,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1739747554063797,
      "backward_entropy": 0.026937635391950605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7763554230332375,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02694654166698456,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17386819521586103,
      "backward_entropy": 0.02450826480984688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7509099811315536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026976703479886056,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.173760583003362,
      "backward_entropy": 0.024141892194747924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7358907863497735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027006424590945245,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17365302046140035,
      "backward_entropy": 0.025094345360994343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.678094682097435,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02703568171709776,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17354570627212523,
      "backward_entropy": 0.023802584558725356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7707586362957954,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027064394019544125,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17343815863132478,
      "backward_entropy": 0.025092762410640717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7723143577575684,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.027092738263309,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.17332916061083475,
      "backward_entropy": 0.024192862063646316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6714612618088722,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027120832540094852,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1732185473044713,
      "backward_entropy": 0.024260147511959075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6722405940294266,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027148435078561305,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17310731013615926,
      "backward_entropy": 0.02291680797934532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6420606434345245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027175663225352763,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.17299560606479647,
      "backward_entropy": 0.023393645584583282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5582298845052719,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02720237597823143,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1728837420543035,
      "backward_entropy": 0.023216262310743332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6063590675592423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.027228458598256112,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17277365227540334,
      "backward_entropy": 0.023754660487174985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6832031309604645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.02725418470799923,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17266389727592468,
      "backward_entropy": 0.020386760756373405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5993475705385208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027279520966112615,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1725528617699941,
      "backward_entropy": 0.020808441340923307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6054757058620452,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027304363995790483,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1724402944246928,
      "backward_entropy": 0.021882294267416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5624437525868415,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027328881062567235,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17232603232065838,
      "backward_entropy": 0.022568778544664384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5564298644661904,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027353095635771752,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1722111622492472,
      "backward_entropy": 0.020794447287917135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5233482860028744,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02737678438425064,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.17209577858448027,
      "backward_entropy": 0.01892762169241905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4871014177799225,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027399986609816553,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17197914520899454,
      "backward_entropy": 0.021684254556894305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4525820344686508,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02742259092628956,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.17186248699824017,
      "backward_entropy": 0.019801423698663712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4761101439595222,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02744480166584253,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1717452307542165,
      "backward_entropy": 0.020890304893255236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.470645634829998,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.027466566301882267,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17162726521492003,
      "backward_entropy": 0.02102828189730644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47705675959587096,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02748790252953768,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.17150940497716266,
      "backward_entropy": 0.02034036561846733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4386079587042332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02750884983688593,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.171390970547994,
      "backward_entropy": 0.02003446772694588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4449846401810646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027529291249811648,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.17127201656500496,
      "backward_entropy": 0.019577795341610908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4068686686456203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027549470961093902,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1711534490187963,
      "backward_entropy": 0.01980020746588707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42536047995090487,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027569126710295676,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1710350513458252,
      "backward_entropy": 0.019399713426828384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3475153990089893,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02758832983672619,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17091699838638302,
      "backward_entropy": 0.018484255224466326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41111536547541616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027607179060578347,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.17079961001873017,
      "backward_entropy": 0.01880365639925003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40377330854535104,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027625728584825992,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1706818660100301,
      "backward_entropy": 0.019258227646350864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.423028989136219,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027643893845379353,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.17056310176849365,
      "backward_entropy": 0.01979556828737259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38499377146363256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02766186073422432,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.17044436732927962,
      "backward_entropy": 0.017147630155086517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35599358975887296,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0276795357465744,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1703243245681127,
      "backward_entropy": 0.017548833191394806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3411429926753044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027696787752211093,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.17020428280035654,
      "backward_entropy": 0.01880156643688679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3060974761843681,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.027713715843856335,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1700844486554464,
      "backward_entropy": 0.019990239441394803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29493173360824587,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027730197459459306,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16996503869692486,
      "backward_entropy": 0.01828123576939106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36345370188355447,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02774643898010254,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1698457837104797,
      "backward_entropy": 0.017237173020839693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31827547401189804,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02776245828717947,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.16972549657026928,
      "backward_entropy": 0.018641217797994613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2967723112553358,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027778229117393492,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16960538625717164,
      "backward_entropy": 0.01833451479673386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3045108214020729,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.027793708816170694,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1694852570692698,
      "backward_entropy": 0.018174887895584108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2791645348072052,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02780898455530405,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1693638245264689,
      "backward_entropy": 0.01716639183461666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33131723403930663,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027823863364756108,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16924269994099933,
      "backward_entropy": 0.018023659884929658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2967947948724031,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.027838574536144734,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1691205362478892,
      "backward_entropy": 0.018133633285760876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25990823581814765,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027853004448115826,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16899836758772532,
      "backward_entropy": 0.01757087573409081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2746767017990351,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027867279760539532,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16887671848138175,
      "backward_entropy": 0.017250010520219804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2725746549665928,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02788127101957798,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1687548150618871,
      "backward_entropy": 0.01788979098200798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24346248768270015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027895023673772813,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16863257487614952,
      "backward_entropy": 0.017456742078065874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22642555497586728,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027908547781407833,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16851230859756472,
      "backward_entropy": 0.01552383616566658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22385045513510704,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027921696193516254,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16839242080847422,
      "backward_entropy": 0.015694944635033604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22705451920628547,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027934486232697963,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16827219128608703,
      "backward_entropy": 0.017215738967061044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19999900199472903,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027946962788701058,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16815175712108613,
      "backward_entropy": 0.01713500328361988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23026718460023404,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02795921191573143,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16803151567777,
      "backward_entropy": 0.015631237104535102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18640491627156736,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027971184626221657,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16791115105152132,
      "backward_entropy": 0.01633786179125309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1808473702520132,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.027982809022068976,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16779291133085888,
      "backward_entropy": 0.015686384886503223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1807513389736414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02799415048211813,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16767532428105672,
      "backward_entropy": 0.017561784982681274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19227935262024404,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028005257062613965,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16755813956260682,
      "backward_entropy": 0.01728315144777298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1709537383168936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02801609691232443,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16744150320688883,
      "backward_entropy": 0.015873389840126036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1683474648743868,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028026599995791913,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1673260758320491,
      "backward_entropy": 0.01642142303287983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1649376068264246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0280368035659194,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16721133987108866,
      "backward_entropy": 0.016757653877139088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.154333758354187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028046788088977335,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16709652344385784,
      "backward_entropy": 0.014714981615543368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1877721067517996,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02805652730166912,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16698253055413564,
      "backward_entropy": 0.01699240505695343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16883423924446106,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028066270239651202,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16686771313349408,
      "backward_entropy": 0.016864375174045564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16269052401185036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028075782768428325,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1667531450589498,
      "backward_entropy": 0.014430241212248802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13302224595099688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028085066191852092,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16663893361886342,
      "backward_entropy": 0.01399104341864586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14447250068187714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02809412479400635,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16652516523996988,
      "backward_entropy": 0.015148250088095666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13016407303512095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.028103019669651987,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16641180912653605,
      "backward_entropy": 0.01608951024711132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10998012609779835,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02811169493943453,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.16629843513170878,
      "backward_entropy": 0.01526197463274002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13980801086872816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028120126761496066,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16618574559688568,
      "backward_entropy": 0.016468149200081824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1233776906505227,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028128422796726227,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1660720020532608,
      "backward_entropy": 0.014914797842502592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12361152954399586,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.028136580996215344,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.16595923801263174,
      "backward_entropy": 0.014400925859808922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11099118907004595,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028144634887576105,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16584695974985758,
      "backward_entropy": 0.016418026089668275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12187427058815956,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028152533620595933,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1657351781924566,
      "backward_entropy": 0.015267335772514342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11991774868220091,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028160262480378152,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16562370061874393,
      "backward_entropy": 0.016200397387146948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1257785080000758,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028167811408638953,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16551274259885151,
      "backward_entropy": 0.01528597578406334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11480541508644819,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028175184689462184,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16540213823318478,
      "backward_entropy": 0.01599694348871708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07872988972812892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028182440809905528,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16529244581858318,
      "backward_entropy": 0.01644963629543781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11083157639950514,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028189492225646973,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1651843458414078,
      "backward_entropy": 0.01398513950407505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09428629744797945,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02819641474634409,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16507680316766102,
      "backward_entropy": 0.013761394545435906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0876532431691885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.028203189186751843,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1649702121814092,
      "backward_entropy": 0.015960925817489625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08255361318588257,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02820976823568344,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16486425101757046,
      "backward_entropy": 0.014580226242542266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09565171264111996,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028216109611093998,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16475912630558015,
      "backward_entropy": 0.014203407838940621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08255864214152098,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028222349658608436,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16465436816215512,
      "backward_entropy": 0.015010407343506813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08723657540977,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028228457272052764,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16455023189385728,
      "backward_entropy": 0.01457347184419632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08147295182570816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028234447166323662,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16444640258948007,
      "backward_entropy": 0.015378069505095482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06995582953095436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028240341693162918,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.164343598484993,
      "backward_entropy": 0.01586259439587593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07114705685526132,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028246099688112737,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16424228847026826,
      "backward_entropy": 0.015376485064625741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07997006429359317,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028251750953495504,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1641415238380432,
      "backward_entropy": 0.01334517166018486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057116116397082806,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028257204778492452,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16404081384340924,
      "backward_entropy": 0.013379691913723948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06513679288327694,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028262442909181118,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16394167443116506,
      "backward_entropy": 0.014377504959702492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06723131882026792,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02826757412403822,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1638434092203776,
      "backward_entropy": 0.013672140091657639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07171510327607393,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028272596932947636,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16374533871809643,
      "backward_entropy": 0.015064142793416977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06599237024784088,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02827753033488989,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.16364692946275075,
      "backward_entropy": 0.013565467521548271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061554442066699265,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02828236799687147,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1635492960611979,
      "backward_entropy": 0.014260970279574394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.062048187106847764,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02828715890645981,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1634526272614797,
      "backward_entropy": 0.012933463603258134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05865380661562085,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02829194124788046,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16335629721482595,
      "backward_entropy": 0.014298399910330772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055858918372541665,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028296593017876147,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1632603307565053,
      "backward_entropy": 0.013630156144499781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04225763138383627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02830112222582102,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1631651331981023,
      "backward_entropy": 0.014031340628862382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05922085968777537,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028305482119321823,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.16307085851828257,
      "backward_entropy": 0.012314524203538894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04603770729154348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02830982320010662,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16297722955544788,
      "backward_entropy": 0.014447720497846603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04713961565867066,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028314043954014777,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16288453340530396,
      "backward_entropy": 0.013114260435104368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0566107215359807,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.028318131901323797,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.16279242535432178,
      "backward_entropy": 0.014129500463604927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04294309411197901,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028322095237672328,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16270053188006084,
      "backward_entropy": 0.014478821232914926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045100279385223985,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02832601387053728,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16261001129945118,
      "backward_entropy": 0.013550318852066992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04401771421544254,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028329885564744473,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.16252010961373647,
      "backward_entropy": 0.013394630402326585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03364591267891228,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02833368945866823,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1624312887589137,
      "backward_entropy": 0.014487433806061744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03506426806561649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028337321989238263,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16234329442183176,
      "backward_entropy": 0.013932721391320227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048130643693730234,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028340847603976725,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16225618819395698,
      "backward_entropy": 0.014730793312191962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046694870200008155,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028344389237463474,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.16216941078503924,
      "backward_entropy": 0.014211988225579262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03886345052160323,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028347855433821678,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16208335955937703,
      "backward_entropy": 0.01443934164941311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026575922733172774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028351237066090107,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1619981110095978,
      "backward_entropy": 0.012913460582494735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03993401941843331,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028354474902153017,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1619143078724543,
      "backward_entropy": 0.013308273553848265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035386642022058365,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028357711061835288,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1618309885263443,
      "backward_entropy": 0.012772444412112236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024180150497704743,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028360904566943644,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1617484857638677,
      "backward_entropy": 0.013163886293768884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03504501823335886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028364005871117114,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16166707972685496,
      "backward_entropy": 0.01286181256175041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02489834576845169,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028367029316723347,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16158684492111205,
      "backward_entropy": 0.013458944782614706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029484981624409556,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02836995106190443,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1615075806776683,
      "backward_entropy": 0.012956748604774476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03536489570979029,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02837279476225376,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.16142900188763937,
      "backward_entropy": 0.012464821487665177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030417975620366633,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028375648893415928,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1613512466351191,
      "backward_entropy": 0.013280127346515657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031248398264870046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02837844528257847,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16127439439296723,
      "backward_entropy": 0.013840409293770792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026244707638397813,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02838118690997362,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1611983338991801,
      "backward_entropy": 0.0120218675583601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02857899824157357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028383865766227246,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16112320919831594,
      "backward_entropy": 0.0132731581479311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027124426211230457,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028386487066745757,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16104871730009715,
      "backward_entropy": 0.014783505648374556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022359508625231683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02838907763361931,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16097488701343537,
      "backward_entropy": 0.01232446253299713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022048023948445915,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.028391643799841403,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16090220510959624,
      "backward_entropy": 0.013491741716861724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024957946292124687,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02839418351650238,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1608310669660568,
      "backward_entropy": 0.012738515362143519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02374650670681149,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02839668281376362,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16076088746388753,
      "backward_entropy": 0.012550569102168082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026438391534611583,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02839912921190262,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1606916278600693,
      "backward_entropy": 0.011528576239943505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017186183715239167,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02840154990553856,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16062332093715667,
      "backward_entropy": 0.013207519575953484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021582450671121477,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028403871692717075,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16055587430795032,
      "backward_entropy": 0.01326211594045162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02222446762025356,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028406178578734398,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.16048873762289687,
      "backward_entropy": 0.013874654993414878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012128605879843235,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02840845678001642,
      "trajectory_length": 7.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.16042231420675915,
      "backward_entropy": 0.01197537802159786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017273779190145434,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028410589322447777,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16035715341567994,
      "backward_entropy": 0.01260625883936882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018743554968386887,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028412661515176296,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.16029298802216846,
      "backward_entropy": 0.011943710744380952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013481426145881414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028414752520620822,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1602297176917394,
      "backward_entropy": 0.01413317933678627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017628093215171246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028416763804852963,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.16016736626625064,
      "backward_entropy": 0.011538901627063752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017877527105156332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0284187413752079,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.16010554333527885,
      "backward_entropy": 0.012636525034904478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014878312929067761,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02842070199549198,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.16004426777362826,
      "backward_entropy": 0.01404811017215252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014183300454169512,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028422622941434383,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15998421708742777,
      "backward_entropy": 0.013020485341548921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013955453166272492,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028424487821757792,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1599251280228297,
      "backward_entropy": 0.011105332151055336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018596304825041442,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.028426305018365385,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15986703137556713,
      "backward_entropy": 0.011587259247899056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013615630043204874,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028428141213953494,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15980926056702932,
      "backward_entropy": 0.013300902098417283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014023718197131529,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02842996586114168,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15975223978360495,
      "backward_entropy": 0.013150738328695297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013908757350873203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028431786969304085,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15969587961832682,
      "backward_entropy": 0.01317020684480667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011446670669829472,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028433571010828017,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15963976085186002,
      "backward_entropy": 0.012197725549340248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012812031235080212,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02843530271202326,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15958456297715504,
      "backward_entropy": 0.01302369751036167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011881767178419978,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028436983376741408,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15952975153923035,
      "backward_entropy": 0.012610021531581878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009357266366714611,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028438629023730753,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15947564840316772,
      "backward_entropy": 0.01309345528483391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010185083228861913,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028440219163894654,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15942232410113016,
      "backward_entropy": 0.011504456102848053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01163689983659424,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02844177894294262,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1593696971734365,
      "backward_entropy": 0.011731628850102425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010212000476894901,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02844332978129387,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15931776265303293,
      "backward_entropy": 0.013639496713876726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009816477523418143,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02844480574131012,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15926642318566642,
      "backward_entropy": 0.011993024200201033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008958789781900123,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028446247056126594,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15921553472677868,
      "backward_entropy": 0.013738430440425876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009555588610237465,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0284476263448596,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15916536251703897,
      "backward_entropy": 0.012214709892868996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007613706652773544,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028448983281850814,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1591158996025721,
      "backward_entropy": 0.014435797706246376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006703889393247664,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02845027968287468,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15906733870506287,
      "backward_entropy": 0.012475822269916535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008717268021428026,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02845149263739586,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15901938875516258,
      "backward_entropy": 0.013846765980124473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0070417133276350794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028452705591917038,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15897208352883657,
      "backward_entropy": 0.01149777188897133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008815410145325586,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028453876636922358,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1589255561431249,
      "backward_entropy": 0.012694326937198639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008976209192769601,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02845507636666298,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.15887973109881082,
      "backward_entropy": 0.013570590466260912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007802235381677747,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02845627088099718,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1588342080513636,
      "backward_entropy": 0.01427163399755955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007481063145678491,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028457434847950935,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15878939827283226,
      "backward_entropy": 0.0136541885137558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005935017202864401,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028458563983440398,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15874521434307098,
      "backward_entropy": 0.011743595823645593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057719390111742545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02845965065062046,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15870183507601418,
      "backward_entropy": 0.013043589591979982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006973163323709741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028460686281323432,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15865909556547803,
      "backward_entropy": 0.012673924043774603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006105259503237903,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028461694531142712,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15861696501572928,
      "backward_entropy": 0.013211122527718545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006050830267486163,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028462707065045834,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15857547720273335,
      "backward_entropy": 0.013458816036581991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006017007617629133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02846367619931698,
      "trajectory_length": 7.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.15853453278541565,
      "backward_entropy": 0.013088160529732704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005910046261851676,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028464579209685325,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15849407116572062,
      "backward_entropy": 0.012828330993652343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00536069568770472,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028465459123253822,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15845431486765543,
      "backward_entropy": 0.013106955215334892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005361650174017995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02846632581204176,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1584152708450953,
      "backward_entropy": 0.012099559456110002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004968938056845218,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028467173501849175,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.1583768586317698,
      "backward_entropy": 0.01176544561982155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005747692807926796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02846802193671465,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15833890438079834,
      "backward_entropy": 0.012900523841381073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005732354322390165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02846886832267046,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15830129285653433,
      "backward_entropy": 0.013135470002889633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003951342063373886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0284697238355875,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15826409260431926,
      "backward_entropy": 0.012076581045985222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004359783635300119,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02847053799778223,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1582275728384654,
      "backward_entropy": 0.012908460497856138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005455673132382799,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028471332602202894,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15819170276323952,
      "backward_entropy": 0.011946130916476248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00460133087617578,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02847211081534624,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15815604229768115,
      "backward_entropy": 0.012381071671843527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003079872670059558,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02847287654876709,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15812103748321532,
      "backward_entropy": 0.013775289207696915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004780508037947584,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028473597951233387,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15808664262294772,
      "backward_entropy": 0.012515770494937897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003799417409754824,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028474315628409387,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1580527146657308,
      "backward_entropy": 0.01310740031301975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034758636218612084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028474996984004974,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15801943639914195,
      "backward_entropy": 0.01089385561645031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003572907770285383,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02847565747797489,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15798668960730236,
      "backward_entropy": 0.012774842530488967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036615566721593497,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028476315177977087,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15795447826385497,
      "backward_entropy": 0.012673136666417121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004353682447253959,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028476962074637412,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15792286992073057,
      "backward_entropy": 0.011528262421488763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003226212465233402,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.028477620892226697,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15789168278376262,
      "backward_entropy": 0.013666673228144646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038903990971448366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.028478273563086985,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15786110758781435,
      "backward_entropy": 0.01301430769264698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00295644808356883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.02847890667617321,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15783071021238965,
      "backward_entropy": 0.011014693602919578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026238111735437998,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02847951278090477,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1578009327252706,
      "backward_entropy": 0.011398425474762917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002523521638067905,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02848009914159775,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15777175923188527,
      "backward_entropy": 0.012393727824091911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029619260400068014,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028480673022568227,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1577431837717692,
      "backward_entropy": 0.012918464094400405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002705024705210235,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028481213562190532,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15771492520968117,
      "backward_entropy": 0.011017390415072442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029983116444782356,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028481733798980714,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15768684645493825,
      "backward_entropy": 0.013278244733810427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003176614292169688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028482252173125742,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15765922764937085,
      "backward_entropy": 0.012600347548723221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002421720840357011,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028482796624302864,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15763189295927682,
      "backward_entropy": 0.013045900166034699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028236988931894303,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028483314625918865,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15760502219200132,
      "backward_entropy": 0.012781723216176034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018273553130711661,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028483841568231583,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15757867097854614,
      "backward_entropy": 0.0134221151471138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024267927881737707,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028484337963163853,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1575528085231781,
      "backward_entropy": 0.01202798292040825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021831935831869488,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02848482672125101,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15752724309762317,
      "backward_entropy": 0.011695228815078736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016385037772124634,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.028485306538641453,
      "trajectory_length": 7.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.15750206311543785,
      "backward_entropy": 0.011250483244657519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017739536546287128,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.028485777042806148,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.15747761030991872,
      "backward_entropy": 0.01462116062641144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023790000141161727,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02848623152822256,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15745366513729092,
      "backward_entropy": 0.011749616786837575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002361102290888084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.028486694023013116,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15742998123168944,
      "backward_entropy": 0.012920312508940695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017231295099918499,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.028487144224345683,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15740640262762703,
      "backward_entropy": 0.01252562291920185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002183585169404978,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028487580083310603,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15738311310609182,
      "backward_entropy": 0.012965772002935411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015770157129736616,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028488028980791568,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15736011962095897,
      "backward_entropy": 0.011738677620887756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016541420056455536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02848845236003399,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15733755429585777,
      "backward_entropy": 0.012212052419781684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018104909220710396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.028488876298069954,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.15731540819009143,
      "backward_entropy": 0.013847192674875258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016183744044610648,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028489307314157487,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15729365547498067,
      "backward_entropy": 0.012016068771481514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011443445851909927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0284897331148386,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15727235575517018,
      "backward_entropy": 0.011896776854991914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014467214297837927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.028490132838487624,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15725144743919375,
      "backward_entropy": 0.011579080596566201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018030786772214925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028490528464317322,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15723089178403218,
      "backward_entropy": 0.013146405667066574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013215549928645488,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028490928187966346,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15721052289009094,
      "backward_entropy": 0.012428338974714279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017545347835039137,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028491329587996005,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15719055533409118,
      "backward_entropy": 0.011794650107622148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012427530460627167,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028491736948490144,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1571706940730413,
      "backward_entropy": 0.012484923228621483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010341772713218234,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02849212195724249,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15715114971001945,
      "backward_entropy": 0.011442298963665961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001192788086245855,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02849250063300133,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15713214576244355,
      "backward_entropy": 0.012775507792830468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010659129520718125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028492870181798934,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15711345076560973,
      "backward_entropy": 0.012120471820235252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009300891913881059,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028493236005306243,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1570951998233795,
      "backward_entropy": 0.01234832838177681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012530752458587812,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02849358357489109,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15707735518614452,
      "backward_entropy": 0.011793554201722144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011425820838667279,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02849392555654049,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15705965956052145,
      "backward_entropy": 0.013379029631614683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008650038664200111,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028494256734848022,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15704215466976165,
      "backward_entropy": 0.012099563926458359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009361505162814865,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02849457450211048,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15702500939369202,
      "backward_entropy": 0.012955842316150665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008965348974015796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02849489115178585,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1570081392923991,
      "backward_entropy": 0.012589676976203917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009883889600132533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028495198488235472,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1569915960232417,
      "backward_entropy": 0.013122130557894707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000750133876408654,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02849550675600767,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15697530806064605,
      "backward_entropy": 0.012401337176561356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007112700977813802,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02849581129848957,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15695946911970776,
      "backward_entropy": 0.011297508627176286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006907994602443068,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028496102429926395,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15694395800431568,
      "backward_entropy": 0.011699345484375952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00091813533763343,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028496374003589155,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15692879458268486,
      "backward_entropy": 0.011850212439894677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007737121465652308,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02849664893001318,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15691379706064862,
      "backward_entropy": 0.012225390374660493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006850090569969324,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028496928699314594,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15689912339051565,
      "backward_entropy": 0.012093618661165238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006219178210358223,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028497204929590226,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15688473979632062,
      "backward_entropy": 0.01134058751165867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007229380695662257,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028497461602091788,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15687059064706166,
      "backward_entropy": 0.012117348983883858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006936524863249361,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.028497717715799807,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15685670475165048,
      "backward_entropy": 0.011679315268993379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006849895661616756,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028497968800365925,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15684301753838853,
      "backward_entropy": 0.012814464792609215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006610293689391256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028498219698667525,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15682952404022216,
      "backward_entropy": 0.013101810961961747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047736480801177097,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028498468920588493,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1568162461121877,
      "backward_entropy": 0.013655344620347024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005274269283290778,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028498709574341773,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15680329799652098,
      "backward_entropy": 0.011717563718557356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006000373424740246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02849894091486931,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1567905843257904,
      "backward_entropy": 0.012866989895701408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004102550647530734,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028499172627925874,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15677805046240487,
      "backward_entropy": 0.012858723104000092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042841519857574897,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028499390929937363,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15676584045092262,
      "backward_entropy": 0.012550619915127754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005350147350327461,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028499596007168292,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15675382912158967,
      "backward_entropy": 0.012932269275188446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044741358715327806,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.028499804995954038,
      "trajectory_length": 7.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.15674205720424653,
      "backward_entropy": 0.010998938381671906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037723546486176927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028500007279217244,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15673052072525026,
      "backward_entropy": 0.011056632325053216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039487233293584724,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.028500204719603062,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15671926140785217,
      "backward_entropy": 0.011815956011414528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003737244624971936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028500400111079217,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15670826236406962,
      "backward_entropy": 0.011848784238100053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030981256763880084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028500586934387683,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1566974898179372,
      "backward_entropy": 0.012041456028819085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040004786137615156,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028500765934586524,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15668699940045674,
      "backward_entropy": 0.010987839922308921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029476120732851996,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028500942140817644,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15667669475078583,
      "backward_entropy": 0.01136517122387886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000386035154633646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028501110337674617,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1566666394472122,
      "backward_entropy": 0.010999158397316933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000247604395349299,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028501277044415473,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15665672918160756,
      "backward_entropy": 0.01300622582435608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034460955159829607,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028501430153846742,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1566470851500829,
      "backward_entropy": 0.012181494683027266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029781872710827885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02850157581269741,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15663757026195527,
      "backward_entropy": 0.01141732431948185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002454877743389261,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02850171457976103,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15662819842497508,
      "backward_entropy": 0.013590828478336333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022796031162215514,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02850184924900532,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1566191057364146,
      "backward_entropy": 0.011539565324783325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002563696341780997,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028501973301172257,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15661020278930662,
      "backward_entropy": 0.012262134328484536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002521078003610455,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028502094373106957,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.156601494550705,
      "backward_entropy": 0.012407799810171127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002069369626383377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02850221674889326,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15659298698107402,
      "backward_entropy": 0.011945643350481986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023355916858918134,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028502342663705348,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15658470193545024,
      "backward_entropy": 0.011454836726188659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002044134636776107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028502468205988406,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15657657186190288,
      "backward_entropy": 0.01181779958307743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002135335514367398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028502591140568256,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15656865040461224,
      "backward_entropy": 0.011970250234007837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020394208386278478,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02850270736962557,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15656087299187976,
      "backward_entropy": 0.011899987757205962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022186630828855414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028502822481095792,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15655326942602793,
      "backward_entropy": 0.012202157229185103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017373473219777224,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028502938337624073,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1565457791090012,
      "backward_entropy": 0.011571046113967896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019836109336779373,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028503047302365303,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15653842588265737,
      "backward_entropy": 0.012474374622106552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001792800432895092,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02850315608084202,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15653121272722884,
      "backward_entropy": 0.011343990042805672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018910222073031946,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.028503262996673585,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1565241316954295,
      "backward_entropy": 0.011253909096121787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014074947401923054,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02850337103009224,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15651716987291972,
      "backward_entropy": 0.012072135806083678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018052369224506038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850347775965929,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15651040573914848,
      "backward_entropy": 0.012250402569770813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001391614899318938,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028503585793077945,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15650375386079152,
      "backward_entropy": 0.011515821814537048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014942904611530138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028503690101206302,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15649726589520774,
      "backward_entropy": 0.012451694011688233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.52590206622972e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028503797389566897,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15649093687534335,
      "backward_entropy": 0.01429739072918892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011169159656105876,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028503896482288838,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15648477574189507,
      "backward_entropy": 0.01147055745124817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012030266667295564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028503990545868874,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15647874375184376,
      "backward_entropy": 0.012190791368484496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011742688032825299,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.028504086285829545,
      "trajectory_length": 7.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1564728707075119,
      "backward_entropy": 0.014902051836252211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011505752225673404,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028504179790616035,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1564671128988266,
      "backward_entropy": 0.012444199696183204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001067953039665781,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028504268266260624,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15646145045757293,
      "backward_entropy": 0.010969900265336037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.201509091032676e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028504353761672974,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15645587742328643,
      "backward_entropy": 0.011577461063861847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912959487190619e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02850443050265312,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1564505040645599,
      "backward_entropy": 0.012763597890734673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.243811858505978e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02850450612604618,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15644525587558747,
      "backward_entropy": 0.011905114650726318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145638404357669e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02850457765161991,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1564401348431905,
      "backward_entropy": 0.011537474766373634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.159306245261177e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028504645638167857,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15643512507279714,
      "backward_entropy": 0.012801775783300398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517828238121638e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02850471492856741,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15643022855122884,
      "backward_entropy": 0.01156158857047558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.749792949771517e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02850478086620569,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15642545918623607,
      "backward_entropy": 0.010964749306440353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.649205667628167e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02850484736263752,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15642076532046,
      "backward_entropy": 0.01305728368461132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.625825742219149e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028504912741482258,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15641617874304453,
      "backward_entropy": 0.013256508111953735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9742450456212734e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028504975885152817,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15641171137491863,
      "backward_entropy": 0.010677331909537315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100590246977845e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028505037352442742,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15640735228856406,
      "backward_entropy": 0.012123437151312828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0332666404860905e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028505098819732667,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.1564030756553014,
      "backward_entropy": 0.01138218857347965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.404366007757289e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.02850516177713871,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15639891326427457,
      "backward_entropy": 0.014286132976412774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.652380586056438e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028505223616957665,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15639483829339346,
      "backward_entropy": 0.012562985047698021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.090473900006941e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.028505283407866955,
      "trajectory_length": 7.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.1563908447821935,
      "backward_entropy": 0.010369344353675843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.803325640414414e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028505336865782736,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15638695061206817,
      "backward_entropy": 0.012018325105309485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.375889015373445e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02850539181381464,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15638312896092732,
      "backward_entropy": 0.011619004085659981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5361858606772785e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02850544359534979,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1563794453938802,
      "backward_entropy": 0.011754260212183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.358134077582122e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02850549593567848,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15637581845124565,
      "backward_entropy": 0.01157731495797634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.347615233693091e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028505550883710384,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15637225906054178,
      "backward_entropy": 0.012554976716637611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0734907594574e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028505601175129413,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15636880298455555,
      "backward_entropy": 0.011797815710306168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.697210987994026e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028505653701722623,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15636540253957115,
      "backward_entropy": 0.01254221223294735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.736946882568759e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850570473819971,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15636209547519683,
      "backward_entropy": 0.011630351841449737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6759712403622305e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028505754098296164,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15635885000228883,
      "backward_entropy": 0.01297879830002785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.759300215300243e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.028505800291895866,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15635566413402555,
      "backward_entropy": 0.011725649535655976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.68617090931167e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028505844809114934,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15635253290335338,
      "backward_entropy": 0.011824315637350081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.570954469793719e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02850589044392109,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15634946127732594,
      "backward_entropy": 0.011363962963223458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.52770279022252e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02850593701004982,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15634646018346152,
      "backward_entropy": 0.011820866167545319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4935511959611746e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02850598469376564,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1563435117403666,
      "backward_entropy": 0.011526164263486863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.534984664350759e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02850603051483631,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15634066065152488,
      "backward_entropy": 0.013476458415389062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.694368114326551e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028506072983145715,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1563378731409709,
      "backward_entropy": 0.011477706134319306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9494660083552162e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02850611638277769,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15633514920870464,
      "backward_entropy": 0.012349071726202965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3045042024172347e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028506155870854855,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15633251865704853,
      "backward_entropy": 0.01311947800219059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.051538582392709e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028506194613873957,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1563299576441447,
      "backward_entropy": 0.012508774921298028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6879498373967294e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02850622981786728,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15632745027542114,
      "backward_entropy": 0.011315462589263917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2034165166928687e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02850626166909933,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15632500847180683,
      "backward_entropy": 0.011940854042768479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.656059435450885e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.02850629426538944,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15632262130578362,
      "backward_entropy": 0.012530323415994643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0302741401145852e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.02850632518529892,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15632030367851255,
      "backward_entropy": 0.01190698429942131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.851042569072092e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.028506356291472912,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1563180257876714,
      "backward_entropy": 0.012865743562579158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3548210249325621e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0285063860937953,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1563157916069031,
      "backward_entropy": 0.013088496401906013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4304723995195446e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028506413847208024,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15631363689899444,
      "backward_entropy": 0.012520945668220521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3744755734990122e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028506441228091716,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15631154278914133,
      "backward_entropy": 0.0124085433781147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4372122696926226e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02850646749138832,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15630950530370075,
      "backward_entropy": 0.012299637123942374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1375313648187557e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02850649431347847,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15630751252174377,
      "backward_entropy": 0.012894591987133028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0884110817599435e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028506519645452498,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15630557239055634,
      "backward_entropy": 0.012197878882288933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5189390855141482e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.028506542555987835,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15630369385083517,
      "backward_entropy": 0.011016418114304543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.846247046889744e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028506566770374775,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1563018480936686,
      "backward_entropy": 0.011618834137916565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0132226167769431e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028506589494645594,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15630005995432536,
      "backward_entropy": 0.013924381062388419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1573500485440036e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02850661091506481,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1562983194986979,
      "backward_entropy": 0.012863319069147111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.125064060455657e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.028506631962954998,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15629660785198213,
      "backward_entropy": 0.012762371748685835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0102744987960931e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02850665245205164,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15629495084285736,
      "backward_entropy": 0.011015736088156699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.833098409903982e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028506673499941827,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15629333357016245,
      "backward_entropy": 0.012248851358890533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.842834880733563e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028506693430244923,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15629176596800487,
      "backward_entropy": 0.01181015484035015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.078474023280989e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028506712056696415,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15629023512204487,
      "backward_entropy": 0.012129943445324897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246996216281332e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02850673012435436,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15628874599933623,
      "backward_entropy": 0.0114652481675148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4081825879469536e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028506748378276825,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15628730356693268,
      "backward_entropy": 0.012917609885334969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922231139545488e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028506765700876714,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1562859078248342,
      "backward_entropy": 0.013075871542096138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100273139215574e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028506783396005632,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562845339377721,
      "backward_entropy": 0.012499907314777374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.240301584232611e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028506800904870032,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15628318687280018,
      "backward_entropy": 0.012068016231060028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.85549558604248e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.028506818413734435,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562818686167399,
      "backward_entropy": 0.011236184686422348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.594733112168626e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028506834618747236,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.15628059009710946,
      "backward_entropy": 0.010939530804753303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9962245085642966e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028506849892437458,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15627934535344443,
      "backward_entropy": 0.011206982582807539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.62064540585061e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.028506864979863166,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15627812147140502,
      "backward_entropy": 0.01360793150961399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.556424362434086e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028506878949701785,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15627692143122354,
      "backward_entropy": 0.012811144515872003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.216502899330066e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028506892547011376,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15627575516700745,
      "backward_entropy": 0.013586879670619964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.74812284991799e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028506907075643538,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15627461373805998,
      "backward_entropy": 0.01203359641134739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5214626539215033e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028506921231746675,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15627350211143493,
      "backward_entropy": 0.011381131038069725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.755904999991344e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028506934642791748,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15627241333325706,
      "backward_entropy": 0.011675099879503251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6229410874000225e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028506947681307793,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.156271364291509,
      "backward_entropy": 0.011622569039463997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1301212278123104e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028506959229707717,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15627033909161886,
      "backward_entropy": 0.011035522297024727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.902083618394613e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028506970778107644,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15626935064792633,
      "backward_entropy": 0.011607113406062127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.887721031541446e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02850698120892048,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1562683830658595,
      "backward_entropy": 0.01228979729115963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869356391954625e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028506990894675253,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.156267445286115,
      "backward_entropy": 0.012258084192872049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869307066966087e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850699983537197,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562665194272995,
      "backward_entropy": 0.011906580552458764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3286337146544157e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02850700858980417,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15626562337080635,
      "backward_entropy": 0.013948947712779044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.917297153752884e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.028507016599178314,
      "trajectory_length": 7.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.15626474618911745,
      "backward_entropy": 0.012507599592208863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.516018341935933e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.028507022745907308,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.1562638988097509,
      "backward_entropy": 0.01192441999912262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2150050890346052e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0285070288926363,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15626307030518852,
      "backward_entropy": 0.012998324260115624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.100812439742583e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.028507034294307232,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15626225570837654,
      "backward_entropy": 0.011125311776995658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1407792576866315e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02850703913718462,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15626146296660107,
      "backward_entropy": 0.012732383310794829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.904198893853959e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02850704435259104,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15626069009304047,
      "backward_entropy": 0.013106016218662262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.914615070219838e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028507050126791,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15625994006792704,
      "backward_entropy": 0.012249232903122902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8240506783229193e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028507055528461934,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15625920494397483,
      "backward_entropy": 0.012008397653698922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3898614078300397e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.028507061302661896,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.156258491675059,
      "backward_entropy": 0.011053574606776237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5054019527838137e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028507066331803797,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15625779926776884,
      "backward_entropy": 0.011631080806255339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.049129183883224e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02850707173347473,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1562571237484614,
      "backward_entropy": 0.011351192370057106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2647896157957915e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02850707620382309,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1562564800182978,
      "backward_entropy": 0.013096179366111755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1790454173876696e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028507080487906934,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15625585218270616,
      "backward_entropy": 0.012372783571481704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.315727191553151e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.028507084213197233,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1562552442153295,
      "backward_entropy": 0.012450459152460099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1704715127791588e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028507088124752045,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1562546521425247,
      "backward_entropy": 0.01151778094470501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1596739646790865e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028507092036306858,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15625407298405966,
      "backward_entropy": 0.012140433043241503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1762421449290628e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028507096506655217,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15625351170698804,
      "backward_entropy": 0.012251411303877831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0210243850394818e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028507100790739058,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1562529633442561,
      "backward_entropy": 0.011609350368380547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616271639283468e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.028507105074822903,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15625242292881014,
      "backward_entropy": 0.013076042979955673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.052437078021058e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028507109358906747,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.15625190834204358,
      "backward_entropy": 0.012698134258389473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.077431873308115e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028507112711668014,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1562513987223307,
      "backward_entropy": 0.013102399930357934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.356858831604086e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.028507115691900252,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.1562509179115295,
      "backward_entropy": 0.011951216608285901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.244062343758628e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.028507119044661522,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15625044405460356,
      "backward_entropy": 0.012202793285250663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.862417724879833e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02850712202489376,
      "trajectory_length": 7.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.1562499831120173,
      "backward_entropy": 0.011018871143460274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.302930567831823e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02850712537765503,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15624954203764596,
      "backward_entropy": 0.01207077406346798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.215675629306361e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028507128730416297,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15624910096327466,
      "backward_entropy": 0.012549812048673628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.321849261998637e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028507131710648538,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15624867677688598,
      "backward_entropy": 0.012436153814196587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7572843921983574e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850713524967432,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562482585509618,
      "backward_entropy": 0.012582366690039634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.985432519395317e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850713822990656,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15624785323937734,
      "backward_entropy": 0.012538872435688972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.605407313424849e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.028507141582667827,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.15624746282895408,
      "backward_entropy": 0.013492188006639483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.99407493950821e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02850714512169361,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562470813592275,
      "backward_entropy": 0.012865069583058355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.751705030197172e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02850714847445488,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.15624670883019767,
      "backward_entropy": 0.012655287384986877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.854921135333256e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.028507151640951633,
      "trajectory_length": 7.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.156246347228686,
      "backward_entropy": 0.01232828862965107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.78411521523492e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028507154807448386,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15624599357446034,
      "backward_entropy": 0.012859255075454712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5944338236125757e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02850715834647417,
      "trajectory_length": 7.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.15624564687410988,
      "backward_entropy": 0.011559770628809928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.60245446806573e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028507162258028983,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1562453101078669,
      "backward_entropy": 0.012029955238103865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8174884533503926e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0285071661695838,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.15624498526255287,
      "backward_entropy": 0.013488997220993042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.28822617490232e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02850717008113861,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562446693579356,
      "backward_entropy": 0.012300026267766953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.292835625501311e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02850717380642891,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.15624436040719353,
      "backward_entropy": 0.013106647133827209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7724880276025486e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.028507176972925662,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.15624405841032663,
      "backward_entropy": 0.01327609583735466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6179475600685007e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.028507180139422418,
      "trajectory_length": 7.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.156243771314621,
      "backward_entropy": 0.01130754955112934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0226385092646526e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028507183119654656,
      "trajectory_length": 7.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.15624349017937977,
      "backward_entropy": 0.01325769357383251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3524542687169968e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028507186099886894,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562432140111923,
      "backward_entropy": 0.011639337092638015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.572355366936563e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028507189080119132,
      "trajectory_length": 7.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1562429517507553,
      "backward_entropy": 0.013420523107051848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3660008885428851e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.028507192246615888,
      "trajectory_length": 7.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1562426914771398,
      "backward_entropy": 0.012929605022072794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1066469546582312e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02850719541311264,
      "trajectory_length": 7.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.15624244809150695,
      "backward_entropy": 0.011839033514261245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3734297300848083e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.028507198207080364,
      "trajectory_length": 7.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1562421977519989,
      "backward_entropy": 0.013075448498129846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2010568603292314e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.028507201001048088,
      "trajectory_length": 7.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.15624196032683055,
      "backward_entropy": 0.01248452328145504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9467109275694837e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.028507203981280326,
      "trajectory_length": 7.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1562417298555374,
      "backward_entropy": 0.013249590471386907,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.887944677702151e-06,
    "avg_log_Z": 0.028506834108382468,
    "success_rate": 1.0,
    "avg_reward": 45.589999999999996,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.156,
      "1": 0.30100000000000005,
      "2": 0.543
    },
    "avg_forward_entropy": 0.15627662456035613,
    "avg_backward_entropy": 0.01229243921339512,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}