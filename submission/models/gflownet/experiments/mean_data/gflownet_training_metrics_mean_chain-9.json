{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07686650156974792,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07686299747890898,
      "exploration_ratio": 0.6578947368421051
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07682607306374444,
      "exploration_ratio": 0.7368421052631577
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687349716822307,
      "exploration_ratio": 0.8157894736842106
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685501443015204,
      "exploration_ratio": 0.8421052631578949
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07686318622695075,
      "exploration_ratio": 0.9210526315789475
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685518463452659,
      "exploration_ratio": 0.9736842105263157
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07684013512399461,
      "exploration_ratio": 0.9736842105263157
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 14.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.0768541607591841,
      "exploration_ratio": 0.9736842105263157
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687430712911818,
      "exploration_ratio": 0.9736842105263157
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685706019401549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685245805316501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685678998629251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687532504399616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687900198830498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685193750593397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07688094311290317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687601182195875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07683600982030234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685136795043944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07689486145973205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685942186249625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687051230006746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07683916754192775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07685771584510803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687805493672688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687357465426128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07688127954800923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07689578003353544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07684062123298645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07687635951571994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970520830154419,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1096884822845459,
      "backward_entropy": 0.07684164841969807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848982191085815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.00010000000111176632,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1096893584728241,
      "backward_entropy": 0.0768277108669281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8467426776886,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00019997691706521436,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10968978285789491,
      "backward_entropy": 0.07687283423211841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.846437072753906,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0002999464748427272,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1096899902820587,
      "backward_entropy": 0.07688610752423604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778621864318847,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00039991677040234207,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10969007730484008,
      "backward_entropy": 0.07681362827618918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823889350891113,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0004998676711693406,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10969028592109682,
      "backward_entropy": 0.07687769068611992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954082775115968,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0005998202075716108,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10969046711921693,
      "backward_entropy": 0.07683895627657572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.939580202102661,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0006998069817200303,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10969062089920043,
      "backward_entropy": 0.0768095288011763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.822715234756469,
      "terminal_state_reached": 1.0,
      "terminal_reward": 18.0,
      "log_Z": 0.0007998184009920806,
      "trajectory_length": 11.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.10969062209129332,
      "backward_entropy": 0.07682781550619337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770980739593506,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0008998058387078345,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10969064354896545,
      "backward_entropy": 0.07681963708665637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683368444442749,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0009997521177865566,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10969052076339722,
      "backward_entropy": 0.07684533198674519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901521492004395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0010996558354236185,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10969029664993286,
      "backward_entropy": 0.07679147985246446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778398942947387,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0011995911365374923,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10969012260437012,
      "backward_entropy": 0.07677740454673768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.852209615707398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.001299512037076056,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10968986988067626,
      "backward_entropy": 0.07676036490334406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713835382461548,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0013994344975799323,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10968952298164367,
      "backward_entropy": 0.07676763600773281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91746735572815,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0014993279473856091,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1096892213821411,
      "backward_entropy": 0.07676660550965203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.940750455856323,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0015992642496712507,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10968891143798828,
      "backward_entropy": 0.07678693268034194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930184412002564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.001699249551165849,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10968855500221253,
      "backward_entropy": 0.07674725585513645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.634552001953125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.001799269171897322,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1096881377696991,
      "backward_entropy": 0.07675054338243273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42685170173645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.001899211434647441,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10968740820884704,
      "backward_entropy": 0.07677591178152296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.680567455291747,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0019990033470094204,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10968653678894043,
      "backward_entropy": 0.07675423555903965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713604545593261,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0020987698575481773,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1096857249736786,
      "backward_entropy": 0.07673026323318483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.108840084075927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0021985281957313417,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10968480467796324,
      "backward_entropy": 0.07671743167771233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.87115936279297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0022984257899224757,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10968395113945009,
      "backward_entropy": 0.07668573061625164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.862313556671143,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0023983463179320097,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10968315839767458,
      "backward_entropy": 0.07670022977723015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.896350479125976,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0024982862407341598,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10968206882476808,
      "backward_entropy": 0.07670967049068875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.976375627517701,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.002598268631845713,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10968101143836975,
      "backward_entropy": 0.07661466863420274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906053495407104,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.002698313188739121,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1096799111366272,
      "backward_entropy": 0.07667367590798271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.709850311279297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0027983903884887694,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10967867374420166,
      "backward_entropy": 0.07666737304793463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.891841697692872,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.00289841596968472,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10967731356620788,
      "backward_entropy": 0.07661207914352416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667674541473389,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.002998477639630437,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10967594146728517,
      "backward_entropy": 0.07663006252712674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630214643478393,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.0030984499491751192,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10967424392700195,
      "backward_entropy": 0.07662951482666863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706814575195313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.0031983444932848215,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10967236876487732,
      "backward_entropy": 0.07658516830868192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.831119155883789,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0032982023200020193,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10967056035995484,
      "backward_entropy": 0.07661433087454901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483319520950317,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.003398085478693247,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1096688234806061,
      "backward_entropy": 0.07664769556787279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776715850830078,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0034978406969457866,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10966700315475464,
      "backward_entropy": 0.07661347455448575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.065684700012207,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.003597594308666885,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10966508507728576,
      "backward_entropy": 0.07661225133472019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024436092376709,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0036974860122427344,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1096632421016693,
      "backward_entropy": 0.07652294702000088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91445484161377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0037974621634930374,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10966132640838624,
      "backward_entropy": 0.07653337584601508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.764369249343872,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0038974645780399443,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10965928912162781,
      "backward_entropy": 0.07658162713050842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.659084224700928,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.00399743476882577,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10965713739395141,
      "backward_entropy": 0.07650082243813408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.938392162322998,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.004097316088154912,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10965495824813842,
      "backward_entropy": 0.0764974508020613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903676509857178,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0041972548235207794,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10965288996696473,
      "backward_entropy": 0.07644708951314291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860741710662841,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0042972192633897064,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1096509051322937,
      "backward_entropy": 0.07650918761889139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670417928695679,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0043971988838165995,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10964882969856263,
      "backward_entropy": 0.07642324566841126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.003728532791138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.004497115965932608,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10964681267738344,
      "backward_entropy": 0.0764475815825992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.958397579193115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 18.0,
      "log_Z": 0.004597122082486749,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10964456796646119,
      "backward_entropy": 0.07644054161177741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.551606035232544,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.004697195673361421,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10964230656623838,
      "backward_entropy": 0.07643364932801988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.941015672683715,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.004797134594991803,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10963993430137635,
      "backward_entropy": 0.07646309865845576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.892423629760742,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.004897120455279946,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10963738679885864,
      "backward_entropy": 0.07641807132297092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90753755569458,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0049971315078437325,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10963492631912233,
      "backward_entropy": 0.0763893100950453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.158822584152222,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.005097175296396017,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10963240265846252,
      "backward_entropy": 0.07642032106717427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.820383977890014,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.005197378061711788,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10962998151779173,
      "backward_entropy": 0.07630571789211696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982680225372315,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.005297552794218063,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10962774515151978,
      "backward_entropy": 0.07629981040954589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.232822704315186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.005397816421464086,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10962557911872864,
      "backward_entropy": 0.07636709213256836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01366605758667,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.005498254019767046,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10962345123291015,
      "backward_entropy": 0.07632526424196032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.493497228622436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.005598736321553588,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10962139248847962,
      "backward_entropy": 0.0762282391389211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.624794483184814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0056989882607012985,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10961925029754638,
      "backward_entropy": 0.07623580363061694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752327156066894,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.005799128022044897,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10961710453033446,
      "backward_entropy": 0.07629598445362515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.916622066497803,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.005899202404543757,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10961502432823181,
      "backward_entropy": 0.0762708432144589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.046852827072144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.005999322189018131,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10961291313171387,
      "backward_entropy": 0.07615554266505772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.741163349151611,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.006099503161385656,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10961065888404846,
      "backward_entropy": 0.07617668840620254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.846070480346679,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0061996093485504385,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10960845351219177,
      "backward_entropy": 0.07621194587813483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804844045639038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.00629971562884748,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10960635542869568,
      "backward_entropy": 0.07624831530782912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.761669492721557,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.006399786472320557,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10960425376892088,
      "backward_entropy": 0.07616210381189983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.770549488067626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.006499815313145518,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10960208892822265,
      "backward_entropy": 0.07624936103820801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.279962301254272,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.006599810207262635,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.1096000635623932,
      "backward_entropy": 0.07604855232768588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.882020139694214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.006700022052973509,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1095980441570282,
      "backward_entropy": 0.07611451678805882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116508722305298,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.006800247309729457,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10959597468376162,
      "backward_entropy": 0.07592523760265775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.924557256698609,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.006900584045797587,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10959381461143494,
      "backward_entropy": 0.07589541806115045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.182772445678712,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.007000921573489904,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10959151029586792,
      "backward_entropy": 0.07604265610376994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.653009700775147,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.00710139973089099,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.10958911657333373,
      "backward_entropy": 0.07584255403942533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.724670696258546,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.00720173716545105,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1095867598056793,
      "backward_entropy": 0.07592995961507161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879045820236206,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.007301989523693919,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10958420872688293,
      "backward_entropy": 0.07577218413352967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156600761413575,
      "terminal_state_reached": 1.0,
      "terminal_reward": 16.0,
      "log_Z": 0.007402248866856098,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1095813250541687,
      "backward_entropy": 0.0758681509229872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13079137802124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.007502647209912538,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10957835793495178,
      "backward_entropy": 0.07585113181008232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855933284759521,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0076031697448343035,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10957537293434143,
      "backward_entropy": 0.0758377989133199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7296808719635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.007703657681122422,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10957246661186218,
      "backward_entropy": 0.07586764295895894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.969442224502563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.0078040361404418945,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10956923127174378,
      "backward_entropy": 0.07571744918823242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636980962753295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.00790444202721119,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10956604003906249,
      "backward_entropy": 0.07570174866252476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285358762741089,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.008004687540233136,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1095626735687256,
      "backward_entropy": 0.07572310500674777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.987839603424073,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008105133939534426,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10955919861793517,
      "backward_entropy": 0.07561837302313909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04394884109497,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.008205635752528907,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10955572605133057,
      "backward_entropy": 0.07567170461018881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.318165159225464,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.008306192234158516,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1095519483089447,
      "backward_entropy": 0.07547019653850132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.852941083908082,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.008406947460025549,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10954814672470095,
      "backward_entropy": 0.07561346226268346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.936445331573486,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.008507638704031706,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10954429149627687,
      "backward_entropy": 0.07562600307994419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92174572944641,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.008608287479728461,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10954026460647584,
      "backward_entropy": 0.0753653413719601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.619999408721924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.008708901423960923,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10953603029251098,
      "backward_entropy": 0.07557667361365424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84631805419922,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.008809326868504285,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.10953196525573732,
      "backward_entropy": 0.07527569135030111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.254617929458618,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.00890970192849636,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10952794909477234,
      "backward_entropy": 0.07556177642610337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839043807983398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.009010249841958284,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10952394127845763,
      "backward_entropy": 0.07521852519777086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70664029121399,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.009110733587294816,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10951986193656922,
      "backward_entropy": 0.07529699405034382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360670471191407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.009211093559861184,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10951581239700318,
      "backward_entropy": 0.0752501951323615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.099856758117676,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.009311145730316639,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.1095117950439453,
      "backward_entropy": 0.07524653805626763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.994491291046142,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.009411336574703454,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10950776815414429,
      "backward_entropy": 0.07527269124984741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731538248062133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.00951159643009305,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10950393438339234,
      "backward_entropy": 0.07526845865779452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656743907928467,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.009611794352531433,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10950006127357484,
      "backward_entropy": 0.07506102985805936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.725012636184692,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.009711865987628698,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10949627995491026,
      "backward_entropy": 0.07508995268079971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.639151763916015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.009811870288103819,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10949231505393982,
      "backward_entropy": 0.07498175700505574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.745593976974487,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.009911772981286048,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.109488468170166,
      "backward_entropy": 0.07484962807761299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949216270446778,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.010011633485555648,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10948429942131041,
      "backward_entropy": 0.07494818700684441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667531490325928,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.010111576225608588,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10948006749153136,
      "backward_entropy": 0.07511600123511421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.773466730117798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.010211440734565258,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10947577357292174,
      "backward_entropy": 0.07469731039471096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89218053817749,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.010311308410018682,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1094712734222412,
      "backward_entropy": 0.07483065591918098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.947547817230225,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.010411213617771864,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10946660757064819,
      "backward_entropy": 0.07478466828664145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360604333877564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.010511214099824428,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10946203351020814,
      "backward_entropy": 0.0746163460943434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.643300867080688,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.010610963311046362,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10945754408836365,
      "backward_entropy": 0.0744673079914517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.563545322418213,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.010710652265697718,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10945283889770507,
      "backward_entropy": 0.07455333934889899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359137773513794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.01081025917083025,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10944851756095886,
      "backward_entropy": 0.07440660463439094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.49357237815857,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.010909687355160713,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10944449782371521,
      "backward_entropy": 0.07439850833680896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991003179550171,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.011009001638740301,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1094404911994934,
      "backward_entropy": 0.07427326771948073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.122175312042236,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.011108465027064085,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10943599224090576,
      "backward_entropy": 0.07442419131596884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57609920501709,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.011208155285567045,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10943127870559692,
      "backward_entropy": 0.07428228126631843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26386637687683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 12.0,
      "log_Z": 0.011307754274457692,
      "trajectory_length": 11.0,
      "branch_chosen": 0.2,
      "forward_entropy": 0.10942665576934814,
      "backward_entropy": 0.07430706686443753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53661026954651,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.011407112888991832,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10942205190658569,
      "backward_entropy": 0.07413892017470465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.655882692337036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.011506393644958734,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10941718935966491,
      "backward_entropy": 0.07386308444870841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.58768572807312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.01160567868500948,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10941191911697387,
      "backward_entropy": 0.07396742436620923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.583848714828491,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.011704932060092687,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10940628528594971,
      "backward_entropy": 0.0740922470887502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177274560928344,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0118041530251503,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1094007110595703,
      "backward_entropy": 0.07379589544402228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.376431751251221,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.011903125606477261,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10939538478851318,
      "backward_entropy": 0.0737417221069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69605302810669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.012001975625753402,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10939005970954896,
      "backward_entropy": 0.07359360390239292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.613387727737427,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.012100912258028984,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10938470244407654,
      "backward_entropy": 0.07405261463589138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.677686023712159,
      "terminal_state_reached": 1.0,
      "terminal_reward": 14.0,
      "log_Z": 0.01219987329095602,
      "trajectory_length": 11.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.10937922954559327,
      "backward_entropy": 0.07375945382648044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.584810924530029,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.012298887968063355,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10937358617782593,
      "backward_entropy": 0.07355857491493226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610051012039184,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.012397882621735334,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10936755180358886,
      "backward_entropy": 0.0735103574064043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.480923843383788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.012496879696846009,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10936120867729186,
      "backward_entropy": 0.07309168444739447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.199742746353149,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.012595824152231216,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1093544352054596,
      "backward_entropy": 0.07337618205282423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3508141040802,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.012694576941430568,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10934771060943604,
      "backward_entropy": 0.07326711614926656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.928618097305298,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.012793232686817646,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1093408215045929,
      "backward_entropy": 0.07329312960306802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231689262390137,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.012891582492738963,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10933411121368408,
      "backward_entropy": 0.07327554027239483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721833992004395,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.012989797722548246,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10932762026786805,
      "backward_entropy": 0.0731054511335161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.517835140228271,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.013088181521743536,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10932095646858216,
      "backward_entropy": 0.07308031320571899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032268905639649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.01318659633398056,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10931439518928528,
      "backward_entropy": 0.0726570831404792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32948341369629,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.013284808304160834,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10930789589881895,
      "backward_entropy": 0.07315230766932168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.988459157943725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.013382989913225174,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10930159926414491,
      "backward_entropy": 0.07258129583464729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.505565500259399,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.013480929285287857,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10929556369781493,
      "backward_entropy": 0.07244035469161139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08555293083191,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.013578957598656415,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10928904056549071,
      "backward_entropy": 0.07243833475642734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.216788959503173,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.01367683345451951,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10928254723548889,
      "backward_entropy": 0.07247219946649339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271096181869506,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0137746661901474,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10927583694458007,
      "backward_entropy": 0.07273339099354215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856665849685669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.01387247359380126,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10926904916763307,
      "backward_entropy": 0.07228862709469265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.161014509201049,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.013970031030476093,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1092625594139099,
      "backward_entropy": 0.07219016088379752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260568952560424,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.014067536126822234,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10925644874572753,
      "backward_entropy": 0.0719410174422794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.854417181015014,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.014165028277784587,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10925012707710266,
      "backward_entropy": 0.07139979468451606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.592302417755127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.014262293558567762,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10924408078193666,
      "backward_entropy": 0.07145087189144558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231470775604247,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.014359775185585021,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10923750281333924,
      "backward_entropy": 0.0716345296965705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.120221757888794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.014457253087311984,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10923030853271484,
      "backward_entropy": 0.07118469278017679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.020985078811645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.014554674737155437,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10922312617301941,
      "backward_entropy": 0.0709019124507904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859876680374145,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.014651993475854396,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10921611547470092,
      "backward_entropy": 0.07120811012056139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4247652053833,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.014749119058251381,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10920926094055176,
      "backward_entropy": 0.07083088821834989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314015579223632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01484639970585704,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10920187711715697,
      "backward_entropy": 0.07061822944217258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.347044324874878,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.01494375430047512,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10919383764266968,
      "backward_entropy": 0.07066209117571512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375083780288696,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.015041205938905478,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10918577194213866,
      "backward_entropy": 0.0697749396165212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697288322448731,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.015138742234557866,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10917765974998472,
      "backward_entropy": 0.07002310951550803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856415557861328,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.015236568264663219,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10916854739189148,
      "backward_entropy": 0.07027357816696167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.956836080551147,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.01533419145271182,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10915937542915347,
      "backward_entropy": 0.07027376227908665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.000261449813843,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.015431666653603316,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10915022611618044,
      "backward_entropy": 0.06967748204867044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.047892332077026,
      "terminal_state_reached": 1.0,
      "terminal_reward": 14.0,
      "log_Z": 0.015529044531285762,
      "trajectory_length": 11.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.10914119839668272,
      "backward_entropy": 0.0699492249223921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.403454971313476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.015626349952071905,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10913241744041442,
      "backward_entropy": 0.06968354649013943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.055303621292115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0157237833365798,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10912306547164916,
      "backward_entropy": 0.06948951284090678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971918439865112,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.015821154043078423,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10911334395408631,
      "backward_entropy": 0.06968202259805467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.741439151763916,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.015918423980474473,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10910365104675293,
      "backward_entropy": 0.06943367653422886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170038318634033,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.01601545438170433,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10909386992454528,
      "backward_entropy": 0.06887620488802593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.951607942581177,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.016112520731985568,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10908384799957276,
      "backward_entropy": 0.06844112939304776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01280517578125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.016209503822028636,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10907371163368226,
      "backward_entropy": 0.06938126815689935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411958074569702,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01630644779652357,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10906364083290102,
      "backward_entropy": 0.06908130182160271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.894373416900635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.016403584368526937,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10905229568481445,
      "backward_entropy": 0.06779928074942695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5239416599273685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.016500608064234257,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10904065728187562,
      "backward_entropy": 0.06842016379038493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360974979400634,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.016597316972911356,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10902948975563047,
      "backward_entropy": 0.06839737759696111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5128696918487545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.016694219782948494,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10901747345924377,
      "backward_entropy": 0.0679579840766059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.98953800201416,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.01679081339389086,
      "trajectory_length": 11.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.10900556325912476,
      "backward_entropy": 0.06763656602965461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.062796211242675,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.016887398436665535,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1089937126636505,
      "backward_entropy": 0.06784918242030673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.597139739990235,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.016984037682414056,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10898119568824767,
      "backward_entropy": 0.06800597773657904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922016239166259,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.01708044782280922,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.10896900773048401,
      "backward_entropy": 0.06782833205329046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.399500846862793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.01717684920877218,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10895678758621215,
      "backward_entropy": 0.0664779696199629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727513599395752,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.017272938787937165,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10894482374191286,
      "backward_entropy": 0.06675124565760295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.521547794342041,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.017368941567838192,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1089329206943512,
      "backward_entropy": 0.06640840570131937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.768573522567749,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01746475901454687,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1089210033416748,
      "backward_entropy": 0.06625819603602091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547555589675904,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.017560558393597603,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10890819311141968,
      "backward_entropy": 0.06577740907669068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.628678655624389,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.017656200006604193,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10889497518539429,
      "backward_entropy": 0.06545031799210442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517658519744873,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01775174718350172,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10888240456581115,
      "backward_entropy": 0.06523017485936482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30720887184143,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.017847157642245294,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1088693916797638,
      "backward_entropy": 0.06609308256043328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6257157802581785,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.017942323908209802,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10885698080062867,
      "backward_entropy": 0.06527053978708056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342820549011231,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.01803746335208416,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1088442254066467,
      "backward_entropy": 0.0647821115122901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.374370479583741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.018132392317056656,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10883134603500366,
      "backward_entropy": 0.06586994462543064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347305965423584,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.018227165378630162,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10881880521774293,
      "backward_entropy": 0.06523338192039066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.730197477340698,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018321799114346504,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10880677819252016,
      "backward_entropy": 0.0646422306696574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.695548248291016,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01841651853173971,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10879374027252198,
      "backward_entropy": 0.06464755866262649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.42078709602356,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.018511297553777693,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10877950668334961,
      "backward_entropy": 0.06364719271659852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.10632209777832,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018605968728661538,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10876531720161438,
      "backward_entropy": 0.06440059807565478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.370042419433593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.018700357154011728,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10875129938125609,
      "backward_entropy": 0.06437304814656575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.337286567687988,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.01879466287791729,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.10873717665672303,
      "backward_entropy": 0.06261715888977051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.212754774093628,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.018888879753649234,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10872229695320128,
      "backward_entropy": 0.0626492460568746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.404358196258545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.018982937186956407,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10870725393295289,
      "backward_entropy": 0.062045609951019286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.349842548370361,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.019076972268521786,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10869114756584168,
      "backward_entropy": 0.06266066564453973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.320915222167969,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.019170943275094034,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10867524266242981,
      "backward_entropy": 0.061707337035073175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.058306312561035,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.019264844618737696,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10865832924842833,
      "backward_entropy": 0.061320140957832336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.681547355651856,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.019358529709279537,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10864155650138854,
      "backward_entropy": 0.06183299289809334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185745620727539,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.019451790489256382,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10862637758255005,
      "backward_entropy": 0.06227760050031874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.32927713394165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.01954496670514345,
      "trajectory_length": 11.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.10861073374748229,
      "backward_entropy": 0.060641653670205006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270545768737793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.019638184830546378,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10859367012977601,
      "backward_entropy": 0.061981288592020664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737030410766602,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.019731393083930016,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10857606887817384,
      "backward_entropy": 0.061711937851376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.752039909362793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.019824264012277125,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10855862975120545,
      "backward_entropy": 0.06093586617045932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.800605440139771,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.019916847907006742,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10854193568229675,
      "backward_entropy": 0.06049838463465372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.816141414642334,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.020009215362370013,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10852502465248108,
      "backward_entropy": 0.058918691343731344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.634245777130127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.020101380720734596,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10850812315940857,
      "backward_entropy": 0.05824370715353224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4995307445526125,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02019326314330101,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10849126100540163,
      "backward_entropy": 0.059624128871493876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.530095386505127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.02028480786830187,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10847571253776551,
      "backward_entropy": 0.057908580700556433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.713213968276977,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.020376081205904485,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.1084600555896759,
      "backward_entropy": 0.058230792151557076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.529237937927246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02046721987426281,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10844520211219788,
      "backward_entropy": 0.057774785161018374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9296036720275875,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.020558114722371103,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10843040347099304,
      "backward_entropy": 0.056311886178122626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.42468376159668,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.020649058185517787,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10841513752937318,
      "backward_entropy": 0.05832827621036105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.393877172470093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.020739717222750188,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10840055704116822,
      "backward_entropy": 0.05702450474103292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.562040233612061,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.020830112509429455,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1083863127231598,
      "backward_entropy": 0.055499088433053755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.643442296981812,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02092036958783865,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10837198615074158,
      "backward_entropy": 0.056169763869709434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.706566047668457,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02101056408137083,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10835651040077207,
      "backward_entropy": 0.05393686857488421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.344230794906617,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.021100735664367674,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10833992958068847,
      "backward_entropy": 0.054702148503727385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.653863954544067,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.021190654113888742,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10832328200340272,
      "backward_entropy": 0.05598319172859192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.092558479309082,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.021280559338629247,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10830610632896424,
      "backward_entropy": 0.054245004720158044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159250164031983,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02137006539851427,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10828951358795165,
      "backward_entropy": 0.05363070567448933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.58327169418335,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.021459260396659373,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10827385425567626,
      "backward_entropy": 0.05225591328408983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.176162767410278,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.021548496559262276,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10825653195381164,
      "backward_entropy": 0.05358299712340037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.27744460105896,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.021637499518692493,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10823922872543335,
      "backward_entropy": 0.05296201374795702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9458136558532715,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.021726355142891406,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10822203159332275,
      "backward_entropy": 0.053358771403630566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.981077337265015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.021814862452447414,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1082045066356659,
      "backward_entropy": 0.05132439831892649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7315497398376465,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02190308403223753,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10818701863288879,
      "backward_entropy": 0.05384646422333188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.856267309188842,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.021990838460624218,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10817006587982178,
      "backward_entropy": 0.05067037476433648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.959529113769531,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022078283503651618,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.1081538939476013,
      "backward_entropy": 0.05246211489041647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.927751541137695,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.022165535762906075,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1081368052959442,
      "backward_entropy": 0.05191563069820404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.772336626052857,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.022252587229013444,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1081192398071289,
      "backward_entropy": 0.050381247533692254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.770164489746094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.022339351661503314,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10810034751892088,
      "backward_entropy": 0.050430166390207073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.798949551582337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02242588121443987,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10808071494102478,
      "backward_entropy": 0.05049763354990218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.789110231399536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.022512203268706798,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10806126952171324,
      "backward_entropy": 0.048429384496476914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6416374206542965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022598330117762088,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10804184913635255,
      "backward_entropy": 0.04840107957522075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.567002058029175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02268420346081257,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10802083015441896,
      "backward_entropy": 0.0492221862077713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.509865760803223,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02276980094611645,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10799984812736511,
      "backward_entropy": 0.048645767569541934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.333195281028748,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.022855060547590254,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1079785370826721,
      "backward_entropy": 0.04912934899330139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.565714764595032,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.022939922474324703,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10795700550079346,
      "backward_entropy": 0.04799637860722013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.467166376113892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.023024583607912062,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10793429970741272,
      "backward_entropy": 0.04725091291798486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.804001307487487,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02310899570584297,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10791166424751282,
      "backward_entropy": 0.04695784350236257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.967271137237549,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.023193448409438135,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.1078869366645813,
      "backward_entropy": 0.044836828112602235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.09909598827362,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02327731028199196,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1078624665737152,
      "backward_entropy": 0.04518317282199859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.999638366699219,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.023360758647322656,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10783822655677797,
      "backward_entropy": 0.04370691312683953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.270681715011596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02344374395906925,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10781414031982421,
      "backward_entropy": 0.04338405794567532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.780278372764587,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02352655231952667,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10778942704200742,
      "backward_entropy": 0.04604838854736752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.22808997631073,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.023608760349452494,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10776493191719054,
      "backward_entropy": 0.043422218826082014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.105709218978882,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.023690812475979327,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.10774004697799681,
      "backward_entropy": 0.04465771582391527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7933279275894165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.023772638477385043,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10771507501602173,
      "backward_entropy": 0.0427338374985589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.561737799644471,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.023854014463722706,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.1076913046836853,
      "backward_entropy": 0.042783144116401675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.455253076553345,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.023934745974838734,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10766813039779663,
      "backward_entropy": 0.045307938920127015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.795691514015198,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.024014861881732942,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10764408588409421,
      "backward_entropy": 0.041323824889130056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.829677844047547,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02409468460828066,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10761921286582947,
      "backward_entropy": 0.0423568993806839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704821515083313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.024174283258616924,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10759386777877807,
      "backward_entropy": 0.041504187054104275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.750694608688354,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.024253605492413045,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.1075671637058258,
      "backward_entropy": 0.040403202507230965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.31324565410614,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02433271277695894,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10754061579704284,
      "backward_entropy": 0.03887019024954902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.599811053276062,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0244112778455019,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10751340627670287,
      "backward_entropy": 0.038557191524240704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.135925245285034,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02448954451829195,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10748548269271851,
      "backward_entropy": 0.041068310870064635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.25276665687561,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024567195028066636,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10745880603790284,
      "backward_entropy": 0.039539049400223625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1996497631073,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.024644378945231436,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10743193387985231,
      "backward_entropy": 0.03945524179273182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.122864985466004,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.024721107445657253,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10740556359291079,
      "backward_entropy": 0.038630382219950354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.231457352638245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.024797362089157105,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10737832188606262,
      "backward_entropy": 0.0380218603544765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.063250851631165,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024873319454491137,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10734966158866881,
      "backward_entropy": 0.035824534793694816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.036284756660462,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.024948819540441036,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10732146024703981,
      "backward_entropy": 0.036366161372926496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8369120836257933,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0250239297747612,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10729276657104492,
      "backward_entropy": 0.035693086352613236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8950581789016723,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.025098482333123683,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10726410031318664,
      "backward_entropy": 0.035716163780954144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7557167530059816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02517257761210203,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10723467946052552,
      "backward_entropy": 0.03724832038084666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9613161087036133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02524616029113531,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10720591664314272,
      "backward_entropy": 0.03758371522029241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.000844144821167,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.025319461710751057,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10717571616172791,
      "backward_entropy": 0.03499136749241087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7142605543136598,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.025392547622323035,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10714416980743406,
      "backward_entropy": 0.0336332059568829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.824262809753418,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.025465204566717147,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10711264848709105,
      "backward_entropy": 0.03614972316556507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.773653268814087,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.025537514314055442,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10708091735839845,
      "backward_entropy": 0.034628370569811925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.532425594329834,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.025609491020441057,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10704766035079956,
      "backward_entropy": 0.032680631511741214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.297172117233276,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02568099182099104,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10701422095298767,
      "backward_entropy": 0.03298164937231276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.37146977186203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02575179636478424,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10698174595832825,
      "backward_entropy": 0.03304553561740452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.313694405555725,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.025822043232619763,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10694978713989259,
      "backward_entropy": 0.030585848953988814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3541131615638733,
      "terminal_state_reached": 1.0,
      "terminal_reward": 22.0,
      "log_Z": 0.02589170690625906,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10691803336143495,
      "backward_entropy": 0.031103325221273632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.383656716346741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.025960910692811014,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10688762068748474,
      "backward_entropy": 0.030780494544241165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.341311991214752,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026029771938920022,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10685655713081359,
      "backward_entropy": 0.03180689629581239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8158053874969484,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026098276674747466,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10682482361793517,
      "backward_entropy": 0.03286399361160067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0124698758125303,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.02616587746888399,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10679466009140015,
      "backward_entropy": 0.030569452709621858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1116788029670714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026232924312353134,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10676363945007324,
      "backward_entropy": 0.03205190549294154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9859559893608094,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.026299518160521985,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10673214554786681,
      "backward_entropy": 0.03058666421307458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.816664147377014,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.026365629211068154,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10669978976249697,
      "backward_entropy": 0.029713106817669338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.022652566432953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026431103609502314,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10666786313056945,
      "backward_entropy": 0.030451061659389073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.46978417634964,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026496217027306555,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10663426756858826,
      "backward_entropy": 0.02748545325464673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.970095467567444,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026560398936271667,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10660262703895569,
      "backward_entropy": 0.027953457501199507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.568105459213257,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.026624289341270924,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10656838655471801,
      "backward_entropy": 0.02795962045590083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6199944734573366,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.026687529124319553,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10653465270996094,
      "backward_entropy": 0.027063970598909592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5797547459602357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02675022017210722,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10650064945220947,
      "backward_entropy": 0.026238098078303868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.409062308073044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.026812328770756722,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10646685004234313,
      "backward_entropy": 0.025290120475822027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6590078711509704,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.026873726211488248,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10643391609191895,
      "backward_entropy": 0.026437538199954563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4420860052108764,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.026934747211635114,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10640022277832031,
      "backward_entropy": 0.0250219550397661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2940884590148927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02699522078037262,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10636554598808287,
      "backward_entropy": 0.025001511640018886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6572300672531126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02705505061894655,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10633049845695494,
      "backward_entropy": 0.024991047299570503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.193415516614914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.0271146934479475,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10629193782806397,
      "backward_entropy": 0.02497043336431185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.309361791610718,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027173624001443387,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10625330090522764,
      "backward_entropy": 0.02527530723147922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0325796484947203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.027231975458562374,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10621402859687805,
      "backward_entropy": 0.02428395450115204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.181440305709839,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.027289496548473836,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.1061747431755066,
      "backward_entropy": 0.02260985912548171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.103744250535965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027346471883356573,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10613648414611818,
      "backward_entropy": 0.024025398161676197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0729062974452974,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02740288060158491,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10609856963157653,
      "backward_entropy": 0.022483362754185998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0473214447498322,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02745874524116516,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10605991721153259,
      "backward_entropy": 0.024915579458077746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.142016613483429,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027514079958200453,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10602040529251097,
      "backward_entropy": 0.02187418987353643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0254112631082535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027569016069173814,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10597914338111877,
      "backward_entropy": 0.02265407492717107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007860690355301,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.027623410150408746,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10593760788440705,
      "backward_entropy": 0.022883780631754135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8978145122528076,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02767732571810484,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10589529693126679,
      "backward_entropy": 0.021763715479109026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8295407891273499,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02773066461086273,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10585158884525299,
      "backward_entropy": 0.02251181279619535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8882152795791627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.027783396653831005,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10580647766590116,
      "backward_entropy": 0.021281750086281033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7612980127334594,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027835637517273425,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10576050817966462,
      "backward_entropy": 0.02082306452923351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6971270740032196,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.02788725420832634,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10571397542953491,
      "backward_entropy": 0.019001948336760204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8353634178638458,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.027938276529312134,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10566603899002076,
      "backward_entropy": 0.019455952942371367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.685029873251915,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02798890620470047,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10561622738838197,
      "backward_entropy": 0.02118900501065784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.746072006225586,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.028038998879492284,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.105565505027771,
      "backward_entropy": 0.019557136876715554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5516259640455246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02808865886181593,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10551381349563597,
      "backward_entropy": 0.018167618496550457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.604822227358818,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02813766002655029,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10546215891838073,
      "backward_entropy": 0.020453749514288376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4572935998439789,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02818610854446888,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.10540906071662903,
      "backward_entropy": 0.018875588890579015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4967998534440994,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028233874402940274,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10535553455352784,
      "backward_entropy": 0.019313569615284604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5133727222681046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.028281066939234732,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10530167043209075,
      "backward_entropy": 0.017791809058851665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4255457192659378,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.028327790647745134,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10524692595005036,
      "backward_entropy": 0.01870969542198711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4106333047151565,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.028373946249485017,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10519198894500732,
      "backward_entropy": 0.018160012364387513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3470490619540214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.028419560007750987,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10513640403747557,
      "backward_entropy": 0.01667422494954533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3155643552541734,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02846451997756958,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10507984340190887,
      "backward_entropy": 0.01795564475986693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2649838119745254,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.028508896939456463,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10502313196659088,
      "backward_entropy": 0.01727831843826506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2805973798036576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.028552613221108913,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10496634364128113,
      "backward_entropy": 0.01600886235634486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2172924131155014,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02859576288610697,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10490924835205077,
      "backward_entropy": 0.016948482394218443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1219255715608596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028638354502618313,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10485146760940552,
      "backward_entropy": 0.015458919521835118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0098722487688065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02868027798831463,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10479409337043762,
      "backward_entropy": 0.015980368355909984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0662626892328262,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02872136477380991,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10473767518997193,
      "backward_entropy": 0.015842801994747586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.140288771688938,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.028761812672019004,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10468063950538635,
      "backward_entropy": 0.016243413339058557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0464939072728157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02880172561854124,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10462308883666993,
      "backward_entropy": 0.016605537633101148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0455510407686233,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.028841042146086692,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10456465244293214,
      "backward_entropy": 0.016138320581780538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9740187019109726,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02887979745864868,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10450550973415376,
      "backward_entropy": 0.01541001871228218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9582783967256546,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.028917901031672955,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.104445960521698,
      "backward_entropy": 0.015546434869368872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8991742193698883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.028955440409481524,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10438607156276702,
      "backward_entropy": 0.014773832509915031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8266904145479202,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.028992344997823237,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10432567596435546,
      "backward_entropy": 0.015826820996072556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.886866657435894,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.029028496332466604,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1042668879032135,
      "backward_entropy": 0.014970204730828607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8121493622660637,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029064130783081055,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10420755028724671,
      "backward_entropy": 0.013898412221007878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.757654121518135,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02909908089786768,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1041475808620453,
      "backward_entropy": 0.014770305570628908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7285071581602096,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02913331352174282,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10408735334873201,
      "backward_entropy": 0.014235510180393854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7402204215526581,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02916677948087454,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10402754426002503,
      "backward_entropy": 0.01445817765262392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7214898571372033,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02919954266399145,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10396778106689453,
      "backward_entropy": 0.012982514335049522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7509575121104717,
      "terminal_state_reached": 1.0,
      "terminal_reward": 17.0,
      "log_Z": 0.029231716878712177,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10390771329402923,
      "backward_entropy": 0.01325743231508467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6686792865395546,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029263387247920037,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10384636878967286,
      "backward_entropy": 0.013700948655605316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7176754280924798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.02929432112723589,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10378501892089845,
      "backward_entropy": 0.01267145574092865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7002039380371571,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.029324809834361077,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10372194170951843,
      "backward_entropy": 0.013122228946950702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6594938255846501,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.029354753345251082,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10365785837173462,
      "backward_entropy": 0.01343885701563623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7151077225804329,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.029384138621389867,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10359260976314547,
      "backward_entropy": 0.012757925358083514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6662670955061912,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.029413259774446487,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10352546572685242,
      "backward_entropy": 0.011608897687660324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6114956825971604,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02944193184375763,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10345719099044799,
      "backward_entropy": 0.01247747548752361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5577945329248906,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.02947012595832348,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.103388209939003,
      "backward_entropy": 0.013735824988947976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5843215741217136,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.029497675970196723,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10331853806972502,
      "backward_entropy": 0.012111410250266394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5590777665376663,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02952471226453781,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10324815213680268,
      "backward_entropy": 0.013529548214541543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5681796256452799,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.029551213048398493,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10317738354206085,
      "backward_entropy": 0.012378514971998003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4797030597925186,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029577227495610713,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10310570776462553,
      "backward_entropy": 0.01182105652987957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5137224666774273,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.029602593369781972,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10303418517112731,
      "backward_entropy": 0.011984109961324266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5062660187482834,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.029627493023872374,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10296180307865144,
      "backward_entropy": 0.012078804191615848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5405810855329036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.029651923291385173,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10288955867290497,
      "backward_entropy": 0.010662130100859535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42031641602516173,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.029676051810383797,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10281600534915925,
      "backward_entropy": 0.012189712954892051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45876778811216357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02969959992915392,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.1027430886030197,
      "backward_entropy": 0.012513748970296648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42385210618376734,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02972269766032696,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10266965210437776,
      "backward_entropy": 0.012227125217517216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4361522413790226,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.029745219647884368,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.1025961834192276,
      "backward_entropy": 0.010854566925101809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3241627737879753,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029767334274947644,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10252193510532379,
      "backward_entropy": 0.010516534083419375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4816448468714952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.02978874444961548,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10244925916194918,
      "backward_entropy": 0.010009625968005921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42923604473471644,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029809965565800668,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10237486004829406,
      "backward_entropy": 0.010663025536470944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36910528801381587,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02983079440891743,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10229907631874084,
      "backward_entropy": 0.011607241796122658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4183443566784263,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.029851079545915128,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10222365617752074,
      "backward_entropy": 0.010377257317304612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3380318105220795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029871038533747195,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10214738368988037,
      "backward_entropy": 0.009931557418571579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34102839082479475,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.029890515841543674,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10207090735435487,
      "backward_entropy": 0.010622133314609528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3523866534233093,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02990944515913725,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10199425160884859,
      "backward_entropy": 0.010794272770484286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30498648155480623,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.029928016103804113,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1019163715839386,
      "backward_entropy": 0.00984033557275931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33136352263391017,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.029946033470332624,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10183817207813264,
      "backward_entropy": 0.009753821417689323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3175236903131008,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02996369022876024,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10175898611545564,
      "backward_entropy": 0.010356656379169887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34112282656133175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.029980987682938574,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.10167902648448943,
      "backward_entropy": 0.010337656488021216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3138880230486393,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.029998085089027883,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10159730672836305,
      "backward_entropy": 0.011004843728409871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3026806268841028,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.030014905147254467,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.10151451587677003,
      "backward_entropy": 0.009563233786159092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2502436026930809,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.03003137055784464,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10143124520778657,
      "backward_entropy": 0.010168025808201895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25985495299100875,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030047398060560226,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10134875893592836,
      "backward_entropy": 0.009873177856206894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30396593660116195,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03006304260343313,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10126595854759217,
      "backward_entropy": 0.009046783132685556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3016825791448355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.03007850591093302,
      "trajectory_length": 11.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.10118212401866913,
      "backward_entropy": 0.009762713188926377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30243472866714,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030093821696937084,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.10109687089920043,
      "backward_entropy": 0.010484411815802258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2331208113580942,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03010898381471634,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10101007521152497,
      "backward_entropy": 0.009397821832034322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23496436029672624,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03012375980615616,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.10092359960079193,
      "backward_entropy": 0.008772742168770897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2510831978172064,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030138171277940273,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.10083708584308623,
      "backward_entropy": 0.009756965107387966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19321386329829693,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.030152248218655586,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.10074964046478271,
      "backward_entropy": 0.009407055709097122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22650790829211473,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030165798589587213,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.10066308557987214,
      "backward_entropy": 0.009768230095505714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20656657107174398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030179091170430182,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10057651579380036,
      "backward_entropy": 0.009655574460824332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.231931403465569,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030191931687295438,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10049001693725587,
      "backward_entropy": 0.008920608750647967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2137485457584262,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.03020456340163946,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.1004030454158783,
      "backward_entropy": 0.008721140689320034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20098175387829542,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03021690733730793,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.10031524181365965,
      "backward_entropy": 0.008866513686047659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19643306080251932,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030228984728455543,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.10022747933864593,
      "backward_entropy": 0.008606863766908645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18489188551902772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03024083822965622,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.10013974845409393,
      "backward_entropy": 0.010028614517715242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18076902218163013,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030252307653427124,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.10005249857902528,
      "backward_entropy": 0.009285894284645716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1998895488679409,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030263515748083593,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09996492385864258,
      "backward_entropy": 0.00923383923040496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18050070479512215,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03027455322444439,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09987623333930969,
      "backward_entropy": 0.008847950274745624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1624095505103469,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03028541188687086,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09978704631328583,
      "backward_entropy": 0.009222695272829796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15778920501470567,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030295956879854202,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09969821035861968,
      "backward_entropy": 0.008442902896139356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1727873919531703,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030306156352162363,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09961017370223998,
      "backward_entropy": 0.008965806663036344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17784241642802953,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03031619545072317,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09952166020870208,
      "backward_entropy": 0.008656052334441078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12541288062930106,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.03032612968236208,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0994324678182602,
      "backward_entropy": 0.00891846761935287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14396738363429903,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030335666984319686,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09934415340423584,
      "backward_entropy": 0.008425652235746383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14603660982102157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.030344850011169912,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09925605595111846,
      "backward_entropy": 0.00870998940534062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13957996675744652,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030353813245892525,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09916789770126341,
      "backward_entropy": 0.007947642273373074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13422605376690627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03036259561777115,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09908015608787538,
      "backward_entropy": 0.008259270216027896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12682979805395006,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030371158942580224,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09899258196353912,
      "backward_entropy": 0.007868643932872349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1243050160817802,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030379438772797585,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09890514016151428,
      "backward_entropy": 0.008607793557975026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11603580685332418,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030387460254132748,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09881827831268311,
      "backward_entropy": 0.008011688540379206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13258505752310157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030395274795591832,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09873194456100463,
      "backward_entropy": 0.00836815701590644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10347470585256816,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.03040299005806446,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09864534318447113,
      "backward_entropy": 0.007933401275012228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10875327149406075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03041042424738407,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09855946779251099,
      "backward_entropy": 0.008019960506094827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11441871030256152,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030417646281421185,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09847391307353973,
      "backward_entropy": 0.00842310438553492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12244062386453151,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030424740351736545,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09838831722736359,
      "backward_entropy": 0.007089039931694667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10982122728601099,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.030431768111884593,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09830206751823425,
      "backward_entropy": 0.00902027918232812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1067594357766211,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030438669584691526,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09821553289890289,
      "backward_entropy": 0.008770869216985172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10883840238675475,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030445431359112263,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09812874674797058,
      "backward_entropy": 0.008370287178291214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09118231497704983,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030452074855566023,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09804201126098631,
      "backward_entropy": 0.00784251553316911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1116349418181926,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030458530783653258,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09795565009117127,
      "backward_entropy": 0.007655700006418758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11065243012271822,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030464892275631428,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09786857366561891,
      "backward_entropy": 0.008144691876239247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10135148866102099,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03047128114849329,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0977813732624054,
      "backward_entropy": 0.007346294447779655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07965907184407114,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.03047757539898157,
      "trajectory_length": 11.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.09769395112991333,
      "backward_entropy": 0.008445927004019419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08142861337400972,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.0304835794493556,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.09760717928409576,
      "backward_entropy": 0.007823967768086328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09399662581272424,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030489377863705158,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09752070903778076,
      "backward_entropy": 0.006997422294484244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08518208479508757,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030495066940784455,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09743419826030732,
      "backward_entropy": 0.00862894525958432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0766831670422107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.03050061333924532,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0973478877544403,
      "backward_entropy": 0.008506371412012312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0820008909329772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030505993217229844,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09726224541664123,
      "backward_entropy": 0.008043227427535587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06807403275743126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030511305294930936,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09717677116394044,
      "backward_entropy": 0.0083588983449671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07674400131218136,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03051644004881382,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09709227740764617,
      "backward_entropy": 0.006952195159263081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07715228293091059,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030521406792104244,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09700779318809508,
      "backward_entropy": 0.008259175552262198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0833980143070221,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.030526315793395042,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09692324697971345,
      "backward_entropy": 0.007928599996699228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0638130352133885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030531261302530765,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09683833956718443,
      "backward_entropy": 0.007245685367120637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06107661153655499,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030535990931093694,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09675400614738464,
      "backward_entropy": 0.007825944821039835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07219167994335293,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030540502071380614,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09666993498802184,
      "backward_entropy": 0.007509010906020799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06300214347429574,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03054498564451933,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09658582746982575,
      "backward_entropy": 0.008727202523085807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06200957088731229,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.030549380369484423,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09650245249271394,
      "backward_entropy": 0.0076851567874352145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060733066662214695,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030553711205720903,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09641915798187256,
      "backward_entropy": 0.007949642381734318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05351936505176127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03055794779211283,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09633622825145723,
      "backward_entropy": 0.008186487894919183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0558566490188241,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030562017299234866,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09625383377075195,
      "backward_entropy": 0.007551771236790551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05452416557818651,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.030565984547138214,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.096171795129776,
      "backward_entropy": 0.007764156742228401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054251399077475074,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030569810420274734,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09609011173248291,
      "backward_entropy": 0.008108234571086035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052577737648971376,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03057356383651495,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09600895762443543,
      "backward_entropy": 0.007407180178496573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05254816270899028,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030577243864536287,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.095928213596344,
      "backward_entropy": 0.008056784835126665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05244891056790948,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030580896697938443,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0958478170633316,
      "backward_entropy": 0.007629460220535596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046372178511228414,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.03058453667908907,
      "trajectory_length": 11.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.09576765120029448,
      "backward_entropy": 0.008138373287187682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050036696181632576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030588087812066077,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09568797409534455,
      "backward_entropy": 0.007859187862939303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040831753064412626,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.030591652169823645,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09560862421989441,
      "backward_entropy": 0.00843162652519014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041028672212269156,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03059508241713047,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09553005516529084,
      "backward_entropy": 0.00814062886767917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04098955380031839,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03059841264039278,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09545223236083984,
      "backward_entropy": 0.007857343554496765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041484459140338006,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030601686984300613,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09537497401237487,
      "backward_entropy": 0.007926198260651694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0394378867931664,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030604957044124602,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09529852449893952,
      "backward_entropy": 0.00828038797610336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040014868101570754,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03060821779072285,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09522264659404756,
      "backward_entropy": 0.007813844415876599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039233339461497964,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030611426942050456,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09514730036258698,
      "backward_entropy": 0.007029051126705275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03543594756629318,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030614583380520345,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09507223725318908,
      "backward_entropy": 0.007052641320559714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03484233324998058,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030617637373507024,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09499797701835631,
      "backward_entropy": 0.0076822546207242545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039429657661821695,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030620603077113628,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09492423951625825,
      "backward_entropy": 0.007949788371721904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03238028961932286,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030623587779700756,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09485059320926667,
      "backward_entropy": 0.007176616994871034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026488275278825312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0306265190243721,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09477768242359162,
      "backward_entropy": 0.007013207301497459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02809004687005654,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.030629294365644454,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09470573008060455,
      "backward_entropy": 0.007919718159569636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030548912595259027,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030631980486214162,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09463485896587372,
      "backward_entropy": 0.006767972682913144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029146169772138818,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030634652823209763,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09456452786922456,
      "backward_entropy": 0.007213178980681632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02952791362768039,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03063725642859936,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09449465155601502,
      "backward_entropy": 0.00782985579636362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026652409159578384,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03063981458544731,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09442521989345551,
      "backward_entropy": 0.006726062960094875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027691324573243036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.03064225185662508,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09435629963874817,
      "backward_entropy": 0.007276019329826036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022323344275355338,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03064468540251255,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0942878556251526,
      "backward_entropy": 0.0072601513316233966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026762129715643825,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03064701985567808,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09422053635120392,
      "backward_entropy": 0.0075416956510808725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024244409857783467,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030649347603321074,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09415367424488066,
      "backward_entropy": 0.007720032003190783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02437162107380573,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03065161034464836,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0940872573852539,
      "backward_entropy": 0.0070033230715327785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022982739750295876,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030653847754001616,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09402152836322783,
      "backward_entropy": 0.0077877096417877404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023048753940383904,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030656047724187376,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09395654320716858,
      "backward_entropy": 0.007242546892828411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022012999909929932,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030658213421702385,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09389206826686859,
      "backward_entropy": 0.006517559703853396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025765750638674943,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030660367198288442,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09382823765277862,
      "backward_entropy": 0.006928587622112697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022503145050723105,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030662569962441922,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0937642228603363,
      "backward_entropy": 0.006884460565116671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01776914052607026,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.030664782598614694,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09370063364505768,
      "backward_entropy": 0.007308759126398298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01994987187499646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030666892975568773,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0936382818222046,
      "backward_entropy": 0.007068401947617531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017093619756633417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030668991431593896,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09357658386230469,
      "backward_entropy": 0.007412917746437919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018662086277618072,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.03067101389169693,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.0935158908367157,
      "backward_entropy": 0.006798089750938946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017791335386573338,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030673001334071158,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09345590591430665,
      "backward_entropy": 0.007417475101020601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01916750272794161,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03067499678581953,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09339652836322784,
      "backward_entropy": 0.007051732225550546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01771392688388005,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030677014589309694,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09333761096000673,
      "backward_entropy": 0.007522859424352646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015765151413506828,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.03067901972681284,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09327927708625794,
      "backward_entropy": 0.007323253610067898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014572479370690417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030680991895496845,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09322181940078736,
      "backward_entropy": 0.007209017872810364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014904866259894334,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030682884342968463,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09316531002521514,
      "backward_entropy": 0.00678387147684892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014492830255767331,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030684742704033853,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09310925185680388,
      "backward_entropy": 0.006820406640569368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015621812325844076,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.030686571821570398,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0930537450313568,
      "backward_entropy": 0.007714868129955399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012776615809707436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030688429810106756,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09299861788749696,
      "backward_entropy": 0.0068311605188581676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013562078928225673,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03069021664559841,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09294419884681702,
      "backward_entropy": 0.006892026298575932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011780057422583923,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03069198913872242,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.09289048254489898,
      "backward_entropy": 0.007255015687810049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012326480812043883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030693723261356352,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09283752381801606,
      "backward_entropy": 0.0069070742775996525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012084830897219945,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03069543410092592,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09278507649898529,
      "backward_entropy": 0.006841566082504061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012325755566416774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030697143636643887,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09273342311382293,
      "backward_entropy": 0.007089878991246223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011693208981159841,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03069882281124592,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09268219470977783,
      "backward_entropy": 0.006456340766615337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011100607876142022,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.03070047255605459,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.09263141095638275,
      "backward_entropy": 0.007578960143857533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010241078747640131,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030702105537056924,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09258127152919769,
      "backward_entropy": 0.007876615102092425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01133105594853987,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030703694745898246,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09253173112869263,
      "backward_entropy": 0.007422139040297931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010281034954823553,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03070529904216528,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09248258471488953,
      "backward_entropy": 0.007257052138447762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009952523645188194,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030706884153187276,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09243404030799865,
      "backward_entropy": 0.007823446641365686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0089632356648508,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030708475783467293,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09238612592220306,
      "backward_entropy": 0.0075564496219158155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009151026981999166,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030710026435554028,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09233881115913391,
      "backward_entropy": 0.006549722866879569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009351619021617807,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03071153648197651,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09229189932346343,
      "backward_entropy": 0.0065430608474546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008041978923574788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03071305323392153,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09224545717239381,
      "backward_entropy": 0.006754648768239552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008651777762861457,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03071453757584095,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09219976723194122,
      "backward_entropy": 0.0069160071925984485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0075533267096034255,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03071601763367653,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09215464532375336,
      "backward_entropy": 0.006802362162205908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007269478397938655,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030717447586357593,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09211002051830292,
      "backward_entropy": 0.006876327221592267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007112950263399398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030718848295509815,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09206593394279479,
      "backward_entropy": 0.007775030574864811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007228841414689669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030720234476029874,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09202251076698303,
      "backward_entropy": 0.007335591316223145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006533910337384441,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.030721585266292095,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.09197960078716277,
      "backward_entropy": 0.006513392345772849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006283077995612984,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030722896754741668,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09193753123283387,
      "backward_entropy": 0.00736358223689927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006283788970540627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030724160373210907,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09189628958702087,
      "backward_entropy": 0.007187472863329781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0064161106318351814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030725393630564212,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09185569226741791,
      "backward_entropy": 0.006482009465495746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00567117907157808,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030726634338498114,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09181565880775451,
      "backward_entropy": 0.006792369112372398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005594811694390955,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030727846920490264,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09177633881568908,
      "backward_entropy": 0.006637585825390285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00590110711291345,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030729044787585737,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09173762738704681,
      "backward_entropy": 0.006948191341426638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005042438626333023,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03073024358600378,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09169936656951905,
      "backward_entropy": 0.00670045738418897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00427848847284622,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030731402710080145,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0916615891456604,
      "backward_entropy": 0.006555856019258499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004951681750935677,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03073249775916338,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09162444174289704,
      "backward_entropy": 0.007196501435505019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004255249302332231,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03073359001427889,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09158787727355956,
      "backward_entropy": 0.007712634280323982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004041117944325379,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030734653770923614,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09155210196971894,
      "backward_entropy": 0.006672546640038491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004127902710933995,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030735673569142818,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09151681244373322,
      "backward_entropy": 0.0068581806702746285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004061987738168682,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03073666226118803,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09148199737071991,
      "backward_entropy": 0.006532151003678641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037251244990329723,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030737623944878577,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09144773423671722,
      "backward_entropy": 0.00738748134010368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004001228289962455,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03073856271803379,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09141409277915954,
      "backward_entropy": 0.007048832832111253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00402251618088485,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03073950782418251,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.091380934715271,
      "backward_entropy": 0.006648334943585925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033357409462041686,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030740463733673097,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09134820580482482,
      "backward_entropy": 0.006889117302166091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034166550106419892,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030741391144692896,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09131608188152313,
      "backward_entropy": 0.007157501205801964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030387019116460577,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030742307752370836,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09128453969955444,
      "backward_entropy": 0.006740173200766246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003523622180273378,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03074319548904896,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0912536782026291,
      "backward_entropy": 0.006730763903922504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002984395753355784,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030744103156030177,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09122326850891113,
      "backward_entropy": 0.0076617647790246535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029512945857277373,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030745005421340465,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.09119354546070099,
      "backward_entropy": 0.006084533118539385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028662214926043817,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030745906569063664,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0911644721031189,
      "backward_entropy": 0.007567132347159916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002730897371930041,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03074679747223854,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09113588511943817,
      "backward_entropy": 0.007983968986405268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002817007964495133,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030747681483626367,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09110770046710968,
      "backward_entropy": 0.006901072793536717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002440998576275888,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030748559534549712,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09107983708381653,
      "backward_entropy": 0.007293959748413828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002788059604336013,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030749423429369926,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09105248868465424,
      "backward_entropy": 0.006422595845328437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002220220167964726,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030750304646790027,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09102548956871033,
      "backward_entropy": 0.006678930959767767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002252409848733805,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030751145072281362,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.0909988135099411,
      "backward_entropy": 0.0072238017287519244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023693807437211944,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.03075196798890829,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09097253262996673,
      "backward_entropy": 0.008249933727913434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019687218429680796,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030752800591289996,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09094660580158234,
      "backward_entropy": 0.007216789407862556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018833146304132243,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030753606744110585,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09092126190662385,
      "backward_entropy": 0.007286323275831011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019112240132471924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.03075438514351845,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.09089641273021698,
      "backward_entropy": 0.006330114685826832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018465369341356564,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030755148641765116,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09087200820446015,
      "backward_entropy": 0.006636350974440574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016644365775846381,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030755900591611863,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09084807693958283,
      "backward_entropy": 0.006771804268161456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016040999541928613,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03075661528855562,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09082458853721619,
      "backward_entropy": 0.006754221394658089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015267554438196385,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03075730726122856,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09080146312713623,
      "backward_entropy": 0.0067426265527804705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015255960676313408,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.03075796812772751,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.0907786989212036,
      "backward_entropy": 0.006310427726970778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001451274445889794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030758618004620077,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09075631618499756,
      "backward_entropy": 0.006754020311766201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013519133455702104,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03075925912708044,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09073435664176942,
      "backward_entropy": 0.007407014899783665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013548847023912459,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030759889259934427,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09071289420127868,
      "backward_entropy": 0.0063426278945472505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001385420117094327,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030760510452091695,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09069176733493803,
      "backward_entropy": 0.006361732259392738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001109353755509801,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03076113257557154,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09067092001438141,
      "backward_entropy": 0.006638948205444547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012731057247492572,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030761731043457984,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09065055906772614,
      "backward_entropy": 0.007043658445278803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010908693472629239,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030762331373989583,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09063057005405425,
      "backward_entropy": 0.005981448458300696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010816589508522156,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03076291847974062,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09061099886894225,
      "backward_entropy": 0.006563447208868133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001033006723798735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03076348453760147,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09059171199798584,
      "backward_entropy": 0.00706973671913147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009666198815239113,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030764034390449523,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0905727231502533,
      "backward_entropy": 0.006994995640383826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008992584938596337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03076457269489765,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09055411398410795,
      "backward_entropy": 0.0066881859468089205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000995848295929136,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030765095725655556,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09053591787815093,
      "backward_entropy": 0.006959946246610747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008151280281595063,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030765622854232788,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0905180412530899,
      "backward_entropy": 0.006870020719038116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008451064997871072,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03076613340526819,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0905005133152008,
      "backward_entropy": 0.006978132368789779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008590091045107328,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030766636319458484,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09048334002494811,
      "backward_entropy": 0.007134979176852438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007884057957653568,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030767141841351986,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0904664820432663,
      "backward_entropy": 0.006356883876853519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007066938698471858,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030767644196748732,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0904499650001526,
      "backward_entropy": 0.006144527552856339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008295390510738798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0307681355625391,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09043379843235017,
      "backward_entropy": 0.006800870017872916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006232336119069259,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030768624506890774,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0904177814722061,
      "backward_entropy": 0.00718546240693993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006254455782141122,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03076908625662327,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0904020518064499,
      "backward_entropy": 0.007643345619241397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006381284350595706,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030769532546401024,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09038659632205963,
      "backward_entropy": 0.007904849408401384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005611181323047276,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030769969895482065,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09037145078182221,
      "backward_entropy": 0.007904885460933049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005375424104272497,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030770400166511537,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09035665571689606,
      "backward_entropy": 0.006719559265507592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005428751825888867,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030770814791321755,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0903421550989151,
      "backward_entropy": 0.006706266270743476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005116267111247907,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030771219357848167,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09032789170742035,
      "backward_entropy": 0.006480820021695562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005568714271134923,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030771614983677864,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09031392633914948,
      "backward_entropy": 0.006270238550172912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004510534018436374,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03077201619744301,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.090300253033638,
      "backward_entropy": 0.0071125624080499005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000474739221863274,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.0307724017649889,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09028684139251708,
      "backward_entropy": 0.006881747477584415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004554392580416788,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030772779509425162,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09027364730834961,
      "backward_entropy": 0.006058756303456095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000448803157854627,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030773151479661465,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.09026070713996887,
      "backward_entropy": 0.006537288592921363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000448684014685341,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030773522332310677,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09024799525737763,
      "backward_entropy": 0.006552409463458591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037444180961188067,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030773890390992164,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.09023546159267427,
      "backward_entropy": 0.0069011938240793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003755446863749512,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03077425193041563,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09022325634956359,
      "backward_entropy": 0.006354711535904142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003466227774140407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030774606205523015,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09021127223968506,
      "backward_entropy": 0.0063294501768218145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003215273538529573,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030774945579469203,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09019948780536652,
      "backward_entropy": 0.006509548218713866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002835756041122295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030775275267660617,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0901879793405533,
      "backward_entropy": 0.007306048274040222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032734823219016107,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03077559396624565,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09017677068710327,
      "backward_entropy": 0.006460128310653898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003267883652199544,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.03077590875327587,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09016578018665314,
      "backward_entropy": 0.007356631714436743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000269951474683694,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030776224099099636,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0901549744606018,
      "backward_entropy": 0.0072195506758160055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029526628415794677,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030776527151465415,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0901443749666214,
      "backward_entropy": 0.007343784181608094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023376054960806415,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03077682536095381,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.09013396561145783,
      "backward_entropy": 0.006771770988901455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026211570622933775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030777107179164886,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.09012375354766847,
      "backward_entropy": 0.006355247646570206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002535411375106378,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030777383595705032,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.09011370360851288,
      "backward_entropy": 0.0070199536366595166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022309733321890235,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030777661874890328,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09010384500026702,
      "backward_entropy": 0.006543652464946111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020276495332609555,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030777930468320846,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0900942039489746,
      "backward_entropy": 0.00621883620818456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020761210417674647,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03077818751335144,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09008478581905366,
      "backward_entropy": 0.006962344547112783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019972437668798194,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030778437666594983,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09007557094097138,
      "backward_entropy": 0.006558177413211928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020610928169730868,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.03077868614345789,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.09006657838821411,
      "backward_entropy": 0.0061967573646042095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019043063032029295,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.030778932385146618,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.09005772292613982,
      "backward_entropy": 0.0077001335306300074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001754187195359691,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030779177136719228,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09004900395870208,
      "backward_entropy": 0.006611613184213638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014606375244454738,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.03077941630035639,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.09004049241542816,
      "backward_entropy": 0.006402027606964111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001580873340827793,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03077964149415493,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09003219306468965,
      "backward_entropy": 0.006501888442370626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015704080552865208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.030779864825308322,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0900240933895111,
      "backward_entropy": 0.007186524404419793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012673073359934506,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03078008648008108,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.09001616954803468,
      "backward_entropy": 0.006796190349592103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001472946863302127,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03078029789030552,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.09000844955444336,
      "backward_entropy": 0.007322943127817577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000128647659740011,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030780511163175105,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0900009047985077,
      "backward_entropy": 0.006058527239494854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001295498570684117,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030780716240406035,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08999354183673859,
      "backward_entropy": 0.0066303607904248775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011936884646388535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030780914425849914,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08998629033565522,
      "backward_entropy": 0.006622954623566733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011329598476947922,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.03078110497444868,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08997918546199798,
      "backward_entropy": 0.006392893526289198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011262612324642873,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.03078129142522812,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08997225403785707,
      "backward_entropy": 0.006671829273303349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011446297424981822,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.030781474336981772,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08996546924114227,
      "backward_entropy": 0.007190785143110489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.727761303930492e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030781657062470914,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.089958815574646,
      "backward_entropy": 0.006528009515669611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.934577190335858e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030781829729676247,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.089952352643013,
      "backward_entropy": 0.006348930671811104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700783103137155e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03078200537711382,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08994602203369141,
      "backward_entropy": 0.00641994211408827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.740397570790037e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030782177112996578,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08993982970714569,
      "backward_entropy": 0.007248530619674259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.459298295591112e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030782349221408368,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08993381202220917,
      "backward_entropy": 0.007007580291893749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.285872580879982e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030782518349587916,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08992791593074799,
      "backward_entropy": 0.006316541714800729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.898665007530781e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03078268337994814,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08992217540740968,
      "backward_entropy": 0.007223428413271904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.481042373209788e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03078284803777933,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08991655111312866,
      "backward_entropy": 0.006026950312985314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.750274103026755e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.030783008225262164,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.0899110770225525,
      "backward_entropy": 0.0061331535793013045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.250810242320881e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030783161334693433,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08990573167800904,
      "backward_entropy": 0.006517140608694819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.111745281245362e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030783309787511825,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08990049481391907,
      "backward_entropy": 0.006764383696847493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5692713476673814e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030783456936478614,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08989537179470063,
      "backward_entropy": 0.006788773751921123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.368661915099438e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030783597379922867,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08989035785198211,
      "backward_entropy": 0.006505840271711349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7540954437153005e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.03078373596072197,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.08988545775413512,
      "backward_entropy": 0.00616919601129161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0179840621922266e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.030783869698643683,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0898806780576706,
      "backward_entropy": 0.007749406910604902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.44692722183504e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.03078400194644928,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0898760211467743,
      "backward_entropy": 0.006658633798360824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8355919213349806e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.03078412637114525,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08987144649028779,
      "backward_entropy": 0.006421310827136038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.901684123874816e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030784251913428307,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08986696422100067,
      "backward_entropy": 0.0064160976558923725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.806544138598156e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030784372054040433,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0898625886440277,
      "backward_entropy": 0.0063324736224280465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.898704635076911e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030784488841891288,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08985831201076508,
      "backward_entropy": 0.0073639389541414035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4220378417870736e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030784604884684087,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08985414922237396,
      "backward_entropy": 0.006500756450825268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.293097736474237e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.03078471589833498,
      "trajectory_length": 11.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.08985008001327513,
      "backward_entropy": 0.006324387258953517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.169894372270221e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030784823931753635,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08984611630439758,
      "backward_entropy": 0.006121810691224204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0354339718030587e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030784928426146507,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08984226405620574,
      "backward_entropy": 0.006259641713566249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8182641858265355e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030785031616687775,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08983851253986358,
      "backward_entropy": 0.005769530228442616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.451051764928991e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030785131454467773,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08983484625816346,
      "backward_entropy": 0.006669772209392653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4763297558649812e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03078522700816393,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08983126759529114,
      "backward_entropy": 0.006529673271709018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1727224901724184e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030785317160189153,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0898277622461319,
      "backward_entropy": 0.007299191132187843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2734817918035333e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030785403773188592,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08982437670230865,
      "backward_entropy": 0.006607952258653111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1190765563261492e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030785487778484822,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08982107639312743,
      "backward_entropy": 0.006769869269596206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0144169419111792e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.030785569734871388,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.0898178690671921,
      "backward_entropy": 0.006159117238389121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9203977876713908e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030785649456083773,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08981474280357361,
      "backward_entropy": 0.006611232666505708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8629324753760556e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.030785728245973587,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08981168806552886,
      "backward_entropy": 0.007065365629063713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.754412062169308e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.03078580480068922,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08980870842933655,
      "backward_entropy": 0.006826330762770441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5820322722071012e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03078587967902422,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08980580329895019,
      "backward_entropy": 0.007170748420887524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.581118503288792e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03078595269471407,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08980297386646272,
      "backward_entropy": 0.007495724740955565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.410203006688704e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030786024034023286,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08980021059513092,
      "backward_entropy": 0.0064452590213881595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4382235008447709e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030786092579364776,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08979753136634827,
      "backward_entropy": 0.00639500758714146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.346266379584904e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.030786159634590148,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08979490876197814,
      "backward_entropy": 0.006590439586175813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3229904469458376e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030786222778260708,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08979233324527741,
      "backward_entropy": 0.006636533720625772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2054189361698775e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03078628461807966,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08978981733322143,
      "backward_entropy": 0.006855614110827446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0505104345881477e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.03078634515404701,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08978735327720644,
      "backward_entropy": 0.006887623957461782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0307779552309882e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.030786401964724062,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.0897849589586258,
      "backward_entropy": 0.007143197084466616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1272051267496863e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030786456540226936,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08978262186050415,
      "backward_entropy": 0.007079709445436795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.711454417526966e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030786511860787867,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08978034317493438,
      "backward_entropy": 0.0071267478995853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.437180468945371e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030786565504968166,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08977813363075256,
      "backward_entropy": 0.0065508596185180875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55121206484455e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030786616913974284,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08977598667144775,
      "backward_entropy": 0.006757775445779164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.72181750861023e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030786666460335253,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08977390348911286,
      "backward_entropy": 0.0069586918171909125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.180785388844925e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.03078671395778656,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08977187395095826,
      "backward_entropy": 0.007019364130165842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223916315979295e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030786760337650775,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08976989328861237,
      "backward_entropy": 0.006223730453186565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.916402772816355e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030786806344985963,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08976796388626099,
      "backward_entropy": 0.006464387931757502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5251597519022654e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.03078685123473406,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08976608753204346,
      "backward_entropy": 0.0074916205058495194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.145491253306546e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.03078689519315958,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08976425647735596,
      "backward_entropy": 0.006988700065347885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.213183853276405e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030786938220262527,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08976247310638427,
      "backward_entropy": 0.0061894344372881785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6858671548809525e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.030786979757249356,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08976072430610657,
      "backward_entropy": 0.007017520442605017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4620950638906155e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030787020176649093,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08975902497768402,
      "backward_entropy": 0.006716616617308722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.522005633234016e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.030787060037255287,
      "trajectory_length": 11.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.08975736558437347,
      "backward_entropy": 0.006428509619500903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.812777386575817e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.030787098221480846,
      "trajectory_length": 11.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.08975575923919679,
      "backward_entropy": 0.0066898376163509144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7135900622663485e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.030787134915590285,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0897541958093643,
      "backward_entropy": 0.006940662695301904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.218077705075984e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030787170678377152,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08975266993045808,
      "backward_entropy": 0.0069575515472226675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9135264984224705e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030787204578518867,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08975118458271028,
      "backward_entropy": 0.0064397313528590724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4800668455403637e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.03078723605722189,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08974973201751708,
      "backward_entropy": 0.006484570726752281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.849277630507686e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030787266790866852,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08974832355976103,
      "backward_entropy": 0.006483533026443587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5901701375351537e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03078729622066021,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08974694609642028,
      "backward_entropy": 0.006413112291031413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.119009203444989e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.030787324905395506,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.08974560856819154,
      "backward_entropy": 0.006149089543355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8067664967323934e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030787352845072745,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08974430561065674,
      "backward_entropy": 0.0075318820774555205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7990823072698845e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.03078738059848547,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08974304497241972,
      "backward_entropy": 0.006621572789218691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.807216402089807e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.030787406861782073,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.0897418177127838,
      "backward_entropy": 0.00634353868663311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.442748159303676e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030787432752549648,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0897406232357025,
      "backward_entropy": 0.006721193591753641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.427314111486112e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03078745845705271,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08973947584629058,
      "backward_entropy": 0.006432176298565334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3774941866783196e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030787483043968677,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08973836064338683,
      "backward_entropy": 0.0070847041077084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.275052607192407e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.030787507258355617,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08973726332187654,
      "backward_entropy": 0.007251672902041012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0412893300125745e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03078753110021353,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0897361969947815,
      "backward_entropy": 0.006493002052108447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8879516517245065e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03078755531460047,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08973516345024109,
      "backward_entropy": 0.006493076019816929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7474569034447995e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.03078757841140032,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08973415911197662,
      "backward_entropy": 0.0065421116848786666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.740875312350454e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030787600204348564,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.0897331887483597,
      "backward_entropy": 0.006945299564136399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6712111623462533e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.030787622183561326,
      "trajectory_length": 11.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.08973224878311156,
      "backward_entropy": 0.006147372764017847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4971411744113538e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.030787643603980543,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08973133325576782,
      "backward_entropy": 0.0072110780411296415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5803152741966642e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.030787664093077184,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08973044097423552,
      "backward_entropy": 0.006461537505189578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.30514254479408e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030787684395909308,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08972957074642181,
      "backward_entropy": 0.006834809606273968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.23396276734411e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030787704139947893,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.0897287219762802,
      "backward_entropy": 0.006207913905382157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2121013540422609e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030787722393870353,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0897279018163681,
      "backward_entropy": 0.007290826572312249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.200554365965445e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030787739902734756,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08972710371017456,
      "backward_entropy": 0.005814623004860348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0495654066744463e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03078775629401207,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08972631990909577,
      "backward_entropy": 0.005921639791793294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.884281126915084e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030787771940231322,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08972555816173552,
      "backward_entropy": 0.00646635422276126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.409065562238084e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030787787027657033,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.0897248262166977,
      "backward_entropy": 0.006619443082147175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671555754347082e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.03078780211508274,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.08972410917282106,
      "backward_entropy": 0.005954675873120626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960168081273423e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030787817016243935,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08972342491149901,
      "backward_entropy": 0.007282173095477952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637113687370857e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03078783117234707,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0897227543592453,
      "backward_entropy": 0.006693078122205204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.066321534272447e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.03078784476965666,
      "trajectory_length": 11.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.08972209930419921,
      "backward_entropy": 0.007242152632938491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.69235986805461e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03078785799443722,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08972146332263947,
      "backward_entropy": 0.006506168055865499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849962211674665e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030787871219217777,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08972085058689118,
      "backward_entropy": 0.007430949600206481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.03434533275049e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030787883326411247,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08972025513648987,
      "backward_entropy": 0.007506771344277593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.481869398555773e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.030787895247340203,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08971968293190002,
      "backward_entropy": 0.006917897653248575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.685093391605278e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030787906609475613,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.0897191196680069,
      "backward_entropy": 0.006618800345394346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.51718909491683e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030787918157875536,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.0897185730934143,
      "backward_entropy": 0.006644763590561019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.937850022201928e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.03078792877495289,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08971804559230803,
      "backward_entropy": 0.006353794659177463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.816677638075362e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030787939205765724,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971753001213073,
      "backward_entropy": 0.006229037625922097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3499461241935935e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.030787949077785016,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.08971703350543975,
      "backward_entropy": 0.0063212258534299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24079388494647e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.03078795913606882,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971654951572418,
      "backward_entropy": 0.006446588122182423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.872811831229228e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.030787969194352626,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0897160828113556,
      "backward_entropy": 0.0065086353570222855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.92669986126748e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.030787978321313858,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08971563160419464,
      "backward_entropy": 0.006293949567609364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.753550942064976e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.030787986889481544,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.08971519291400909,
      "backward_entropy": 0.0063858730511532884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.44511089167554e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030787995643913747,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971476614475249,
      "backward_entropy": 0.005900163907143805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.309275207641349e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030788004398345947,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08971434950828552,
      "backward_entropy": 0.006787755133377181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.05671236588978e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.030788012593984605,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08971394896507263,
      "backward_entropy": 0.006431534431046911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.897906732357569e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.03078802041709423,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971355378627777,
      "backward_entropy": 0.0073582574311229915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.697738622714496e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.03078802805393934,
      "trajectory_length": 11.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.089713174700737,
      "backward_entropy": 0.006383780390024185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.623349239172512e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.03078803513199091,
      "trajectory_length": 11.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.0897128051519394,
      "backward_entropy": 0.006741282675001356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2338665601751017e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.030788042210042478,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08971244633197785,
      "backward_entropy": 0.006217534508970048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.299913433034817e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.030788048543035983,
      "trajectory_length": 11.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.0897121012210846,
      "backward_entropy": 0.007141561350888677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.239910138257528e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030788054689764977,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.0897117668390274,
      "backward_entropy": 0.0064842332568433554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0096346631248707e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030788061209023,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971144676208496,
      "backward_entropy": 0.00628871979812781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9335774581463738e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.030788067355751993,
      "trajectory_length": 11.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.08971113443374633,
      "backward_entropy": 0.007219190978341632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.969902452714223e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.030788073502480983,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971082925796509,
      "backward_entropy": 0.006229834341340596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8108099837377266e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.030788079276680945,
      "trajectory_length": 11.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.08971053063869476,
      "backward_entropy": 0.006893551266855663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.554203244324981e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.03078808505088091,
      "trajectory_length": 11.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.08971024394035339,
      "backward_entropy": 0.00627373249994384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4604955254071683e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.030788090638816358,
      "trajectory_length": 11.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.08970996439456938,
      "backward_entropy": 0.006836462972892655,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.305647655257096e-06,
    "avg_log_Z": 0.030787046428769827,
    "success_rate": 1.0,
    "avg_reward": 50.379999999999995,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14200000000000002,
      "1": 0.22199999999999998,
      "2": 0.6360000000000001
    },
    "avg_forward_entropy": 0.08975594408512115,
    "avg_backward_entropy": 0.006663629065785143,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}