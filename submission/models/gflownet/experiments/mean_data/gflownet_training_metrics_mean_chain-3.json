{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23065627614657083,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2306242525577545,
      "exploration_ratio": 0.6285714285714286
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2306705673535665,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23066994349161782,
      "exploration_ratio": 0.7428571428571429
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307098706563314,
      "exploration_ratio": 0.8857142857142856
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2306732714176178,
      "exploration_ratio": 0.8857142857142856
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307827254136403,
      "exploration_ratio": 0.9428571428571428
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23067964116732279,
      "exploration_ratio": 0.9714285714285715
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23073137799898782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307111839453379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307091454664866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23070820768674216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23081117272377014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2308019638061523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307536602020263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23059689799944558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2306156019369761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23075362245241804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.230697230497996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23077768683433533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23069119056065873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23063955704371134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307038108507792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23063184022903443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23068693280220026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2306942562262217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23077379465103148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307681759198507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23082485795021057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23075541655222573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.23077526688575745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884922742843628,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743299037218094,
      "backward_entropy": 0.2307438830534617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840910243988038,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27433132827281953,
      "backward_entropy": 0.23080141146977745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706414651870727,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.000199991166300606,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27433125376701356,
      "backward_entropy": 0.2307986239592234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94176812171936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.00029995069780852646,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743304580450058,
      "backward_entropy": 0.2307071407636007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869440269470214,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.0003999435517471284,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.274330136179924,
      "backward_entropy": 0.23053167064984642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78131833076477,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.000499939639121294,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.274329274892807,
      "backward_entropy": 0.23072972496350608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.64911766052246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0005999133863952011,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743281751871109,
      "backward_entropy": 0.23056641022364296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6941650390625,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0006998382334131748,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2743267595767975,
      "backward_entropy": 0.23065181771914167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.809609365463256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0007997416018042713,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27432501912117,
      "backward_entropy": 0.2306047896544139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68113374710083,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0008996642252895981,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2743227809667587,
      "backward_entropy": 0.23061237136522933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527795362472535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.0009995594387874006,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27432080209255216,
      "backward_entropy": 0.2306146482626597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.851834535598755,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0010993914678692819,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27431834042072295,
      "backward_entropy": 0.23061996698379517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55350375175476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.0011992763145826757,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.2743159204721451,
      "backward_entropy": 0.23031046191851295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146190404891968,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0012991075054742396,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2743134468793869,
      "backward_entropy": 0.23046679496765138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393971967697144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.0013990934705361724,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.274310776591301,
      "backward_entropy": 0.23035375674565634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59787712097168,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0014989483053795994,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27430763840675354,
      "backward_entropy": 0.23019223809242248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.825195217132569,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0015987721038982273,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2743044078350067,
      "backward_entropy": 0.2304358204205831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.937390804290771,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.0016986494301818311,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27430068254470824,
      "backward_entropy": 0.2303626596927643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.033539962768554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.0017986052320338787,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27429713904857633,
      "backward_entropy": 0.23023090163866677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.699804973602294,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.001898665854241699,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.274293652176857,
      "backward_entropy": 0.23035269180933632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662017583847046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.001998700341209769,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27429028451442716,
      "backward_entropy": 0.2303531527519226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695846605300904,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0020986943040043116,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.274286162853241,
      "backward_entropy": 0.2303406655788422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.385309171676635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.0021986697101965547,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2742817014455795,
      "backward_entropy": 0.23007844090461732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45771746635437,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.0022984973853453993,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2742767959833145,
      "backward_entropy": 0.22997844020525618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589296007156372,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.002398240636102855,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27427118122577665,
      "backward_entropy": 0.23040865858395895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.650733709335327,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.0024979572044685483,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27426483035087584,
      "backward_entropy": 0.23000158071517945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696668672561646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0025976848555728793,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27425811886787416,
      "backward_entropy": 0.22996482253074646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024715328216553,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.002697441540658474,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.274251252412796,
      "backward_entropy": 0.23004358609517417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.885172080993652,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0027973657473921777,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27424448132514956,
      "backward_entropy": 0.23017568985621137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54537100791931,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0028973652282729746,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2742373406887054,
      "backward_entropy": 0.22956323027610778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.470009279251098,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0029972908087074757,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2742302268743515,
      "backward_entropy": 0.22966501315434776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662432432174683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.0030971165746450425,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2742233693599701,
      "backward_entropy": 0.22985691229502359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798771381378174,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.003196930163539946,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27421610057353973,
      "backward_entropy": 0.22982257008552556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730235624313355,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.0032968000741675496,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2742083668708801,
      "backward_entropy": 0.22965636054674782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.727918243408203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0033966846764087676,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2742008179426193,
      "backward_entropy": 0.22946266730626425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.849269342422485,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.0034965795930474997,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27419306337833405,
      "backward_entropy": 0.22975577116012574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5445885181427,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.0035965407732874155,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27418514490127566,
      "backward_entropy": 0.22921986977259318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827274274826049,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.0036964305909350514,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27417722940444944,
      "backward_entropy": 0.2294330974419912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.927482986450196,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.003796387650072575,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2741689711809158,
      "backward_entropy": 0.22939110596974693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771814727783203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.003896426595747471,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2741602033376694,
      "backward_entropy": 0.2290908952554067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729309129714967,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.00399649259634316,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2741514027118683,
      "backward_entropy": 0.22901385426521298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763425302505492,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.0040965649299323555,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27414182126522063,
      "backward_entropy": 0.22888596256573995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654275703430176,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.004196643643081188,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2741324156522751,
      "backward_entropy": 0.22893016338348388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.726180934906006,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.004296686919406057,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2741238117218018,
      "backward_entropy": 0.2288851002852122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.561559915542603,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.004396729124709964,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27411502301692964,
      "backward_entropy": 0.22894562482833866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.377014780044556,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0044966965913772585,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2741060346364975,
      "backward_entropy": 0.22848270535469056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.006305599212647,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00459650531411171,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2740975469350815,
      "backward_entropy": 0.22796713511149086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687664318084718,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.004696468915790319,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27408879697322847,
      "backward_entropy": 0.22898005843162536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56860146522522,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.004796434426680207,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2740798592567444,
      "backward_entropy": 0.22829519708951315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669733953475951,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.004896334372460842,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27407026290893555,
      "backward_entropy": 0.22889650662740074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.300063228607177,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.004996233992278576,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2740601748228073,
      "backward_entropy": 0.22796359658241272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.751811122894287,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.005095963273197413,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2740494817495346,
      "backward_entropy": 0.22863655885060624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92079725265503,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005195747734978795,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27403842508792875,
      "backward_entropy": 0.2277202387650808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531700849533081,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.00529565210454166,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27402629256248473,
      "backward_entropy": 0.2280611395835876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.858128643035888,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.005395487369969487,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27401451468467714,
      "backward_entropy": 0.2278855860233307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.384585189819337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.005495428992435336,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2740021914243698,
      "backward_entropy": 0.227874888976415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.529956340789795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.0055952257011085745,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27399052381515504,
      "backward_entropy": 0.22744204998016357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72087140083313,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0056949502788484095,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2739786714315414,
      "backward_entropy": 0.2279650390148163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.593143320083618,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.005794716812670231,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.273967108130455,
      "backward_entropy": 0.22781969110171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93981990814209,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.005894464766606688,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.273955363035202,
      "backward_entropy": 0.22760290702184044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471581602096558,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.005994368717074395,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2739432990550995,
      "backward_entropy": 0.2275776108105977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869977569580078,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.006094177393242717,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2739316910505295,
      "backward_entropy": 0.22727955977121989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719555282592774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.006194116128608584,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2739197343587875,
      "backward_entropy": 0.22682636380195623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848889064788818,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.006294074654579163,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2739076167345047,
      "backward_entropy": 0.22713590860366817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669159030914306,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.006394117278978229,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27389515936374664,
      "backward_entropy": 0.22720728913942972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616943979263306,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.00649415822699666,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2738816231489182,
      "backward_entropy": 0.22660091519355774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991793727874756,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0065941520035266874,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27386805415153503,
      "backward_entropy": 0.22684950828552247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.422441864013672,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.0066943019162863495,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2738539308309555,
      "backward_entropy": 0.22687293092409772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.507444143295288,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.006794315157458186,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27384044528007506,
      "backward_entropy": 0.22577922145525614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.768640422821045,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.006894251285120845,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27382721900939944,
      "backward_entropy": 0.22635325590769448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177250003814697,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.006994238728657365,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.27381326258182526,
      "backward_entropy": 0.2257756471633911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55280623435974,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0070939743891358376,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.27380055487155913,
      "backward_entropy": 0.22648600935935975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04629306793213,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.007193678291514516,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27378833293914795,
      "backward_entropy": 0.2254425942897796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.728366470336914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.007293591275811195,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2737754315137863,
      "backward_entropy": 0.22603476444880172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78396496772766,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.007393550826236606,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27376272082328795,
      "backward_entropy": 0.2252093931039174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.628817367553712,
      "terminal_state_reached": 1.0,
      "terminal_reward": 19.0,
      "log_Z": 0.007493566581979394,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.27374930679798126,
      "backward_entropy": 0.22448506951332087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85838475227356,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.007593557145446539,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.273735785484314,
      "backward_entropy": 0.22497035463651022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231288862228393,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.007693653739988804,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27372256815433504,
      "backward_entropy": 0.22469125986099242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48784351348877,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.007793508842587471,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2737096220254898,
      "backward_entropy": 0.22469439705212912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647535705566407,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00789331253618002,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.27369738519191744,
      "backward_entropy": 0.22443753282229104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.246959733963013,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.00799313336610794,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2736853718757629,
      "backward_entropy": 0.2250015477339427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.578278875350952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.008092757035046815,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27367386519908904,
      "backward_entropy": 0.2242396076520284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259574556350708,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.008192387502640485,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2736627787351608,
      "backward_entropy": 0.22397332986195878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602019357681275,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.00829184865579009,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27365203499794005,
      "backward_entropy": 0.22331132491429648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.568618154525756,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.008391346409916877,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27364138662815096,
      "backward_entropy": 0.22341432174046835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469507503509522,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.008490858320146798,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2736315786838531,
      "backward_entropy": 0.22345334688822427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933963823318482,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.008590320870280267,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2736213982105255,
      "backward_entropy": 0.22310068209966025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456285858154297,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.00868998672813177,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27360968589782714,
      "backward_entropy": 0.22300248742103576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495822095870972,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.008789574820548296,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27359887659549714,
      "backward_entropy": 0.22237276037534076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.725009107589722,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.008889124635607005,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2735867083072662,
      "backward_entropy": 0.22248420914014183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.151447057723999,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.008988767024129629,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2735744774341583,
      "backward_entropy": 0.2231487532456716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.581373929977417,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.00908818831667304,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.27356255054473877,
      "backward_entropy": 0.22113607327143353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.545944881439208,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.00918764779344201,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27354986071586607,
      "backward_entropy": 0.22084240714708964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166362047195435,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.009287109877914191,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27353730201721194,
      "backward_entropy": 0.2204788088798523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.401603555679321,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.009386385791003704,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2735254943370819,
      "backward_entropy": 0.21988773941993714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.459773778915405,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.009485601726919413,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2735143393278122,
      "backward_entropy": 0.2208383560180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.596444797515868,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.00958480779081583,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27350300550460815,
      "backward_entropy": 0.22133904894193016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589609909057618,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.009684079978615045,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2734904080629349,
      "backward_entropy": 0.22020347913106283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.510363674163818,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.009783412609249354,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2734772115945816,
      "backward_entropy": 0.2195708215236664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600658798217774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.009882743656635284,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27346315085887907,
      "backward_entropy": 0.21843490600585938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429139995574952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.009982135146856308,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27344928979873656,
      "backward_entropy": 0.22014436523119607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417205572128296,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.010081468801945447,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27343515753746034,
      "backward_entropy": 0.2177923798561096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.240076446533203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.010180758126080037,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27342005670070646,
      "backward_entropy": 0.21912038127581276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706254005432129,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.010279920138418674,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.27340418100357056,
      "backward_entropy": 0.21927548249562578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.681562471389771,
      "terminal_state_reached": 1.0,
      "terminal_reward": 18.0,
      "log_Z": 0.010379233304411173,
      "trajectory_length": 5.0,
      "branch_chosen": 0.4,
      "forward_entropy": 0.2733874052762985,
      "backward_entropy": 0.2183172305425008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.209815120697021,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.010478661302477122,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2733700811862946,
      "backward_entropy": 0.21757322549819946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.405567169189453,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.01057793665677309,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27335296869277953,
      "backward_entropy": 0.21704509456952414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.076726341247559,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.010677182395011187,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2733357548713684,
      "backward_entropy": 0.21684812307357787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.258837938308716,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.010776219237595797,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27331829369068145,
      "backward_entropy": 0.21612078547477723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399935150146485,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.010875181294977665,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.27330088913440703,
      "backward_entropy": 0.21640918056170144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642508792877198,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.010974150989204646,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.27328376173973085,
      "backward_entropy": 0.21510467131932573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21108889579773,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.011073242966085672,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2732656091451645,
      "backward_entropy": 0.21496646602948505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.349300289154053,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.011172221228480338,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2732472211122513,
      "backward_entropy": 0.21557694673538208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.829205799102784,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.011271175928413868,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.27322768568992617,
      "backward_entropy": 0.21485493580500284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.175243711471557,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.011370390374213456,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27320673763751985,
      "backward_entropy": 0.2142131368319194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.917903757095337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.011469461303204299,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27318601310253143,
      "backward_entropy": 0.2142219583193461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.950427007675171,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.011568263825029134,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.27316688001155853,
      "backward_entropy": 0.2136554539203644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1505841255188,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.011666835006326436,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2731485843658447,
      "backward_entropy": 0.2123105823993683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9977397441864015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.011765310354530812,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.2731303572654724,
      "backward_entropy": 0.21132404605547586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.297957468032838,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.011863627191632985,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2731116056442261,
      "backward_entropy": 0.21220841805140175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434803438186645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.011961971875280142,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.273092058300972,
      "backward_entropy": 0.2110804259777069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.839434242248535,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.012060405779629945,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27307228446006776,
      "backward_entropy": 0.21097394227981567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02627091407776,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.012158585619181395,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27305383086204527,
      "backward_entropy": 0.21020202040672303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.204159450531005,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01225665919482708,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2730358809232712,
      "backward_entropy": 0.20895975232124328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413233232498168,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01235472345724702,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2730169057846069,
      "backward_entropy": 0.20882042845090226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260716962814332,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.012452910654246807,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27299692034721373,
      "backward_entropy": 0.2084862728913625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.147822761535645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.012551115453243255,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2729750990867615,
      "backward_entropy": 0.20959628025690719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162851810455322,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.012649276573210955,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27295265197753904,
      "backward_entropy": 0.20906557043393453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.064645147323608,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.012747410498559476,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27292925119400024,
      "backward_entropy": 0.20815855860710145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.291469097137451,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.01284545725211501,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27290585935115813,
      "backward_entropy": 0.2075037479400635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.087295436859131,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01294356184080243,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27288133800029757,
      "backward_entropy": 0.20785876115163165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197039890289307,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.013041612692177296,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.27285621166229246,
      "backward_entropy": 0.20691423813501997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.745065307617187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.013139685150235891,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2728292942047119,
      "backward_entropy": 0.20425696571667987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142232322692871,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.013237489014863968,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2728031575679779,
      "backward_entropy": 0.20531933705012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.022735023498536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.013335308525711298,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.272775936126709,
      "backward_entropy": 0.20307031671206155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819472932815552,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.013433058559894562,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27274823784828184,
      "backward_entropy": 0.20490463376045226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971891069412232,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.013530652318149806,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2727200001478195,
      "backward_entropy": 0.2036216159661611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05298171043396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.013628183584660291,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2726902365684509,
      "backward_entropy": 0.2033755362033844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890711069107056,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.01372570488601923,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.27266018092632294,
      "backward_entropy": 0.20245175758997602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08666958808899,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.013823124300688504,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.272629976272583,
      "backward_entropy": 0.20375427405039467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.158087587356567,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.013920566067099571,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27259824275970457,
      "backward_entropy": 0.19874245524406434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663806390762329,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.014018085040152072,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2725644886493683,
      "backward_entropy": 0.2005481084187825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840543651580811,
      "terminal_state_reached": 1.0,
      "terminal_reward": 21.0,
      "log_Z": 0.014115377888083458,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27253156900405884,
      "backward_entropy": 0.1984472135702769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.992423963546753,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.014212595392018556,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.27249821126461027,
      "backward_entropy": 0.19844641685485842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718792200088501,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.014309803862124682,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27246502637863157,
      "backward_entropy": 0.20069525837898256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8361609935760494,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.014406886044889688,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27243258357048034,
      "backward_entropy": 0.19790828426678977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5534769058227536,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.014503901079297065,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27239753901958463,
      "backward_entropy": 0.19497056007385255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.779214096069336,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.014600685890763998,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27236116826534273,
      "backward_entropy": 0.19726366599400838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9755635261535645,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.014697379618883132,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27232261896133425,
      "backward_entropy": 0.19664838512738547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.66502628326416,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.014794128853827715,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2722848981618881,
      "backward_entropy": 0.19161131183306376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.345774984359741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.014890759158879519,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2722474694252014,
      "backward_entropy": 0.1968505601088206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185197257995606,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.014987085666507482,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27220989763736725,
      "backward_entropy": 0.19076738158861797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.639739370346069,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.015083037409931421,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27217385470867156,
      "backward_entropy": 0.19417047103246052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.359737157821655,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.015178911294788123,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2721370905637741,
      "backward_entropy": 0.18988860150178274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.594747495651245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.015274550765752792,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27210199236869814,
      "backward_entropy": 0.18773760994275412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.572856616973877,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.015370150189846754,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.27206596434116365,
      "backward_entropy": 0.19088028073310853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.618555116653442,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.015465694665908813,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2720276415348053,
      "backward_entropy": 0.19036087791124978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00750994682312,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01556121725589037,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2719858348369598,
      "backward_entropy": 0.18986050486564635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.148287200927735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.015656360518187286,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27194524705410006,
      "backward_entropy": 0.18735851645469664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.295085477828979,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.015751245710998774,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27190411388874053,
      "backward_entropy": 0.18476924300193787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.177747344970703,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.015845994092524053,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.271863716840744,
      "backward_entropy": 0.18591867884000143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.41311559677124,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.015940551273524763,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27182249128818514,
      "backward_entropy": 0.18822236657142638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.232915782928467,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.016035085543990135,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2717794358730316,
      "backward_entropy": 0.1881802519162496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.156752014160157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.016129466891288757,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27173573076725005,
      "backward_entropy": 0.1828520268201828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.875976037979126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.016223687492311,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2716918528079987,
      "backward_entropy": 0.1826620002587636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.382484674453735,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.01631759703159332,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.27164789736270906,
      "backward_entropy": 0.18233000636100768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.290498733520508,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.016411526314914226,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2716021746397018,
      "backward_entropy": 0.18241242170333863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270982027053833,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.016505435295403003,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.27155396342277527,
      "backward_entropy": 0.17488080263137817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.077919769287109,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.01659933589398861,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2715043187141418,
      "backward_entropy": 0.17394116620222727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.880535984039307,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.016693102195858955,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2714550822973251,
      "backward_entropy": 0.17732264796892802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.113941287994384,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.016786623373627664,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27140767574310304,
      "backward_entropy": 0.17483016451199845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.830994081497193,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.016880075633525848,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2713589608669281,
      "backward_entropy": 0.17088161408901215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.905584287643433,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.01697328556329012,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.271309632062912,
      "backward_entropy": 0.1748095949490865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.765512847900391,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.017066319845616816,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2712580651044846,
      "backward_entropy": 0.17335481643676756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.461604928970337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.017159108258783817,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2712070882320404,
      "backward_entropy": 0.17541008989016213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.723923921585083,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.01725150179117918,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2711570292711258,
      "backward_entropy": 0.16901337603727978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.855423212051392,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.017343686334788798,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.27110456228256224,
      "backward_entropy": 0.17275573611259462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.527953195571899,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.017435814067721368,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.27105108797550204,
      "backward_entropy": 0.16707048018773396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.346048402786255,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.017527647875249387,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2709968626499176,
      "backward_entropy": 0.16496456265449524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745244073867798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.017619081400334836,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2709426164627075,
      "backward_entropy": 0.16995712121327716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.442754316329956,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.017710453644394875,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2708856165409088,
      "backward_entropy": 0.1638806958993276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.36275691986084,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.017801576294004917,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2708297908306122,
      "backward_entropy": 0.16220216651757555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.336686754226685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.01789241973310709,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.27077292203903197,
      "backward_entropy": 0.16393177310625712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.392257738113403,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.017983021028339864,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2707151859998703,
      "backward_entropy": 0.1543894370396932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0969737529754635,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018073405511677264,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27065610587596894,
      "backward_entropy": 0.15798685948053998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1065257549285885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018163404241204262,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2705996513366699,
      "backward_entropy": 0.15770327150821684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.169914197921753,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.0182530852034688,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.27054452896118164,
      "backward_entropy": 0.15595052937666576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2446608543396,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.0183425085619092,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2704873114824295,
      "backward_entropy": 0.15782418449719748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.195708417892456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.018431722931563855,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2704291701316833,
      "backward_entropy": 0.15533136626084645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.822219467163086,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.01852074433118105,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2703719764947891,
      "backward_entropy": 0.15373636881510416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.850850248336792,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.018609341979026795,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.27031476199626925,
      "backward_entropy": 0.15387814144293468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241558027267456,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.01869759950786829,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2702591121196747,
      "backward_entropy": 0.14872472882270815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.26621675491333,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.01878583785146475,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.27020042240619657,
      "backward_entropy": 0.15194441278775533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.058296203613281,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.01887407936155796,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.27013482749462125,
      "backward_entropy": 0.15346538722515107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0991082191467285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.018962152861058713,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.27006555795669557,
      "backward_entropy": 0.15009674926598868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.748032188415527,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.01905011646449566,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26999219357967374,
      "backward_entropy": 0.14933537046114606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.308340001106262,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.019137703627347947,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2699210911989212,
      "backward_entropy": 0.1454963703950246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.626977348327637,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.019224661961197854,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26985339224338534,
      "backward_entropy": 0.1412829647461573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.615085220336914,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.019311253726482392,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.26978594064712524,
      "backward_entropy": 0.14398898780345917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.686979842185974,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01939753033220768,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2697166472673416,
      "backward_entropy": 0.13385958870251974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.202658152580261,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.01948357466608286,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26964406967163085,
      "backward_entropy": 0.14115884006023408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.677931690216065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.019569085165858268,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26957234740257263,
      "backward_entropy": 0.14371494154135386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.371774697303772,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.019654462672770025,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26949737370014193,
      "backward_entropy": 0.13857651750246686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.204599738121033,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.01973950881510973,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2694257289171219,
      "backward_entropy": 0.13824155032634736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.982118749618531,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.01982412748038769,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2693547308444977,
      "backward_entropy": 0.1347047080596288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.824152612686158,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.019908188842236996,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26928648054599763,
      "backward_entropy": 0.13445806701978047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.065096426010132,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.01999163944274187,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.269223091006279,
      "backward_entropy": 0.13333528935909272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.403432726860046,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.020074712857604027,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2691593885421753,
      "backward_entropy": 0.129940727353096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.911255049705505,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.020157723501324654,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26908735632896424,
      "backward_entropy": 0.13516735037167865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8732754468917845,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.020240283198654653,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.26901642680168153,
      "backward_entropy": 0.13100329240163167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.964721369743347,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.020322421938180922,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2689454793930054,
      "backward_entropy": 0.1340441733598709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.170483589172363,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.020404257439076902,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2688742309808731,
      "backward_entropy": 0.12616564134756728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.757628917694092,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.020485991798341274,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.26879976093769076,
      "backward_entropy": 0.1218613257010778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.717582559585571,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.020567305758595465,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2687269002199173,
      "backward_entropy": 0.12718426783879597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.805013966560364,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.020648208819329737,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26865401566028596,
      "backward_entropy": 0.12393534382184346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.604305577278137,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.02072881832718849,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2685786813497543,
      "backward_entropy": 0.12160657544930775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.515678644180298,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.020809011347591878,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2685044050216675,
      "backward_entropy": 0.11754998962084454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.435881304740906,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.020888742059469223,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2684343606233597,
      "backward_entropy": 0.11443605621655781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.40876407623291,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.020967996679246426,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2683651566505432,
      "backward_entropy": 0.11733389447132744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.431196570396423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.021046839095652102,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.26829438507556913,
      "backward_entropy": 0.11341845889886219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.166305422782898,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.02112528309226036,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26821991205215456,
      "backward_entropy": 0.11528215507666269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2098479747772215,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.021203161031007767,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2681490838527679,
      "backward_entropy": 0.11888278822104137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.142280387878418,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02128055300563574,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2680790454149246,
      "backward_entropy": 0.1171906054019928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0272005796432495,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.021357473731040955,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26800502836704254,
      "backward_entropy": 0.11225328743457794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8200973987579347,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.02143383417278528,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2679318904876709,
      "backward_entropy": 0.1039932002623876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.865590310096741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.021509547904133796,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2678637206554413,
      "backward_entropy": 0.11153756678104401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.994646692276001,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.021584697626531126,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.26779823899269106,
      "backward_entropy": 0.10797246843576432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.998635244369507,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.021659472770988942,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.26773035526275635,
      "backward_entropy": 0.1003738542397817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.833180546760559,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02173394486308098,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26765764951705934,
      "backward_entropy": 0.1034629056851069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0001626968383786,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.021807923167943954,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26758613288402555,
      "backward_entropy": 0.1001570001244545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.66394362449646,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.021881666965782642,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26750933825969697,
      "backward_entropy": 0.1022509753704071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7426716566085814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.021954843401908876,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2674335569143295,
      "backward_entropy": 0.10639605820178985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.698505234718323,
      "terminal_state_reached": 1.0,
      "terminal_reward": 20.0,
      "log_Z": 0.022027600929141043,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2673575907945633,
      "backward_entropy": 0.09514065235853196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.749298429489136,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.022099962458014488,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2672772824764252,
      "backward_entropy": 0.09893604516983032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5532407760620117,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.022172004170715808,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.2671911418437958,
      "backward_entropy": 0.09126806110143662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4558055639266967,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.022243616729974748,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2671029895544052,
      "backward_entropy": 0.09637077997128168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.56275315284729,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.022314718924462795,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2670159816741943,
      "backward_entropy": 0.09601972301801046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4481451988220213,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.022385486774146555,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.26692580580711367,
      "backward_entropy": 0.09498867839574815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.346539282798767,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.022455823421478272,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2668290376663208,
      "backward_entropy": 0.09223384509483974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.274262750148773,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022525673732161522,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.26673213541507723,
      "backward_entropy": 0.08982965995868046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1970391869544983,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02259507793933153,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.26663451492786405,
      "backward_entropy": 0.09364655464887618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3248997926712036,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.022663942351937295,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26653989851474763,
      "backward_entropy": 0.08814494758844375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3506321907043457,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02273246869444847,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26643804013729094,
      "backward_entropy": 0.08964693049589793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.069228720664978,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.022800710797309876,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.266328901052475,
      "backward_entropy": 0.08201184918483098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0584556102752685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.022868404723703863,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2662158519029617,
      "backward_entropy": 0.08215153614679974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8515545248985292,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.022935576550662518,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2661015272140503,
      "backward_entropy": 0.08548669517040253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6820510387420655,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02300205286592245,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2659896522760391,
      "backward_entropy": 0.08025780469179154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8572373390197754,
      "terminal_state_reached": 1.0,
      "terminal_reward": 16.0,
      "log_Z": 0.02306773830205202,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.26587978303432463,
      "backward_entropy": 0.0765133981903394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.710026741027832,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.023132940381765367,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.26576985120773317,
      "backward_entropy": 0.07848522414763769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.583105719089508,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.023197513073682785,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2656634211540222,
      "backward_entropy": 0.08522071441014609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7282695055007933,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02326133269816637,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2655583590269089,
      "backward_entropy": 0.07526058902343113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.715181577205658,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.0233247060328722,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2654505431652069,
      "backward_entropy": 0.0756903146704038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3251094222068787,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02338765263557434,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.26533996164798734,
      "backward_entropy": 0.07806335637966791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.434119629859924,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.023449723608791828,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26523264944553376,
      "backward_entropy": 0.0747643123070399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.594389045238495,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.023511165753006935,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2651267319917679,
      "backward_entropy": 0.07720633298158645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.434165620803833,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.023572195507586,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2650148868560791,
      "backward_entropy": 0.06859388401110968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.454169452190399,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.023632707260549068,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2648986130952835,
      "backward_entropy": 0.07466494590044023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2574937462806703,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.023692760430276395,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2647782951593399,
      "backward_entropy": 0.07244907567898431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2554834604263307,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02375216130167246,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26465860903263094,
      "backward_entropy": 0.0726756989955902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.108221012353897,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.023810981214046477,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.26453950703144075,
      "backward_entropy": 0.07304249058167141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2283775925636293,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.0238690335303545,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2644226312637329,
      "backward_entropy": 0.0706841140985489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9597058713436126,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.023926553316414356,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2643032491207123,
      "backward_entropy": 0.06769707178076108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2174206376075745,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.023983216285705565,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26418628096580504,
      "backward_entropy": 0.06519014885028204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9878321647644044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02403955515474081,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2640644937753677,
      "backward_entropy": 0.06974737048149107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0471380293369292,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.02409524004906416,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2639437079429626,
      "backward_entropy": 0.06703855544328689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8631273269653321,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.024150444194674492,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2638181746006012,
      "backward_entropy": 0.06495486324032149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.867919236421585,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.024204889498651027,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.26369369626045225,
      "backward_entropy": 0.06176183049877484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7235970139503478,
      "terminal_state_reached": 1.0,
      "terminal_reward": 15.0,
      "log_Z": 0.02425873689353466,
      "trajectory_length": 5.0,
      "branch_chosen": 0.5,
      "forward_entropy": 0.26356645226478576,
      "backward_entropy": 0.056640206525723144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7188336253166199,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.024311795830726624,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26344103515148165,
      "backward_entropy": 0.06318550805250803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.783629196882248,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02436413150280714,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2633128553628922,
      "backward_entropy": 0.05970443909366926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6387289941310883,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.024415918067097662,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2631811827421188,
      "backward_entropy": 0.05858698685963949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6180384695529937,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.024467024393379687,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2630482703447342,
      "backward_entropy": 0.06338409533103308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.818935626745224,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.024517396837472914,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2629167020320892,
      "backward_entropy": 0.057930325716733934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.397552067041397,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.024567482993006706,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2627760410308838,
      "backward_entropy": 0.05865238805611929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4826734066009521,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02461661323904991,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26264157593250276,
      "backward_entropy": 0.05662911037604015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.535282850265503,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024665085971355437,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2625046342611313,
      "backward_entropy": 0.05837326024969419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.544340091943741,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02471298146992922,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2623628795146942,
      "backward_entropy": 0.05795021032293638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4621834933757782,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.024760379269719125,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.26221776008605957,
      "backward_entropy": 0.054690264413754144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5405132353305817,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.024807258695363998,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26207020282745364,
      "backward_entropy": 0.05486963068445523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4311116188764572,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.024853823892772197,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2619197219610214,
      "backward_entropy": 0.058458896726369856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.309869757294655,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.024899857677519323,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2617662698030472,
      "backward_entropy": 0.0490971140563488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2897460609674454,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.024945201352238655,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2616154164075851,
      "backward_entropy": 0.04969770312309265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2096892416477203,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.024989924393594265,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2614642083644867,
      "backward_entropy": 0.05474745829900106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1272028535604477,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.025034006126224993,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26131569743156435,
      "backward_entropy": 0.05390336861213048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2324474662542344,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.025077319331467153,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.26116867959499357,
      "backward_entropy": 0.049780124674240755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1994876474142075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.025120116397738458,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2610186576843262,
      "backward_entropy": 0.049832341820001604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2186597734689713,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.025162305496633054,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2608625143766403,
      "backward_entropy": 0.05305616706609726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1167702049016952,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.025204004347324373,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2607040137052536,
      "backward_entropy": 0.05121480599045754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0268647432327271,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025245092809200287,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.26054468750953674,
      "backward_entropy": 0.04633398825923602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.084061050415039,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.025285376980900765,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2603888213634491,
      "backward_entropy": 0.05133705710371335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.034158056974411,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.02532514315098524,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.260230952501297,
      "backward_entropy": 0.049971085786819455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0642255157232285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 23.0,
      "log_Z": 0.02536440845578909,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.26007224023342135,
      "backward_entropy": 0.04331369847059249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9813040047883987,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.025403215363621712,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.25991045832633974,
      "backward_entropy": 0.04715149030089378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0977702960371971,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.025441463850438596,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.25974639803171157,
      "backward_entropy": 0.04532936463753382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.865248391032219,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.025479513965547086,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2595747262239456,
      "backward_entropy": 0.048015326261520386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9159108340740204,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.025516881421208382,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.25940366089344025,
      "backward_entropy": 0.04442889665563901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8653228387236596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.025553677789866926,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2592282235622406,
      "backward_entropy": 0.045146388063828154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8915768414735794,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.025589857995510102,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.25905548632144926,
      "backward_entropy": 0.04399059837063153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8763721987605095,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.025625510886311532,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2588798001408577,
      "backward_entropy": 0.04221240282058715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7720558851957321,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.02566057275980711,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2587017357349396,
      "backward_entropy": 0.042892281462748844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7908116683363915,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02569500673562288,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25852253586053847,
      "backward_entropy": 0.04037845407923062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8312531128525734,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.025728875771164894,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25834122449159624,
      "backward_entropy": 0.04101431543628374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.717365437746048,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.02576238475739956,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25815321803092955,
      "backward_entropy": 0.041691011935472484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7601619079709053,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02579520791769028,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.25796509683132174,
      "backward_entropy": 0.03681069960196813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7126176297664643,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.025827561132609846,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.257773320376873,
      "backward_entropy": 0.04204450820883115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7214115992188453,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02585933618247509,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.25757810920476915,
      "backward_entropy": 0.039215375483036045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6596001073718071,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.025890629924833774,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2573789909482002,
      "backward_entropy": 0.040480157484610875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.720435930788517,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.025921417586505412,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.25718152672052386,
      "backward_entropy": 0.04095810850461324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6442890159785748,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02595187947154045,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.25697932541370394,
      "backward_entropy": 0.03577780512471993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6238116540014744,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02598177995532751,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25677641928195954,
      "backward_entropy": 0.0375706451634566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.604903369396925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.026011172495782376,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.25657061487436295,
      "backward_entropy": 0.03535670861601829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6044626027345658,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026040072180330755,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.25636318922042844,
      "backward_entropy": 0.034772737448414165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6133062530308961,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.026068533584475518,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.25615307688713074,
      "backward_entropy": 0.03964263175924619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.561483247578144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.026096579805016517,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.25594043731689453,
      "backward_entropy": 0.035555363198121394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5554756909608841,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.026124155335128307,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.25572733730077746,
      "backward_entropy": 0.03874286065498988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5254193570464849,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026151187345385553,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2555106654763222,
      "backward_entropy": 0.03234269171953201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5241273630410432,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.026177761517465113,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2552958995103836,
      "backward_entropy": 0.03290786519646645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4946680340915918,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.026203918643295764,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2550792023539543,
      "backward_entropy": 0.03478126774231593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49035702347755433,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.026229563541710375,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.25486127436161043,
      "backward_entropy": 0.03447531846662362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4971683479845524,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026254748366773127,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25464046895504,
      "backward_entropy": 0.03477855063974857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4277969140559435,
      "terminal_state_reached": 1.0,
      "terminal_reward": 29.0,
      "log_Z": 0.02627950459718704,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.25441586375236513,
      "backward_entropy": 0.03293291951219241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43464166335761545,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.02630365304648876,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2541939839720726,
      "backward_entropy": 0.03386233672499657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35849648229777814,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026327280700206755,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.25397211164236067,
      "backward_entropy": 0.03320532565315564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3819089956581593,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026350268349051475,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2537527665495872,
      "backward_entropy": 0.03165834657847881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3977356027811766,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.026372713968157768,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2535328432917595,
      "backward_entropy": 0.03371091683705647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3500262537971139,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02639472857117653,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.253312286734581,
      "backward_entropy": 0.03558727179964384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4178859891369939,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02641623578965664,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.25309440940618516,
      "backward_entropy": 0.0321769838531812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3743891764432192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02643753346055746,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2528715118765831,
      "backward_entropy": 0.03134150505065918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3999007724225521,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02645839061588049,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.25264652669429777,
      "backward_entropy": 0.03324662894010544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34147948380559684,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.026479005813598633,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2524149477481842,
      "backward_entropy": 0.03206321919957797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3131711395457387,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02649910170584917,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2521826684474945,
      "backward_entropy": 0.03258962382872899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.330369545891881,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.026518594659864902,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2519521594047546,
      "backward_entropy": 0.03108854045470556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30246871393173935,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02653768416494131,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.25171954184770584,
      "backward_entropy": 0.03129848688840866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2968985455110669,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.026556392572820185,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2514881879091263,
      "backward_entropy": 0.03163606201608976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2713881363160908,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02657464798539877,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2512568265199661,
      "backward_entropy": 0.03235927671194076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.310940632596612,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02659248374402523,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2510276049375534,
      "backward_entropy": 0.02847626780470212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2805218459106982,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.026610152795910835,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.25079635828733443,
      "backward_entropy": 0.030842847128709154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2688012355938554,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.026627461425960064,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2505653962492943,
      "backward_entropy": 0.031157756348450978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23748689852654933,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.026644366979599,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2503346145153046,
      "backward_entropy": 0.031816423684358594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2481674154289067,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.026660844683647156,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.25010495632886887,
      "backward_entropy": 0.03001659139990807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27032035710290075,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026676981896162032,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24987433850765228,
      "backward_entropy": 0.029598142330845196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27628026753664015,
      "terminal_state_reached": 1.0,
      "terminal_reward": 70.0,
      "log_Z": 0.02669291738420725,
      "trajectory_length": 5.0,
      "branch_chosen": 2.0,
      "forward_entropy": 0.2496405214071274,
      "backward_entropy": 0.02909655123949051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.256613947218284,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.026708726398646833,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24940330684185028,
      "backward_entropy": 0.026994229977329576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23694057101383806,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.026724368892610074,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2491629183292389,
      "backward_entropy": 0.025649319464961684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22909862832166256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.026739656738936902,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2489215686917305,
      "backward_entropy": 0.027717374389370282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20504269069060682,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026754610426723956,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24867915809154512,
      "backward_entropy": 0.028341724847753845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22524072416126728,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.026769104599952697,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.24843852669000627,
      "backward_entropy": 0.025987978527943295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1943785967770964,
      "terminal_state_reached": 1.0,
      "terminal_reward": 27.0,
      "log_Z": 0.02678340319544077,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.24819677472114562,
      "backward_entropy": 0.026918856799602507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20963400639593602,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02679734081029892,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24795677959918977,
      "backward_entropy": 0.02822974734008312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20625595115125178,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.026811036840081216,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.2477162539958954,
      "backward_entropy": 0.025997608279188473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2057445341022685,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.02682451382279396,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.24747447669506073,
      "backward_entropy": 0.02649916311105092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1607188515830785,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.026837779581546782,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.24722978472709656,
      "backward_entropy": 0.02872798542181651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17163273792248218,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026850533671677113,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2469859391450882,
      "backward_entropy": 0.02504773462812106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16770113066304476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026862972788512705,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24674178659915924,
      "backward_entropy": 0.02657596692442894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16441060113720596,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.026875138096511365,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.24649797677993773,
      "backward_entropy": 0.027718785653511678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1585267706075683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02688696011900902,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24625353664159774,
      "backward_entropy": 0.026974551007151605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17000537496060134,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02689856253564358,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24601006805896758,
      "backward_entropy": 0.02806459938486417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16338802061509342,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.026910056360065937,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2457660108804703,
      "backward_entropy": 0.026630144814650213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1425744076957926,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.026921363174915315,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24552118480205537,
      "backward_entropy": 0.025555869812766707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13981004329398275,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.026932384073734283,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.24527736902236938,
      "backward_entropy": 0.02599518932402134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13608295479789376,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.026943153142929076,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2450344979763031,
      "backward_entropy": 0.02333256664375464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15294530105311424,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.026953649148344992,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.24479220509529115,
      "backward_entropy": 0.025355412065982817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1159396778093651,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.026964069902896882,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2445484921336174,
      "backward_entropy": 0.02576066106557846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11575807973276823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.026974137499928476,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24430775344371797,
      "backward_entropy": 0.02552279122173786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13760221221018581,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.02698392104357481,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2440692290663719,
      "backward_entropy": 0.026935700575510656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11133935713442042,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.026993635483086108,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24382789433002472,
      "backward_entropy": 0.025065485263864196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1258268826873973,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027003039047122,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2435879573225975,
      "backward_entropy": 0.02476354638735453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1189771591045428,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.027012269571423532,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24334628582000734,
      "backward_entropy": 0.02500401611129443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10740823153173551,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027021310292184353,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24310337603092194,
      "backward_entropy": 0.025511055439710616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10443125909660012,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02703004386276007,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24286095052957535,
      "backward_entropy": 0.0258553896099329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10797485004877672,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02703859321773052,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24261927604675293,
      "backward_entropy": 0.024784657980004947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10280803358182311,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.027047022990882397,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.24237841069698335,
      "backward_entropy": 0.02510171954830488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0919867847871501,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027055269107222557,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.24213881343603133,
      "backward_entropy": 0.02402358340720336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.096949707204476,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.027063324674963952,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.24190085977315903,
      "backward_entropy": 0.02586974290510019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08975895652547479,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027071267925202848,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2416636437177658,
      "backward_entropy": 0.02538404228786627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09575700284913183,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027079039439558982,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.24142602384090422,
      "backward_entropy": 0.025933246314525604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08644218075787649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02708671260625124,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2411881908774376,
      "backward_entropy": 0.024336060260732966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.082710390369175,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027094227634370326,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.240952530503273,
      "backward_entropy": 0.025685352087020875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06826530614634976,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02710159793496132,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.24071823954582214,
      "backward_entropy": 0.024292737742265067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08257122315117157,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.02710875030606985,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.24048772305250168,
      "backward_entropy": 0.022069303567210836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07405198037740775,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02711581327021122,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.24025702923536302,
      "backward_entropy": 0.023553929726282754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07711465212050825,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027122735604643823,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.24002792835235595,
      "backward_entropy": 0.02420499920845032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07190437624813058,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.027129524014890195,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.23979840725660323,
      "backward_entropy": 0.021650556971629462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06677659015404061,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02713619638234377,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23957088738679885,
      "backward_entropy": 0.023361584544181822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07247708044596948,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027142708376049995,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23934427350759507,
      "backward_entropy": 0.022927925735712052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07108607363479677,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027149208076298236,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2391190618276596,
      "backward_entropy": 0.024249346926808357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06703314171172678,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027155626937747,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.23889386504888535,
      "backward_entropy": 0.02428075348337491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05178179012145847,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027161921560764312,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23866873532533645,
      "backward_entropy": 0.021533834437529247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05086952647252474,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.027167945355176925,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.23844668567180632,
      "backward_entropy": 0.02278898134827614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05161873770703096,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02717369459569454,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2382279008626938,
      "backward_entropy": 0.02295361223320166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04913336289464496,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027179276384413243,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.23801175653934478,
      "backward_entropy": 0.023498331507047016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04502604184672236,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02718469761312008,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.23779892474412917,
      "backward_entropy": 0.021463215351104736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05198937591048889,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02718991842120886,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23759000599384308,
      "backward_entropy": 0.023299658422668776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05105685466551222,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02719506248831749,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2373831257224083,
      "backward_entropy": 0.02278201977411906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04327394749852829,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.027200117520987988,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2371769741177559,
      "backward_entropy": 0.022906210273504254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04783673749770969,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027204989083111288,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.23697430193424224,
      "backward_entropy": 0.023669278249144554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048524945456301795,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02720982152968645,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2367727667093277,
      "backward_entropy": 0.021044307077924408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04583455766114639,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02721463479101658,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2365718424320221,
      "backward_entropy": 0.022698332990209263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03958369932952337,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02721942625939846,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2363722488284111,
      "backward_entropy": 0.021965431049466137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03810316958115436,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027224080823361873,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23617543876171113,
      "backward_entropy": 0.022020658974846206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040776200403342955,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027228597924113272,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.23598013818264008,
      "backward_entropy": 0.021968859558304153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03829999734880403,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02723305355757475,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2357863202691078,
      "backward_entropy": 0.02162970006465912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03763092045555823,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02723742164671421,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.23559413254261016,
      "backward_entropy": 0.021847437943021457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03360415421484504,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027241732738912106,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.23540349453687667,
      "backward_entropy": 0.020649664600690208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03456286073633237,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02724596206098795,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2352150022983551,
      "backward_entropy": 0.02209674579401811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03425923444738146,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027250094525516032,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2350274994969368,
      "backward_entropy": 0.021421472355723382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03326379198115319,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.0272541681304574,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23484145402908324,
      "backward_entropy": 0.02173566867907842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02945785625342978,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027258148044347764,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2346567466855049,
      "backward_entropy": 0.020605367670456568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02956120380986249,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02726197652518749,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.23447426557540893,
      "backward_entropy": 0.022796863690018654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028397524476167745,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0272657111287117,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2342931032180786,
      "backward_entropy": 0.021792529399196306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03154854860331398,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02726928871124983,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.23411295861005782,
      "backward_entropy": 0.020281294360756874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02501444731169613,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027272870205342768,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.23393371999263762,
      "backward_entropy": 0.021361378456155457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02585447408273467,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027276330254971982,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.233757683634758,
      "backward_entropy": 0.022536932925383252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02686066015739925,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027279702387750147,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23358369320631028,
      "backward_entropy": 0.02187893278896809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022601246865815484,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02728299703449011,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23341033458709717,
      "backward_entropy": 0.022233025853832564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024925127519236413,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027286143973469734,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23323967605829238,
      "backward_entropy": 0.02039750404655933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02474678906291956,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027289266884326934,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2330707922577858,
      "backward_entropy": 0.02099528263012568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02217184039618587,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027292350493371486,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2329031392931938,
      "backward_entropy": 0.02207266017794609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02362549399913405,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027295381762087345,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23273801058530807,
      "backward_entropy": 0.022400358443458872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021476102570886724,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.027298448234796525,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.23257479071617126,
      "backward_entropy": 0.020987031236290928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02015757996123284,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027301432192325593,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2324131891131401,
      "backward_entropy": 0.020369697610537214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020676294296572452,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02730433363467455,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.23225274980068206,
      "backward_entropy": 0.023557655016581216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018709589986974605,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.027307185903191568,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.23209379911422728,
      "backward_entropy": 0.02051626406610012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017842248136730632,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02730997893959284,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.23193697035312652,
      "backward_entropy": 0.020582550764083864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0175387503564707,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027312707714736463,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.23178193122148513,
      "backward_entropy": 0.02114507034420967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015911251261422878,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02731539011001587,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2316298231482506,
      "backward_entropy": 0.02198011328776677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015738201784552076,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02731800191104412,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23148052841424943,
      "backward_entropy": 0.020120998596151667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01666511727962643,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027320544049143792,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.23133357912302016,
      "backward_entropy": 0.02041587692995866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015079242591309595,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.0273230766877532,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23118824660778045,
      "backward_entropy": 0.02201685371498267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015204892570909578,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.0273255817592144,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2310452565550804,
      "backward_entropy": 0.021194731319944066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013814491441371502,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027328069880604745,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.23090438842773436,
      "backward_entropy": 0.019189218555887542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013469619051465997,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.027330480329692364,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.23076513260602952,
      "backward_entropy": 0.023530987277626994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012471800282219192,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.027332828007638456,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.23062800168991088,
      "backward_entropy": 0.020344639693697295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013761755332598113,
      "terminal_state_reached": 1.0,
      "terminal_reward": 24.0,
      "log_Z": 0.027335115522146226,
      "trajectory_length": 5.0,
      "branch_chosen": 0.6,
      "forward_entropy": 0.2304936483502388,
      "backward_entropy": 0.0233252023657163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012796745232117246,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027337401546537875,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.23036067187786102,
      "backward_entropy": 0.021664623046914737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011201993830763968,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02733967062085867,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.23022936284542084,
      "backward_entropy": 0.019967560345927875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011248654779046774,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02734186202287674,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.23010020852088928,
      "backward_entropy": 0.02170999770363172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011459672125056386,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02734400164335966,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.229973104596138,
      "backward_entropy": 0.019592974210778873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011052332012695842,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027346089109778406,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22984713464975357,
      "backward_entropy": 0.020754071945945425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009156126291054533,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027348150312900544,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2297226145863533,
      "backward_entropy": 0.02083235097428163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0108957537337119,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02735009454190731,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22960034608840943,
      "backward_entropy": 0.020628137141466142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01062670677274582,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02735201772302389,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22947899103164673,
      "backward_entropy": 0.022305644179383913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008299655712471576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027353915944695474,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2293588861823082,
      "backward_entropy": 0.022319352875153225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00844927189136797,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.0273557610809803,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22924149930477142,
      "backward_entropy": 0.0222552885611852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008345826774166199,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02735754307359457,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22912608534097673,
      "backward_entropy": 0.022124160081148148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008940950482792687,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027359274215996265,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2290121868252754,
      "backward_entropy": 0.021778186162312828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007826279796427115,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027361008152365685,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2288992777466774,
      "backward_entropy": 0.021444057673215867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006911545164439303,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02736269887536764,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.22878837436437607,
      "backward_entropy": 0.01971493562062581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007027616560480965,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.02736429963260889,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.22867957651615142,
      "backward_entropy": 0.020926967263221737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0069336333643150285,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027365863136947156,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22857302874326707,
      "backward_entropy": 0.020012063160538676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007423839700641111,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027367398887872697,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22846854776144027,
      "backward_entropy": 0.02067813699444135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006705951493313478,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02736895103007555,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22836578637361526,
      "backward_entropy": 0.020346628874540328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007319792152702576,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.027370486967265607,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.22826448678970337,
      "backward_entropy": 0.022799982006351152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006342034008775954,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.027372042648494244,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22816420048475267,
      "backward_entropy": 0.02142607010900974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005678110194639885,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027373585291206835,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.228065787255764,
      "backward_entropy": 0.019672017296155295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00637120466963097,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02737508900463581,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2279691755771637,
      "backward_entropy": 0.0208377397308747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005536733991721121,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02737661823630333,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22787362188100815,
      "backward_entropy": 0.021470915650328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005624833789624972,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02737811841070652,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22777985781431198,
      "backward_entropy": 0.020411486675341928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004997045694199187,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02737960945814848,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22768748700618743,
      "backward_entropy": 0.021644545470674834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005070405556944024,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027381046675145626,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2275961995124817,
      "backward_entropy": 0.021309719607233997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004763890165486373,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.027382457070052622,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22750611901283263,
      "backward_entropy": 0.018469632913668953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004891232210866292,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027383827976882456,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22741747051477432,
      "backward_entropy": 0.020351629207531613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0046935188303905305,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02738520372658968,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22733049541711808,
      "backward_entropy": 0.02113727405667305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004357980151689844,
      "terminal_state_reached": 1.0,
      "terminal_reward": 28.0,
      "log_Z": 0.027386563643813134,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.2272445812821388,
      "backward_entropy": 0.021468581507603324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00454172635654686,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027387920953333377,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22716024667024612,
      "backward_entropy": 0.02175525774558385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004331819336493936,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02738925293087959,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2270769938826561,
      "backward_entropy": 0.020732766265670458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003973681367824611,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027390556782484053,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2269946277141571,
      "backward_entropy": 0.02086229970057805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035608433461675306,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027391840144991873,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22691387981176375,
      "backward_entropy": 0.020881257206201553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003803026365039841,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027393092028796674,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2268347591161728,
      "backward_entropy": 0.01949471421539783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037261064996528146,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027394342981278897,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2267570361495018,
      "backward_entropy": 0.018592755372325583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032507537596757176,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027395594492554666,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22668060660362244,
      "backward_entropy": 0.02204042971134186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033034052366929245,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.0273967906832695,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.2266053944826126,
      "backward_entropy": 0.01900409845014413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003341632180399756,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02739795744419098,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22653113305568695,
      "backward_entropy": 0.01875507570803165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031322737052050798,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027399116568267344,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22645778357982635,
      "backward_entropy": 0.018786003192265827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030567510379569283,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027400266379117966,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22638570070266723,
      "backward_entropy": 0.02009289711713791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002978854846969625,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02740139178931713,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22631450593471528,
      "backward_entropy": 0.018441111470262207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027837819986416433,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027402497082948684,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22624433785676956,
      "backward_entropy": 0.02130270612736543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002631335086107356,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027403585612773895,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22617538571357726,
      "backward_entropy": 0.018734828755259513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00258953764796388,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027404669672250748,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22610791325569152,
      "backward_entropy": 0.02072338983416557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022859495900320326,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.02740572262555361,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.22604156136512757,
      "backward_entropy": 0.019148808717727662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024589634447238495,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.027406732738018035,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2259764552116394,
      "backward_entropy": 0.018834712480505306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024253541154394044,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02740773744881153,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22591241896152497,
      "backward_entropy": 0.020855781560142835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020131394453983377,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027408728934824468,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22584912180900574,
      "backward_entropy": 0.02191581279039383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00192029110439762,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02740968931466341,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22578709423542023,
      "backward_entropy": 0.01911326063175996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018945212974358582,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02741063926368952,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.225726680457592,
      "backward_entropy": 0.020429457848270736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001699405614999705,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027411571890115737,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22566740065813065,
      "backward_entropy": 0.019092423344651856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017915676938173419,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027412475645542146,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22560945302248,
      "backward_entropy": 0.02085515260696411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017614046192420574,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027413350343704224,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22555233389139176,
      "backward_entropy": 0.020618701229492824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015323344851367437,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027414199151098727,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22549599409103394,
      "backward_entropy": 0.020732882991433145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015515308211888623,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027415003813803195,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22544065862894058,
      "backward_entropy": 0.019050752123196922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001576155157613357,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027415781468153,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2253864273428917,
      "backward_entropy": 0.020309207836786906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012946621584887907,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027416559495031835,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22533316165208817,
      "backward_entropy": 0.017906991516550383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013996947540363181,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027417303621768953,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22528101056814193,
      "backward_entropy": 0.019803931812445323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011543490040367033,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027418034337460994,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22522984594106674,
      "backward_entropy": 0.020424165452520054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012306032215519736,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02741872612386942,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22517988383769988,
      "backward_entropy": 0.02008005691071351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012165542608045144,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02741939052939415,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22513088583946228,
      "backward_entropy": 0.01979487054049969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011255344811388567,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027420041523873805,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22508302628993987,
      "backward_entropy": 0.021561499560872714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010974961025112862,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027420691587030886,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22503623068332673,
      "backward_entropy": 0.020486636832356454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010592896124990148,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027421319857239723,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2249902904033661,
      "backward_entropy": 0.01995842109123866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010441273644119064,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0274219224229455,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22494496554136276,
      "backward_entropy": 0.021743882944186527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001055909641490871,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02742252890020609,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22490066289901733,
      "backward_entropy": 0.02155199075738589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009722304036586138,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027423131465911865,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22485707998275756,
      "backward_entropy": 0.021458678444226584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007968672730612525,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.027423736825585365,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22481433153152466,
      "backward_entropy": 0.022194397822022437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008675928065713379,
      "terminal_state_reached": 1.0,
      "terminal_reward": 46.0,
      "log_Z": 0.02742430418729782,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22477252334356307,
      "backward_entropy": 0.01919356162349383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008853160412058969,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.027424846775829792,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22473140954971313,
      "backward_entropy": 0.020680133004983264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007664151112294348,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027425378933548926,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22469092905521393,
      "backward_entropy": 0.01978408508002758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008038987995291791,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027425891347229482,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2246512532234192,
      "backward_entropy": 0.019757275780042015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007010049997006717,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0274263970553875,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.224612295627594,
      "backward_entropy": 0.01905501956741015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007192666189666852,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.02742688562721014,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22457417249679565,
      "backward_entropy": 0.018287403384844463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006850150544778444,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027427372336387635,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2245367795228958,
      "backward_entropy": 0.019176591311891873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005901564146142846,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02742784395813942,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22450007647275924,
      "backward_entropy": 0.021288057044148444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006086592179372019,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027428306452929974,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22446443736553193,
      "backward_entropy": 0.019137752677003544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006239489581162161,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027428759820759298,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2244296595454216,
      "backward_entropy": 0.021490246430039408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006007327856991651,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027429204434156418,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22439550161361693,
      "backward_entropy": 0.01843753680586815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005790546906723649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027429630793631078,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2243618994951248,
      "backward_entropy": 0.019397864366571108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005193736112687475,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02743005584925413,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2243287593126297,
      "backward_entropy": 0.022170655677715936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004684291833939369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027430467866361143,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22429622560739518,
      "backward_entropy": 0.019903348137935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004926943125724392,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02743086963891983,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22426445931196212,
      "backward_entropy": 0.021202117577195166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004450034465378394,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.027431269362568855,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.22423334270715714,
      "backward_entropy": 0.021840732420484225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044262868124178567,
      "terminal_state_reached": 1.0,
      "terminal_reward": 34.0,
      "log_Z": 0.027431665733456612,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22420308142900466,
      "backward_entropy": 0.020544005930423735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004542176493828265,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02743205465376377,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22417331635951995,
      "backward_entropy": 0.020658006394902863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004052571420913864,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02743244096636772,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22414410561323167,
      "backward_entropy": 0.018683821707963944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000404005147782982,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02743281200528145,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22411541342735292,
      "backward_entropy": 0.021729663262764615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035598236493683544,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027433178573846816,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2240873247385025,
      "backward_entropy": 0.02154874838888645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033163920633114683,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02743353247642517,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22405973970890045,
      "backward_entropy": 0.021857660760482154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032382437287878927,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02743387594819069,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22403287440538405,
      "backward_entropy": 0.020584183310468993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003096147770008884,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0274342093616724,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2240065425634384,
      "backward_entropy": 0.019546598941087723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002799170224648151,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027434526942670345,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22398092448711396,
      "backward_entropy": 0.02005992184082667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000277603078671973,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027434836141765118,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22395608127117156,
      "backward_entropy": 0.02102197619775931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027792672174200563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027435134537518023,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22393183261156083,
      "backward_entropy": 0.020078826571504275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026208382614072433,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027435421012341976,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22390803098678588,
      "backward_entropy": 0.020809952790538468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022899158997233827,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027435693144798278,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2238847568631172,
      "backward_entropy": 0.019719479729731877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002621108877690403,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02743595838546753,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22386217266321182,
      "backward_entropy": 0.018482422456145287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002443636122734461,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027436226792633533,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22384000718593597,
      "backward_entropy": 0.01999809021751086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020976864105364256,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02743649370968342,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22381825894117355,
      "backward_entropy": 0.019128639250993725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021872325621927758,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027436756528913975,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22379706054925919,
      "backward_entropy": 0.021514480064312617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001660023914610065,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027437008172273635,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22377630621194838,
      "backward_entropy": 0.018221440290411315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019776979047776423,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.02743725460022688,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22375622391700745,
      "backward_entropy": 0.01902597521742185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001980665343836563,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02743749711662531,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22373663783073425,
      "backward_entropy": 0.01936164187888304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017961710182134993,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0274377366527915,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22371730655431749,
      "backward_entropy": 0.019236454491813975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001617854113476369,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027437970228493213,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22369833290576935,
      "backward_entropy": 0.02106367126107216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017011825214012787,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02743819672614336,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22367987632751465,
      "backward_entropy": 0.019372397661209108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017621809165575543,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02743842303752899,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22366173714399337,
      "backward_entropy": 0.02067281802495321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015725669875621406,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027438647858798505,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22364386022090912,
      "backward_entropy": 0.020501636589566864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015285761738823567,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027438868209719657,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22362639904022216,
      "backward_entropy": 0.01895848624408245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001317599149359694,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02743907868862152,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22360928654670714,
      "backward_entropy": 0.019391553724805517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001356693828924449,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027439285628497602,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2235926181077957,
      "backward_entropy": 0.020968518654505414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011941442844403128,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027439486421644687,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22357627600431443,
      "backward_entropy": 0.019322176774342854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011988800807216649,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027439687214791775,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2235604166984558,
      "backward_entropy": 0.019620300332705176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011758614022738811,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027439883165061473,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22354498207569123,
      "backward_entropy": 0.020975935583313305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011302774007333482,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027440067566931247,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2235298529267311,
      "backward_entropy": 0.01894485739370187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9485222756025e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.02744024693965912,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22351504862308502,
      "backward_entropy": 0.019695035492380462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.926023477930812e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.027440420538187026,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.22350068539381027,
      "backward_entropy": 0.020609968155622483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002451001549616e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744058482348919,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2234865501523018,
      "backward_entropy": 0.021057217195630078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84919257025274e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027440742775797843,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.223472760617733,
      "backward_entropy": 0.019236429904898007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735502538570472e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027440898492932318,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22345928549766542,
      "backward_entropy": 0.020335908482472104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656704618772437e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027441053465008736,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22344615310430527,
      "backward_entropy": 0.019359700133403143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748736774999543e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027441209368407726,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22343331575393677,
      "backward_entropy": 0.01859915107488632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550377444260903e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744136769324541,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22342084348201752,
      "backward_entropy": 0.019255556041995685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.72510474007504e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027441519498825073,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22340873032808303,
      "backward_entropy": 0.019638186569015184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543088387616081e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 33.0,
      "log_Z": 0.027441668882966043,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22339686155319213,
      "backward_entropy": 0.021216648196180663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.86330700730764e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02744181137531996,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22338529974222182,
      "backward_entropy": 0.02126800504823526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.819709838836729e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027441948466002942,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22337405383586884,
      "backward_entropy": 0.021593268712361655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.409087889096554e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02744208350777626,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22336304187774658,
      "backward_entropy": 0.019449645653367043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.701552844001867e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.027442215755581856,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22335225194692612,
      "backward_entropy": 0.018403418486317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.526573485710173e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027442345209419728,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22334170788526536,
      "backward_entropy": 0.020557000860571863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9563306212263567e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744247354567051,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22333147376775742,
      "backward_entropy": 0.020836861059069633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.688882216541401e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744260001927614,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2233215555548668,
      "backward_entropy": 0.01997270062565804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4940630830581084e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02744272258132696,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2233118936419487,
      "backward_entropy": 0.01904852626224359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.122824107497536e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027442838810384274,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22330249100923538,
      "backward_entropy": 0.019413222248355545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.57650143431465e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027442952804267406,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22329332828521728,
      "backward_entropy": 0.018487693990270296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5433897376412345e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027443057857453823,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22328428775072098,
      "backward_entropy": 0.01858135958512624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.733500521008182e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.027443161606788634,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.22327542603015899,
      "backward_entropy": 0.018620004008213682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7028843519237856e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744326237589121,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22326683700084687,
      "backward_entropy": 0.02105522900819778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.799113868581116e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027443360164761545,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22325844913721085,
      "backward_entropy": 0.019443066666523616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.081723417996841e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02744345385581255,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2232502967119217,
      "backward_entropy": 0.018823421622316046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.425045490033085e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 25.0,
      "log_Z": 0.027443543821573258,
      "trajectory_length": 5.0,
      "branch_chosen": 0.7,
      "forward_entropy": 0.22324225604534148,
      "backward_entropy": 0.02136924477914969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.214257589263525e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027443631179630758,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2232344001531601,
      "backward_entropy": 0.021926938245693844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9136470120150193e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0274437153711915,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22322674393653869,
      "backward_entropy": 0.02025818464656671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8234842133301184e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.02744379676878452,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22321932911872863,
      "backward_entropy": 0.019335621719559035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.615952688387324e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02744387984275818,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22321210354566573,
      "backward_entropy": 0.020533655459682144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6325142007976866e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027443961426615714,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22320512384176255,
      "backward_entropy": 0.019919669752319652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8541860836028833e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027444040216505528,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2231982946395874,
      "backward_entropy": 0.01872381679713726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.397241658051996e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744411677122116,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22319162786006927,
      "backward_entropy": 0.020909206320842106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6314837167262795e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027444191090762616,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22318513691425323,
      "backward_entropy": 0.018936804806192715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0970431025801874e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027444263733923436,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22317876517772675,
      "backward_entropy": 0.02008657269179821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.150171930708211e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027444334328174592,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2231725350022316,
      "backward_entropy": 0.019487319514155388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.910700771485807e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.02744440212845802,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22316649854183196,
      "backward_entropy": 0.018355842679739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9778533653003195e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744446787983179,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2231605902314186,
      "backward_entropy": 0.018961716815829276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0253647418044807e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744453102350235,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22315486073493956,
      "backward_entropy": 0.020183451722065607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6628602543811155e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744459230452776,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22314923703670503,
      "backward_entropy": 0.019751974691947304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.694878155902302e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027444654516875742,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2231438010931015,
      "backward_entropy": 0.021274431174000102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5675824585059672e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027444715052843092,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22313855439424515,
      "backward_entropy": 0.020146566753586132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4262646673302015e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.0274447750300169,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22313346862792968,
      "backward_entropy": 0.020509665583570796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.466887828716068e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027444832399487494,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22312853038311004,
      "backward_entropy": 0.020516110832492513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.343790453613991e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027444889582693578,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22312375754117966,
      "backward_entropy": 0.02033038946489493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1601908310865383e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027444945089519023,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22311908453702928,
      "backward_entropy": 0.020756828039884566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3510696764740259e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027444997616112233,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22311452478170396,
      "backward_entropy": 0.01946721511582533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2209264082940763e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027445048838853837,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2231100618839264,
      "backward_entropy": 0.019627100229263304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3571063986272946e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027445099130272866,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22310574650764464,
      "backward_entropy": 0.020742069805661838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0546733404481757e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02744514588266611,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22310150265693665,
      "backward_entropy": 0.01888574746747812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2085571069064826e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027445190586149693,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22309741228818894,
      "backward_entropy": 0.019747814039389293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0570506080975762e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744523361325264,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22309342324733733,
      "backward_entropy": 0.018955358862876893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.812513519274034e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02744527403265238,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22308949679136275,
      "backward_entropy": 0.017750611901283263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.099084065785405e-05,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027445312589406967,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2230856880545616,
      "backward_entropy": 0.01999467797577381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.682891327855714e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 40.0,
      "log_Z": 0.027445351146161555,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2230819806456566,
      "backward_entropy": 0.019851735979318618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.910046727983456e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.02744538877159357,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22307834178209304,
      "backward_entropy": 0.020356110483407977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512240879416822e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027445424534380435,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22307480424642562,
      "backward_entropy": 0.0181747713436683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317126001600172e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027445458993315696,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22307132333517074,
      "backward_entropy": 0.02110239962736766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.415476709267011e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 30.0,
      "log_Z": 0.027445490658283233,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.2230679288506508,
      "backward_entropy": 0.021700555707017583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.257374972231446e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.027445521764457227,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22306460440158843,
      "backward_entropy": 0.019733870526154836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.905904509579841e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027445551939308643,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22306134253740312,
      "backward_entropy": 0.019213289643327393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.107607778777947e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744558248668909,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22305817157030106,
      "backward_entropy": 0.019104122618834176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.651136661162127e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02744561079889536,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22305505722761154,
      "backward_entropy": 0.01939942687749863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5290704480626115e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027445637434720994,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22305202931165696,
      "backward_entropy": 0.018899523591001825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.062193551237272e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744566332548857,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22304910868406297,
      "backward_entropy": 0.019502261156837147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.360776611063045e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027445688284933566,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22304624766111375,
      "backward_entropy": 0.020091570913791656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.290746259589696e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02744571343064308,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22304346263408661,
      "backward_entropy": 0.019414562607804935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.575077953106188e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027445739693939687,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22304075509309768,
      "backward_entropy": 0.02067074328660965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.325022046458571e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027445766143500805,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22303812801837922,
      "backward_entropy": 0.018780456110835075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.771501750866492e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027445792220532894,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22303559333086015,
      "backward_entropy": 0.0202613686521848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.194101340004863e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 37.0,
      "log_Z": 0.027445817925035955,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22303311973810197,
      "backward_entropy": 0.01940094232559204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.229155024049192e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.027445842698216438,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.22303072214126587,
      "backward_entropy": 0.018278376137216883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6624690956443827e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027445865981280803,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22302837818861007,
      "backward_entropy": 0.01980485158662001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8553374380967394e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02744588889181614,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22302611619234086,
      "backward_entropy": 0.02020878568291664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.344186758624801e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027445911429822445,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.2230239301919937,
      "backward_entropy": 0.018902891129255292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.567954809824414e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744593359529972,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22302184998989105,
      "backward_entropy": 0.019664431239167852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0173529379950994e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027445955947041512,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22301983535289766,
      "backward_entropy": 0.01925833187997341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3175752754743825e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027445977181196214,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22301786690950393,
      "backward_entropy": 0.019047161936759947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.806335016458661e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027445997484028338,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2230159595608711,
      "backward_entropy": 0.021263711030284564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2473085238061684e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027446017228066923,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22301409542560577,
      "backward_entropy": 0.01914535996814569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8194033212969318e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027446036413311958,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2230123206973076,
      "backward_entropy": 0.019520397608478866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9792808465979307e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.02744605578482151,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2230105847120285,
      "backward_entropy": 0.018997182821234068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.477272803247388e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027446075156331063,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2230089247226715,
      "backward_entropy": 0.02059329772988955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2210927618004916e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.027446094155311584,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2230073019862175,
      "backward_entropy": 0.01861634912590186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1903271367307296e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.0274461118504405,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2230057179927826,
      "backward_entropy": 0.02142888233065605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.641431883176892e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446128986775876,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22300416976213455,
      "backward_entropy": 0.01893967352807522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0948132128495443e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027446145191788673,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22300264984369278,
      "backward_entropy": 0.017785616591572764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9616655563936545e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446160651743413,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22300117313861847,
      "backward_entropy": 0.01974704253176848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.062607832442609e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02744617499411106,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22299972027540207,
      "backward_entropy": 0.020458235591650005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7906086579699832e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446188591420652,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22299830466508866,
      "backward_entropy": 0.020254377772410712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5137836275158634e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02744620181620121,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22299692332744597,
      "backward_entropy": 0.02083735739191373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7130670155296457e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446214854717255,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229955866932869,
      "backward_entropy": 0.018245604261755942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.94704175271454e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446226961910725,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22299426794052124,
      "backward_entropy": 0.01986450304587682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3248520494002491e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 35.0,
      "log_Z": 0.02744623851031065,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.22299297004938126,
      "backward_entropy": 0.0220037829130888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.550614494583158e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 36.0,
      "log_Z": 0.027446250431239605,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.22299172282218932,
      "backward_entropy": 0.021137412389119467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5160308358019847e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02744626197963953,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.222990520298481,
      "backward_entropy": 0.02012090173860391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3460102096019e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 60.0,
      "log_Z": 0.027446272410452367,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22298933416604996,
      "backward_entropy": 0.018863123158613843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5467342690200781e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446283027529716,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22298818379640578,
      "backward_entropy": 0.021010649452606837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1431208413625881e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744629271328449,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22298704236745834,
      "backward_entropy": 0.021879342570900916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3537168323196625e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027446301840245723,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229859486222267,
      "backward_entropy": 0.01865874429543813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1974667708969377e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744631078094244,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2229848697781563,
      "backward_entropy": 0.020003278553485875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.885572595180748e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027446318976581098,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22298382818698884,
      "backward_entropy": 0.02074274830520153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.816467994028244e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 45.0,
      "log_Z": 0.027446326985955238,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229828044772148,
      "backward_entropy": 0.02090345894296964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0595286852321806e-06,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027446334809064867,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22298182994127275,
      "backward_entropy": 0.01967744578917821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05344121346252e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446342818439006,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22298088371753694,
      "backward_entropy": 0.017746599266926448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.076659857498725e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027446350455284117,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22297995537519455,
      "backward_entropy": 0.018864920487006505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709572340530713e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027446358092129232,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22297907024621963,
      "backward_entropy": 0.018951351816455523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199776284494419e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02744636554270983,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22297819554805756,
      "backward_entropy": 0.01948892958462238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848095815887745e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446372993290426,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22297735810279845,
      "backward_entropy": 0.01959569056828817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.029374833043221e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 65.0,
      "log_Z": 0.027446380443871023,
      "trajectory_length": 5.0,
      "branch_chosen": 1.9,
      "forward_entropy": 0.22297655045986176,
      "backward_entropy": 0.019578483824928602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.162549181316536e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446388080716134,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22297577410936356,
      "backward_entropy": 0.021018253887693086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.811631126562133e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027446395345032217,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.2229750171303749,
      "backward_entropy": 0.018883484477798147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.406243515082565e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027446402609348296,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22297428250312806,
      "backward_entropy": 0.02167931447426478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.593708341995352e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027446409687399864,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2229735732078552,
      "backward_entropy": 0.022072757532199224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2554782009318615e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027446416020393372,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2229728803038597,
      "backward_entropy": 0.021767560889323558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.209595194344274e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.02744642272591591,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22297221124172212,
      "backward_entropy": 0.022905933360258736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.742042648331335e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 32.0,
      "log_Z": 0.027446428872644903,
      "trajectory_length": 5.0,
      "branch_chosen": 1.0,
      "forward_entropy": 0.22297155857086182,
      "backward_entropy": 0.019036235039432844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6618869706804846e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027446435019373893,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2229709357023239,
      "backward_entropy": 0.020419794569412862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.643908802393071e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.027446440979838373,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22297031581401824,
      "backward_entropy": 0.019068094218770665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4431299741631845e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02744644694030285,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.2229697272181511,
      "backward_entropy": 0.019101903090874357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0771310025888854e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027446452341973782,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2229691430926323,
      "backward_entropy": 0.021182975793878237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.980071653586492e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.02744645792990923,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22296856790781022,
      "backward_entropy": 0.018283686911066376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.377103081765199e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.027446463145315646,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2229679986834526,
      "backward_entropy": 0.019324604297677676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.090374534333364e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.027446467988193037,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22296744585037231,
      "backward_entropy": 0.019796305273969972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0174175016384195e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 41.0,
      "log_Z": 0.027446472458541392,
      "trajectory_length": 5.0,
      "branch_chosen": 1.1,
      "forward_entropy": 0.22296689599752426,
      "backward_entropy": 0.022142376502354937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.155679472399697e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 58.0,
      "log_Z": 0.027446476556360722,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22296635508537294,
      "backward_entropy": 0.019274216641982398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.941589698934877e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.02744648102670908,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2229658454656601,
      "backward_entropy": 0.021071789537866915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3644911912867882e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027446485497057437,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22296534478664398,
      "backward_entropy": 0.020443895210822426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0877786336702686e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744648978114128,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22296485900878907,
      "backward_entropy": 0.02041546752055486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2527804244276695e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027446493878960608,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229643940925598,
      "backward_entropy": 0.020165435845653217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9404416839184934e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027446497790515424,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.22296394407749176,
      "backward_entropy": 0.018677818278471627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.469328112653102e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446501515805723,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22296349853277206,
      "backward_entropy": 0.019210537771383922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3382849718700526e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446505054831503,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22296305894851684,
      "backward_entropy": 0.018159396573901174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.491276891447569e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 55.0,
      "log_Z": 0.027446508593857288,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.222962649166584,
      "backward_entropy": 0.018917364006241163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2854836885244366e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027446511760354043,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22296223789453506,
      "backward_entropy": 0.021134623015920322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.211349364955595e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027446514926850796,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2229618400335312,
      "backward_entropy": 0.020745951433976492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8691522818414796e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027446518093347548,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229614481329918,
      "backward_entropy": 0.018875852227211002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1678384456436107e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027446521259844304,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22296105921268464,
      "backward_entropy": 0.01888563980658849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1998151744639927e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027446524426341056,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2229606866836548,
      "backward_entropy": 0.019348183274269105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2562698891448464e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744652722030878,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22296031862497329,
      "backward_entropy": 0.01916911751031876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5538007875903758e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744652982801199,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22295995354652404,
      "backward_entropy": 0.019717951491475105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.439402264935552e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 39.0,
      "log_Z": 0.027446532063186167,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22295961230993272,
      "backward_entropy": 0.021078075965245566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2897730314875843e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 59.0,
      "log_Z": 0.02744653429836035,
      "trajectory_length": 5.0,
      "branch_chosen": 1.7,
      "forward_entropy": 0.222959266602993,
      "backward_entropy": 0.018383656069636344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.370026373237465e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 47.0,
      "log_Z": 0.02744653671979904,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2229589357972145,
      "backward_entropy": 0.02090475435058276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2039410606234925e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02744653932750225,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22295862287282944,
      "backward_entropy": 0.020597587525844573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0932096046190054e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.02744654193520546,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22295831739902497,
      "backward_entropy": 0.02056431323289871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3231420119552696e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.027446544729173183,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.2229580268263817,
      "backward_entropy": 0.021338411048054694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1656288094741285e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446547336876393,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22295773327350615,
      "backward_entropy": 0.019447527080774307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0714980653858675e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 52.0,
      "log_Z": 0.02744654957205057,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2229574516415596,
      "backward_entropy": 0.020169172435998917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.520178210209451e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027446551993489266,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22295718491077424,
      "backward_entropy": 0.019219975670178732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.408577087948287e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446554228663444,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22295692712068557,
      "backward_entropy": 0.020206951722502708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514457014996423e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 64.0,
      "log_Z": 0.027446556836366653,
      "trajectory_length": 5.0,
      "branch_chosen": 1.8,
      "forward_entropy": 0.22295666188001634,
      "backward_entropy": 0.019262662281592687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0312059863792911e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 44.0,
      "log_Z": 0.02744655907154083,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.2229564219713211,
      "backward_entropy": 0.01845567213992278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145758035344898e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 26.0,
      "log_Z": 0.027446561306715012,
      "trajectory_length": 5.0,
      "branch_chosen": 0.8,
      "forward_entropy": 0.22295618802309036,
      "backward_entropy": 0.021178811664382614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018267418918868e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 38.0,
      "log_Z": 0.02744656354188919,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.2229559451341629,
      "backward_entropy": 0.020101726676026978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.822038868316895e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.02744656577706337,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.22295572608709335,
      "backward_entropy": 0.019656168793638545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0396323713024458e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 43.0,
      "log_Z": 0.02744656801223755,
      "trajectory_length": 5.0,
      "branch_chosen": 1.3,
      "forward_entropy": 0.22295551151037216,
      "backward_entropy": 0.0198458361128966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.729749895129089e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 31.0,
      "log_Z": 0.027446570061147212,
      "trajectory_length": 5.0,
      "branch_chosen": 0.9,
      "forward_entropy": 0.22295529693365096,
      "backward_entropy": 0.018813957646489143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0204771658806066e-07,
      "terminal_state_reached": 1.0,
      "terminal_reward": 50.0,
      "log_Z": 0.027446572110056876,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2229550838470459,
      "backward_entropy": 0.019631634280085564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.056044299957876e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 54.0,
      "log_Z": 0.027446573972702025,
      "trajectory_length": 5.0,
      "branch_chosen": 1.6,
      "forward_entropy": 0.2229548767209053,
      "backward_entropy": 0.01979528951148192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.004538939980876e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027446575835347174,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22295468747615815,
      "backward_entropy": 0.018871261800328894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.120716875557263e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02744657751172781,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229544922709465,
      "backward_entropy": 0.019725562632083894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.148339141669567e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.027446579188108444,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.2229543000459671,
      "backward_entropy": 0.020120647301276526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.331633173317641e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 53.0,
      "log_Z": 0.027446581050753593,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22295411974191665,
      "backward_entropy": 0.02136719450354576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032011619083733e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 49.0,
      "log_Z": 0.02744658272713423,
      "trajectory_length": 5.0,
      "branch_chosen": 1.5,
      "forward_entropy": 0.22295394390821457,
      "backward_entropy": 0.020052552968263627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.315116412025645e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027446584217250346,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22295376807451248,
      "backward_entropy": 0.019316876803835235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8343065312271844e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 48.0,
      "log_Z": 0.027446585707366467,
      "trajectory_length": 5.0,
      "branch_chosen": 1.4,
      "forward_entropy": 0.22295359671115875,
      "backward_entropy": 0.019510787228743234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.565819248294247e-08,
      "terminal_state_reached": 1.0,
      "terminal_reward": 42.0,
      "log_Z": 0.027446586824953555,
      "trajectory_length": 5.0,
      "branch_chosen": 1.2,
      "forward_entropy": 0.22295343577861787,
      "backward_entropy": 0.021599639331301053,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.029168999536978e-06,
    "avg_log_Z": 0.027446357082575562,
    "success_rate": 1.0,
    "avg_reward": 49.269999999999996,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.16299999999999998,
      "1": 0.21900000000000003,
      "2": 0.618
    },
    "avg_forward_entropy": 0.22297864264249806,
    "avg_backward_entropy": 0.019886452789107955,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}