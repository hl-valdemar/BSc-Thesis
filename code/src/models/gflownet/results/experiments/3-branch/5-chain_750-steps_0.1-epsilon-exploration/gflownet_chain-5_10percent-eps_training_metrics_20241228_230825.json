{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13856472969055175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13862876892089843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.42822265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233092625935873,
      "backward_entropy": 0.13860559463500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.38490295410156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182320237159729,
      "backward_entropy": 0.1385645866394043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.68380737304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00020000000949949026,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18230919043223062,
      "backward_entropy": 0.13860819339752198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.63673400878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003000808064825833,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822977066040039,
      "backward_entropy": 0.1386094570159912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.07398986816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00040055549470707774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822858452796936,
      "backward_entropy": 0.13861067295074464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.873779296875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0004998840158805251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18227400382359824,
      "backward_entropy": 0.13856322765350343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.47781372070312,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0006001144647598267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18226162592569986,
      "backward_entropy": 0.13856277465820313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.4481658935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006959841120988131,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18224958578745523,
      "backward_entropy": 0.13861358165740967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.86036682128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007932038861326873,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18223696947097778,
      "backward_entropy": 0.13861438035964965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.67330932617188,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.000892382173333317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822239557902018,
      "backward_entropy": 0.13855977058410646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.26527404785156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0009898251155391335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18221092224121094,
      "backward_entropy": 0.13862746953964233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.0765838623047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0010855119908228517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821979284286499,
      "backward_entropy": 0.13862744569778443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.84640502929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001182079897262156,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821844975153605,
      "backward_entropy": 0.1386164665222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.46583557128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001279233954846859,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821707288424174,
      "backward_entropy": 0.13861685991287231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.63449096679688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0013783285394310951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18215628465016684,
      "backward_entropy": 0.13855061531066895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.54611206054688,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0014759117038920522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18214150269826254,
      "backward_entropy": 0.13862743377685546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.25927734375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0015754809137433767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18212572733561197,
      "backward_entropy": 0.13862742185592652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.8672332763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001678147935308516,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18210899829864502,
      "backward_entropy": 0.1386183261871338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.48814392089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017787821125239134,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820917328198751,
      "backward_entropy": 0.13861868381500245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.77694702148438,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0018815958173945546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207383155822754,
      "backward_entropy": 0.13862732648849488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.9271240234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001982250716537237,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18205535411834717,
      "backward_entropy": 0.1386193037033081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.4139862060547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002085361396893859,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18203572432200113,
      "backward_entropy": 0.13861963748931885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.99754333496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021893056109547615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18201535940170288,
      "backward_entropy": 0.1386199712753296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.38540649414062,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.002295242389664054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18199398120244345,
      "backward_entropy": 0.13862712383270265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.21641540527344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0024025514721870422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18197202682495117,
      "backward_entropy": 0.13852994441986083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.6375732421875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.002512833569198847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18194913864135742,
      "backward_entropy": 0.1385283350944519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.89639282226562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.002623829524964094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18192549546559653,
      "backward_entropy": 0.13862686157226561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.21922302246094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.002737105591222644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18190109729766846,
      "backward_entropy": 0.13862674236297606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.90211486816406,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0028461001347750425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818766991297404,
      "backward_entropy": 0.1385228753089905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.3629608154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0029555081855505705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18185188372929892,
      "backward_entropy": 0.13862236738204955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.07568359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003062567440792918,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18182690938313803,
      "backward_entropy": 0.13862249851226807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.92774963378906,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0031659407541155815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18180189530054727,
      "backward_entropy": 0.1386268377304077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.6615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032730528619140387,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817756493886312,
      "backward_entropy": 0.13862264156341553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.33665466308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033807065337896347,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817490061124166,
      "backward_entropy": 0.13862268924713134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.13552856445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034824085887521505,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817228396733602,
      "backward_entropy": 0.13862264156341553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.09056091308594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0035838144831359386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18169647455215454,
      "backward_entropy": 0.13849761486053466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.19091796875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0036813223268836737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816705862681071,
      "backward_entropy": 0.13862757682800292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 298.3264465332031,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.003782240441069007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18164350589116415,
      "backward_entropy": 0.13862777948379518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.4840850830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003890116000548005,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18161455790201822,
      "backward_entropy": 0.13862215280532836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.78451538085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003998246509581804,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1815850337346395,
      "backward_entropy": 0.13862206935882568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.54591369628906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.004105605650693178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815546751022339,
      "backward_entropy": 0.1384702205657959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.91493225097656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.004213372711092234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815236210823059,
      "backward_entropy": 0.13846449851989745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.004317122511565685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18149236838022867,
      "backward_entropy": 0.13862850666046142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.1029815673828,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.004418424796313047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18146119515101114,
      "backward_entropy": 0.13845160007476806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.21286010742188,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.004522522445768118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814286708831787,
      "backward_entropy": 0.13844504356384277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.88856506347656,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.004630211740732193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18139477570851645,
      "backward_entropy": 0.13862890005111694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.60569763183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0047353156842291355,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18136056264241537,
      "backward_entropy": 0.13862125873565673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.21456909179688,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.004840620793402195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18132621049880981,
      "backward_entropy": 0.13862910270690917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.73660278320312,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.004943158943206072,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812919576962789,
      "backward_entropy": 0.13862922191619872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.79421997070312,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.005049386061728001,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18125633398691812,
      "backward_entropy": 0.13840811252593993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.1024169921875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005149444565176964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812212864557902,
      "backward_entropy": 0.13862936496734618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3665313720703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005250716581940651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18118526538213095,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.221923828125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005344368517398834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18115049600601196,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.8124542236328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005433493293821812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18111568689346313,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.09873962402344,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005527670029550791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18107978502909342,
      "backward_entropy": 0.13862931728363037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.10897827148438,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0056224968284368515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810427705446879,
      "backward_entropy": 0.1383469820022583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 267.72149658203125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005720658227801323,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18100444475809732,
      "backward_entropy": 0.13862903118133546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.6123046875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.005823986139148474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18096490701039633,
      "backward_entropy": 0.13832523822784423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.82760620117188,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.005925219506025314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18092477321624756,
      "backward_entropy": 0.13862849473953248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.12098693847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006030138116329908,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18088428179423013,
      "backward_entropy": 0.13861572742462158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.74099731445312,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0061324723064899445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18084406852722168,
      "backward_entropy": 0.13862767219543456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.1986083984375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.006234413478523493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18080190817515054,
      "backward_entropy": 0.13862714767456055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.4749298095703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.006334212608635426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807591120402018,
      "backward_entropy": 0.13862650394439696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.36807250976562,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.006430065259337425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18071643511454263,
      "backward_entropy": 0.13825310468673707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.48686981201172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.006526111159473658,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18067272504170737,
      "backward_entropy": 0.13862476348876954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.8662872314453,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.006613716948777437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18062961101531982,
      "backward_entropy": 0.13862361907958984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.68028259277344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.00670212646946311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1805857022603353,
      "backward_entropy": 0.1382091760635376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.2609558105469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006784738972783089,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1805419127146403,
      "backward_entropy": 0.13860952854156494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.1626434326172,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0068767559714615345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180495023727417,
      "backward_entropy": 0.13817853927612306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.85450744628906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.006965527776628733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18044918775558472,
      "backward_entropy": 0.1381627321243286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.6860122680664,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.00704953633248806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18040448427200317,
      "backward_entropy": 0.13814539909362794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.3231201171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007125696633011103,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18036083380381265,
      "backward_entropy": 0.13860514163970947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.03766632080078,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0072059971280395985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18031525611877441,
      "backward_entropy": 0.13810832500457765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.09707641601562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0072782919742167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18027130762736002,
      "backward_entropy": 0.13860757350921632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.70620727539062,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.00735589349642396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1802259882291158,
      "backward_entropy": 0.1386043906211853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.41500854492188,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.00743561377748847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1801792581876119,
      "backward_entropy": 0.13860102891921997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.51565551757812,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0075154597871005535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18013165394465128,
      "backward_entropy": 0.13859741687774657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.63755798339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007593903224915266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18008333444595337,
      "backward_entropy": 0.13859571218490602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.46096801757812,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.007666958495974541,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18003563086191812,
      "backward_entropy": 0.13798172473907472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.1669158935547,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.007742701563984156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17998645702997842,
      "backward_entropy": 0.13858456611633302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.9681854248047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.007817333564162254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17993668715159097,
      "backward_entropy": 0.1385796546936035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8570098876953,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.007895874790847301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17988550662994385,
      "backward_entropy": 0.13791189193725586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.23609924316406,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.00797112938016653,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798343062400818,
      "backward_entropy": 0.1378868818283081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.75978088378906,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008044720627367496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17978322505950928,
      "backward_entropy": 0.1385621428489685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9054718017578,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.008117303252220154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17973162730534872,
      "backward_entropy": 0.13783271312713624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6602325439453,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008185557089745998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17968002955118814,
      "backward_entropy": 0.1385475754737854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.94691467285156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008251568302512169,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17962821324666342,
      "backward_entropy": 0.13853942155838012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.57884216308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00832290668040514,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1795742909113566,
      "backward_entropy": 0.13857319355010986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.9812774658203,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.008389877155423164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1795206069946289,
      "backward_entropy": 0.13771452903747558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.71253967285156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008463922888040543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17946426073710123,
      "backward_entropy": 0.13851324319839478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.37767028808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00853266753256321,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1794090469678243,
      "backward_entropy": 0.13856496810913085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.61892700195312,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008600950241088867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1793532371520996,
      "backward_entropy": 0.13849303722381592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.0303497314453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008664488792419434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1792983611424764,
      "backward_entropy": 0.1385584831237793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.49795532226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008729761466383934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17924241224924722,
      "backward_entropy": 0.13855502605438233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.0217056274414,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008791431784629822,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17918614546457926,
      "backward_entropy": 0.1384572982788086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.04396057128906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.008843549527227879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791316270828247,
      "backward_entropy": 0.13746973276138305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.4964141845703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.008898774161934853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17907551924387613,
      "backward_entropy": 0.13842949867248536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.5994644165039,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.008953440003097057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1790183981259664,
      "backward_entropy": 0.13738861083984374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.80894470214844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.009002923965454102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1789622108141581,
      "backward_entropy": 0.13734554052352904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.6665267944336,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009051927365362644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17890548706054688,
      "backward_entropy": 0.13838441371917726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.41468811035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009092332795262337,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1788505514462789,
      "backward_entropy": 0.13852503299713134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.3217544555664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009135772474110126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17879350980122885,
      "backward_entropy": 0.13835008144378663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.9290008544922,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009172934107482433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17873791853586832,
      "backward_entropy": 0.13833154439926149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.76559448242188,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009212279692292213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17868143320083618,
      "backward_entropy": 0.13831233978271484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.50729370117188,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009256403893232346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1786226232846578,
      "backward_entropy": 0.13829290866851807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.15900421142578,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009308590553700924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17856059471766153,
      "backward_entropy": 0.13827359676361084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.5077362060547,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009354549460113049,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1784992218017578,
      "backward_entropy": 0.13825318813323975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.31736755371094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009398488327860832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17843735218048096,
      "backward_entropy": 0.13823177814483642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.68882751464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009446640498936176,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17837289969126383,
      "backward_entropy": 0.13848304748535156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.4619140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00949490163475275,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1783070762952169,
      "backward_entropy": 0.13847763538360597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.5077362060547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.009549234993755817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17823821306228638,
      "backward_entropy": 0.1367438793182373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.4546356201172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009600941091775894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17816909154256186,
      "backward_entropy": 0.13814172744750977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.9245147705078,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.009655637666583061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1780986189842224,
      "backward_entropy": 0.1366328001022339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.460205078125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009711452759802341,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17802693446477255,
      "backward_entropy": 0.1380922317504883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.0443115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00976882129907608,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1779534419377645,
      "backward_entropy": 0.138451087474823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.2605743408203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.009829367510974407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1778778632481893,
      "backward_entropy": 0.1380390405654907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.2581024169922,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.009897065348923206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17779852946599325,
      "backward_entropy": 0.13640141487121582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.29730224609375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.009964270517230034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17771889766057333,
      "backward_entropy": 0.13633928298950196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.8709259033203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01002561952918768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17764015992482504,
      "backward_entropy": 0.13795316219329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.79349517822266,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010083516128361225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1775620182355245,
      "backward_entropy": 0.13792113065719605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.8064727783203,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010136083699762821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17748610178629556,
      "backward_entropy": 0.13613474369049072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.4906997680664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010192588903009892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17740760246912637,
      "backward_entropy": 0.13785279989242555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.04965209960938,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010242397896945477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17733017603556314,
      "backward_entropy": 0.13598639965057374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.99665069580078,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010293756611645222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17725157737731934,
      "backward_entropy": 0.135906982421875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.3256378173828,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010340789332985878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17717347542444864,
      "backward_entropy": 0.13773937225341798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.65892028808594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010387840680778027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17709439992904663,
      "backward_entropy": 0.13574023246765138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.5384521484375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010437504388391972,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.177013099193573,
      "backward_entropy": 0.13765711784362794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.38360595703125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01049298606812954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17692895730336508,
      "backward_entropy": 0.13557274341583253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.33099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01054337341338396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17684765656789145,
      "backward_entropy": 0.13548493385314941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.48358154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010589158162474632,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1767672300338745,
      "backward_entropy": 0.13834656476974488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.59866333007812,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010630974546074867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1766873598098755,
      "backward_entropy": 0.13529905080795288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.24838256835938,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010671684518456459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17660663525263467,
      "backward_entropy": 0.13742713928222655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.81649780273438,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01071575004607439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1765233874320984,
      "backward_entropy": 0.1373767852783203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.31588745117188,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01076022069901228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17643914620081583,
      "backward_entropy": 0.13500745296478273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.2450408935547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.010807898826897144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17635230223337808,
      "backward_entropy": 0.13490865230560303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.06251525878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010858479887247086,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17626309394836426,
      "backward_entropy": 0.13828837871551514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.0375518798828,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.010905994102358818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17617470026016235,
      "backward_entropy": 0.13716397285461426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.05430603027344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01095170620828867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1760859489440918,
      "backward_entropy": 0.13459824323654174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.79197692871094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0109934713691473,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1759986678759257,
      "backward_entropy": 0.1344873785972595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.6164779663086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01102754008024931,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17591184377670288,
      "backward_entropy": 0.13824474811553955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.4940948486328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01105603575706482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17582754294077554,
      "backward_entropy": 0.13691978454589843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.7379913330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011086761020123959,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1757412552833557,
      "backward_entropy": 0.13821883201599122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.83590698242188,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01111735962331295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17565321922302246,
      "backward_entropy": 0.13678646087646484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.7485809326172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011151966638863087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17556118965148926,
      "backward_entropy": 0.1367180109024048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.87580871582031,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011195006780326366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17546365658442178,
      "backward_entropy": 0.13376847505569459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.35293579101562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011234570294618607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17536606391270956,
      "backward_entropy": 0.13658233880996704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.66590881347656,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011281898245215416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17526360352834067,
      "backward_entropy": 0.1365140438079834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.8560791015625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011330835521221161,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17515973250071207,
      "backward_entropy": 0.1333756446838379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.2664566040039,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011382395401597023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17505319913228354,
      "backward_entropy": 0.1363762617111206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.85420227050781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011430257000029087,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17494658629099527,
      "backward_entropy": 0.13812320232391356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.1273651123047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011470982804894447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.174842635790507,
      "backward_entropy": 0.13622725009918213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.60183715820312,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011510666459798813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17473785082499185,
      "backward_entropy": 0.13280680179595947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.24781799316406,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011550618335604668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1746322512626648,
      "backward_entropy": 0.13265206813812255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.91127014160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011592408642172813,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17452404896418253,
      "backward_entropy": 0.13806991577148436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.20602416992188,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01163308136165142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17441614468892416,
      "backward_entropy": 0.13233914375305175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.94908142089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011678917333483696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17430265744527182,
      "backward_entropy": 0.1380429148674011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.63809204101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011727637611329556,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17418752113978067,
      "backward_entropy": 0.13802990913391114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.93504333496094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.011778771877288818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17407011985778809,
      "backward_entropy": 0.1356410026550293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0762939453125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011839071288704872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1739467978477478,
      "backward_entropy": 0.13169234991073608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.56565856933594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01189345121383667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17382589975992838,
      "backward_entropy": 0.1315218210220337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.8007049560547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.011947317980229855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1737052003542582,
      "backward_entropy": 0.1313463568687439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.74776458740234,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.012007802724838257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17357981204986572,
      "backward_entropy": 0.1352764368057251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.33273315429688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012060518376529217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17345734437306723,
      "backward_entropy": 0.1309884548187256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.19798278808594,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01212228648364544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17332879702250162,
      "backward_entropy": 0.1350806474685669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.48130798339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012182824313640594,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17319985230763754,
      "backward_entropy": 0.13792891502380372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.64723205566406,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.012240859679877758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17307122548421225,
      "backward_entropy": 0.13487756252288818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.42298889160156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012301228940486908,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1729386250178019,
      "backward_entropy": 0.13024569749832154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.2689666748047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01236703060567379,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17280272642771402,
      "backward_entropy": 0.1346726894378662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.31179809570312,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.012431631796061993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17266619205474854,
      "backward_entropy": 0.13456871509552001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.8227996826172,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012508023530244827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1725220282872518,
      "backward_entropy": 0.12966588735580445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.3699493408203,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012580163776874542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1723787784576416,
      "backward_entropy": 0.12946751117706298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.9502410888672,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012656881473958492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17223177353541055,
      "backward_entropy": 0.1292670726776123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.96876525878906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01272872556000948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17208649714787802,
      "backward_entropy": 0.12906267642974853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.73536682128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012802503071725368,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17193917433420816,
      "backward_entropy": 0.13782036304473877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.91360473632812,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.012873506173491478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17179258664449057,
      "backward_entropy": 0.13390851020812988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.45138549804688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.012945763766765594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17164373397827148,
      "backward_entropy": 0.12841081619262695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2244110107422,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01301620528101921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1714949607849121,
      "backward_entropy": 0.13366153240203857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.4778289794922,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013087592087686062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17134501536687216,
      "backward_entropy": 0.13353488445281983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.74337768554688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.013168076984584332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17118660608927408,
      "backward_entropy": 0.12773497104644777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.31396484375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.013243740424513817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17103073994318643,
      "backward_entropy": 0.12750394344329835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.04930114746094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01332118920981884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17087272802988687,
      "backward_entropy": 0.12726666927337646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.4872817993164,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01339829619973898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1707137624422709,
      "backward_entropy": 0.1330207347869873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.0478973388672,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01346625667065382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1705592672030131,
      "backward_entropy": 0.12676892280578614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.289306640625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013535039499402046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17040292421976724,
      "backward_entropy": 0.1327319860458374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.67420959472656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01359937060624361,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17024850845336914,
      "backward_entropy": 0.12624063491821289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.44188690185547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.013653317466378212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17009969552357992,
      "backward_entropy": 0.12595994472503663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.02572631835938,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013699757866561413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16995481650034586,
      "backward_entropy": 0.13225066661834717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.37161254882812,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01374679896980524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16980824867884317,
      "backward_entropy": 0.13207911252975463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.46733093261719,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013791948556900024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16966267426808676,
      "backward_entropy": 0.1319029450416565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.9282989501953,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0138335470110178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16951709985733032,
      "backward_entropy": 0.12476050853729248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.81062316894531,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.013873602263629436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1693705916404724,
      "backward_entropy": 0.12444610595703125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.21459197998047,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01390937902033329,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16922728220621744,
      "backward_entropy": 0.12411983013153076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.60993957519531,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013945433311164379,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16908204555511475,
      "backward_entropy": 0.13115293979644777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.2762908935547,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.013975514099001884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16894014676411948,
      "backward_entropy": 0.13095133304595946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.18206787109375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014007914811372757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16879538695017496,
      "backward_entropy": 0.12311725616455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.60333251953125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014037423767149448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1686521569887797,
      "backward_entropy": 0.1305375576019287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.95143127441406,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01406180765479803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16851125160853067,
      "backward_entropy": 0.13032248020172119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.13677978515625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014089120551943779,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16836607456207275,
      "backward_entropy": 0.13010599613189697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.57484436035156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014117201790213585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16821960608164468,
      "backward_entropy": 0.12988545894622802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.42259216308594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014143465086817741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16807317733764648,
      "backward_entropy": 0.12132757902145386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.4027099609375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0141702089458704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16792519887288412,
      "backward_entropy": 0.12942798137664796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.10801696777344,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014204724691808224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16777026653289795,
      "backward_entropy": 0.12919726371765136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.28778839111328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014250335283577442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16760619481404623,
      "backward_entropy": 0.12896983623504638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.72935485839844,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014286517165601254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16744891802469888,
      "backward_entropy": 0.1287311792373657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.35340881347656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014322024770081043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.167290469010671,
      "backward_entropy": 0.1194380521774292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.44094848632812,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01435672864317894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16713162263234457,
      "backward_entropy": 0.1282339572906494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.26032257080078,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014393867924809456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.166969895362854,
      "backward_entropy": 0.12797715663909912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.5914306640625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014427942223846912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16680959860483804,
      "backward_entropy": 0.11821901798248291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.28633117675781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014463300816714764,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1666476329167684,
      "backward_entropy": 0.13694770336151124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.48458099365234,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014494486153125763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16648664077123007,
      "backward_entropy": 0.11736228466033935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.0183868408203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014523633755743504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16632596651713052,
      "backward_entropy": 0.12688241004943848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.89027404785156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014555227942764759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16616169611612955,
      "backward_entropy": 0.11648657321929931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2803955078125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014589043334126472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1659951110680898,
      "backward_entropy": 0.11603916883468628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.38391876220703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014626795426011086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16582475105921426,
      "backward_entropy": 0.12601170539855958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.49452209472656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0146567327901721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1656596064567566,
      "backward_entropy": 0.11512339115142822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.679447174072266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014689099043607712,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1654913822809855,
      "backward_entropy": 0.1366971492767334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.2006072998047,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014705941081047058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16533548633257547,
      "backward_entropy": 0.11416165828704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.18993377685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014724155887961388,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16517722606658936,
      "backward_entropy": 0.1366102695465088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.5992431640625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014742097817361355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16501784324645996,
      "backward_entropy": 0.11316827535629273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.82823181152344,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014775780960917473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16484447320302328,
      "backward_entropy": 0.12402235269546509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.69224548339844,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01480685081332922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1646725336710612,
      "backward_entropy": 0.12367706298828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.70269775390625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014840291813015938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16449791193008423,
      "backward_entropy": 0.12332751750946044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.89822387695312,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.014872901141643524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16432363788286844,
      "backward_entropy": 0.12297098636627198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.71548461914062,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014915172941982746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16414054234822592,
      "backward_entropy": 0.1106576919555664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.86836242675781,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014955977909266949,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16395927468935648,
      "backward_entropy": 0.11013318300247192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.08797454833984,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.014995683915913105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16377745072046915,
      "backward_entropy": 0.10959985256195068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.2132110595703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015032251365482807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16359668970108032,
      "backward_entropy": 0.121501624584198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.76748657226562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015070324763655663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16341322660446167,
      "backward_entropy": 0.12111555337905884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.69843292236328,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015113377012312412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1632252335548401,
      "backward_entropy": 0.10796797275543213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.7316436767578,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015152997337281704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1630395253499349,
      "backward_entropy": 0.10741573572158813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.7366714477539,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015199403278529644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16284720102945963,
      "backward_entropy": 0.1199386477470398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.77596282958984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01524228323251009,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16265708208084106,
      "backward_entropy": 0.13606854677200317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.01172637939453,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015284590423107147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16246668497721353,
      "backward_entropy": 0.11912052631378174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.956844329833984,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015324857085943222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622768541177114,
      "backward_entropy": 0.10518522262573242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.7784652709961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015348647721111774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16210208336512247,
      "backward_entropy": 0.13593809604644774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.63224792480469,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015363328158855438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619350810845693,
      "backward_entropy": 0.10398645401000976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6295623779297,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015374827198684216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177034378051758,
      "backward_entropy": 0.10336878299713134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.50598907470703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015390461310744286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16160271565119425,
      "backward_entropy": 0.11685941219329835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.5377197265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015405464917421341,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16143697500228882,
      "backward_entropy": 0.1357142448425293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.1186981201172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015429500490427017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1612635056177775,
      "backward_entropy": 0.11591038703918458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.97625732421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015457121655344963,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1610847512880961,
      "backward_entropy": 0.13561108112335205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.20127868652344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01548099610954523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16090776522954306,
      "backward_entropy": 0.10024175643920899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.49320220947266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015501078218221664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16073421637217203,
      "backward_entropy": 0.09961123466491699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.69229888916016,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015519959852099419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16056135296821594,
      "backward_entropy": 0.11396912336349488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.09822082519531,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015537350438535213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16038969159126282,
      "backward_entropy": 0.11346120834350586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.73236083984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015547911636531353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16022481520970663,
      "backward_entropy": 0.13532620668411255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.64839172363281,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01555804442614317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600598692893982,
      "backward_entropy": 0.09696534872055054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.48894500732422,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015571728348731995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15989051262537637,
      "backward_entropy": 0.11188015937805176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.7273406982422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015587999485433102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1597172518571218,
      "backward_entropy": 0.09562889337539673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.85031127929688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015614088624715805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15953266620635986,
      "backward_entropy": 0.09497300386428834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.93866729736328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01564859226346016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15934025247891745,
      "backward_entropy": 0.11030962467193603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.55403900146484,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01567711867392063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15915462374687195,
      "backward_entropy": 0.10977575778961182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.97898864746094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015707261860370636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15896652142206827,
      "backward_entropy": 0.09298722743988037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.58607482910156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01573210023343563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1587841510772705,
      "backward_entropy": 0.09229646921157837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.05323791503906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015753233805298805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15860499938329062,
      "backward_entropy": 0.09159719944000244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.4067840576172,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01577349193394184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15842642386754355,
      "backward_entropy": 0.0908923625946045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.27044677734375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015800710767507553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15824135144551596,
      "backward_entropy": 0.09019430875778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.21613311767578,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015831584110856056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15805254379908243,
      "backward_entropy": 0.10637475252151489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.61268615722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01586047187447548,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15786508719126383,
      "backward_entropy": 0.13459054231643677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.5472412109375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01589003950357437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1576764980951945,
      "backward_entropy": 0.10520446300506592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.99207305908203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015924157574772835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15748490889867148,
      "backward_entropy": 0.10461950302124023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.44447326660156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.015958907082676888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15729121367136636,
      "backward_entropy": 0.10403132438659668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.49971008300781,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.015994038432836533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15709603826204935,
      "backward_entropy": 0.0860182523727417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.59571075439453,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016024192795157433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1569055120150248,
      "backward_entropy": 0.10282655954360961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.4254150390625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016047831624746323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15672087669372559,
      "backward_entropy": 0.08458546400070191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.49311828613281,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016067232936620712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15654165546099344,
      "backward_entropy": 0.08385310173034669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.08634185791016,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016085734590888023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15636380513509116,
      "backward_entropy": 0.08311254978179931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.59285736083984,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016103874891996384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15618673960367838,
      "backward_entropy": 0.08237006664276122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.89115142822266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016123764216899872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15600765744845072,
      "backward_entropy": 0.08162214159965515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.40350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016134895384311676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15583711862564087,
      "backward_entropy": 0.08085916638374328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.40287780761719,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016145823523402214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15566539764404297,
      "backward_entropy": 0.08009060025215149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.05261993408203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01615162193775177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15549858411153158,
      "backward_entropy": 0.09760733842849731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.0398406982422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016147634014487267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15534212191899618,
      "backward_entropy": 0.0785287857055664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.5174789428711,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01615125685930252,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1551764408747355,
      "backward_entropy": 0.09621481895446778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.62594604492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016153672710061073,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15501252810160318,
      "backward_entropy": 0.13350391387939453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.5035400390625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016165394335985184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15483708182970682,
      "backward_entropy": 0.0762306034564972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.73875427246094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01617659442126751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15466241041819254,
      "backward_entropy": 0.07546285390853882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.7656021118164,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016195017844438553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1544810930887858,
      "backward_entropy": 0.09344242811203003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.99372100830078,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01621316745877266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15430078903834024,
      "backward_entropy": 0.0927478551864624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.08363342285156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01623130962252617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541203260421753,
      "backward_entropy": 0.07316787838935852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9281997680664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016255289316177368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15393341581026712,
      "backward_entropy": 0.09135527014732361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.7033462524414,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016277898102998734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15374881029129028,
      "backward_entropy": 0.07166123390197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.78045654296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016300780698657036,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15356375773747763,
      "backward_entropy": 0.1329532742500305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.23192596435547,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016324957832694054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15337934096654257,
      "backward_entropy": 0.08925450444221497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.75479888916016,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016346389427781105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15319782495498657,
      "backward_entropy": 0.08854005336761475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.18302917480469,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01636473648250103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15301970640818277,
      "backward_entropy": 0.08781403303146362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.22527313232422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016386399045586586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15283934275309244,
      "backward_entropy": 0.06788654327392578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.31285095214844,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016410240903496742,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15265685319900513,
      "backward_entropy": 0.08636770248413086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.19664001464844,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016438156366348267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15247011184692383,
      "backward_entropy": 0.08565424680709839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.7234649658203,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016475558280944824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15227444966634116,
      "backward_entropy": 0.06566156148910522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.02544403076172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016516156494617462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15207799275716147,
      "backward_entropy": 0.08426047563552856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.326416015625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016549240797758102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15188985069592795,
      "backward_entropy": 0.06419026851654053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.5074462890625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016578728333115578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15170560280481973,
      "backward_entropy": 0.0828099012374878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6962127685547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01660563237965107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15152392784754434,
      "backward_entropy": 0.06270391941070556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.1412239074707,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016640227288007736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15133479237556458,
      "backward_entropy": 0.0813452124595642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.63182067871094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016662973910570145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15115869045257568,
      "backward_entropy": 0.08060064911842346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.88251495361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01668577454984188,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.150982936223348,
      "backward_entropy": 0.1320115566253662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.66631317138672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016700483858585358,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15081650018692017,
      "backward_entropy": 0.13192178010940553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.54185485839844,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016713805496692657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15065171321233115,
      "backward_entropy": 0.0783395528793335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.87517547607422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016733435913920403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15048001209894815,
      "backward_entropy": 0.05831285119056702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.09722900390625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016755657270550728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1503059963385264,
      "backward_entropy": 0.05759221911430359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.04561710357666,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01677837036550045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15013211965560913,
      "backward_entropy": 0.0761179804801941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.23875427246094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01678643375635147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14997371037801108,
      "backward_entropy": 0.0753517746925354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.08405303955078,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016795823350548744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14981484413146973,
      "backward_entropy": 0.07458796501159667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.7732925415039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016803933307528496,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14965838193893433,
      "backward_entropy": 0.13132121562957763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.68424987792969,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016814693808555603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14949911832809448,
      "backward_entropy": 0.07306109666824341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.81572723388672,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01682453230023384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1493414044380188,
      "backward_entropy": 0.05332424640655518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.80213165283203,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016837986186146736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14918129642804465,
      "backward_entropy": 0.052620673179626466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.8712158203125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016850121319293976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.149023175239563,
      "backward_entropy": 0.051920002698898314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.06464385986328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016866767778992653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1488607923189799,
      "backward_entropy": 0.07005584836006165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.04319763183594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016879960894584656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14870238304138184,
      "backward_entropy": 0.050553524494171144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.21758270263672,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016894083470106125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1485443413257599,
      "backward_entropy": 0.06856670379638671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.30248260498047,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01691264472901821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14838277300198874,
      "backward_entropy": 0.049206340312957765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.5470199584961,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016921155154705048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14823349316914877,
      "backward_entropy": 0.04852176308631897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.15071868896484,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016928236931562424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14808738231658936,
      "backward_entropy": 0.0478315681219101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.8997344970703,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.016932586207985878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14794421195983887,
      "backward_entropy": 0.0655556082725525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.7812728881836,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016947539523243904,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14779072999954224,
      "backward_entropy": 0.0464885413646698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.50199127197266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.016963912174105644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14763657251993814,
      "backward_entropy": 0.045834630727767944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.60435485839844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01698119193315506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14748317003250122,
      "backward_entropy": 0.04517938196659088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.94083404541016,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017002472653985023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14732744296391806,
      "backward_entropy": 0.044532525539398196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.94812774658203,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01702236197888851,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14717419942220053,
      "backward_entropy": 0.06192764639854431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.07945251464844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017032405361533165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14703241984049478,
      "backward_entropy": 0.04323740601539612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.82133483886719,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017042456194758415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14689119656880698,
      "backward_entropy": 0.042596441507339475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.79222106933594,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017054051160812378,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14675025145212808,
      "backward_entropy": 0.059733635187149046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.66343688964844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01706981658935547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1466067632039388,
      "backward_entropy": 0.04132051765918732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.5738754272461,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01709771528840065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14645286401112875,
      "backward_entropy": 0.05833995342254639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.34595489501953,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01713135652244091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14629557728767395,
      "backward_entropy": 0.05766620635986328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.02562713623047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017159966751933098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14614444971084595,
      "backward_entropy": 0.05698007345199585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.90917205810547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01718367449939251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14599947134653726,
      "backward_entropy": 0.03889922499656677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.64013671875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017214078456163406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1458495855331421,
      "backward_entropy": 0.05560550093650818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.72217559814453,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01723717525601387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1457077463467916,
      "backward_entropy": 0.03771674931049347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.7887954711914,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01726420782506466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14556376139322916,
      "backward_entropy": 0.05423671007156372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.46101379394531,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017286883667111397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1454253296057383,
      "backward_entropy": 0.05355115532875061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.0288314819336,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017316734418272972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14528165260950723,
      "backward_entropy": 0.035994327068328856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.68704605102539,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017344972118735313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14514067769050598,
      "backward_entropy": 0.052215808629989625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.34125518798828,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017363620921969414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14500985542933145,
      "backward_entropy": 0.05153698921203613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.65443420410156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017379743978381157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1448814868927002,
      "backward_entropy": 0.05085862874984741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.20066833496094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01739785633981228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14475245277086893,
      "backward_entropy": 0.05019079446792603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.01525115966797,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01741570420563221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14462495843569437,
      "backward_entropy": 0.049528443813323976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.01390075683594,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01743234694004059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1445008118947347,
      "backward_entropy": 0.032709750533103946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.82366943359375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017445635050535202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14438112576802573,
      "backward_entropy": 0.048207855224609374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.26061248779297,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01746891252696514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14425448576609293,
      "backward_entropy": 0.047569602727890015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.03311920166016,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017485767602920532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14413472016652426,
      "backward_entropy": 0.046920469403266905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.3382797241211,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01750815287232399,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14401113986968994,
      "backward_entropy": 0.04628277122974396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.61564636230469,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01752995140850544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1438892682393392,
      "backward_entropy": 0.030087870359420777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.21693420410156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017558978870511055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14376338322957358,
      "backward_entropy": 0.02959146201610565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.454833984375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017591465264558792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14363645513852438,
      "backward_entropy": 0.0291020929813385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.08966064453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01762421987950802,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14351141452789307,
      "backward_entropy": 0.12771637439727784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.7724380493164,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017655769363045692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14338862895965576,
      "backward_entropy": 0.028129154443740846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.476478576660156,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017694156616926193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14326149225234985,
      "backward_entropy": 0.027661868929862977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.1815071105957,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01772465743124485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14314299821853638,
      "backward_entropy": 0.042063665390014646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.05326843261719,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01774870790541172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14303096135457358,
      "backward_entropy": 0.026713073253631592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.52469253540039,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017779892310500145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14291503032048544,
      "backward_entropy": 0.040885326266288755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.45059967041016,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01780427247285843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14280611276626587,
      "backward_entropy": 0.02578902542591095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.72748565673828,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01783277466893196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14269540707270303,
      "backward_entropy": 0.025334107875823974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.18711853027344,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017855649814009666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14259004592895508,
      "backward_entropy": 0.03915584087371826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.430572509765625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017880216240882874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14248497287432352,
      "backward_entropy": 0.03859082162380219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.97880554199219,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.017902160063385963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14238287011782327,
      "backward_entropy": 0.02400113046169281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.71489715576172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.017926989123225212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14227940638860068,
      "backward_entropy": 0.03747683763504028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.18241119384766,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01794888637959957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14217954874038696,
      "backward_entropy": 0.02315208166837692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.9446792602539,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01797397993505001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420784592628479,
      "backward_entropy": 0.03639473915100098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.483909606933594,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01800507865846157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1419740617275238,
      "backward_entropy": 0.035873943567276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.1855697631836,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.018030691891908646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1418752670288086,
      "backward_entropy": 0.03534726500511169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.5290756225586,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01805582270026207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.141778697570165,
      "backward_entropy": 0.0348229318857193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.2383804321289,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.018086329102516174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14167978366216025,
      "backward_entropy": 0.021181632578372956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.307674407958984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0181211419403553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14157969752947488,
      "backward_entropy": 0.12640070915222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.44766998291016,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01815243810415268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14148362477620444,
      "backward_entropy": 0.020433001220226288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.74294662475586,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01819298416376114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14138304193814596,
      "backward_entropy": 0.032840588688850404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.69195556640625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.018227268010377884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14128804206848145,
      "backward_entropy": 0.03235629498958588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.187110900878906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01826833002269268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14118982354799905,
      "backward_entropy": 0.01935293972492218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.5120620727539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01830568164587021,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14109563827514648,
      "backward_entropy": 0.12615928649902344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.5502471923828,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01834998093545437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14099876085917154,
      "backward_entropy": 0.018663258850574495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.30574035644531,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01840614341199398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14089603225390115,
      "backward_entropy": 0.018340182304382325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.58338928222656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01846555806696415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14079289635022482,
      "backward_entropy": 0.018026812374591826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.8226089477539,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01853547990322113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14068504174550375,
      "backward_entropy": 0.029691672325134276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.8043441772461,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.018603792414069176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14058059453964233,
      "backward_entropy": 0.017430734634399415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.9269027709961,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.018678996711969376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14047410090764365,
      "backward_entropy": 0.01714245080947876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.773054122924805,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.018755851313471794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1403684119383494,
      "backward_entropy": 0.028499430418014525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.09803771972656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.018821367993950844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1402712861696879,
      "backward_entropy": 0.01657990962266922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.139129638671875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.018893951550126076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1401719649632772,
      "backward_entropy": 0.02771006226539612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.00557708740234,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.018957417458295822,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14008037249247232,
      "backward_entropy": 0.02731407284736633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.95771026611328,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019017569720745087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1399927536646525,
      "backward_entropy": 0.026918002963066102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.261871337890625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01908014714717865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13990541299184164,
      "backward_entropy": 0.026529860496520997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.23179626464844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019137753173708916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1398223340511322,
      "backward_entropy": 0.015192793309688568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.972686767578125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0191955603659153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13974077502886453,
      "backward_entropy": 0.014920750260353088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.56011962890625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01924617774784565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1396647890408834,
      "backward_entropy": 0.025363889336586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.4903450012207,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019295956939458847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13959028323491415,
      "backward_entropy": 0.014387059211730956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.1296615600586,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019342252984642982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13951881726582846,
      "backward_entropy": 0.024600352346897125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.370458602905273,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019388996064662933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13944733142852783,
      "backward_entropy": 0.024228313565254213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.19407272338867,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01942521147429943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13938273986180624,
      "backward_entropy": 0.013632294535636903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.60356903076172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01945926807820797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1393204132715861,
      "backward_entropy": 0.023480305075645448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.6478042602539,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019496245309710503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13925770918528238,
      "backward_entropy": 0.013144144415855407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.4168758392334,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019536465406417847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1391942302385966,
      "backward_entropy": 0.02276773601770401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.48065185546875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019567439332604408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1391362945238749,
      "backward_entropy": 0.012671868503093719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.36148452758789,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.01959700882434845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1390803654988607,
      "backward_entropy": 0.01244012787938118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.5641098022461,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01962611824274063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13902541001637778,
      "backward_entropy": 0.0217126801609993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.13898468017578,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01965634524822235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13897132873535156,
      "backward_entropy": 0.02137221544981003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.326480865478516,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019687823951244354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1389177441596985,
      "backward_entropy": 0.011773285269737244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.53182220458984,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01971512846648693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13886767625808716,
      "backward_entropy": 0.02070188820362091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.230377197265625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019744282588362694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13881754875183105,
      "backward_entropy": 0.011336463689804076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.3730697631836,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019772768020629883,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13876842459042868,
      "backward_entropy": 0.020050346851348877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.1214599609375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019806236028671265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13871729373931885,
      "backward_entropy": 0.010920451581478119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.8326644897461,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.019845880568027496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13866421580314636,
      "backward_entropy": 0.010722242295742035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.00885009765625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01988876424729824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13861081997553507,
      "backward_entropy": 0.019142471253871918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.15088653564453,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.01993752457201481,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13855573534965515,
      "backward_entropy": 0.018858812749385834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.1716079711914,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.019976982846856117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13850589593251547,
      "backward_entropy": 0.01857047826051712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.00871276855469,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020022207871079445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13845463593800864,
      "backward_entropy": 0.009975147247314454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.82958221435547,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020067956298589706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1384042501449585,
      "backward_entropy": 0.018017204105854036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.02405548095703,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020113319158554077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1383556922276815,
      "backward_entropy": 0.009617792814970017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.02354431152344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020158939063549042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1383082369963328,
      "backward_entropy": 0.009441447257995606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.561142921447754,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02020466886460781,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13826205333073935,
      "backward_entropy": 0.017216937243938447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.97260665893555,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020241783931851387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13822035988171896,
      "backward_entropy": 0.009095922112464905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.16754913330078,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020276140421628952,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13818044463793436,
      "backward_entropy": 0.016691972315311433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.08043670654297,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020306799560785294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1381434698899587,
      "backward_entropy": 0.016433221101760865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.34442901611328,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020337289199233055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13810731967290243,
      "backward_entropy": 0.00860009491443634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.29634857177734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02037041448056698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1380706230799357,
      "backward_entropy": 0.12481892108917236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.545632362365723,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02041318081319332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13803058862686157,
      "backward_entropy": 0.008292119204998016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.17496109008789,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02044747769832611,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13799479603767395,
      "backward_entropy": 0.008141829073429108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.831926345825195,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02048383466899395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1379589041074117,
      "backward_entropy": 0.007994423061609269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.9471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020513029769062996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13792633016904196,
      "backward_entropy": 0.015004116296768188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.1598014831543,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020537661388516426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13789633909861246,
      "backward_entropy": 0.01477268934249878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.19043731689453,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020566029474139214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1378653645515442,
      "backward_entropy": 0.007567287981510162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.59698486328125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020594580098986626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13783520460128784,
      "backward_entropy": 0.007430323958396911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.27779769897461,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0206307340413332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13780305782953897,
      "backward_entropy": 0.014120148122310638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.09357833862305,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020664073526859283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13777294754981995,
      "backward_entropy": 0.00716606080532074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.4001235961914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02069799415767193,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13774311542510986,
      "backward_entropy": 0.12441673278808593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.582942962646484,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0207368154078722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13771218061447144,
      "backward_entropy": 0.013513803482055664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.14005661010742,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020774908363819122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13768239816029867,
      "backward_entropy": 0.006791276484727859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.42523193359375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020810946822166443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1376537879308065,
      "backward_entropy": 0.006670931726694107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.123249053955078,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020846478641033173,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13762633005777994,
      "backward_entropy": 0.012938766181468964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.4883041381836,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020878341048955917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13760040203730264,
      "backward_entropy": 0.01275160014629364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.12214279174805,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.020918427035212517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13757221897443137,
      "backward_entropy": 0.006323009729385376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.96127700805664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.020960457623004913,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1375442941983541,
      "backward_entropy": 0.012400291115045547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.915924072265625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021005509421229362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1375157038370768,
      "backward_entropy": 0.012233032286167145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.17376708984375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02105194889008999,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1374876101811727,
      "backward_entropy": 0.01206880882382393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.35222625732422,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021096089854836464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1374606490135193,
      "backward_entropy": 0.011906786262989045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.47565841674805,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02113933116197586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1374348203341166,
      "backward_entropy": 0.011746013909578324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.4939193725586,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.021180013194680214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13741047183672586,
      "backward_entropy": 0.005699549615383148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.99955749511719,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02123047597706318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13738377888997397,
      "backward_entropy": 0.01143556386232376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.01134490966797,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02129007875919342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13735494017601013,
      "backward_entropy": 0.0112942174077034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.71076965332031,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021362686529755592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13732300202051798,
      "backward_entropy": 0.011163651943206787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.02863693237305,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.021444376558065414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1372894048690796,
      "backward_entropy": 0.0053465314209461216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.910133361816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021522223949432373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13725791374842325,
      "backward_entropy": 0.12478978633880615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.22996520996094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02159908041357994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1372275948524475,
      "backward_entropy": 0.005185062438249588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.75830078125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021679233759641647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13719754417737326,
      "backward_entropy": 0.010674448311328888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.06489944458008,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021757910028100014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13716883460680643,
      "backward_entropy": 0.010554856061935425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.98579788208008,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02183128148317337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13714218139648438,
      "backward_entropy": 0.004947227984666824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.65001678466797,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.021902181208133698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13711678981781006,
      "backward_entropy": 0.010315120220184326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.44374084472656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.021975703537464142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13709123929341635,
      "backward_entropy": 0.004795509204268455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.27442169189453,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0220516175031662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13706553975741068,
      "backward_entropy": 0.004723808914422989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.83734130859375,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022127490490674973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13704033692677817,
      "backward_entropy": 0.009976864606142045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.93537902832031,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022202234715223312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13701619704564413,
      "backward_entropy": 0.009866508841514587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.89562225341797,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.022281233221292496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13699165980021158,
      "backward_entropy": 0.004514629766345024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.4412841796875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022363757714629173,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13696710268656412,
      "backward_entropy": 0.009655722975730896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.62269401550293,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022449789568781853,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1369423766930898,
      "backward_entropy": 0.009554573148488999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.38165283203125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.022527143359184265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13692047198613486,
      "backward_entropy": 0.004314060509204865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.76368713378906,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022604195401072502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13689919312795004,
      "backward_entropy": 0.00934850424528122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.21226501464844,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02268352173268795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13687791426976523,
      "backward_entropy": 0.004188022762537003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.04022216796875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022763829678297043,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136857271194458,
      "backward_entropy": 0.009151396155357362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.171600341796875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.022848308086395264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13683616121610007,
      "backward_entropy": 0.004067977517843246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.94145584106445,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.022929400205612183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13681634267171225,
      "backward_entropy": 0.008963917195796967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.12296676635742,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02300606109201908,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13679774602254233,
      "backward_entropy": 0.008871358633041383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.76103210449219,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023083001375198364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13677942752838135,
      "backward_entropy": 0.003897707536816597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.56992721557617,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02316654846072197,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13676024476687113,
      "backward_entropy": 0.0086955264210701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.96263885498047,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023246949538588524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13674218455950418,
      "backward_entropy": 0.0037919729948043823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.899909973144531,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.023331044241786003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13672396540641785,
      "backward_entropy": 0.008523806929588318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.421451568603516,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023405276238918304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367080807685852,
      "backward_entropy": 0.0036867175251245497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.086402893066406,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023479871451854706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13669255375862122,
      "backward_entropy": 0.003635021299123764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.29353332519531,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.023551095277071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13667788108189902,
      "backward_entropy": 0.008266264945268631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.92387008666992,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.023629479110240936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1366624434789022,
      "backward_entropy": 0.008186374604701997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.80175018310547,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023707902058959007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366474429766337,
      "backward_entropy": 0.003489835187792778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.3070297241211,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023789124563336372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366321841875712,
      "backward_entropy": 0.00344485305249691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.33737564086914,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023876959457993507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366159717241923,
      "backward_entropy": 0.0034019134938716887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.01167678833008,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.023964105173945427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13660027583440146,
      "backward_entropy": 0.0033596061170101167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.7454605102539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024045638740062714,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1365859111150106,
      "backward_entropy": 0.12813405990600585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.394599914550781,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.024135857820510864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13657049338022867,
      "backward_entropy": 0.007751718908548355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.482566833496094,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.024215923622250557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13655714193979898,
      "backward_entropy": 0.007680128514766693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.421321868896484,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.024299003183841705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13654353221257529,
      "backward_entropy": 0.0031923387199640275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.333173751831055,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.024382131174206734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1365302006403605,
      "backward_entropy": 0.007547102868556976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.33986282348633,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.024458082392811775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1365184485912323,
      "backward_entropy": 0.007479889690876007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.04219055175781,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02453201450407505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13650735219319662,
      "backward_entropy": 0.0030742645263671874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.94929122924805,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.024611186236143112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13649568955103555,
      "backward_entropy": 0.003036097064614296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.64862632751465,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.024688368663191795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364846428235372,
      "backward_entropy": 0.0029983431100845336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.48650360107422,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02476211078464985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13647436102231345,
      "backward_entropy": 0.007223239541053772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.38432693481445,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02484295517206192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1364633838335673,
      "backward_entropy": 0.007163245975971222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.385154724121094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02492215670645237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13645285367965698,
      "backward_entropy": 0.002891124039888382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.937782287597656,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025001434609293938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13644262154897055,
      "backward_entropy": 0.007045703381299973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.414926528930664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025083303451538086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13643227020899454,
      "backward_entropy": 0.006988632678985596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.86998748779297,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025160713121294975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13642281293869019,
      "backward_entropy": 0.006930842250585556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.78666305541992,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.025247490033507347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13641236225763956,
      "backward_entropy": 0.002755952812731266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.65391159057617,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0253320150077343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13640244801839194,
      "backward_entropy": 0.002724364399909973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.5731315612793,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025414539501070976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13639305035273233,
      "backward_entropy": 0.006772728264331817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.4579849243164,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025495152920484543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363841692606608,
      "backward_entropy": 0.0067214518785476685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.82709312438965,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.025580497458577156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1363749404748281,
      "backward_entropy": 0.002633447013795376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.56571578979492,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025661079213023186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13636666536331177,
      "backward_entropy": 0.006622599065303802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.6058120727539,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025743845850229263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363584299882253,
      "backward_entropy": 0.006573106348514557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.63265609741211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0258326418697834,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13634981711705527,
      "backward_entropy": 0.13012845516204835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.69221878051758,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.025920651853084564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363415320714315,
      "backward_entropy": 0.006476517766714096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.772159576416016,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.026006609201431274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13633365432421365,
      "backward_entropy": 0.0024870732799172402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.855077743530273,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.026090074330568314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136326273282369,
      "backward_entropy": 0.0024587729945778846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.869519233703613,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.026170212775468826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13631939888000488,
      "backward_entropy": 0.006337897479534149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.19243621826172,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.026243139058351517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363133986790975,
      "backward_entropy": 0.006294252723455429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.519681930541992,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02631928212940693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13630718986193338,
      "backward_entropy": 0.006251765787601471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.57689666748047,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02638966217637062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363017757733663,
      "backward_entropy": 0.006207990273833275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.64619827270508,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02646114118397236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13629637161890665,
      "backward_entropy": 0.006164297088980674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.64881706237793,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02653617225587368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13629082838694254,
      "backward_entropy": 0.006122523546218872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.07199478149414,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02660769410431385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362858017285665,
      "backward_entropy": 0.002276996150612831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.54487228393555,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.026674702763557434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362813115119934,
      "backward_entropy": 0.0022520676255226137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.11394500732422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02674187161028385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13627692063649496,
      "backward_entropy": 0.0022279553115367888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.38676834106445,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.026815619319677353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13627201318740845,
      "backward_entropy": 0.005962001532316208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.478233337402344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.026888640597462654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13626728455225626,
      "backward_entropy": 0.0021828848868608473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.4539680480957,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.026963042095303535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13626256585121155,
      "backward_entropy": 0.0021607320755720138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.94619369506836,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02704094909131527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13625768820444742,
      "backward_entropy": 0.00213930606842041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.13104248046875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.027118155732750893,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362529993057251,
      "backward_entropy": 0.002118704840540886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.78302764892578,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.027196001261472702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13624838987986246,
      "backward_entropy": 0.0020979588851332666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.525644302368164,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02727530524134636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13624369104703268,
      "backward_entropy": 0.002078261598944664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.605770111083984,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.027351824566721916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13623927036921182,
      "backward_entropy": 0.005728148296475411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.35542678833008,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.027429472655057907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13623483975728354,
      "backward_entropy": 0.0020405225455760955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.34071731567383,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02750864066183567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13623040914535522,
      "backward_entropy": 0.0020225221291184426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.20736312866211,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.027588577941060066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13622601826985678,
      "backward_entropy": 0.0056439809501171116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.94858169555664,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.027667364105582237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13622182607650757,
      "backward_entropy": 0.0019865619018673898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.7797737121582,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.027747469022870064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13621763388315836,
      "backward_entropy": 0.0019692610949277878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.02060890197754,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.027828888967633247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13621342182159424,
      "backward_entropy": 0.005565287545323372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.68953323364258,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.027906836941838264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13620954751968384,
      "backward_entropy": 0.005540083721280098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.354251861572266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02798413299024105,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13620582222938538,
      "backward_entropy": 0.13222241401672363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.051334381103516,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.028063058853149414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13620206713676453,
      "backward_entropy": 0.005492927506566048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.597246170043945,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02814517728984356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619819283485413,
      "backward_entropy": 0.0054709292948246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.74980354309082,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02822417952120304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13619460662206015,
      "backward_entropy": 0.00187420304864645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.01470947265625,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02829853445291519,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619136810302734,
      "backward_entropy": 0.005428478866815567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.72745132446289,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.028380202129483223,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13618779182434082,
      "backward_entropy": 0.005407650396227837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.90390396118164,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02846262976527214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13618424534797668,
      "backward_entropy": 0.00538690909743309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.306007385253906,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02854391746222973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13618085781733194,
      "backward_entropy": 0.0018161354586482049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.12161636352539,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0286268163472414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13617746035257974,
      "backward_entropy": 0.0018028521910309792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.868550300598145,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02870626002550125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13617432117462158,
      "backward_entropy": 0.0017893865704536438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.40288543701172,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02877880446612835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13617157936096191,
      "backward_entropy": 0.001775975339114666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.8233528137207,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02884700335562229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13616910576820374,
      "backward_entropy": 0.0017624590545892715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.22890853881836,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.028917821124196053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136166512966156,
      "backward_entropy": 0.005273624137043953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.15716552734375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.028988845646381378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361639698346456,
      "backward_entropy": 0.0017369952052831649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.008094787597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029059844091534615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1361614465713501,
      "backward_entropy": 0.13322818279266357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.6377182006836,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.02913116291165352,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13615894317626953,
      "backward_entropy": 0.00522376149892807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.40972328186035,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.029210226610302925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361561417579651,
      "backward_entropy": 0.0017004815861582756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.74114227294922,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02928677387535572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13615349928538004,
      "backward_entropy": 0.0016888139769434928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.92603874206543,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.029362672939896584,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361509164174398,
      "backward_entropy": 0.005176625773310661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.83597183227539,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.029434245079755783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13614853223164877,
      "backward_entropy": 0.0016655292361974715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.949710845947266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.02950771525502205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361461083094279,
      "backward_entropy": 0.0016539821401238442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.24892044067383,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029585227370262146,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13614355524381003,
      "backward_entropy": 0.1336735486984253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471758842468262,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.029662560671567917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13614105184872946,
      "backward_entropy": 0.0051188159734010695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.028079986572266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0297334473580122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613879680633545,
      "backward_entropy": 0.001621781289577484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.79023551940918,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.029804937541484833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13613655169804892,
      "backward_entropy": 0.005094388127326965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.85112380981445,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.029874542728066444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13613434632619223,
      "backward_entropy": 0.005082739889621735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.77292251586914,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.029944684356451035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613216082255045,
      "backward_entropy": 0.0015924820676445962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.65188980102539,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030015110969543457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13612993558247885,
      "backward_entropy": 0.0015830732882022858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.92813110351562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030086003243923187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13612773021062216,
      "backward_entropy": 0.005051281303167343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.38167953491211,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03016495890915394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13612528642018637,
      "backward_entropy": 0.005041977763175965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.275949478149414,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030241528525948524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361229419708252,
      "backward_entropy": 0.001556413434445858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.28831100463867,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030313853174448013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13612071673075357,
      "backward_entropy": 0.005024459958076477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.143701553344727,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030385863035917282,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13611849149068198,
      "backward_entropy": 0.001538892276585102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.12452507019043,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030454400926828384,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13611634572347006,
      "backward_entropy": 0.005005382001399994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.83366775512695,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030521027743816376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13611421982447305,
      "backward_entropy": 0.004994996264576912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.61402130126953,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030592290684580803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13611197471618652,
      "backward_entropy": 0.0015124833211302758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.96168041229248,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030669482424855232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361095905303955,
      "backward_entropy": 0.00497530996799469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.52734375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030742429196834564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13610729575157166,
      "backward_entropy": 0.0014951655641198159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.34379959106445,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03081711195409298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13610494136810303,
      "backward_entropy": 0.0014864710159599782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.845882415771484,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.030894022434949875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136102557182312,
      "backward_entropy": 0.001478279009461403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.29753303527832,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.030976634472608566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13610008358955383,
      "backward_entropy": 0.0049395948648452755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16872017085552216,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.031058521941304207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360976298650106,
      "backward_entropy": 0.004932733252644539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.585166931152344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.031131785362958908,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13609532515207926,
      "backward_entropy": 0.001455032080411911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.588584899902344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03120850771665573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13609294096628824,
      "backward_entropy": 0.0014469798654317856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849903583526611,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03128081187605858,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360905865828196,
      "backward_entropy": 0.00490928627550602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.09783172607422,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03134727105498314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13608829180399576,
      "backward_entropy": 0.001430636178702116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.421205520629883,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0314183346927166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13608592748641968,
      "backward_entropy": 0.0014226047322154045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.42161178588867,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03148575872182846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360835631688436,
      "backward_entropy": 0.0014146646484732629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.885177612304688,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03155943378806114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13608109951019287,
      "backward_entropy": 0.0014067309908568858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.380054473876953,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03163144364953041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13607865571975708,
      "backward_entropy": 0.0013992090709507466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.4885482788086,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03170362859964371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13607619206110635,
      "backward_entropy": 0.0013918603770434856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.1606502532959,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03178714960813522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13607358932495117,
      "backward_entropy": 0.004853004962205887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.580854415893555,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03186968341469765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360710064570109,
      "backward_entropy": 0.004845964908599854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.37839889526367,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03194915130734444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13606841365496317,
      "backward_entropy": 0.0013696099631488323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.383920669555664,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03203003481030464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13606580098470053,
      "backward_entropy": 0.004831408336758614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.533023834228516,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03210862725973129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13606319824854532,
      "backward_entropy": 0.0048258349299430845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.23818588256836,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03218080848455429,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13606059551239014,
      "backward_entropy": 0.0013487514108419419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4841485023498535,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03225123509764671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13605799277623495,
      "backward_entropy": 0.004814254492521286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.0841064453125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03231591731309891,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360553503036499,
      "backward_entropy": 0.0013351975008845328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.021020889282227,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03237985819578171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136052668094635,
      "backward_entropy": 0.004802443459630013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.67155933380127,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03244296833872795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13604996601740518,
      "backward_entropy": 0.0047976583242416385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.89996910095215,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.032503508031368256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360472043355306,
      "backward_entropy": 0.004793596267700195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.30409240722656,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.032563164830207825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13604439298311868,
      "backward_entropy": 0.0013103710487484932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.548444747924805,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.032625991851091385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136041522026062,
      "backward_entropy": 0.0013041763566434383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.88392448425293,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03268589824438095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603860139846802,
      "backward_entropy": 0.004777488484978676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.448888778686523,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0327473059296608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603564103444418,
      "backward_entropy": 0.004772413522005081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.866615295410156,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03280634805560112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603262106577554,
      "backward_entropy": 0.004768262803554535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.3634672164917,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03286871314048767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360295613606771,
      "backward_entropy": 0.0012804360128939151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.65606689453125,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.032928477972745895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602644205093384,
      "backward_entropy": 0.0012748118489980698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.448198318481445,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.032991115003824234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360232631365458,
      "backward_entropy": 0.004754972085356713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.3568115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03305491432547569,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13602005441983542,
      "backward_entropy": 0.13607072830200195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.223949432373047,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03311976045370102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13601679603258768,
      "backward_entropy": 0.001257458422333002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.19557571411133,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03318352252244949,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360134780406952,
      "backward_entropy": 0.0047418706119060515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.075340270996094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03324999287724495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13601013024648032,
      "backward_entropy": 0.0012461857870221138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.84413528442383,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03331904113292694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13600673278172812,
      "backward_entropy": 0.0012405501678586007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.86734390258789,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03339763730764389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136003315448761,
      "backward_entropy": 0.0012347654439508915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.926358222961426,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03347593545913696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13599986831347147,
      "backward_entropy": 0.0012292995117604733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.653690338134766,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.033549387007951736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359963615735372,
      "backward_entropy": 0.004715337976813316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.816100120544434,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03362291306257248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13599284489949545,
      "backward_entropy": 0.0012176339514553547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.923140525817871,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03369273245334625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598925868670145,
      "backward_entropy": 0.0012121248058974744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.996788024902344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03375749662518501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598559300104776,
      "backward_entropy": 0.0012070002034306527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.4409294128418,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03382641077041626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598191738128662,
      "backward_entropy": 0.0012015641666948795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.382204055786133,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.033902961760759354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13597822189331055,
      "backward_entropy": 0.001195959560573101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.817265033721924,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03397736698389053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13597444693247476,
      "backward_entropy": 0.0011905793100595475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.949222564697266,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03404616564512253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13597063223520914,
      "backward_entropy": 0.004679654911160469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.15350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.034115634858608246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13596676786740622,
      "backward_entropy": 0.0011806589551270007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.084531784057617,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.034183479845523834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359628438949585,
      "backward_entropy": 0.0011758738197386264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.30672836303711,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03425025939941406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13595885038375854,
      "backward_entropy": 0.004669540002942086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.18973159790039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03431953489780426,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13595480720202127,
      "backward_entropy": 0.13673665523529052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.463533401489258,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.034391433000564575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13595069448153177,
      "backward_entropy": 0.001162892859429121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.93416976928711,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03446367755532265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359465221563975,
      "backward_entropy": 0.004664377868175506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.615696907043457,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.034537848085165024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13594230016072592,
      "backward_entropy": 0.004663536697626114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.16416358947754,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03460674360394478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13593798875808716,
      "backward_entropy": 0.004664085060358048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.56877899169922,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03467627242207527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13593361775080362,
      "backward_entropy": 0.004665159434080124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.966426849365234,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03474815934896469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359291672706604,
      "backward_entropy": 0.004666497930884361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.31736755371094,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03482024371623993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13592464725176492,
      "backward_entropy": 0.0011422025039792062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.910466194152832,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03489423170685768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13592010736465454,
      "backward_entropy": 0.004668925702571869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.47377395629883,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.034964535385370255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591550787289938,
      "backward_entropy": 0.001135881058871746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.186147689819336,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03503885865211487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359108587106069,
      "backward_entropy": 0.004671501368284226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.16463088989258,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.035111259669065475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590614000956217,
      "backward_entropy": 0.0011297080665826798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.035091400146484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03518715128302574,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13590139150619507,
      "backward_entropy": 0.13713784217834474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.958087921142578,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0352611318230629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589656352996826,
      "backward_entropy": 0.0011230994947254657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.155092239379883,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.035333383828401566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589167594909668,
      "backward_entropy": 0.0011201174929738045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.805124282836914,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.035405684262514114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588673869768778,
      "backward_entropy": 0.004675840958952904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.950664520263672,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.035476308315992355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358817219734192,
      "backward_entropy": 0.0011142377741634845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.26301956176758,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03554685786366463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587671518325806,
      "backward_entropy": 0.0011111236177384852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.58404541015625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.035621076822280884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587166865666708,
      "backward_entropy": 0.0011078582145273685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.96173858642578,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03569357469677925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586652278900146,
      "backward_entropy": 0.004677705839276314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.300238609313965,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03576968237757683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586129744847616,
      "backward_entropy": 0.004678121954202652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.45168113708496,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03584200143814087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13585599263509116,
      "backward_entropy": 0.004679300636053085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.42307472229004,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03591442480683327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358506182829539,
      "backward_entropy": 0.0010963468812406063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.298974990844727,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03598852455615997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358452041943868,
      "backward_entropy": 0.001093513984233141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.140262603759766,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0360642746090889,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583970069885254,
      "backward_entropy": 0.004682227969169617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.037001609802246,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.036139655858278275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583414753278097,
      "backward_entropy": 0.001087856851518154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.96824073791504,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03621116280555725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582855463027954,
      "backward_entropy": 0.0010851471684873103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.942441940307617,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.036281175911426544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358228623867035,
      "backward_entropy": 0.0010826826095581056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.821063995361328,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.036347996443510056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358171502749125,
      "backward_entropy": 0.001080426387488842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.752676010131836,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.036413632333278656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358113388220469,
      "backward_entropy": 0.0010782145895063878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912124156951904,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0364781953394413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13580546776453653,
      "backward_entropy": 0.0010760520584881307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.770398139953613,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.036538027226924896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579962650934854,
      "backward_entropy": 0.004696401953697205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.879278659820557,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.0365959107875824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357936461766561,
      "backward_entropy": 0.004700269550085068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.681714057922363,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03665001317858696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357876161734263,
      "backward_entropy": 0.0010703093372285365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.25716209411621,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03670240193605423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578155636787415,
      "backward_entropy": 0.0010687110014259815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.610143661499023,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03675675019621849,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577542702356973,
      "backward_entropy": 0.0047135274857282635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03325321525335312,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03680944815278053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357692082722982,
      "backward_entropy": 0.0010655255988240241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.530030250549316,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03685710206627846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576300938924155,
      "backward_entropy": 0.0010641870088875295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.504768371582031,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03690345212817192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575685024261475,
      "backward_entropy": 0.004727932810783386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.63691520690918,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.036948852241039276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357506513595581,
      "backward_entropy": 0.0010612482205033303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.95078659057617,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03699860721826553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574434320131937,
      "backward_entropy": 0.004736181348562241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.768251419067383,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.037055473774671555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357379456361135,
      "backward_entropy": 0.0010575685650110246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.346923828125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03711385652422905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357314387957255,
      "backward_entropy": 0.004739757999777794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.605527877807617,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.037175219506025314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572484254837036,
      "backward_entropy": 0.004741005599498749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.891887664794922,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.037237800657749176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571804761886597,
      "backward_entropy": 0.0010513225570321083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.61322784423828,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03729959949851036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357111930847168,
      "backward_entropy": 0.004745044931769371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.48115158081055,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03736549988389015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357043186823527,
      "backward_entropy": 0.0010470114648342133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.687305450439453,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.037435274571180344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569729526837668,
      "backward_entropy": 0.0010445197112858295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.135269165039062,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03750365227460861,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569011290868124,
      "backward_entropy": 0.0010422910563647747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.546152114868164,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.037572260946035385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356829305489858,
      "backward_entropy": 0.00104009248316288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.9365234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037642866373062134,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13567562898000082,
      "backward_entropy": 0.13787152767181396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.39190101623535,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03771338611841202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566828767458597,
      "backward_entropy": 0.0010356840677559376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.748693466186523,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.037782371044158936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566084702809653,
      "backward_entropy": 0.004748998582363129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.059701919555664,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.037851642817258835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356532076994578,
      "backward_entropy": 0.0010316166095435618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.926565170288086,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.037922900170087814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13564538955688477,
      "backward_entropy": 0.004752041026949883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.737666130065918,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03799571469426155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13563746213912964,
      "backward_entropy": 0.0010276453569531441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.34810447692871,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03806502744555473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13562955458958945,
      "backward_entropy": 0.004755350947380066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.949551582336426,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03813444450497627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356215476989746,
      "backward_entropy": 0.0010241108946502208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.154455184936523,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.038202423602342606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356134613355001,
      "backward_entropy": 0.004760240018367767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280883312225342,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03827058523893356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356053352355957,
      "backward_entropy": 0.004762774333357811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.209426879882812,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03833392634987831,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355973482131958,
      "backward_entropy": 0.004765899106860161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.237837314605713,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.038399577140808105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355891227722168,
      "backward_entropy": 0.0010178861208260058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.989383697509766,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03846072405576706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558103640874228,
      "backward_entropy": 0.004771116748452186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.216552734375,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.038524407893419266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355727712313334,
      "backward_entropy": 0.0010150578804314137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.459061622619629,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038593534380197525,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13556426763534546,
      "backward_entropy": 0.13803453445434571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.634414672851562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03866099938750267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355558236440023,
      "backward_entropy": 0.004776206240057946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.319649696350098,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.038730233907699585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554726044336954,
      "backward_entropy": 0.00477675125002861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.170370101928711,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.038797907531261444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355386277039846,
      "backward_entropy": 0.004777952656149864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.38682556152344,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.038862477988004684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355301042397817,
      "backward_entropy": 0.0010064676403999328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.21207809448242,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03893233463168144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355212132136027,
      "backward_entropy": 0.00478014163672924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.021636962890625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03900686278939247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13551214337348938,
      "backward_entropy": 0.0010024898685514927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.886659622192383,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03908229619264603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13550305366516113,
      "backward_entropy": 0.004777426272630692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.909829139709473,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03915850445628166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13549399375915527,
      "backward_entropy": 0.0009979676455259324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.785881996154785,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03923063352704048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13548514246940613,
      "backward_entropy": 0.0009958528913557529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.50630760192871,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03930080682039261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354762613773346,
      "backward_entropy": 0.004771626740694046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.501083374023438,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.039372410625219345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1354671816031138,
      "backward_entropy": 0.000991977844387293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.713492393493652,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03944356366991997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13545817136764526,
      "backward_entropy": 0.000990019179880619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.311553955078125,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03951127082109451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13544916113217673,
      "backward_entropy": 0.004768174514174462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.817175388336182,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.039579056203365326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13544000188509622,
      "backward_entropy": 0.004767922684550285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.897939682006836,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.039642103016376495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13543101151784262,
      "backward_entropy": 0.0009854882955551147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.783206939697266,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.039707135409116745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1354219118754069,
      "backward_entropy": 0.0009840783663094045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.39547348022461,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.03977394104003906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1354127029577891,
      "backward_entropy": 0.0009825354442000388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.431051254272461,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03984389826655388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354032556215922,
      "backward_entropy": 0.0047674842178821565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.746829986572266,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.03991052880883217,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13539386789004007,
      "backward_entropy": 0.0047672994434833525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.9927978515625,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.039977286010980606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13538422187169394,
      "backward_entropy": 0.000977795384824276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.925918579101562,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04004255309700966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13537456591924033,
      "backward_entropy": 0.0009765079244971276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.081010818481445,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04010651633143425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135364830493927,
      "backward_entropy": 0.0009754011407494545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.96601676940918,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.040172357112169266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13535485665003458,
      "backward_entropy": 0.0009742005728185177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.28505516052246,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04023988917469978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1353446046511332,
      "backward_entropy": 0.0009729535318911076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.637832641601562,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.04030746594071388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353340446949005,
      "backward_entropy": 0.004771620035171509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.08720588684082,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.04037332907319069,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13532386223475137,
      "backward_entropy": 0.004772871732711792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.51096773147583,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0404391884803772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13531357049942017,
      "backward_entropy": 0.1382247567176819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.91522216796875,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.040500473231077194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13530365626017252,
      "backward_entropy": 0.004775311425328254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.732385635375977,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04056233540177345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352934738000234,
      "backward_entropy": 0.0009679886512458325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.73587989807129,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.04062775522470474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13528279463450113,
      "backward_entropy": 0.0047784816473722454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.045068740844727,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.040693316608667374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13527188698450723,
      "backward_entropy": 0.0009660637006163597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.161928176879883,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04076042398810387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352608303229014,
      "backward_entropy": 0.0009649848565459251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729179382324219,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.040825869888067245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13524989287058511,
      "backward_entropy": 0.004781819507479667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.377971649169922,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.040888216346502304,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13523942232131958,
      "backward_entropy": 0.00478331595659256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.27118492126465,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04095543548464775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352283457914988,
      "backward_entropy": 0.0009621655568480492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.469209671020508,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.041022513061761856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13521718978881836,
      "backward_entropy": 0.0009611727669835091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.279284477233887,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.041091009974479675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13520547747612,
      "backward_entropy": 0.0009600382298231124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.471084594726562,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.0411546416580677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13519432147343954,
      "backward_entropy": 0.0009592851623892784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.89357566833496,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.041221342980861664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13518297672271729,
      "backward_entropy": 0.004785594344139099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.601217269897461,
      "terminal_state_reached": true,
      "terminal_reward": 100,
      "log_Z": -0.041287872940301895,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13517157236735025,
      "backward_entropy": 0.004785754904150963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.70868492126465,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04135270416736603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1351603865623474,
      "backward_entropy": 0.0009564569219946862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.617055892944336,
      "terminal_state_reached": true,
      "terminal_reward": 900,
      "log_Z": -0.04141754284501076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13514904181162515,
      "backward_entropy": 0.0009556000120937824,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 19.98316684268415,
    "avg_log_Z": -0.03813784763216972,
    "success_rate": 1.0,
    "avg_reward": 544.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.4,
      "2": 0.56
    },
    "avg_forward_entropy": 0.13559504638115563,
    "avg_backward_entropy": 0.007989813313819469,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}