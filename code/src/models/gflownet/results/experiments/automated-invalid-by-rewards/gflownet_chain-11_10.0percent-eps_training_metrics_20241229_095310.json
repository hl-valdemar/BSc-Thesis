{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301160292191939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06300260803916237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.16796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131671984990437,
      "backward_entropy": 0.06301101771267978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.33270263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913144052028656,
      "backward_entropy": 0.06301132115450772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.30116271972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019962167425546795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913120408852895,
      "backward_entropy": 0.06301144036379727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.26953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00029916816856712103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130961696306865,
      "backward_entropy": 0.06301067092201927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.46279907226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0003986915689893067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130712350209554,
      "backward_entropy": 0.06301029161973433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.20643615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004982842947356403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913046399752299,
      "backward_entropy": 0.06300990148024126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.1747283935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005978454719297588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130207697550456,
      "backward_entropy": 0.06301217729395087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.14303588867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006973881972953677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129943450291951,
      "backward_entropy": 0.06301232901486484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3663787841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007969202706590295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129671255747478,
      "backward_entropy": 0.06300860643386841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.08009338378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008943252032622695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129398067792256,
      "backward_entropy": 0.0630126107822765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.25912475585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009922097669914365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129116932551067,
      "backward_entropy": 0.06301272999156605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.44644165039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010889933910220861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128826856613159,
      "backward_entropy": 0.06301283836364746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.20162963867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001182927517220378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128536780675252,
      "backward_entropy": 0.06301293589852074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.78878784179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001275471062399447,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128238757451375,
      "backward_entropy": 0.06301148371262984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7675018310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013658070238307118,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912793477376302,
      "backward_entropy": 0.06300552866675636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.13014221191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014554369263350964,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127624829610188,
      "backward_entropy": 0.06301207434047353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.72030639648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015444235177710652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127306938171387,
      "backward_entropy": 0.06301319599151611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.69677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016329666832461953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126983086268108,
      "backward_entropy": 0.06300385431809859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.43814086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017211601370945573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09126654267311096,
      "backward_entropy": 0.06301328268918124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.40411376953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018100118031725287,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126316507657369,
      "backward_entropy": 0.06301283836364746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3761444091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019004405476152897,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125971794128418,
      "backward_entropy": 0.06301333687522194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.7455291748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019922354258596897,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912562112013499,
      "backward_entropy": 0.06300148096951572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.20570373535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002084166742861271,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125260512034099,
      "backward_entropy": 0.06300087408585982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.53726196289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002174302702769637,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124894936879475,
      "backward_entropy": 0.06301321224732832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.51119995117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022650512401014566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124525388081868,
      "backward_entropy": 0.0629996278069236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3692169189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002356352750211954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124151865641277,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.61289978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024461266584694386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09123777349789937,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.96339416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025364034809172153,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123392899831136,
      "backward_entropy": 0.06299771503968672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.3277587890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026241217274218798,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123008449872334,
      "backward_entropy": 0.0630133639682423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.43382263183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002709477674216032,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122620026270549,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.38265991210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027937779668718576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122224648793538,
      "backward_entropy": 0.06301333145661787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.18685913085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002878419356420636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121821324030559,
      "backward_entropy": 0.06301331520080566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.01470947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002966406987980008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121405084927876,
      "backward_entropy": 0.06301329352638939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.50819396972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030518448911607265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120983878771464,
      "backward_entropy": 0.0630132718519731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.62538146972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0031405058689415455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120547771453857,
      "backward_entropy": 0.06301325017755682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.91319274902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032252504024654627,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120107690493266,
      "backward_entropy": 0.06301335854963823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.3965606689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033091213554143906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119662642478943,
      "backward_entropy": 0.06301318515430797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.48426818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033912514336407185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911921759446462,
      "backward_entropy": 0.06301315264268355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.80075073242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003472923533990979,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118768572807312,
      "backward_entropy": 0.06301333687522194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.11297607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0035554429050534964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911831259727478,
      "backward_entropy": 0.06298992850563744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.00083923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036399250384420156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911784569422404,
      "backward_entropy": 0.06298922950571234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4912872314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003725738264620304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117380777994792,
      "backward_entropy": 0.06298855218020352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.99431610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038118159864097834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116904934247334,
      "backward_entropy": 0.06301292506131259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.60682678222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003893171437084675,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09116432070732117,
      "backward_entropy": 0.0630133097822016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.25170135498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0039801509119570255,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911594529946645,
      "backward_entropy": 0.06301330436359752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.71363830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004060972947627306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115465482076009,
      "backward_entropy": 0.06301272999156605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.3304901123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004143840167671442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114969770113628,
      "backward_entropy": 0.06301265954971313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.33718872070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0042308634147048,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114456176757812,
      "backward_entropy": 0.06301329352638939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.96429443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004318021237850189,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113933642705281,
      "backward_entropy": 0.06298339366912842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.04722595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004409851506352425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113388260205586,
      "backward_entropy": 0.06301241571252997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.10121154785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004501095972955227,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112830956776936,
      "backward_entropy": 0.06298189813440497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.16236877441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004589833319187164,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112287561098735,
      "backward_entropy": 0.06301329352638939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.89358520507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004682084079831839,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111743172009786,
      "backward_entropy": 0.06298031048341231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.00440979003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0047726319171488285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111190835634868,
      "backward_entropy": 0.06301199306141246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.13966369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00486608874052763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110615650812785,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.43824768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0049612936563789845,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110027551651001,
      "backward_entropy": 0.06297793171622536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.15713500976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005054565612226725,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09109437465667725,
      "backward_entropy": 0.06301328268918124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.42506408691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005148346070200205,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108839432398479,
      "backward_entropy": 0.06301328268918124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.71514129638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00524378614500165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108226497968037,
      "backward_entropy": 0.06297547166997736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.71975708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005333433393388987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107618530591328,
      "backward_entropy": 0.06301112608476118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.76904296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00542163010686636,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107004602750142,
      "backward_entropy": 0.06297360767017711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.90859985351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005514753051102161,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910637378692627,
      "backward_entropy": 0.0630132718519731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.69157409667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005606234539300203,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09105739990870158,
      "backward_entropy": 0.06297161362387917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.14329528808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0056934654712677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09105108181635539,
      "backward_entropy": 0.062970524484461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1724090576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0057809920981526375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09104469418525696,
      "backward_entropy": 0.06296938115900214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005866238847374916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09103830655415852,
      "backward_entropy": 0.06301323934034868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.75782775878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00595447700470686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103176991144817,
      "backward_entropy": 0.06300942464308305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.82994842529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00604519248008728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102502465248108,
      "backward_entropy": 0.06300912120125511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.87490844726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006131927017122507,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09101832906405131,
      "backward_entropy": 0.06300878524780273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.84954833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0062174308113753796,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09101154406865437,
      "backward_entropy": 0.06296300888061523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.57359313964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006301843095570803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100462992986043,
      "backward_entropy": 0.06296163255518133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.92584228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00638702604919672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099765618642171,
      "backward_entropy": 0.06296020204370673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.54119873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006472815293818712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099058310190837,
      "backward_entropy": 0.06300724636424672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.36753845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006560380570590496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098329146703084,
      "backward_entropy": 0.06300681829452515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.18589782714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006646775174885988,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09097576141357422,
      "backward_entropy": 0.06301307678222656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.78715515136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00673125172033906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096819162368774,
      "backward_entropy": 0.06300588087602095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.27606201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006810836493968964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096063176790874,
      "backward_entropy": 0.06300534985282204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.25839233398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006888902746140957,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0909529725710551,
      "backward_entropy": 0.06301297924735329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.60009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006971110589802265,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09094504515329997,
      "backward_entropy": 0.06301294673572887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.20767211914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00705021433532238,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09093709786732991,
      "backward_entropy": 0.0630129033868963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.80186462402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007129084784537554,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09092897176742554,
      "backward_entropy": 0.06301286003806374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.2913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00720786489546299,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092070659001668,
      "backward_entropy": 0.06300230459733443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.75164794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007283690385520458,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09091238180796306,
      "backward_entropy": 0.06294063004580411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.43035888671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007358541712164879,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09090399742126465,
      "backward_entropy": 0.0630127028985457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.45823669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00743795745074749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09089529514312744,
      "backward_entropy": 0.06300016424872658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.27392578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007515837904065847,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09088651339213054,
      "backward_entropy": 0.06301259994506836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007595119532197714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09087751309076945,
      "backward_entropy": 0.0629986199465665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.81500244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007676967419683933,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908682147661845,
      "backward_entropy": 0.06301249699159102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.47154235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007761117536574602,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09085863828659058,
      "backward_entropy": 0.06292729486118663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.16915893554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007850222289562225,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09084874391555786,
      "backward_entropy": 0.0630124265497381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.169921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007938364520668983,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09083876013755798,
      "backward_entropy": 0.06301239403811368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.15252685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008029693737626076,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082851807276408,
      "backward_entropy": 0.06292059204795143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.67788696289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008127615787088871,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09081790844599406,
      "backward_entropy": 0.06291839751330289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.6653594970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008228790014982224,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080700079600017,
      "backward_entropy": 0.06301236152648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.18063354492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008327803574502468,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09079607327779134,
      "backward_entropy": 0.06301235610788519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1511993408203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008423268795013428,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078514575958252,
      "backward_entropy": 0.0630123344334689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.32211303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008515546098351479,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077419837315877,
      "backward_entropy": 0.06299058957533403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4373321533203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008606388233602047,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907631516456604,
      "backward_entropy": 0.06301226399161598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.93426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008698537945747375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075182676315308,
      "backward_entropy": 0.06290340965444391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.2313690185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008788157254457474,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074055155118306,
      "backward_entropy": 0.06290050528266213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.50953674316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008879532106220722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09072904785474141,
      "backward_entropy": 0.06289757923646407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.09002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008976275101304054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09071707725524902,
      "backward_entropy": 0.06289475614374335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.24493408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009075132198631763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09070478876431783,
      "backward_entropy": 0.06298421187834306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.00218200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00917237251996994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09069254000981648,
      "backward_entropy": 0.06298311190171675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.70901489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009271673858165741,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09067996342976888,
      "backward_entropy": 0.06298200650648637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.49134826660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009372608736157417,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066701928774516,
      "backward_entropy": 0.06298087401823564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.44052124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0094736497849226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065378705660503,
      "backward_entropy": 0.0629796873439442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.6952362060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009571011178195477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09064061443010966,
      "backward_entropy": 0.06287662549452348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.06350708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009670703671872616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09062731266021729,
      "backward_entropy": 0.06297706473957408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.50302124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00977320596575737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09061402082443237,
      "backward_entropy": 0.0629757588559931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.02865600585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009873272851109505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906006892522176,
      "backward_entropy": 0.06297435001893477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 305.80023193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009973322041332722,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09058702985445659,
      "backward_entropy": 0.06297286532141945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.54254150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010082104243338108,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057250618934631,
      "backward_entropy": 0.06286013668233698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.77049255371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010189108550548553,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0905579427878062,
      "backward_entropy": 0.06301205808466132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.44224548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010295570828020573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09054317077000935,
      "backward_entropy": 0.06296836788004095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.28106689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010398812592029572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09052836894989014,
      "backward_entropy": 0.06296652013605292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.0040740966797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010499468073248863,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09051356712977092,
      "backward_entropy": 0.06301199306141246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.2089080810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010599288158118725,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09049869577089946,
      "backward_entropy": 0.06301194429397583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0453338623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01069775689393282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09048364559809367,
      "backward_entropy": 0.06296013702045787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.50225830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010795320384204388,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904683768749237,
      "backward_entropy": 0.06283333084800026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.83082580566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010893349535763264,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09045275052388509,
      "backward_entropy": 0.06301172213120894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.70128631591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010991696268320084,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09043685595194499,
      "backward_entropy": 0.06282433596524326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.10638427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011085424572229385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09042120973269145,
      "backward_entropy": 0.06281934001229027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.21109008789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011181493289768696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09040515621503194,
      "backward_entropy": 0.06281434405933727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.56906127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011276805773377419,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09038889408111572,
      "backward_entropy": 0.0628091963854703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.95889282226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011370450258255005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09037258227666219,
      "backward_entropy": 0.06294063004580411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.06333923339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011466455645859241,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035581350326538,
      "backward_entropy": 0.06293725967407227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.95335388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01156340166926384,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09033876657485962,
      "backward_entropy": 0.06279260461980646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.24990844726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011663689278066158,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09032118320465088,
      "backward_entropy": 0.06301084431734952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.57821655273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01176297664642334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903034508228302,
      "backward_entropy": 0.0629268234426325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.28170013427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011861267499625683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09028549989064534,
      "backward_entropy": 0.06292299790815874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6874237060547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011954400688409805,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0902676781018575,
      "backward_entropy": 0.06301047585227272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.90518188476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012048269622027874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024942914644878,
      "backward_entropy": 0.0629143389788541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.2919158935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012136598117649555,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090231587489446,
      "backward_entropy": 0.06290957060727206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.84738159179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012227662838995457,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09021315972010295,
      "backward_entropy": 0.06300993399186568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.25776672363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012315846048295498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09019472201665242,
      "backward_entropy": 0.06289957870136607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0138397216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012400412000715733,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090176522731781,
      "backward_entropy": 0.06273422457955101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.48281860351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012485326267778873,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09015790621439616,
      "backward_entropy": 0.06300914287567139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.23606872558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01257097627967596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09013899167378743,
      "backward_entropy": 0.06288272684270685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.55848693847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012658501043915749,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09011962016423543,
      "backward_entropy": 0.06271102211692116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.95559692382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012747606262564659,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09009973208109538,
      "backward_entropy": 0.06300828673622826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.13198852539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012828544713556767,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09008054931958516,
      "backward_entropy": 0.06269488551399925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.78189086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012913268059492111,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09006067117055257,
      "backward_entropy": 0.06285844065926292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.61871337890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012999765574932098,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09004022677739461,
      "backward_entropy": 0.06300735473632812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.96922302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013088165782392025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09001932541529338,
      "backward_entropy": 0.06284567442807285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.25625610351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013179568573832512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.089997798204422,
      "backward_entropy": 0.06283938884735107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.00090789794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01327215600758791,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08997577428817749,
      "backward_entropy": 0.0628329569643194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.81689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01336037740111351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08995398879051208,
      "backward_entropy": 0.06282597238367255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.80364227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013453012332320213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08993138869603474,
      "backward_entropy": 0.06281928582624956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.9126434326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013540121726691723,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08990925550460815,
      "backward_entropy": 0.063006422736428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.6079559326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013626327738165855,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08988696336746216,
      "backward_entropy": 0.06300619515505704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.450439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013711518608033657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0898644228776296,
      "backward_entropy": 0.06260941787199541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.24925231933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013793193735182285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0898420512676239,
      "backward_entropy": 0.06259914961728183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.33901977539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013879827223718166,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08981851736704509,
      "backward_entropy": 0.06258936361833052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.306884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013971383683383465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08979411919911702,
      "backward_entropy": 0.06277158043601296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.88600158691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01406312920153141,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08976946274439494,
      "backward_entropy": 0.06256996501575816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.81410217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014155151322484016,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0897445281346639,
      "backward_entropy": 0.06255970759825273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.20730590820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014248840510845184,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08971912662188213,
      "backward_entropy": 0.06300487301566383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.43515014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014345008879899979,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0896929403146108,
      "backward_entropy": 0.06273809346285733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.7774200439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014442198909819126,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08966624736785889,
      "backward_entropy": 0.06300476464358243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.01300048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014538789168000221,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08963921666145325,
      "backward_entropy": 0.06251775134693492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.03305053710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01463754940778017,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08961144089698792,
      "backward_entropy": 0.06300469962033359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.02401733398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014735441654920578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08958329757054646,
      "backward_entropy": 0.06300465627150102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.70877075195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014831126667559147,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08955499529838562,
      "backward_entropy": 0.06300450455058705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.60879516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014929385855793953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08952599763870239,
      "backward_entropy": 0.06268162618983876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.37164306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01502405945211649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08949707945187886,
      "backward_entropy": 0.06267066435380415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.8115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015119809657335281,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08946758508682251,
      "backward_entropy": 0.0630040548064492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.09674072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01521357148885727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08943790197372437,
      "backward_entropy": 0.06243498216975819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.2275390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01530431117862463,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08940836787223816,
      "backward_entropy": 0.06300342082977295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.15516662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015390541404485703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08937892317771912,
      "backward_entropy": 0.0626206939870661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.11615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0154842184856534,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08934783935546875,
      "backward_entropy": 0.062392559918490326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.54878997802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015570768155157566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08931773900985718,
      "backward_entropy": 0.06259354136206886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.58797454833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015650447458028793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08928831418355306,
      "backward_entropy": 0.06257788701490923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.76873779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015725983306765556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08925935626029968,
      "backward_entropy": 0.06256143071434715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.61249542236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015806036069989204,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08922921617825826,
      "backward_entropy": 0.06232651797207919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.27076721191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015881581231951714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08919950326283772,
      "backward_entropy": 0.06230853904377331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.28355407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01596176065504551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08916860818862915,
      "backward_entropy": 0.0625117150220004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.7167205810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016041547060012817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08913727601369222,
      "backward_entropy": 0.062494619326158005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.71446228027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016123680397868156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08910493055979411,
      "backward_entropy": 0.062477306886152786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.62220764160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016205662861466408,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0890723168849945,
      "backward_entropy": 0.06299653920260342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.289794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016288654878735542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08903908729553223,
      "backward_entropy": 0.062441349029541016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.28923034667969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01637234352529049,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08900514245033264,
      "backward_entropy": 0.06299532543529164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.4045867919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016452351585030556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08897144595781963,
      "backward_entropy": 0.062178189104253594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.92378234863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01653158664703369,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08893706401189168,
      "backward_entropy": 0.06215753338553689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4705352783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01660737209022045,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890275160471599,
      "backward_entropy": 0.06299267573790117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.46592712402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016683371737599373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08886802196502686,
      "backward_entropy": 0.06211395155299793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.68490600585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016756363213062286,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08883349100748698,
      "backward_entropy": 0.06209103085777976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.3863525390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016835713759064674,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08879753947257996,
      "backward_entropy": 0.06298973343589089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.61048889160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016914604231715202,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08876099189122517,
      "backward_entropy": 0.06298893148248846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.44772338867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01699891686439514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08872288465499878,
      "backward_entropy": 0.06202594800428911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.97378540039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01708078756928444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08868453900019328,
      "backward_entropy": 0.06200383468107744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.32566833496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017168980091810226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08864434560139973,
      "backward_entropy": 0.061983097683299675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.33599853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0172563586384058,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08860411246617635,
      "backward_entropy": 0.061961488290266556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.54411315917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01734468713402748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08856361111005147,
      "backward_entropy": 0.06214483759619973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.78880310058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017427507787942886,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08852372566858928,
      "backward_entropy": 0.06298599459908226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.93142700195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01751267910003662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08848288655281067,
      "backward_entropy": 0.06209260767156428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017598504200577736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088441401720047,
      "backward_entropy": 0.062066078186035156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.7041015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017687713727355003,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08839868505795796,
      "backward_entropy": 0.06298456950621172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.86524963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01778397522866726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08835369348526001,
      "backward_entropy": 0.06201539256355979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.89207458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01787860319018364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08830881118774414,
      "backward_entropy": 0.06198982217095115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.83416748046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017967211082577705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08826485276222229,
      "backward_entropy": 0.06298435276204889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.57830810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018056321889162064,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08822037776311238,
      "backward_entropy": 0.061747177080674606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3994903564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018147019669413567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08817489941914876,
      "backward_entropy": 0.06190465797077526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.05907440185547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018237799406051636,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08812883496284485,
      "backward_entropy": 0.06298335573889992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92549896240234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018324553966522217,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08808336655298869,
      "backward_entropy": 0.06298271092501553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.16929626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018408019095659256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08803855379422505,
      "backward_entropy": 0.0618102875622836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.21722412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018490629270672798,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08799315492312114,
      "backward_entropy": 0.06160511753775857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.1774139404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01857852376997471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08794585863749187,
      "backward_entropy": 0.06174243580211292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.46401977539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018672440201044083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08789642651875813,
      "backward_entropy": 0.06171052022413774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.70824432373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018763504922389984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08784735202789307,
      "backward_entropy": 0.061676859855651855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.71538543701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018850520253181458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0877988338470459,
      "backward_entropy": 0.06164098869670521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.48699188232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018930429592728615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08775142828623454,
      "backward_entropy": 0.061448882926594124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.91477966308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01900634355843067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08770505587259929,
      "backward_entropy": 0.061560414054177025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.78488159179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019081011414527893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08765841523806255,
      "backward_entropy": 0.061517785895954476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.77238464355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019160695374011993,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08760998646418254,
      "backward_entropy": 0.06133614345030351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.35712432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019237369298934937,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08756185571352641,
      "backward_entropy": 0.061433846300298516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 231.57174682617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01931145042181015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08751400311787923,
      "backward_entropy": 0.06138914281671697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.84359741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019392993301153183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08746323982874553,
      "backward_entropy": 0.061218456788496536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.41256713867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01947706565260887,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08741108576456706,
      "backward_entropy": 0.061180374839089134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.94703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019562162458896637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08735813697179158,
      "backward_entropy": 0.06125885790044611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.85165405273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019649645313620567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08730395634969075,
      "backward_entropy": 0.06121503223072399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.64675903320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019739268347620964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08724857370058696,
      "backward_entropy": 0.061064709316600456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.55789184570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01982617937028408,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08719328045845032,
      "backward_entropy": 0.06296790729869496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.19477844238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019909599795937538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08713867266972859,
      "backward_entropy": 0.0610753135247664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.78318786621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019988596439361572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08708523710568745,
      "backward_entropy": 0.06102412397211248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.64962768554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020064789801836014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0870321790377299,
      "backward_entropy": 0.06097075072201816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.87307739257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02013986185193062,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08697887261708577,
      "backward_entropy": 0.06296217983419244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.94097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020214155316352844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08692540725072224,
      "backward_entropy": 0.060789996927434746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.65316772460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020296068862080574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08686869343121846,
      "backward_entropy": 0.0607432560487227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.16631317138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02038220502436161,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08680999279022217,
      "backward_entropy": 0.06069759889082475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.76690673828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020460160449147224,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08675344785054524,
      "backward_entropy": 0.06064771522175182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.85401916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02053937129676342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08669606844584148,
      "backward_entropy": 0.060597473924810234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.60189819335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020617282018065453,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08663890759150188,
      "backward_entropy": 0.0605456991629167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.35250854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020695749670267105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08658126990000407,
      "backward_entropy": 0.06051150235262784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.7675018310547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020773116499185562,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08652359247207642,
      "backward_entropy": 0.06295291943983598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.2483673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020854678004980087,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08646347125371297,
      "backward_entropy": 0.06038679859854958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.61448669433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02093450166285038,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08640331029891968,
      "backward_entropy": 0.06033241206949407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.95237731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02101460099220276,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08634267250696818,
      "backward_entropy": 0.06027714772657915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.27183532714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02109149470925331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08628243207931519,
      "backward_entropy": 0.060186684131622314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.17123413085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021172989159822464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0862198273340861,
      "backward_entropy": 0.06011862104589289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.30642700195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021255983039736748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0861562192440033,
      "backward_entropy": 0.06005025993693958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.7736053466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02133861742913723,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08609209458033244,
      "backward_entropy": 0.060047469355843285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.56484985351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02142401598393917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08602641026178996,
      "backward_entropy": 0.05998945236206055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.50155639648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021510308608412743,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08595975240071614,
      "backward_entropy": 0.05993087725205855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.70147705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021597078070044518,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0858919620513916,
      "backward_entropy": 0.05976304140957919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.85012817382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021684499457478523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08582324783007304,
      "backward_entropy": 0.05981073596260764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.07330322265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02177690528333187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08575195074081421,
      "backward_entropy": 0.0629438270222057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.20799255371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02186790108680725,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0856805145740509,
      "backward_entropy": 0.05969127741726962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.05027770996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021961726248264313,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08560703198115031,
      "backward_entropy": 0.059630865400487724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.72991943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022051338106393814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08553483088811238,
      "backward_entropy": 0.059373557567596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.85530853271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02214016020298004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08546255032221477,
      "backward_entropy": 0.05928909778594971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.21507263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02222364768385887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08539191881815593,
      "backward_entropy": 0.05919632044705478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.71869659423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02230675332248211,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08532084027926128,
      "backward_entropy": 0.059359041127291595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.3218994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022386731579899788,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08525062600771587,
      "backward_entropy": 0.059001033956354317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.623779296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02246367558836937,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08518104751904805,
      "backward_entropy": 0.05920643156225031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.48652648925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022540360689163208,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08511046568552653,
      "backward_entropy": 0.059127460826526985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.43785095214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022612936794757843,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0850411852200826,
      "backward_entropy": 0.059045022184198555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.96237182617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022682780399918556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08497211337089539,
      "backward_entropy": 0.05856803330508145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.88945007324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022752264514565468,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08490275343259175,
      "backward_entropy": 0.05845154957337813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.41522216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022820133715867996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08483387033144633,
      "backward_entropy": 0.058333299376747826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.63699340820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022889267653226852,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0847638448079427,
      "backward_entropy": 0.058214008808135986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.48907470703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022959774360060692,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08469282587369283,
      "backward_entropy": 0.06291445276953957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.23348236083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023032810539007187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0846200982729594,
      "backward_entropy": 0.05797507546164773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.33984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023103678598999977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08454787731170654,
      "backward_entropy": 0.05785208398645574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.81014251708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023175431415438652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08447462320327759,
      "backward_entropy": 0.05772710930217396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.52378845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0232436191290617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08440242211023967,
      "backward_entropy": 0.05759818987412886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.64680480957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023317288607358932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08432689309120178,
      "backward_entropy": 0.05747014284133911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.91383361816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02338755689561367,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08425287405649821,
      "backward_entropy": 0.06290083581751044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.12989807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023463215678930283,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0841755469640096,
      "backward_entropy": 0.057918678630482064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.09121704101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023539530113339424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08409746487935384,
      "backward_entropy": 0.05781178040937944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.95599365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023619234561920166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08401713768641154,
      "backward_entropy": 0.05694555152546276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.26364135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023702315986156464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08393486340840657,
      "backward_entropy": 0.056815602562644264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.31266021728516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023783575743436813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08385282754898071,
      "backward_entropy": 0.06289701570164073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.38368225097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023861560970544815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08377162615458171,
      "backward_entropy": 0.05653833801096136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.28541564941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023938477039337158,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08369054396947224,
      "backward_entropy": 0.05639317360791293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.03655242919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024014778435230255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08360968033472697,
      "backward_entropy": 0.05624496936798096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.85153198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024089006707072258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08352975050608318,
      "backward_entropy": 0.056092934174971146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.63922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02416386641561985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08344875772794087,
      "backward_entropy": 0.05593615770339966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.18775939941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024238457903265953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08336787422498067,
      "backward_entropy": 0.05577848716215654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.99456024169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024312591180205345,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08328694105148315,
      "backward_entropy": 0.06288489428433505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.1181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024380015209317207,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08320913215478261,
      "backward_entropy": 0.056478272784839974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.41915893554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024450093507766724,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08312891920407613,
      "backward_entropy": 0.06287895549427379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.40457153320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024524305015802383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0830458402633667,
      "backward_entropy": 0.05510902404785156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.96717834472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0245978981256485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08296264211336772,
      "backward_entropy": 0.05606043338775635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.57481384277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024671057239174843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08287931481997173,
      "backward_entropy": 0.06287261572751132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.62029266357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024746323004364967,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08279394606749217,
      "backward_entropy": 0.06287077340212735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.00843811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0248175747692585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08271010220050812,
      "backward_entropy": 0.05562619729475542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.18536376953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024891598150134087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08262437582015991,
      "backward_entropy": 0.054200508377768776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.08993530273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02496529184281826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08253867427508037,
      "backward_entropy": 0.05401310053738681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.22447204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025041751563549042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08245127399762471,
      "backward_entropy": 0.05382763797586614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.16796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025123266503214836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08236048618952434,
      "backward_entropy": 0.0536425763910467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.67981719970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025200529024004936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08227179447809856,
      "backward_entropy": 0.05487568811936812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.60124206542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025275282561779022,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08218396703402202,
      "backward_entropy": 0.053252306851473724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.32714080810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025346240028738976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08209774394830067,
      "backward_entropy": 0.05455324866554954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.08760833740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025411128997802734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08201499780019124,
      "backward_entropy": 0.05283455415205522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.48336791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547333389520645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0819333444039027,
      "backward_entropy": 0.05261902917515148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.69454956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025537891313433647,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08184996247291565,
      "backward_entropy": 0.05240365591916171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.70365905761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02560858614742756,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08176219960053761,
      "backward_entropy": 0.053862403739582405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.27912139892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025677597150206566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08167511224746704,
      "backward_entropy": 0.05197192322124134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.42613220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025745218619704247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08158783614635468,
      "backward_entropy": 0.05175061659379439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.04701232910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02581785060465336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08149653673171997,
      "backward_entropy": 0.051534820686687126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.32162475585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025891371071338654,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08140356341997783,
      "backward_entropy": 0.06283127719705756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.26250457763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025958405807614326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08131418128808339,
      "backward_entropy": 0.05298414555462924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.2413787841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026022614911198616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08122600118319194,
      "backward_entropy": 0.05085169727152044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.25289916992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026090584695339203,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08113513886928558,
      "backward_entropy": 0.050619965249841865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.68238830566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026160411536693573,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08104283114274342,
      "backward_entropy": 0.052428397265347565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.64554595947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026224270462989807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08095406989256541,
      "backward_entropy": 0.050147544253956185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.64231872558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02628721483051777,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08086541791756947,
      "backward_entropy": 0.052034367214549675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.07716369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02635517157614231,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0807728370030721,
      "backward_entropy": 0.04966033588756214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.61392211914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02642633579671383,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08067772785822551,
      "backward_entropy": 0.06280886043201793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.93797302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026500502601265907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08058049281438191,
      "backward_entropy": 0.049176237799904564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.22544860839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026576809585094452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08048105239868164,
      "backward_entropy": 0.04892916029149836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.17647552490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0266541987657547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08038078745206197,
      "backward_entropy": 0.05103119936856357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.45250701904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026729267090559006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08028173943360646,
      "backward_entropy": 0.05082327669317072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.89835357666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026802487671375275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0801837941010793,
      "backward_entropy": 0.050609100948680534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.36317443847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026872389018535614,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08008780082066853,
      "backward_entropy": 0.05038750713521784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.65961456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026939082890748978,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07999329268932343,
      "backward_entropy": 0.04763540354642001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.599853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027003129944205284,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07990023493766785,
      "backward_entropy": 0.04992479085922241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.60154724121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02706254832446575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07980906466643016,
      "backward_entropy": 0.049685424024408516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.62269592285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027118965983390808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07972033818562825,
      "backward_entropy": 0.0467832630330866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.55055236816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02717691846191883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07963039477666219,
      "backward_entropy": 0.046494668180292305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.77277374267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02723482809960842,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07954046130180359,
      "backward_entropy": 0.04894228415055708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.88134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027294384315609932,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07944948474566142,
      "backward_entropy": 0.048693429340015755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.99563980102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027362661436200142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07935244341691335,
      "backward_entropy": 0.04564301534132524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.9024658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027423519641160965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07926035920778911,
      "backward_entropy": 0.048204356973821465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.948974609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027485528960824013,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07916738092899323,
      "backward_entropy": 0.06275902011177757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.89321899414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027557088062167168,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07906735936800639,
      "backward_entropy": 0.04771277037533847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.81842803955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027630386874079704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07896641890207927,
      "backward_entropy": 0.04449277574365789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.00972747802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02769797295331955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07887014746665955,
      "backward_entropy": 0.04420468211174011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.50082397460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027766186743974686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07877352833747864,
      "backward_entropy": 0.04391558332876726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.45404815673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02783377654850483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07867785294850667,
      "backward_entropy": 0.04362640597603538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.83860778808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027900362387299538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858269413312276,
      "backward_entropy": 0.04333226789127697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.02461242675781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027962714433670044,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07848989963531494,
      "backward_entropy": 0.06274512681094083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.01626586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028022486716508865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07839791973431905,
      "backward_entropy": 0.045912455428730355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.21975708007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028086496517062187,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07830254236857097,
      "backward_entropy": 0.04564656452699141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.01770782470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028149351477622986,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782072941462199,
      "backward_entropy": 0.045377861369739876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.77613830566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028210310265421867,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07811363538106282,
      "backward_entropy": 0.04510504549199885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.84334945678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028272688388824463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07801924149195354,
      "backward_entropy": 0.04483269561420788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.04871368408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028330577537417412,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07792870203653972,
      "backward_entropy": 0.041142842986366966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.64834594726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02838386408984661,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07784120241800944,
      "backward_entropy": 0.04082099957899614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.84695434570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02843794785439968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07775332033634186,
      "backward_entropy": 0.04050091179934415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.26071166992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028495196253061295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07766248782475789,
      "backward_entropy": 0.04018003832210194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.59807586669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028557637706398964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07756861050923665,
      "backward_entropy": 0.03987038677388972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.53591918945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028618568554520607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07747625311215718,
      "backward_entropy": 0.03955844315615567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.74436950683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028682809323072433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738205790519714,
      "backward_entropy": 0.039252991026098076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.36662292480469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028755251318216324,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07728168368339539,
      "backward_entropy": 0.06270338188518178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.24183654785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02882344461977482,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07718456288178761,
      "backward_entropy": 0.04232087460431186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.35542297363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028899874538183212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07708208759625752,
      "backward_entropy": 0.03833466226404363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.9381561279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02897157520055771,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07698292533556621,
      "backward_entropy": 0.04178115725517273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.35494232177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029049428179860115,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07687915861606598,
      "backward_entropy": 0.04151355678384954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.72844696044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02912398986518383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07677814861138661,
      "backward_entropy": 0.037408292293548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.76712799072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029197480529546738,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07667856415112813,
      "backward_entropy": 0.037097036838531494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.56446838378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029271114617586136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07657885551452637,
      "backward_entropy": 0.04068020257082852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.65103149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029346533119678497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07647814353307088,
      "backward_entropy": 0.036473008719357575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.610897064208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029423899948596954,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07637679576873779,
      "backward_entropy": 0.04012689807198264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.0065155029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02949199452996254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07628226280212402,
      "backward_entropy": 0.03584827076305042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.90757751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02957148291170597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0761803388595581,
      "backward_entropy": 0.03554755449295044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.08505249023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02965100109577179,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760791649421056,
      "backward_entropy": 0.03524931452491067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.53900146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029732596129179,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07597614328066508,
      "backward_entropy": 0.039021345702084625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.2301025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02982391230762005,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0758668730656306,
      "backward_entropy": 0.038763344287872314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.21449279785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029912572354078293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07576045393943787,
      "backward_entropy": 0.06272518634796143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.38722229003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030002929270267487,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07565327485402425,
      "backward_entropy": 0.03406751968643882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.2808380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030092040076851845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07554756601651509,
      "backward_entropy": 0.033768044276670975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.14310455322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030183034017682076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07544125119845073,
      "backward_entropy": 0.033470885320143265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.31474304199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03026960976421833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07533831397692363,
      "backward_entropy": 0.03316469625993208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.37430572509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030352553352713585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07523861527442932,
      "backward_entropy": 0.03285606882788918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.27800750732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03043213300406933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07514175772666931,
      "backward_entropy": 0.036834456703879616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.13828659057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030509669333696365,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07504606246948242,
      "backward_entropy": 0.036537024107846344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.05957794189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030581364408135414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07495480279127757,
      "backward_entropy": 0.03190769932486794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.82125091552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030652280896902084,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0748641590277354,
      "backward_entropy": 0.035929333079944954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.89555358886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030719581991434097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07477655013402303,
      "backward_entropy": 0.03126427802172574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.17529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030783535912632942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07469137509663899,
      "backward_entropy": 0.03093807263807817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.21305847167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030841318890452385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07461038728555043,
      "backward_entropy": 0.030605088580738415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.7783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03089696355164051,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07453128198782603,
      "backward_entropy": 0.03467487747018987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.098514556884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030960965901613235,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07444668312867482,
      "backward_entropy": 0.029950765046206387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.89940643310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03102072700858116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07436550656954448,
      "backward_entropy": 0.02962718497623097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.51180267333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03108104132115841,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07428417603174846,
      "backward_entropy": 0.03375240347602151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.18009948730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03114057518541813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07420407732327779,
      "backward_entropy": 0.028984779661351986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.6021728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031202351674437523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0741228461265564,
      "backward_entropy": 0.03314117951826616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.34909439086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03125767409801483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07404511670271556,
      "backward_entropy": 0.02834138816053217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.55221557617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03130841627717018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07397149999936421,
      "backward_entropy": 0.028010975230823864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.861141204833984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03135767579078674,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07389913499355316,
      "backward_entropy": 0.06266346302899448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.67141723632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03140398859977722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0738287369410197,
      "backward_entropy": 0.03186860409649936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.26581573486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031449094414711,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07375901937484741,
      "backward_entropy": 0.02701071175661954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.05545043945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03149466961622238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07368891437848409,
      "backward_entropy": 0.031228528781370682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.45272827148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03154804930090904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0736134151617686,
      "backward_entropy": 0.030924065546555954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.30630493164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031604696065187454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07353674372037251,
      "backward_entropy": 0.030627906322479248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.04299926757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03165910392999649,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07346149285634358,
      "backward_entropy": 0.06262261217290704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.78829193115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03171876072883606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0733826607465744,
      "backward_entropy": 0.025396398522637108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.66493606567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031777989119291306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07330507040023804,
      "backward_entropy": 0.029750796881589023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.00468444824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031834252178668976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07323088745276134,
      "backward_entropy": 0.02946040305224332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.79771423339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031890153884887695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07315737009048462,
      "backward_entropy": 0.024468920447609642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.40409278869629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031947050243616104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07308318217595418,
      "backward_entropy": 0.02888289364901456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.38035583496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03199616074562073,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0730147659778595,
      "backward_entropy": 0.023847290060736916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.16413879394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03204580396413803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07294629017512004,
      "backward_entropy": 0.028292561119252987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.08794403076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032094113528728485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07287858426570892,
      "backward_entropy": 0.02799942276694558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.71875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032143089920282364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0728108137845993,
      "backward_entropy": 0.02771044048396024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.81741333007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03219829872250557,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07273904482523601,
      "backward_entropy": 0.06258759173479947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.13096618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03225773572921753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0726649562517802,
      "backward_entropy": 0.02232971245592291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.29312896728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03231831267476082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07259085277716319,
      "backward_entropy": 0.022042544050650162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.84405517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03237671032547951,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07251847783724467,
      "backward_entropy": 0.02175282754681327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.00714874267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03243338689208031,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07244786620140076,
      "backward_entropy": 0.026358314535834572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.88246154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03249015659093857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07237806419531505,
      "backward_entropy": 0.021177549253810535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.42214584350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03254811838269234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07230762143929799,
      "backward_entropy": 0.020893905650485645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.85718536376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032603394240140915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07224006454149882,
      "backward_entropy": 0.020615640011700718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.95187377929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0326576828956604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07217408219973247,
      "backward_entropy": 0.02529556101018732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.5472412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032718393951654434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0721049706141154,
      "backward_entropy": 0.025045264850963245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.64009857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03278150036931038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07203460733095805,
      "backward_entropy": 0.019821903922341087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.81521606445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03284379094839096,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07196496923764546,
      "backward_entropy": 0.024553469636223534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.39804077148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032911330461502075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07189266880353291,
      "backward_entropy": 0.024315395138480446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.17060852050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03298105299472809,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07181995610396068,
      "backward_entropy": 0.019062477079304783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.88158416748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033048391342163086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07174970209598541,
      "backward_entropy": 0.02384781837463379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.70587158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03311200439929962,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07168245315551758,
      "backward_entropy": 0.023609123446724632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.85094451904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03318091109395027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07161260644594829,
      "backward_entropy": 0.023379044099287552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.757728576660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03325173631310463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07154229780038197,
      "backward_entropy": 0.02315299077467485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.23652648925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03331835940480232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07147490978240967,
      "backward_entropy": 0.017847784540869972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.07646179199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03338569775223732,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07140763600667317,
      "backward_entropy": 0.01761021668260748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.25886917114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03344793990254402,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07134396334489186,
      "backward_entropy": 0.0224654268134724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.02545166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03350701555609703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07128260533014934,
      "backward_entropy": 0.01713358543135903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.96817016601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03357216343283653,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07121854523817699,
      "backward_entropy": 0.022014868530360134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.23049926757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03363627567887306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07115514079729716,
      "backward_entropy": 0.021793847734277897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.38176727294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03369840607047081,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07109315196673076,
      "backward_entropy": 0.016441227360205216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.12349700927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0337616428732872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07103072106838226,
      "backward_entropy": 0.016211405396461487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.79582214355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03382442146539688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07096886138121287,
      "backward_entropy": 0.01598371836272153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.47196197509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03388849273324013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07090705633163452,
      "backward_entropy": 0.02092381769960577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.55284881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03395237401127815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0708460807800293,
      "backward_entropy": 0.015541084788062355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.14104461669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0340188592672348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07078427076339722,
      "backward_entropy": 0.015326368537816134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.85716247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034087903797626495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0707219938437144,
      "backward_entropy": 0.015117489478804848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.16645812988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034157902002334595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07066015402475993,
      "backward_entropy": 0.020123251459815285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.80915832519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034228287637233734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07059849301973979,
      "backward_entropy": 0.019930880178104748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.20984649658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034300606697797775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07053641478220622,
      "backward_entropy": 0.019741161303086716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.8460693359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03437507152557373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07047436634699504,
      "backward_entropy": 0.019557085904208096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.34830474853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03445695713162422,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07040929794311523,
      "backward_entropy": 0.014132166450673883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.61421966552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0345354899764061,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0703468124071757,
      "backward_entropy": 0.01920619336041537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.216064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03461422771215439,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07028532028198242,
      "backward_entropy": 0.013764092868024652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.97408294677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034689780324697495,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0702258547147115,
      "backward_entropy": 0.018856135281649502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.72146606445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034762583673000336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07016825675964355,
      "backward_entropy": 0.013393794948404486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.931640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0348401702940464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07010917862256368,
      "backward_entropy": 0.013215739618648182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.10235595703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03491804003715515,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07005075613657634,
      "backward_entropy": 0.0627333630215038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4555206298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03500029444694519,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06999120116233826,
      "backward_entropy": 0.012876518748023293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.03536224365234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03508799895644188,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0699302355448405,
      "backward_entropy": 0.06275134736841376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.27771759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517203405499458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06987181305885315,
      "backward_entropy": 0.012562411752614107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.044719696044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035255566239356995,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06981436411539714,
      "backward_entropy": 0.06276669827374545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.56653594970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035331252962350845,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06976083914438884,
      "backward_entropy": 0.01758121360432018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.20980072021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03540864959359169,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06970713535944621,
      "backward_entropy": 0.017427021806890316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.85092163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035483766347169876,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06965539852778117,
      "backward_entropy": 0.017275605689395557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.91584014892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03555801138281822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06960469981034596,
      "backward_entropy": 0.011768120256337252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.44707489013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03563416749238968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06955372790495555,
      "backward_entropy": 0.011616152795878324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.74919128417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035709481686353683,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06950386861960094,
      "backward_entropy": 0.01683747497471896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.81063079833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03578341752290726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0694546749194463,
      "backward_entropy": 0.011316263540224596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.2814483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03586067631840706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06940466662247975,
      "backward_entropy": 0.011168016628785566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.175241470336914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03594400733709335,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06935299932956696,
      "backward_entropy": 0.0628071589903398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.71861267089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0360199399292469,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0693049430847168,
      "backward_entropy": 0.01628113876689564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.546287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03609752655029297,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06925669312477112,
      "backward_entropy": 0.016145798293027012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.55841064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0361715629696846,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06921073794364929,
      "backward_entropy": 0.016013755039735275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.766685485839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036244649440050125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06916557749112447,
      "backward_entropy": 0.010466239669106224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.83352661132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0363159216940403,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06912168860435486,
      "backward_entropy": 0.010330071503465826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.58808898925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036387182772159576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0690785547097524,
      "backward_entropy": 0.015625292604619808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.18836975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036460746079683304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06903502345085144,
      "backward_entropy": 0.010071400214325298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.320621490478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03653091937303543,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0689932107925415,
      "backward_entropy": 0.009942717172882774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.93443298339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036599479615688324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06895243128140767,
      "backward_entropy": 0.00981541316617619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.25663757324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036667048931121826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06891279419263203,
      "backward_entropy": 0.009693403135646473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.14935302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036734726279973984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06887351969877879,
      "backward_entropy": 0.009573005817153236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.15491485595703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03680243343114853,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0688345730304718,
      "backward_entropy": 0.06283600763841109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.74424743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03687159717082977,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06879550218582153,
      "backward_entropy": 0.009335557168180292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.41301727294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03694085031747818,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06875697275002797,
      "backward_entropy": 0.014695190570571205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.58145904541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037010546773672104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06871893008550008,
      "backward_entropy": 0.009112788194959814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.38760375976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03708320111036301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06868045528729756,
      "backward_entropy": 0.01450023732402108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.063758850097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03715696185827255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06864212950070699,
      "backward_entropy": 0.00890950858592987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.021018981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0372290201485157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06860483686129253,
      "backward_entropy": 0.008808632465926084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.76203918457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03729790821671486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06856883565584819,
      "backward_entropy": 0.008704765953800896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.81324768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03736710175871849,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06853325168291728,
      "backward_entropy": 0.014125744050199335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.53120422363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03744286298751831,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06849578022956848,
      "backward_entropy": 0.014033965089104393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.15705108642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03751547262072563,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06845984359582265,
      "backward_entropy": 0.013943708755753258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.38321304321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037592045962810516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06842320660750072,
      "backward_entropy": 0.008311816914515062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.05892181396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03766641393303871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06838753819465637,
      "backward_entropy": 0.008215717293999412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.71240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03774036467075348,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06835238635540009,
      "backward_entropy": 0.013684058731252497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.53130340576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781648352742195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06831693649291992,
      "backward_entropy": 0.00802595777945085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.87458801269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03789350390434265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06828198830286662,
      "backward_entropy": 0.00793392685326663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.33509826660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03796727582812309,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06824812789758046,
      "backward_entropy": 0.007843055508353493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.83988952636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03804091364145279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06821483373641968,
      "backward_entropy": 0.007755395363677631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.71280288696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038116805255413055,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06818122665087382,
      "backward_entropy": 0.013277099891142412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.65534591674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03818846493959427,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06814945737520854,
      "backward_entropy": 0.007584151896563443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.31698989868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03825625404715538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06811924775441487,
      "backward_entropy": 0.007501831108873541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.67684936523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038321804255247116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06809002161026001,
      "backward_entropy": 0.007420594041997736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.75882339477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038387738168239594,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06806084513664246,
      "backward_entropy": 0.012988506392999128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.54327392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038453035056591034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06803221503893535,
      "backward_entropy": 0.01292032545263117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.55543899536133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03851807862520218,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06800413131713867,
      "backward_entropy": 0.012858805331316862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.976563453674316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0385824590921402,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06797646482785542,
      "backward_entropy": 0.012797762047160755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.317142486572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03864118084311485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06795067588488261,
      "backward_entropy": 0.0070390721613710575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.66508483886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03869990259408951,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0679250955581665,
      "backward_entropy": 0.0069671977650035515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.005367279052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038760311901569366,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06789941092332204,
      "backward_entropy": 0.006898984313011169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.42185974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03881797939538956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06787463525931041,
      "backward_entropy": 0.006830996410413222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.431964874267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0388801284134388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06784910957018535,
      "backward_entropy": 0.006767054173079404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.21888732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03893779590725899,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0678247759739558,
      "backward_entropy": 0.006700615991245617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.00164794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038996949791908264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06780029833316803,
      "backward_entropy": 0.006635028530250896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.73468780517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039057809859514236,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06777563691139221,
      "backward_entropy": 0.06290473179383711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.59146118164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039122797548770905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06775039931138356,
      "backward_entropy": 0.0065143379298123446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.57471466064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039191290736198425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06772461533546448,
      "backward_entropy": 0.006456438113342632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.17839813232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03926058113574982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06769904494285583,
      "backward_entropy": 0.012261146848851984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.01089096069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039333026856184006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06767324606577556,
      "backward_entropy": 0.012226539579304781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.46595001220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039404187351465225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06764783958594005,
      "backward_entropy": 0.012190476059913635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.01873016357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03947697952389717,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06762219965457916,
      "backward_entropy": 0.012155646627599543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.35916900634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039549827575683594,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06759698192278545,
      "backward_entropy": 0.0121203674511476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.10784149169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962542861700058,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06757158537705739,
      "backward_entropy": 0.006134832447225397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.04198455810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03970370441675186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06754601995150249,
      "backward_entropy": 0.006085521118207412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.02635955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03977934271097183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06752145290374756,
      "backward_entropy": 0.012032880024476484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.19013977050781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039852023124694824,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06749769548575084,
      "backward_entropy": 0.06293725967407227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.10496520996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039924874901771545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0674741913874944,
      "backward_entropy": 0.005944317714734511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.25154113769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03999955207109451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06745072702566783,
      "backward_entropy": 0.005900544199076566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.70561218261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04007953777909279,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06742661197980244,
      "backward_entropy": 0.005858625877987255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.46812438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04015891253948212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0674029141664505,
      "backward_entropy": 0.005816170437769456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.40019989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04023659601807594,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06737985213597615,
      "backward_entropy": 0.011899574236436323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.21799087524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031795635819435,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06735648214817047,
      "backward_entropy": 0.011881898749958385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.93927764892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040395911782979965,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06733398636182149,
      "backward_entropy": 0.0056927420876242895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.004825592041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040476132184267044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06731140613555908,
      "backward_entropy": 0.011842179027470675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.770286560058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04055216908454895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06728989879290263,
      "backward_entropy": 0.0056130926717411385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.14341735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040626753121614456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06726887822151184,
      "backward_entropy": 0.005574441768906333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.31891632080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04070537909865379,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06724749008814494,
      "backward_entropy": 0.0055374526842073965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.99713897705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04078386351466179,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06722644964853923,
      "backward_entropy": 0.005502335049889304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.40256881713867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04086330533027649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06720553835233052,
      "backward_entropy": 0.01177585937760093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.520442962646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040939703583717346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0671853522459666,
      "backward_entropy": 0.011764843355525623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.90990447998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04101203754544258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06716602047284444,
      "backward_entropy": 0.0054003166204149074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.37986755371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04108857735991478,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06714632610479991,
      "backward_entropy": 0.01174152439290827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.95552444458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041170187294483185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06712615489959717,
      "backward_entropy": 0.005334891040216793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.178810119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04124849662184715,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06710674365361531,
      "backward_entropy": 0.005302228033542633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.74165344238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04132252186536789,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06708806256453197,
      "backward_entropy": 0.005269049243493514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.605384826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04139384999871254,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06707003215948741,
      "backward_entropy": 0.011693954467773438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.26377868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04146320000290871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06705249349276225,
      "backward_entropy": 0.005202479999173771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.20954132080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041534602642059326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06703485548496246,
      "backward_entropy": 0.005172095515511252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.44148254394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04161028936505318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06701686978340149,
      "backward_entropy": 0.005142676559361545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.20790100097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041688308119773865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06699879467487335,
      "backward_entropy": 0.005112545734102076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.490478515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041768528521060944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06698071956634521,
      "backward_entropy": 0.0050825513899326324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.38975524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041849587112665176,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06696269412835439,
      "backward_entropy": 0.005053567615422336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.982255935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04192880541086197,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06694518029689789,
      "backward_entropy": 0.005025055598128925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.07410430908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042002610862255096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06692854563395183,
      "backward_entropy": 0.004997260868549347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.41378021240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0420815572142601,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06691149870554607,
      "backward_entropy": 0.011617527766661211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.15165710449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04216408357024193,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06689427296320598,
      "backward_entropy": 0.004943680356849323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.956260681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042249564081430435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06687695781389873,
      "backward_entropy": 0.0049175443974408236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.50018310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04233404994010925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06686000029246013,
      "backward_entropy": 0.011600959030064669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.56157684326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04241625592112541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06684352457523346,
      "backward_entropy": 0.004866274920376864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.975830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04250289499759674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06682680050532024,
      "backward_entropy": 0.004841988059607419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.66697883605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04258579760789871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06681070725123088,
      "backward_entropy": 0.004817591133442792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.734500885009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0426642931997776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06679526468118031,
      "backward_entropy": 0.004794607108289545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.749656677246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04273996874690056,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06678027908007304,
      "backward_entropy": 0.011584352363239635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.90896606445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04281419888138771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06676559646924336,
      "backward_entropy": 0.004749103703282096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.537254333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042890775948762894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06675087908903758,
      "backward_entropy": 0.004724957048892975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.238216400146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04296724125742912,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06673632562160492,
      "backward_entropy": 0.011571331457658247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.17095947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043039627373218536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06672238806883495,
      "backward_entropy": 0.004677563905715942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.01367950439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04310981184244156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06670865416526794,
      "backward_entropy": 0.004654578187248923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.98880386352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043184153735637665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06669476131598155,
      "backward_entropy": 0.004631774669343775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.71650695800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04325473681092262,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06668135523796082,
      "backward_entropy": 0.004608990116552873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.733211517333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04332580789923668,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06666802366574605,
      "backward_entropy": 0.004587136547673832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.864192962646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043394554406404495,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06665503978729248,
      "backward_entropy": 0.011540536176074635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.811613082885742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04345901310443878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06664253274599712,
      "backward_entropy": 0.01153745028105649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.27760314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043519482016563416,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06663047273953755,
      "backward_entropy": 0.011535215106877413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.97005081176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0435803197324276,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06661838293075562,
      "backward_entropy": 0.011536466804417696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.82865524291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04364250600337982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06660637259483337,
      "backward_entropy": 0.011537554589184847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.386648178100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04370598867535591,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06659432252248128,
      "backward_entropy": 0.0044651349837129765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.53746795654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04376700147986412,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06658248106638591,
      "backward_entropy": 0.004447818818417462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.1179428100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04382926970720291,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0665706992149353,
      "backward_entropy": 0.004429890689524737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.24688720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04389409348368645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06655878822008769,
      "backward_entropy": 0.004412602971900593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.42422103881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04395991191267967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06654690206050873,
      "backward_entropy": 0.004395536401055076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.657596588134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04402536526322365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06653515994548798,
      "backward_entropy": 0.004378625615076585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.17174530029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044089388102293015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06652359664440155,
      "backward_entropy": 0.011558967557820406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.65271759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04415319114923477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06651216248671214,
      "backward_entropy": 0.004346788268197666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.35435104370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044218290597200394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06650066872437795,
      "backward_entropy": 0.011570307341488924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.88980102539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04428191855549812,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06648936867713928,
      "backward_entropy": 0.004319198768247257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.68309020996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044347841292619705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06647802889347076,
      "backward_entropy": 0.011584712700410322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.04520034790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04441370069980621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06646668414274852,
      "backward_entropy": 0.004293230108239434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.412715911865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04448059946298599,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06645532449086507,
      "backward_entropy": 0.01161003519188274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.50977325439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044547028839588165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0664441188176473,
      "backward_entropy": 0.004270614886825735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.14933776855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04461929574608803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0664325753847758,
      "backward_entropy": 0.011635815555399115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.4002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04469069465994835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06642116109530131,
      "backward_entropy": 0.011650651693344116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.86929702758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04476255550980568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06640980144341786,
      "backward_entropy": 0.004239976744760166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.40030670166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04483354091644287,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06639856100082397,
      "backward_entropy": 0.011684542352502996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.665193557739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04490622133016586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0663872907559077,
      "backward_entropy": 0.004222322594035755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.57173919677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04497408866882324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06637648741404216,
      "backward_entropy": 0.004213001240383495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.8171157836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045046281069517136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0663654903570811,
      "backward_entropy": 0.011734033172780817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.947776794433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04511995241045952,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06635449330012004,
      "backward_entropy": 0.011748659339818087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.80888366699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04519130289554596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06634371479352315,
      "backward_entropy": 0.004184988411990079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.544437408447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04526659473776817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06633280217647552,
      "backward_entropy": 0.011777937412261963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.87705612182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04533802345395088,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0663222720225652,
      "backward_entropy": 0.004165791652419351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.82415008544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04540971666574478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06631181637446086,
      "backward_entropy": 0.004155812615698034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.533939361572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045482996851205826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06630125145117442,
      "backward_entropy": 0.011814874681559477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.30986022949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04555634409189224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06629072626431783,
      "backward_entropy": 0.004137358882210471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.093008041381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04562858119606972,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0662803053855896,
      "backward_entropy": 0.011839984492822126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.02291107177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045696113258600235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06627025206883748,
      "backward_entropy": 0.011852875351905823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.95162010192871,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045768000185489655,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06625994543234508,
      "backward_entropy": 0.06300878524780273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.57715606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04583648219704628,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06624989211559296,
      "backward_entropy": 0.011880672790787437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.52776336669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04590795189142227,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06623979409535725,
      "backward_entropy": 0.011894788254391064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.236454010009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04597978666424751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06622948249181111,
      "backward_entropy": 0.0040877627378160305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.17689895629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04605306684970856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06621921062469482,
      "backward_entropy": 0.004080847244371067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.1751708984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04612645134329796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06620903313159943,
      "backward_entropy": 0.004074243997985666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.82399368286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04619873687624931,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0661988506714503,
      "backward_entropy": 0.0040681490843946285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.339168548583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046271152794361115,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06618878245353699,
      "backward_entropy": 0.004062105986205014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.525074005126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0463399738073349,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06617904206116994,
      "backward_entropy": 0.0040554793720895595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752588272094727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046404559165239334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.066169540087382,
      "backward_entropy": 0.004049691964279522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.18162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04646402224898338,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06616039077440898,
      "backward_entropy": 0.004044199531728571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.367216110229492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04652484878897667,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06615120669205983,
      "backward_entropy": 0.01205919547514482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.96702766418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658208787441254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06614229579766591,
      "backward_entropy": 0.004032423211769624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.51844024658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04663737118244171,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06613349914550781,
      "backward_entropy": 0.012096881866455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.41990661621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046692050993442535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06612477699915568,
      "backward_entropy": 0.004021166061813181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.056175231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04675207659602165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06611582140127818,
      "backward_entropy": 0.004014635627919977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.2264404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04681464657187462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0661067267258962,
      "backward_entropy": 0.004008529877120798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034150078892707825,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04687585309147835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06609777609507243,
      "backward_entropy": 0.004002348265864633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.53980255126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693112522363663,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06608917315800984,
      "backward_entropy": 0.0039969679306853904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.463863372802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04698935151100159,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06608039140701294,
      "backward_entropy": 0.0039914355359294195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.30335998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0470455028116703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06607174873352051,
      "backward_entropy": 0.012215030464259062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.75321960449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047102175652980804,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06606310606002808,
      "backward_entropy": 0.012233102863485163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.07378387451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04715808108448982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06605452299118042,
      "backward_entropy": 0.003976451402360743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.567779541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04721459746360779,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06604588031768799,
      "backward_entropy": 0.0039721524173563175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.56064987182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047270383685827255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06603727738062541,
      "backward_entropy": 0.003967934034087441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.039979934692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04732906445860863,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06602853536605835,
      "backward_entropy": 0.012308153239163485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.91361999511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04738560691475868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06601996223131816,
      "backward_entropy": 0.003959375010295348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.185672760009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047443825751543045,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0660112698872884,
      "backward_entropy": 0.012346182357181202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.35954284667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047501128166913986,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06600264708201091,
      "backward_entropy": 0.012365251779556274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.71889114379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04755886644124985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06599396467208862,
      "backward_entropy": 0.003948066044937481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.676897048950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04761924967169762,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06598518292109172,
      "backward_entropy": 0.00394422628662803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.182865142822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04767735302448273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06597654024759929,
      "backward_entropy": 0.003940824080597271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.36551666259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047736965119838715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0659677783648173,
      "backward_entropy": 0.012444030154835094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.303606033325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04780019819736481,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.065958837668101,
      "backward_entropy": 0.0039341256699778815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.372047424316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047859594225883484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06595020492871602,
      "backward_entropy": 0.012480630116029219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.39181900024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04791676998138428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06594170133272807,
      "backward_entropy": 0.003927282311699607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.50331497192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047973114997148514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06593326230843861,
      "backward_entropy": 0.003924119540236213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.23868942260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048032231628894806,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0659246693054835,
      "backward_entropy": 0.012536723505366932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.15221405029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04809144139289856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06591612100601196,
      "backward_entropy": 0.0039171894842928105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.96108627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0481531023979187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06590743362903595,
      "backward_entropy": 0.003913359885865992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.812767028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048218097537755966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06589860220750172,
      "backward_entropy": 0.003909085284579884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.64214324951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048283837735652924,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06588967641194661,
      "backward_entropy": 0.06301193887537176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.744678497314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04835016652941704,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06588078538576762,
      "backward_entropy": 0.012610742991620844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.31116485595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048413511365652084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06587209800879161,
      "backward_entropy": 0.0038970180533149028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.581586837768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04847768694162369,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06586338082949321,
      "backward_entropy": 0.012637719511985779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.99093246459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04853910207748413,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06585484743118286,
      "backward_entropy": 0.012651623650030657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.619528770446777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048601582646369934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06584622462590535,
      "backward_entropy": 0.003885829990560358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.675758361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0486602857708931,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06583791971206665,
      "backward_entropy": 0.0038825571537017822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.270174026489258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872019961476326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0658294955889384,
      "backward_entropy": 0.0038789646192030473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.465630531311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04877780005335808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06582126021385193,
      "backward_entropy": 0.003875764256173914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.93803024291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04883204773068428,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06581333776315053,
      "backward_entropy": 0.012723235921426252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.729137420654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488891564309597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06580512722333272,
      "backward_entropy": 0.00386910851706158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.9041976928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0489453561604023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06579702099164327,
      "backward_entropy": 0.0038659460842609406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.038700103759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04900649935007095,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0657885620991389,
      "backward_entropy": 0.012763009829954668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.210129737854004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049070946872234344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06577988465627034,
      "backward_entropy": 0.003858891400423917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.732524871826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04913131892681122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06577156980832417,
      "backward_entropy": 0.012785216624086554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.109583854675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04918920248746872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06576348344484965,
      "backward_entropy": 0.0038510588082400236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.112138748168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0492437407374382,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06575565536816914,
      "backward_entropy": 0.012805635278875177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.024513244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929756373167038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06574785709381104,
      "backward_entropy": 0.003843727098269896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.87894821166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935312643647194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0657398800055186,
      "backward_entropy": 0.003840453584085811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.91639518737793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04941024258732796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06573174397150676,
      "backward_entropy": 0.003837507556785237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.4443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04946409538388252,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06572381655375163,
      "backward_entropy": 0.003834860568696802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049521882086992264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06571565568447113,
      "backward_entropy": 0.0038319074294783854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.905906677246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049578651785850525,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0657075047492981,
      "backward_entropy": 0.012877435846762224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.427141189575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496356301009655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06569936871528625,
      "backward_entropy": 0.003826547075401653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.655967712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049691662192344666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06569126745065053,
      "backward_entropy": 0.0038241127675229854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.14285659790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049747906625270844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06568320592244466,
      "backward_entropy": 0.0038213452154939823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.565709114074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04980665072798729,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06567494571208954,
      "backward_entropy": 0.0129241482778029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.04505157470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049861907958984375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06566700339317322,
      "backward_entropy": 0.003815417601303621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.380558013916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04992087930440903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06565878788630168,
      "backward_entropy": 0.012943057851357893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.81409454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998095706105232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06565043330192566,
      "backward_entropy": 0.003809174353426153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.06344985961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05003965646028519,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06564225753148396,
      "backward_entropy": 0.003805899145928296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.455617904663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050099439918994904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06563400228818257,
      "backward_entropy": 0.012967399575493553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.502199172973633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05015678331255913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0656260351339976,
      "backward_entropy": 0.012975302609530363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.206256866455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050213031470775604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06561799844106038,
      "backward_entropy": 0.0037963922050866213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.38386535644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05026610195636749,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06561023990313213,
      "backward_entropy": 0.012992372567003424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.16155242919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050319671630859375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.065602441628774,
      "backward_entropy": 0.0037914633073590017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.118816375732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050371430814266205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06559476256370544,
      "backward_entropy": 0.0037893111055547542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.022661209106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05042262375354767,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06558715303738911,
      "backward_entropy": 0.0037869543514468455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.90631103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050472211092710495,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06557969748973846,
      "backward_entropy": 0.013031108812852339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.847179412841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050523750483989716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06557204325993855,
      "backward_entropy": 0.003782488744367253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.943327903747559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05057479441165924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06556442379951477,
      "backward_entropy": 0.013049796223640442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.836597442626953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05062199383974075,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06555711229642232,
      "backward_entropy": 0.0630114891312339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.48542785644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05066680163145065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0655500590801239,
      "backward_entropy": 0.0037769350138577547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.257511138916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05071288347244263,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06554288665453593,
      "backward_entropy": 0.013080426237799904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.41883087158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05076126009225845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06553544600804646,
      "backward_entropy": 0.003773348236625845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.82722473144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05080942437052727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0655280202627182,
      "backward_entropy": 0.013099865479902788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.664146423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050860777497291565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0655202567577362,
      "backward_entropy": 0.013109142130071466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.571279525756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050914984196424484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06551221013069153,
      "backward_entropy": 0.013117798350074074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.525994300842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05096609517931938,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06550451119740804,
      "backward_entropy": 0.003766131671992215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.222049713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05101446062326431,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06549705068270366,
      "backward_entropy": 0.003764505074782805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.873849868774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05106152966618538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06548962990442912,
      "backward_entropy": 0.003763350912115791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.8775634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05110848695039749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06548220912615459,
      "backward_entropy": 0.003762195056135004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.73640441894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05115872621536255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0654744307200114,
      "backward_entropy": 0.003761030056259849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.18553161621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05121520161628723,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0654660960038503,
      "backward_entropy": 0.013174952431158586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.484556198120117,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0512751080095768,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06545721491177876,
      "backward_entropy": 0.06301170045679266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.56570053100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05133359134197235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06544854243596394,
      "backward_entropy": 0.013192580504850908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.702579498291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05139302462339401,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06543977061907451,
      "backward_entropy": 0.01320085742256858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.247188568115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05144994333386421,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06543128192424774,
      "backward_entropy": 0.013208799741484901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.05879020690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05150794982910156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06542266408602397,
      "backward_entropy": 0.003752197392962196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.420127868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05156466364860535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06541423002878825,
      "backward_entropy": 0.003750474954193289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.30944061279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05162354186177254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06540556252002716,
      "backward_entropy": 0.0037485361099243164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.3061580657959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051682181656360626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06539688507715861,
      "backward_entropy": 0.003746694123203104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.410811901092529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051738396286964417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06538844108581543,
      "backward_entropy": 0.013240482319485058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.927064895629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051790181547403336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0653805136680603,
      "backward_entropy": 0.0037436393851583653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.08534049987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051842398941516876,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06537251671155293,
      "backward_entropy": 0.013253412463448265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.015499114990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051892805844545364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06536467870076497,
      "backward_entropy": 0.003740844062783501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.948286056518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05194156616926193,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06535703937212627,
      "backward_entropy": 0.0037395798347213054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.47028923034668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05198884755373001,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06534954905509949,
      "backward_entropy": 0.013273417949676514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.087697982788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05203699693083763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0653419295946757,
      "backward_entropy": 0.0037372423843903975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.99917984008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05208481848239899,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06533433000246684,
      "backward_entropy": 0.0037361119281161914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.684133529663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05213233828544617,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06532673041025798,
      "backward_entropy": 0.013292664831334894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.825233459472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05217849835753441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06531927486260732,
      "backward_entropy": 0.003733990544622595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.109676361083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222448706626892,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06531187395254771,
      "backward_entropy": 0.0037328583950346165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.650882720947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05227252468466759,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06530419985453288,
      "backward_entropy": 0.0037315901030193677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.70253562927246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0523202158510685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06529656052589417,
      "backward_entropy": 0.0037303099578077144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.82460403442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05236868932843208,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06528879205385844,
      "backward_entropy": 0.0037290443750945005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.375751495361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05242002755403519,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06528064608573914,
      "backward_entropy": 0.013324004682627592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.28154182434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05247066169977188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06527259945869446,
      "backward_entropy": 0.003726119344884699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.141313552856445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05252067744731903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06526461243629456,
      "backward_entropy": 0.0037247318435798993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.097362518310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256904661655426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06525680422782898,
      "backward_entropy": 0.003723473372784528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.007638931274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05261700600385666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06524903575579326,
      "backward_entropy": 0.0037222382697192106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.89763641357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05266459286212921,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06524129708607991,
      "backward_entropy": 0.00372105904600837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.827816009521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05271291732788086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06523343920707703,
      "backward_entropy": 0.003719803284515034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.60591506958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05276082828640938,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06522560616334279,
      "backward_entropy": 0.013349996371702715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.37688446044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052810508757829666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06521754463513692,
      "backward_entropy": 0.0037173804911700163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.431827545166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05286286026239395,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06520906090736389,
      "backward_entropy": 0.013355444778095592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.308124542236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291544273495674,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0652005672454834,
      "backward_entropy": 0.013357595963911577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.347444534301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05296823009848595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06519200404485066,
      "backward_entropy": 0.013359535824168812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.249460220336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053020134568214417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0651835302511851,
      "backward_entropy": 0.013361873951825228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.153276443481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05307123437523842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06517514089743297,
      "backward_entropy": 0.003710838881405917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.058025360107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312161147594452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06516679128011067,
      "backward_entropy": 0.0037098374556411395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.964284896850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053171321749687195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06515850126743317,
      "backward_entropy": 0.0037089196795767002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.435883522033691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05322043597698212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06515028079350789,
      "backward_entropy": 0.0037081095982681622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.87082290649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326685309410095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.065142422914505,
      "backward_entropy": 0.003707438030026176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.690275192260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05331617221236229,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06513413786888123,
      "backward_entropy": 0.013379714705727318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.89649200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05336490646004677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06512591242790222,
      "backward_entropy": 0.003705864264206453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.877178192138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053415216505527496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0651174287001292,
      "backward_entropy": 0.0037049759518016467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.21806716918945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05346377193927765,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06510920325915019,
      "backward_entropy": 0.013386867263100365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.313541412353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05351497605443001,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06510062019030254,
      "backward_entropy": 0.0037033852528442035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.66346549987793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05356539040803909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06509197254975636,
      "backward_entropy": 0.003702712668613954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.594192504882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05361402779817581,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0650835633277893,
      "backward_entropy": 0.003702234815467488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.527332305908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05366105958819389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06507542232672374,
      "backward_entropy": 0.0037018947980620646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.9239616394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05370665341615677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06506741046905518,
      "backward_entropy": 0.013400658965110779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.39449691772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05375409498810768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06505907575289409,
      "backward_entropy": 0.0037014406513084064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.32904815673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053800035268068314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0650509496529897,
      "backward_entropy": 0.003701271658593958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.68684196472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0538446269929409,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06504298249880473,
      "backward_entropy": 0.0037012269551103764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.602375030517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053889039903879166,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0650350550810496,
      "backward_entropy": 0.01341525532982566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.517864227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05393329635262489,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06502708792686462,
      "backward_entropy": 0.013419446620074186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.433671951293945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053977400064468384,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06501910090446472,
      "backward_entropy": 0.06301127780567516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.349647521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05402136221528053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06501110394795735,
      "backward_entropy": 0.0037018277428366923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.632966995239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406519025564194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06500309705734253,
      "backward_entropy": 0.0037019615146246824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.482778549194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410679429769516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06499547759691875,
      "backward_entropy": 0.0037021721628579226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.276331424713135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054149530827999115,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06498763958613078,
      "backward_entropy": 0.003702316771854054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.285688400268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418911203742027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06498028834660848,
      "backward_entropy": 0.00370263240554116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.950197219848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054230011999607086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06497272849082947,
      "backward_entropy": 0.003702842376448891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.653564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05427105352282524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06496505439281464,
      "backward_entropy": 0.013448086651888761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.58843994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054311178624629974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06495759387811025,
      "backward_entropy": 0.0037031972950155086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.708791732788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435565114021301,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06494933366775513,
      "backward_entropy": 0.003703109242699363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.311914443969727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054399892687797546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06494107345740001,
      "backward_entropy": 0.013454514470967379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.135891437530518,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05444185063242912,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06493321061134338,
      "backward_entropy": 0.06301140785217285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234185218811035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054480716586112976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06492588917414348,
      "backward_entropy": 0.003703357143835588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.39676284790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05451783165335655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06491884589195251,
      "backward_entropy": 0.0037036775188012557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.16224479675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05455542728304863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06491170326868693,
      "backward_entropy": 0.003703946755691008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.191376686096191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05459139123558998,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0649048388004303,
      "backward_entropy": 0.013466073708100752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.326324462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05462691932916641,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0648979942003886,
      "backward_entropy": 0.013468506661328402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.110736846923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05466615408658981,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06489042937755585,
      "backward_entropy": 0.003704765980893915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.068641662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05470564216375351,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06488280495007832,
      "backward_entropy": 0.003704835068095814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.962249755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05474944785237312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06487434109052022,
      "backward_entropy": 0.0037046332250941882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.90048599243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05479201674461365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06486608584721883,
      "backward_entropy": 0.003704510967839848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.68051528930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05483346804976463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06485804418722789,
      "backward_entropy": 0.003704446621916511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.554180145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05487697198987007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06484954555829366,
      "backward_entropy": 0.0037042420696128497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.711272239685059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05492231249809265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06484066943327586,
      "backward_entropy": 0.0037039325318553233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.17723846435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05496624857187271,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06483205159505208,
      "backward_entropy": 0.0037037178196690297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.87864303588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05501297488808632,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06482284764448802,
      "backward_entropy": 0.013470300219275734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.177644729614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05506321042776108,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06481291850407918,
      "backward_entropy": 0.013468646190383217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.05580711364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511356517672539,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06480290989081065,
      "backward_entropy": 0.003702181645415046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.573587417602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05516401305794716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06479284167289734,
      "backward_entropy": 0.0037016330117529087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.527663230895996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05521151050925255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06478334466616313,
      "backward_entropy": 0.003701251677491448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.710582733154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055256348103284836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06477432449658711,
      "backward_entropy": 0.003701045093211261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.160465240478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530180409550667,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06476513048013051,
      "backward_entropy": 0.0037008175118403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.494285583496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0553458034992218,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06475621461868286,
      "backward_entropy": 0.013461066917939619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.708980560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05539048835635185,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06474711497624715,
      "backward_entropy": 0.0134601430459456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.967461585998535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05543478578329086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0647380252679189,
      "backward_entropy": 0.0037004981528628955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.54012680053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055477723479270935,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06472919881343842,
      "backward_entropy": 0.013458541848442772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.68600845336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0555204376578331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06472036242485046,
      "backward_entropy": 0.003700586205179041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.371198654174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05556493252515793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06471111873785655,
      "backward_entropy": 0.0037005770612846722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.28571319580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05560903251171112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06470190982023875,
      "backward_entropy": 0.0037006166848269377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.650754928588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055652767419815063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06469273567199707,
      "backward_entropy": 0.0037006644362753086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.17802619934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055695176124572754,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06468377510706584,
      "backward_entropy": 0.013454281470992348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.524794578552246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055739354342222214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06467436750729878,
      "backward_entropy": 0.0037008920176462693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.92501449584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055782146751880646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0646652380625407,
      "backward_entropy": 0.003700986165891994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.931951522827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05582665652036667,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06465563178062439,
      "backward_entropy": 0.013450856913219799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.67296028137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05586875602602959,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06464659174283345,
      "backward_entropy": 0.013449912721460516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.121122360229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05591261759400368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06463705996672313,
      "backward_entropy": 0.003701277415860783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.20798110961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05595707893371582,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.064627339442571,
      "backward_entropy": 0.0037013278766111894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.145465850830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05600009486079216,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06461792190869649,
      "backward_entropy": 0.013445538553324613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.25368881225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05604182556271553,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06460875272750854,
      "backward_entropy": 0.013444380326704546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.33921480178833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05608825013041496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0645984411239624,
      "backward_entropy": 0.00370166924866763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636689186096191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05613107606768608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.064588929216067,
      "backward_entropy": 0.0037019476294517517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.194612503051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056171637028455734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06457996368408203,
      "backward_entropy": 0.003702362152663144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.953128814697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05621210113167763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06457095344861348,
      "backward_entropy": 0.003702807832847942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.25822639465332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05625537782907486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06456119815508525,
      "backward_entropy": 0.0037030543793331494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.95486831665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056295353919267654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06455223759015401,
      "backward_entropy": 0.0037034451961517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.658222198486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05633527785539627,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06454321245352428,
      "backward_entropy": 0.0037038912149992857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.00259017944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05637418106198311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06453440090020497,
      "backward_entropy": 0.0037044662643562665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.72480010986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05641408637166023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.064525306224823,
      "backward_entropy": 0.0037049959329041567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.809322357177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05645392835140228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06451616684595744,
      "backward_entropy": 0.003705585544759577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.426478385925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056494660675525665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06450675427913666,
      "backward_entropy": 0.0037060962481932206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.61460304260254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05653427168726921,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0644976149002711,
      "backward_entropy": 0.0037067092277786946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.413135528564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657479166984558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06448814272880554,
      "backward_entropy": 0.0037074227902022276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.25121021270752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056615158915519714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06447865565617879,
      "backward_entropy": 0.003708134320649234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.387882232666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0566544234752655,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06446943680445354,
      "backward_entropy": 0.013426139950752258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.134215354919434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05669555813074112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06445968151092529,
      "backward_entropy": 0.003709640015255321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.126676559448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05673549696803093,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0644501547018687,
      "backward_entropy": 0.013423417102206837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.016817092895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0567762553691864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06444040934244792,
      "backward_entropy": 0.003710898824713447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9866061210632324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056815847754478455,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06443089246749878,
      "backward_entropy": 0.013419721614230763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.874492645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05685247853398323,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0644221305847168,
      "backward_entropy": 0.0037121779539368367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.852405548095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05688929185271263,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06441327929496765,
      "backward_entropy": 0.003712833266366612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.73318862915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056925322860479355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0644046018520991,
      "backward_entropy": 0.003713576631112532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.40964126586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696158856153488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06439582506815593,
      "backward_entropy": 0.0037142949348146267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.483074188232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05700088292360306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06438619395097096,
      "backward_entropy": 0.003714793785051866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.631566047668457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05704101547598839,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06437613566716512,
      "backward_entropy": 0.00371532142162323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.432892799377441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057080019265413284,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06436642507712047,
      "backward_entropy": 0.013405611569231207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.875165939331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057118915021419525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06435667475064595,
      "backward_entropy": 0.0037164434113285756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.457545280456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05716053023934364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06434611479441325,
      "backward_entropy": 0.013399424878033724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.198429107666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057200830429792404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06433585782845815,
      "backward_entropy": 0.003716924989765341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.120706558227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057240892201662064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06432565053304036,
      "backward_entropy": 0.0037171613763679156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.804147720336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05728074163198471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06431542833646138,
      "backward_entropy": 0.003717512569644234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.96476936340332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05732131376862526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06430494288603465,
      "backward_entropy": 0.013385230844671076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.60820198059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736162140965462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06429443260033925,
      "backward_entropy": 0.0037183575332164764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.80729866027832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0574025921523571,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06428373853365581,
      "backward_entropy": 0.0037188743325796995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.41067886352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05744321644306183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06427302956581116,
      "backward_entropy": 0.003719369118863886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324653148651123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057484447956085205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06426212688287099,
      "backward_entropy": 0.0037197877060283313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004771388485096395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575234591960907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06425182024637859,
      "backward_entropy": 0.0037203790111975236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.131696701049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057558611035346985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06424266596635182,
      "backward_entropy": 0.013366771015253935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.826629638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575948990881443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06423310438791911,
      "backward_entropy": 0.00372186540202661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.366829872131348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05763036012649536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0642237514257431,
      "backward_entropy": 0.003722644326361743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.872356414794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05766599252820015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06421429415543874,
      "backward_entropy": 0.01335841417312622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.897001266479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057702671736478806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06420441965262096,
      "backward_entropy": 0.0037240541794083333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.688426971435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05774211138486862,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0641936461130778,
      "backward_entropy": 0.003724454478784041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.62797737121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05778220668435097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06418258945147197,
      "backward_entropy": 0.0037247799336910248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4982352256774902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05782468989491463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06417071322600047,
      "backward_entropy": 0.0037248825485056095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.309572219848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786386877298355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06415988008181255,
      "backward_entropy": 0.0037250498479062862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005775740137323737,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05790730565786362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06414757668972015,
      "backward_entropy": 0.003724953667684035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.317621231079102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05794643610715866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06413667400677998,
      "backward_entropy": 0.003725015642968091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.421344518661499,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05798443779349327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06412607928117116,
      "backward_entropy": 0.0037254501472819934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.616082191467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05801958218216896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06411637365818024,
      "backward_entropy": 0.0037260258739644832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.548335075378418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05805487558245659,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06410655379295349,
      "backward_entropy": 0.003726826472715898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.850345611572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058090269565582275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06409662961959839,
      "backward_entropy": 0.0037276074290275574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.468034744262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05812666192650795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06408630311489105,
      "backward_entropy": 0.0037284517152742906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.335677146911621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058165714144706726,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06407498319943745,
      "backward_entropy": 0.013303974812681025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.26136302947998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058204472064971924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06406374275684357,
      "backward_entropy": 0.0037298520857637577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5941362380981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05824294686317444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06405261158943176,
      "backward_entropy": 0.00373044339093295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.838506698608398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058279406279325485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06404198209444682,
      "backward_entropy": 0.003731238909743049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.049813270568848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058314938098192215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06403164068857829,
      "backward_entropy": 0.0037322349169037557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.98176383972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058350492268800735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06402124961217244,
      "backward_entropy": 0.003733152354305441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.913725852966309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058386076241731644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06401076416174571,
      "backward_entropy": 0.0037341036579825663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.268123626708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05842166766524315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06400023897488911,
      "backward_entropy": 0.013278806751424616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.967639923095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058459024876356125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06398901343345642,
      "backward_entropy": 0.0037358338859948244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.87669849395752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05849706009030342,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06397749483585358,
      "backward_entropy": 0.0037364282391288066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.627666473388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058535732328891754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06396564841270447,
      "backward_entropy": 0.003737112337892706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.969757080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058574073016643524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0639538715283076,
      "backward_entropy": 0.013261617584662004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.71501350402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05861471965909004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06394118070602417,
      "backward_entropy": 0.003738180480220101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.39716911315918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058656565845012665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06392792860666911,
      "backward_entropy": 0.013251315463672985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.080271005630493,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05869775637984276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0639148751894633,
      "backward_entropy": 0.0037390626966953278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.36953353881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05873575434088707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06390296419461568,
      "backward_entropy": 0.013242285359989513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12906265258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058775175362825394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06389045715332031,
      "backward_entropy": 0.0037405721165917134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.124155044555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058813270181417465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0638783872127533,
      "backward_entropy": 0.003741182725537907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.019878387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05885189399123192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06386603911717732,
      "backward_entropy": 0.013227806849913164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.955399513244629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058889273554086685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06385410825411479,
      "backward_entropy": 0.0037423528053543782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.769357681274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058926377445459366,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06384220719337463,
      "backward_entropy": 0.013217595490542326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.760969161987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05896664038300514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06382899979750316,
      "backward_entropy": 0.0037433315407146106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9337210655212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05900716409087181,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06381562848885854,
      "backward_entropy": 0.013205800544131886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.831338882446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05904453992843628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06380341450373332,
      "backward_entropy": 0.0037443410943854938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.59503173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05907990783452988,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06379201511542003,
      "backward_entropy": 0.01319504596970298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.292381286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05911516398191452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06378055115540822,
      "backward_entropy": 0.0037460049444978886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.781938552856445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05915201082825661,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06376831730206807,
      "backward_entropy": 0.0037469240752133455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.764041900634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05919279903173447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06375441948572795,
      "backward_entropy": 0.013178918849338184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.775814056396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05923624336719513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06373937427997589,
      "backward_entropy": 0.013172496448863636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.03980827331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05928124859929085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06372355421384175,
      "backward_entropy": 0.003748852082274177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.563149452209473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05933014303445816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06370611985524495,
      "backward_entropy": 0.003749305551702326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.039962768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05937584117054939,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06368993719418843,
      "backward_entropy": 0.013152458451010964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.696114540100098,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059420328587293625,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06367415189743042,
      "backward_entropy": 0.06301042166623202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.748802185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05946454778313637,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06365840633710225,
      "backward_entropy": 0.003751296888698231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.182493209838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059510935097932816,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0636416623989741,
      "backward_entropy": 0.013132447546178644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3515424728393555,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05955767631530762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06362460056940715,
      "backward_entropy": 0.06301032413135875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.621214866638184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05960145592689514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0636087457338969,
      "backward_entropy": 0.0037531642751260238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.271753787994385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05964416638016701,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06359325846036275,
      "backward_entropy": 0.013114109635353088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.851661205291748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059684280306100845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06357877453168233,
      "backward_entropy": 0.003755444830114191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.595561027526855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05972285568714142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0635649561882019,
      "backward_entropy": 0.0037567016075957904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.486370086669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059762489050626755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06355046729246776,
      "backward_entropy": 0.013098372654481367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.125696182250977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05980303883552551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06353554129600525,
      "backward_entropy": 0.0037594386799768968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.545832633972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059841182082891464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06352150440216064,
      "backward_entropy": 0.003760873255404559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.173130989074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987638235092163,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06350876887639363,
      "backward_entropy": 0.003762729804624211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.537073612213135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05991291254758835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0634952982266744,
      "backward_entropy": 0.0037645680660551243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.96803092956543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05994822829961777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06348229944705963,
      "backward_entropy": 0.0037664459510283036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95830774307251,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05998640134930611,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06346788505713145,
      "backward_entropy": 0.01307143812829798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.387150764465332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06002232804894447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0634545087814331,
      "backward_entropy": 0.0037690655074336314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.447399854660034,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06005709990859032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06344156463940938,
      "backward_entropy": 0.0037704259157180786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.295997142791748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06008921563625336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06342984239260356,
      "backward_entropy": 0.01305388862436468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.835926532745361,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06012049689888954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06341845790545146,
      "backward_entropy": 0.003773177889260379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.616292953491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06015024334192276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06340771913528442,
      "backward_entropy": 0.003774432973428206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.562005043029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06018020957708359,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06339678168296814,
      "backward_entropy": 0.013035817579789595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.754204273223877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06021033227443695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06338569521903992,
      "backward_entropy": 0.003777195784178647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.81849479675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0602390356361866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06337520480155945,
      "backward_entropy": 0.0037785802375186572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.100921630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060268815606832504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06336408853530884,
      "backward_entropy": 0.0037800107489932666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.679728507995605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060300327837467194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06335198879241943,
      "backward_entropy": 0.013012387535788796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9644551277160645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06033257767558098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06333945691585541,
      "backward_entropy": 0.0037824985655871305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.921777725219727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06036394461989403,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06332733233769734,
      "backward_entropy": 0.01299869336865165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.759217262268066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060394514352083206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06331552068392436,
      "backward_entropy": 0.003784435377879576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115131378173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060426682233810425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06330280502637227,
      "backward_entropy": 0.00378528508273038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.584860801696777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0604587197303772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06329011917114258,
      "backward_entropy": 0.003785932944579558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99649715423584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06049220636487007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06327652434508006,
      "backward_entropy": 0.003786696290427988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702857971191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060525454580783844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06326295932133992,
      "backward_entropy": 0.012961527163332159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878747940063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06055769324302673,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06324985126654308,
      "backward_entropy": 0.003788556226275184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.206228494644165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06058976799249649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06323678294817607,
      "backward_entropy": 0.012946760112589056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.576050281524658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06061941385269165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0632249265909195,
      "backward_entropy": 0.0037901787595315413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.894372940063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06064840406179428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0632133682568868,
      "backward_entropy": 0.003791125999255614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.992521286010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06067829206585884,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06320122877756755,
      "backward_entropy": 0.00379201431166042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.454559803009033,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06070974841713905,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0631881554921468,
      "backward_entropy": 0.06301002068953081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.276134967803955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060740359127521515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06317541003227234,
      "backward_entropy": 0.003793813965537331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.250334739685059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06076943874359131,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06316343943277995,
      "backward_entropy": 0.0037949010729789734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.561965942382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060797110199928284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06315220395723979,
      "backward_entropy": 0.003795839846134186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.398629188537598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060825761407613754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06314040223757426,
      "backward_entropy": 0.003796580840240825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.260759353637695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060854554176330566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06312842170397441,
      "backward_entropy": 0.003797318786382675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.37108325958252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06088273599743843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06311666965484619,
      "backward_entropy": 0.003798203373497183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.123219966888428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06091184541583061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06310431162516277,
      "backward_entropy": 0.003799131309444254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.34231948852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06093957647681236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06309263904889424,
      "backward_entropy": 0.0038003867322748356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.107445240020752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0609697625041008,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06307943165302277,
      "backward_entropy": 0.012852660634300926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.023646831512451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06099916994571686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0630665918191274,
      "backward_entropy": 0.003803188827904788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012674134923145175,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061026401817798615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06305492917696635,
      "backward_entropy": 0.0038047189062291927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.000452995300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06105092912912369,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06304479638735454,
      "backward_entropy": 0.0038063302636146545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.947626113891602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06107449159026146,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0630352000395457,
      "backward_entropy": 0.01283043081110174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.871119499206543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061099350452423096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06302477419376373,
      "backward_entropy": 0.0038092732429504395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9677480459213257,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061126116663217545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06301319102446239,
      "backward_entropy": 0.0038103701716119594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.73494815826416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06115096062421799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06300262610117595,
      "backward_entropy": 0.003811599856073206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.720905303955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06117770075798035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06299089392026265,
      "backward_entropy": 0.0038127005100250244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7281084060668945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06120537593960762,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06297860542933147,
      "backward_entropy": 0.06300980394536798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.51851749420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06123320758342743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06296610832214355,
      "backward_entropy": 0.0038141465999863363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6279120445251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061262600123882294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06295258800188701,
      "backward_entropy": 0.012779693711887707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.364389419555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06129196286201477,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06293899814287822,
      "backward_entropy": 0.012771842154589567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7619943618774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061322711408138275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06292449434598286,
      "backward_entropy": 0.0038160959428006954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8691691160202026,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06135186180472374,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06291085481643677,
      "backward_entropy": 0.012756446545774286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.569237232208252,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06137881055474281,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06289853155612946,
      "backward_entropy": 0.06300964138724587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.379637718200684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061405248939991,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06288641691207886,
      "backward_entropy": 0.0038189224221489644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014467551372945309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06143190711736679,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06287409861882527,
      "backward_entropy": 0.0038200000470334835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291930675506592,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06145589053630829,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06286345422267914,
      "backward_entropy": 0.012727615508166227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.498251914978027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0614803284406662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06285240252812703,
      "backward_entropy": 0.003821920264850963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.801288366317749,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06150797754526138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06283933420976003,
      "backward_entropy": 0.003822646696459163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.736013412475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0615336112678051,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0628273884455363,
      "backward_entropy": 0.003823742947795174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.888242721557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061560939997434616,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06281425555547078,
      "backward_entropy": 0.012699121778661554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.532042980194092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0615890696644783,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06280051668485005,
      "backward_entropy": 0.012692825360731646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7552852630615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06161579117178917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06278762221336365,
      "backward_entropy": 0.0038273412395607343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.204387664794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06164054200053215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06277600427468617,
      "backward_entropy": 0.003828423944386569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.928155899047852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06166772171854973,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06276267766952515,
      "backward_entropy": 0.012672627514058893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.161576271057129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061694975942373276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06274921695391338,
      "backward_entropy": 0.0038306394761258907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4187581539154053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06172160059213638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06273614366849263,
      "backward_entropy": 0.012659064748070457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7933173179626465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06174696981906891,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06272376577059428,
      "backward_entropy": 0.003832969137213447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3754823207855225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06177256628870964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06271123389403026,
      "backward_entropy": 0.012645782394842668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.062198638916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06179700419306755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06269932786623637,
      "backward_entropy": 0.0038353082808581266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.661408424377441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06182309240102768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06268640359242757,
      "backward_entropy": 0.0038360797546126628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.616398334503174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061851371079683304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06267183025677998,
      "backward_entropy": 0.0038367320190776477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6431427001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061879564076662064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06265726685523987,
      "backward_entropy": 0.003837381235577843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.155881881713867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0619056411087513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06264407436052959,
      "backward_entropy": 0.012607632712884382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.860136032104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06193250045180321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06263031562169392,
      "backward_entropy": 0.003838801925832575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6096783876419067,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061958715319633484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0626169244448344,
      "backward_entropy": 0.0038394020362333818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.993375778198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06198303401470184,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06260472536087036,
      "backward_entropy": 0.0125839195468209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.528194427490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062008295208215714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0625917911529541,
      "backward_entropy": 0.0038414373993873596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.614603996276855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062035102397203445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06257760524749756,
      "backward_entropy": 0.003842613913796165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.694424629211426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062064606696367264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06256140271822612,
      "backward_entropy": 0.012562843886288729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1063945293426514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06209319457411766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06254583597183228,
      "backward_entropy": 0.012555958195166155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.707760334014893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06212027370929718,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06253123780091603,
      "backward_entropy": 0.012548972259868275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5311907529830933,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06214800849556923,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062515988945961,
      "backward_entropy": 0.0038478946821256118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.559093952178955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06217365339398384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06250224510828654,
      "backward_entropy": 0.0038495219566605306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.528265953063965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06219875440001488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06248872478802999,
      "backward_entropy": 0.003851423886689273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.997115612030029,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06222334876656532,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06247547268867493,
      "backward_entropy": 0.06300960345701738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.490254521369934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0622481107711792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06246208151181539,
      "backward_entropy": 0.012519197030500933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.439581871032715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06227104738354683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062450011571248375,
      "backward_entropy": 0.0038566365838050842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.352138996124268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062293652445077896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06243816018104553,
      "backward_entropy": 0.003858028826388446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.922105073928833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06231725588440895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06242544452349345,
      "backward_entropy": 0.0038592409003864636,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.675001942034578,
    "avg_log_Z": -0.06095472551882267,
    "success_rate": 1.0,
    "avg_reward": 62.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.28,
      "2": 0.66
    },
    "avg_forward_entropy": 0.06306094775597254,
    "avg_backward_entropy": 0.00988115642219782,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}