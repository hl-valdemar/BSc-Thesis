{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701613505681355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.07701202233632405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.21075439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943875312805176,
      "backward_entropy": 0.0770161681705051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1825714111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942988395690918,
      "backward_entropy": 0.07701599597930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.3896026611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00020000003860332072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942085981369018,
      "backward_entropy": 0.0770157708062066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.85165405273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00030011212220415473,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941183567047119,
      "backward_entropy": 0.07701635360717773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.33433532714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004006201634183526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094027042388916,
      "backward_entropy": 0.07700896925396389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.0705108642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005008546868339181,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939397811889648,
      "backward_entropy": 0.07701481713189019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.2281265258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006007336778566241,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938512086868286,
      "backward_entropy": 0.0770144330130683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.53948211669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006966966902837157,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937626361846924,
      "backward_entropy": 0.07701398928960164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.89656066894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007920951466076076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936741828918457,
      "backward_entropy": 0.07701351245244344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.81919860839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008869613520801067,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10935842990875244,
      "backward_entropy": 0.07701589663823445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.0872573852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009831509087234735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934942960739136,
      "backward_entropy": 0.07701247268252903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.8239517211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010789474472403526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934045314788818,
      "backward_entropy": 0.0770023332701789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.0206298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011741764610633254,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933133363723754,
      "backward_entropy": 0.07701130708058675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.78953552246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012646414106711745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093222975730896,
      "backward_entropy": 0.07700026035308838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.4455108642578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013583182590082288,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093130111694336,
      "backward_entropy": 0.0770155323876275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.10659790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014532878994941711,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930347442626953,
      "backward_entropy": 0.07699813445409139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.56468963623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015476038679480553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929352045059204,
      "backward_entropy": 0.07700853215323554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6685333251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016419368330389261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928362607955933,
      "backward_entropy": 0.07699580987294515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.01612854003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001738897291943431,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927340984344483,
      "backward_entropy": 0.07699465751647949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.0047836303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018379325047135353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926285982131959,
      "backward_entropy": 0.07699342568715413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.30278778076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019356487318873405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925205945968627,
      "backward_entropy": 0.07700516780217488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.22893524169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002030276693403721,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10924112796783447,
      "backward_entropy": 0.07700416776869032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.92731475830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021200969349592924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923023223876953,
      "backward_entropy": 0.07698907454808553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.68008422851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022098012268543243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10921909809112548,
      "backward_entropy": 0.0770150555504693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.74336242675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023018564097583294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920796394348145,
      "backward_entropy": 0.0769857300652398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.07765197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023939625825732946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919677019119263,
      "backward_entropy": 0.07698400815327962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.82327270507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024905328173190355,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10918517112731933,
      "backward_entropy": 0.07701484362284343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.4198226928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025860629975795746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10917332172393798,
      "backward_entropy": 0.07699706819322374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.81583404541016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026808339171111584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10916132926940918,
      "backward_entropy": 0.07701468467712402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.71929168701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002768096048384905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10914943218231202,
      "backward_entropy": 0.0769763986269633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.34191131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0028534813318401575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913746356964112,
      "backward_entropy": 0.07699247201283772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.65567779541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029393178410828114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912532806396484,
      "backward_entropy": 0.07697171635097927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.56935119628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0030213352292776108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10911341905593872,
      "backward_entropy": 0.07701408863067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1732940673828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031079957261681557,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091010570526123,
      "backward_entropy": 0.07701393630769518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.75335693359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032002064399421215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090882420539856,
      "backward_entropy": 0.07698514064153035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.0903778076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003295840695500374,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10907531976699829,
      "backward_entropy": 0.07701373100280762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.93516540527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033927704207599163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10906224250793457,
      "backward_entropy": 0.07701365152994792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9014892578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003490146016702056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10904868841171264,
      "backward_entropy": 0.07701354556613499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.98204040527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003591878106817603,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10903483629226685,
      "backward_entropy": 0.07701349258422852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.19961547851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003698196494951844,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10902037620544433,
      "backward_entropy": 0.07701349920696682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.68255615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003807354485616088,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10900561809539795,
      "backward_entropy": 0.07694862948523627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.74668884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003915640525519848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899066925048828,
      "backward_entropy": 0.07694592078526814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4338836669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004026563372462988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10897549390792846,
      "backward_entropy": 0.0769432783126831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.78672790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004140710923820734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10895978212356568,
      "backward_entropy": 0.07694062921735975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.42071533203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004256248939782381,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10894368886947632,
      "backward_entropy": 0.07701361179351807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.51254272460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004376706667244434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892708301544189,
      "backward_entropy": 0.07696519295374553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.22311401367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004494542721658945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10891036987304688,
      "backward_entropy": 0.07696330547332764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.48253631591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004609774798154831,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10889343023300171,
      "backward_entropy": 0.07692942354414198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.94757080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004721367731690407,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10887660980224609,
      "backward_entropy": 0.07695877552032471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.74522399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004834266379475594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885939598083497,
      "backward_entropy": 0.07692239019605848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.50603485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004945160821080208,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10884206295013428,
      "backward_entropy": 0.07695357004801433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.90234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0050523849204182625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10882463455200195,
      "backward_entropy": 0.07691421773698595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.83868408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005154445301741362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10880725383758545,
      "backward_entropy": 0.07694727844662136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.41307830810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005257495678961277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10878958702087402,
      "backward_entropy": 0.0769047737121582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.31488037109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005357662215828896,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1087717890739441,
      "backward_entropy": 0.07701258526908027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4672088623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005456923041492701,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10875362157821655,
      "backward_entropy": 0.07693643040127224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.76258850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005557250697165728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10873503684997558,
      "backward_entropy": 0.07693254947662354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2096710205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00565719697624445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087164044380188,
      "backward_entropy": 0.07688392533196343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.62176513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0057562533766031265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869740247726441,
      "backward_entropy": 0.07692420482635498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.94114685058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005861225072294474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10867762565612793,
      "backward_entropy": 0.07691986031002468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.6529312133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005966660100966692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10865752696990967,
      "backward_entropy": 0.07686694463094075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.02761840820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006066967733204365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10863757133483887,
      "backward_entropy": 0.07686079872979058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.53246307373047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006170038599520922,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10861718654632568,
      "backward_entropy": 0.07700998253292507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.19888305664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006264176219701767,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1085972785949707,
      "backward_entropy": 0.07690025700463189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.1627655029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006354415323585272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10857751369476318,
      "backward_entropy": 0.07700896925396389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.92749786376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006448851898312569,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10855734348297119,
      "backward_entropy": 0.07688881291283502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.11595916748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006541553884744644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10853722095489501,
      "backward_entropy": 0.07682710223727757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.218505859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00663048354908824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10851719379425048,
      "backward_entropy": 0.07681965165668064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.97662353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006719423457980156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10849660634994507,
      "backward_entropy": 0.07681188980738322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.413551330566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006809244863688946,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10847592353820801,
      "backward_entropy": 0.07700637314054701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.37774658203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006889848038554192,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1084562063217163,
      "backward_entropy": 0.07700567775302464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.3735809326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006971646100282669,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10843595266342163,
      "backward_entropy": 0.0767873658074273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.46351623535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0070569622330367565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10841528177261353,
      "backward_entropy": 0.07677898142072889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.68083953857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0071473089046776295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10839405059814453,
      "backward_entropy": 0.07677094141642253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.62474060058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00723635358735919,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10837380886077881,
      "backward_entropy": 0.07676268948449029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.05108642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007327970117330551,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10835322141647338,
      "backward_entropy": 0.07675449715720283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.1400909423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007421315647661686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10833187103271484,
      "backward_entropy": 0.07674610614776611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.23765563964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007520322222262621,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10830975770950317,
      "backward_entropy": 0.07673821184370253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.8866958618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00762047478929162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10828713178634644,
      "backward_entropy": 0.07673017183939616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.68678283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007718120701611042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10826449394226074,
      "backward_entropy": 0.07679200834698147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.47837829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007815252989530563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10824153423309327,
      "backward_entropy": 0.07678446504804823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.07093811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007913612760603428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10821795463562012,
      "backward_entropy": 0.07677685552173191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.20765686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008013201877474785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10819388628005981,
      "backward_entropy": 0.07669472032123142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.15943908691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008112207055091858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10816962718963623,
      "backward_entropy": 0.0766855345831977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.19041442871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008216078393161297,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1081445574760437,
      "backward_entropy": 0.07675347063276503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.73849487304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008325903676450253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10811854600906372,
      "backward_entropy": 0.07666949431101482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.3375015258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008431696332991123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10809242725372314,
      "backward_entropy": 0.07666092448764378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.31065368652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008534010499715805,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1080662488937378,
      "backward_entropy": 0.07700079017215306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.4700927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008640552870929241,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10803920030593872,
      "backward_entropy": 0.0766425265206231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.07447052001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008741755969822407,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10801256895065307,
      "backward_entropy": 0.0767135222752889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.64363098144531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008838298730552197,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10798652172088623,
      "backward_entropy": 0.0769997967614068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.24008178710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008931685239076614,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10795997381210327,
      "backward_entropy": 0.0769990152782864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.84294128417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009031753055751324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793206691741944,
      "backward_entropy": 0.07659901512993707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.4426498413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009128568693995476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10790394544601441,
      "backward_entropy": 0.07658697499169244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.32209777832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009222612716257572,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10787568092346192,
      "backward_entropy": 0.07657427257961696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.80572509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009309936314821243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10784763097763062,
      "backward_entropy": 0.07665085792541504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.60771942138672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00939937774091959,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10781891345977783,
      "backward_entropy": 0.07699477010303074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.13450622558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009487099945545197,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10779016017913819,
      "backward_entropy": 0.07699365748299493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.2303466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009580635465681553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10776028633117676,
      "backward_entropy": 0.07651861508687337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.87728881835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009669631719589233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10773046016693115,
      "backward_entropy": 0.07650401857164171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.73456954956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009758852422237396,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10769999027252197,
      "backward_entropy": 0.07648923661973742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.67491149902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009835236705839634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10767024755477905,
      "backward_entropy": 0.07647287845611572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.36804962158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009907214902341366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10764088630676269,
      "backward_entropy": 0.07656088140275744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.17587280273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009974906221032143,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10761163234710694,
      "backward_entropy": 0.07654517889022827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.03081512451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010052531026303768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10758050680160522,
      "backward_entropy": 0.0765308870209588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.84890747070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010124997235834599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10754944086074829,
      "backward_entropy": 0.0764043198691474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.55759811401367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010191541165113449,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10751925706863404,
      "backward_entropy": 0.0769808292388916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.56637573242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010247866623103619,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10749014616012573,
      "backward_entropy": 0.07648135556115045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.20591735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010305662639439106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10746042728424073,
      "backward_entropy": 0.07634680800967747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.79893493652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010370848700404167,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10742920637130737,
      "backward_entropy": 0.07697468996047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.85913848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010442760773003101,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10739667415618896,
      "backward_entropy": 0.07643002933926052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.49801635742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01051007304340601,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10736416578292847,
      "backward_entropy": 0.07641306188371447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.7396469116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01057115476578474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10733199119567871,
      "backward_entropy": 0.07626774575975206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.8066635131836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01063311006873846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10729920864105225,
      "backward_entropy": 0.07696761687596639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.3771743774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0106932008638978,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1072657823562622,
      "backward_entropy": 0.07635761631859674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.98184204101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010753992013633251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10723159313201905,
      "backward_entropy": 0.07619928651385838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.5405731201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01081558782607317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10719674825668335,
      "backward_entropy": 0.07631997267405193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.54731750488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010880261659622192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10716121196746826,
      "backward_entropy": 0.07615175512101915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.39857482910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010945537127554417,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1071252703666687,
      "backward_entropy": 0.0769568681716919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.6448211669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0110156936571002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10708826780319214,
      "backward_entropy": 0.0761043628056844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6523895263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011092162691056728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10704988241195679,
      "backward_entropy": 0.07624895042843288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.38166046142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011170515790581703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1070110559463501,
      "backward_entropy": 0.07623252603742811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.77882385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01124811265617609,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1069718599319458,
      "backward_entropy": 0.07603816191355388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.09651184082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011329912580549717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10693213939666749,
      "backward_entropy": 0.07601617442237006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.7693099975586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01140635460615158,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10689315795898438,
      "backward_entropy": 0.07694885465833876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.23896789550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011477644555270672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.106854248046875,
      "backward_entropy": 0.07596578862931994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.28172302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011547178030014038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10681545734405518,
      "backward_entropy": 0.0759383307562934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.03086853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011621540412306786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.106776762008667,
      "backward_entropy": 0.07591217093997532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.08411407470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011697781272232533,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10673741102218628,
      "backward_entropy": 0.07610407140519884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.95024871826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01177353784441948,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10669679641723633,
      "backward_entropy": 0.07585885789659289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.83287048339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011842744424939156,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10665709972381592,
      "backward_entropy": 0.07606226868099636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.08724975585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011916112154722214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10661520957946777,
      "backward_entropy": 0.076040784517924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.7965087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011999591253697872,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10657074451446533,
      "backward_entropy": 0.07602130704455906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.33686828613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012077560648322105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10652661323547363,
      "backward_entropy": 0.07574624485439724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.94454956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012152496725320816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10648201704025269,
      "backward_entropy": 0.07571590609020656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.12128448486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012230048887431622,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10643712282180787,
      "backward_entropy": 0.07693000634511311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.16767883300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012306849472224712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10639135837554932,
      "backward_entropy": 0.07565484444300334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.53700256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012381227687001228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10634571313858032,
      "backward_entropy": 0.07562233342064752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.83250427246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012457557953894138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10629900693893432,
      "backward_entropy": 0.07588167323006524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.54425811767578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012535495683550835,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10625114440917968,
      "backward_entropy": 0.07692119810316297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.76519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012613308615982533,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10620307922363281,
      "backward_entropy": 0.07691910531785753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.79595184326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01269213855266571,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10615352392196656,
      "backward_entropy": 0.07580612765418158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.9247283935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012770617380738258,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10610368251800537,
      "backward_entropy": 0.07578000757429335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.25062561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012850841507315636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10605298280715943,
      "backward_entropy": 0.07575378815333049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.17267608642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012932023964822292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10600093603134156,
      "backward_entropy": 0.07572701242234972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.54087829589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013010243885219097,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10594871044158935,
      "backward_entropy": 0.07690820429060194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.51083374023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013092899695038795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10589549541473389,
      "backward_entropy": 0.07566916942596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.0645523071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013179067522287369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10584090948104859,
      "backward_entropy": 0.0752685202492608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.81465148925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013261307962238789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10578594207763672,
      "backward_entropy": 0.07522911495632595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.03924560546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013342270627617836,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10573016405105591,
      "backward_entropy": 0.0768995549943712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.99390411376953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013433088548481464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10567169189453125,
      "backward_entropy": 0.0768982966740926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.86567687988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013522513210773468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10561327934265137,
      "backward_entropy": 0.07511112425062391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.145263671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013607683591544628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10555462837219239,
      "backward_entropy": 0.07689446873135036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.61801147460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013701626099646091,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10549278259277343,
      "backward_entropy": 0.0750290420320299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.91226196289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01379555743187666,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.105430269241333,
      "backward_entropy": 0.07689197195900811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.97598266601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013888879679143429,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10536750555038452,
      "backward_entropy": 0.07538761032952203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.24502563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013977865688502789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10530579090118408,
      "backward_entropy": 0.07489347457885742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.35765075683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014071924611926079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10524251461029052,
      "backward_entropy": 0.07484731409284803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.14208221435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014165965840220451,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10517851114273072,
      "backward_entropy": 0.07527926895353529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9560089111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014255911111831665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10511516332626343,
      "backward_entropy": 0.0747500393125746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.59617614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014348424971103668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10505050420761108,
      "backward_entropy": 0.07469977935155232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.85208129882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014445772394537926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10498446226119995,
      "backward_entropy": 0.07687897152370876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.30229949951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014547264203429222,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10491694211959839,
      "backward_entropy": 0.07687776618533665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.72569274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014646247029304504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10484968423843384,
      "backward_entropy": 0.07455370823542277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.81597137451172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014751076698303223,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10478024482727051,
      "backward_entropy": 0.07687530252668592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.42546844482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014850708656013012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10471150875091553,
      "backward_entropy": 0.07445372475518121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.3704605102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01494581624865532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10464351177215576,
      "backward_entropy": 0.07495521836810642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.9922866821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015036853961646557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045760989189148,
      "backward_entropy": 0.07434048917558458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.26296997070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015125525183975697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10450760126113892,
      "backward_entropy": 0.07427855332692464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.8576202392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015212837606668472,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443871021270752,
      "backward_entropy": 0.07479946480857001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.10264587402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015303119085729122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10436810255050659,
      "backward_entropy": 0.07685561312569512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.36093139648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015398304909467697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10429542064666748,
      "backward_entropy": 0.07408902380201551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.6365203857422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01549532264471054,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1042209506034851,
      "backward_entropy": 0.07684938112894694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.89878845214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015591846778988838,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10414541959762573,
      "backward_entropy": 0.07457962301042345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.11842346191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015688229352235794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1040690541267395,
      "backward_entropy": 0.07452195220523411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.0736846923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015786759555339813,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10399142503738404,
      "backward_entropy": 0.07446410920884874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.11573028564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015884792432188988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10391287803649903,
      "backward_entropy": 0.07375743654039171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.38267517089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01597832515835762,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10383505821228027,
      "backward_entropy": 0.07434029711617364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.41116333007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016077900305390358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10375399589538574,
      "backward_entropy": 0.07361584239535862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.93162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016171054914593697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10367494821548462,
      "backward_entropy": 0.07354128360748291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.60910034179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016268489882349968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10359344482421876,
      "backward_entropy": 0.07346755928463405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.3490982055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016359101980924606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10351325273513794,
      "backward_entropy": 0.07338772879706489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.84022521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01644769497215748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1034324049949646,
      "backward_entropy": 0.07330433527628581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.10345458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016536658629775047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10335017442703247,
      "backward_entropy": 0.0732194185256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.74070739746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016632433980703354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1032646656036377,
      "backward_entropy": 0.07679527335696751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.42505645751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016737960278987885,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10317454338073731,
      "backward_entropy": 0.07679269048902723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.75536346435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01683332771062851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10308670997619629,
      "backward_entropy": 0.0737105409304301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.96467590332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01692030020058155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10300173759460449,
      "backward_entropy": 0.07288628154330784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.52601623535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016998616978526115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10291817188262939,
      "backward_entropy": 0.07354358832041423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.45439147949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017080586403608322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10283383131027221,
      "backward_entropy": 0.07268788417180379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.66339111328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01716197282075882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10275014638900756,
      "backward_entropy": 0.07258779472774929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.91000366210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017237821593880653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10266726016998291,
      "backward_entropy": 0.07327836751937866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.16542053222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017312973737716675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10258324146270752,
      "backward_entropy": 0.07318421204884847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.84361267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017392152920365334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10249687433242798,
      "backward_entropy": 0.07226539982689752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.20866394042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017466334626078606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1024117112159729,
      "backward_entropy": 0.07215244240230984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.35905456542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017537796869874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10232621431350708,
      "backward_entropy": 0.07289025518629286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.20751190185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017604727298021317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10224136114120483,
      "backward_entropy": 0.07191242112053765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.42166137695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017672060057520866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10215532779693604,
      "backward_entropy": 0.07178796662224664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.98345184326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01773270033299923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10207042694091797,
      "backward_entropy": 0.07256223758061726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.1056900024414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017792465165257454,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10198525190353394,
      "backward_entropy": 0.07666305038664076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.89006042480469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01784737966954708,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1019022822380066,
      "backward_entropy": 0.07664875851737128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.37979888916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0178934708237648,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10182273387908936,
      "backward_entropy": 0.0721919337908427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.78646850585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017936374992132187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10174427032470704,
      "backward_entropy": 0.07110072506798638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.18732452392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01799136959016323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10165973901748657,
      "backward_entropy": 0.07192871305677626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.83489227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018043357878923416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10157464742660523,
      "backward_entropy": 0.07179802656173706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.346763610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01809476874768734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1014878511428833,
      "backward_entropy": 0.07067702213923137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.06907653808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018139410763978958,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10140323638916016,
      "backward_entropy": 0.07655464940600926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.00518035888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018182560801506042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10131845474243165,
      "backward_entropy": 0.070368316438463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.480224609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018226362764835358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10123203992843628,
      "backward_entropy": 0.07020984093348186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.87089157104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01828213594853878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1011394739151001,
      "backward_entropy": 0.07006025314331055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.7904052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018328892067074776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1010511875152588,
      "backward_entropy": 0.06990312867694431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.36974334716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018375959247350693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10096137523651123,
      "backward_entropy": 0.07081152995427449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.39926147460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018421031534671783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1008712649345398,
      "backward_entropy": 0.06957867410447863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.93113708496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018475933000445366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1007759690284729,
      "backward_entropy": 0.07051867246627808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.46571350097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01853504218161106,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10067799091339111,
      "backward_entropy": 0.07643271817101373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.18431854248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018600016832351685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10057688951492309,
      "backward_entropy": 0.06911097632514106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.85609436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018661728128790855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10047723054885864,
      "backward_entropy": 0.07009569141599867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.93701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018728764727711678,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10037364959716796,
      "backward_entropy": 0.06878968079884847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.53419494628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01879911497235298,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10026817321777344,
      "backward_entropy": 0.07639192210303412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.75232696533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01887260004878044,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10016142129898072,
      "backward_entropy": 0.06967269712024265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.14789581298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018946383148431778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10005376338958741,
      "backward_entropy": 0.06831145286560059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.00506591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019013477489352226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09994832277297974,
      "backward_entropy": 0.06814010938008626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.31959533691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019090628251433372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09983786344528198,
      "backward_entropy": 0.06923365592956543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.64476776123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019174724817276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09972405433654785,
      "backward_entropy": 0.06782492664125231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.60206604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019251294434070587,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09961323142051696,
      "backward_entropy": 0.06894667281044854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.2670135498047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019330522045493126,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09950102567672729,
      "backward_entropy": 0.076341536309984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.88377380371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019411258399486542,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09938624501228333,
      "backward_entropy": 0.07633566194110447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.34597778320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01949627511203289,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09926894903182984,
      "backward_entropy": 0.06715791755252415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.76756286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019584834575653076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0991489052772522,
      "backward_entropy": 0.06699284580018786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.6822280883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01966758444905281,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09903073310852051,
      "backward_entropy": 0.06681545575459798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.21650695800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019745107740163803,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09891433715820312,
      "backward_entropy": 0.06662782695558336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.94107818603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01982227712869644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0987965703010559,
      "backward_entropy": 0.06785223219129774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.84634399414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01989220269024372,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09868096709251403,
      "backward_entropy": 0.07629080613454182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.87266540527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019958501681685448,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856705665588379,
      "backward_entropy": 0.07627622286478679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.84455108642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020031962543725967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09844732284545898,
      "backward_entropy": 0.06581389241748387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.678466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020099032670259476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09833056926727295,
      "backward_entropy": 0.06559611029095119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.87167358398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020166855305433273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09821233749389649,
      "backward_entropy": 0.06537487771775988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.47520446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020242001861333847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09808862209320068,
      "backward_entropy": 0.06516052616967095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.25739288330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020327676087617874,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.097957181930542,
      "backward_entropy": 0.07621658510631985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.1329803466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020410005003213882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09782692193984985,
      "backward_entropy": 0.06474387645721436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.52810668945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02049332857131958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09769425988197326,
      "backward_entropy": 0.06452446513705784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.114253997802734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020576084032654762,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09756166934967041,
      "backward_entropy": 0.07618747817145453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.8842315673828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020649926736950874,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09743554592132568,
      "backward_entropy": 0.07617217964596218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.34959411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020726097747683525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09730683565139771,
      "backward_entropy": 0.06382961405648126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.88871765136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020808439701795578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09717292785644531,
      "backward_entropy": 0.0635977652337816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.7500457763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020889904350042343,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09703830480575562,
      "backward_entropy": 0.07613401942782932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.57630920410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020974978804588318,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09690039753913879,
      "backward_entropy": 0.06489922602971394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.63955688476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02106544002890587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09675816297531128,
      "backward_entropy": 0.06289311250050862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.49478149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02115684561431408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09661526679992676,
      "backward_entropy": 0.06266074048148261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.95620727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021249104291200638,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09647167325019837,
      "backward_entropy": 0.06242668628692627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.04071044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021339667961001396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09632846117019653,
      "backward_entropy": 0.0640677743487888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.96685791015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02143235132098198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09618145823478699,
      "backward_entropy": 0.06385310490926106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.30665588378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02152949571609497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09603060483932495,
      "backward_entropy": 0.06169275442759196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.81918334960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021634913980960846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09587399959564209,
      "backward_entropy": 0.06344255473878649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.04701232910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02173917554318905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09571709632873535,
      "backward_entropy": 0.06121543380949232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.63488006591797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0218473169952631,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0955582857131958,
      "backward_entropy": 0.07606882519192165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.05389404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02195187471807003,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0954006552696228,
      "backward_entropy": 0.06072766251034207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53876495361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022055506706237793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09524288177490234,
      "backward_entropy": 0.06259611580106947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.59691619873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022150160744786263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09509156942367554,
      "backward_entropy": 0.060200903150770396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.7726058959961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02224346250295639,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09494199752807617,
      "backward_entropy": 0.07603324784172906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.15003204345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022334851324558258,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09479256868362426,
      "backward_entropy": 0.07601969109641181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.22239685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02242424711585045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09464271068572998,
      "backward_entropy": 0.05935824579662747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.57897186279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02251686528325081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09449076652526855,
      "backward_entropy": 0.059075395266215004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.513410568237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022605491802096367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09434079527854919,
      "backward_entropy": 0.05878130594889323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.121395111083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022679496556520462,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09420055150985718,
      "backward_entropy": 0.05846152040693495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.15603637695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022745292633771896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09406647682189942,
      "backward_entropy": 0.05812991327709622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.20211791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022811859846115112,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09393011331558228,
      "backward_entropy": 0.0577964981396993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.29087829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022881606593728065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0937909185886383,
      "backward_entropy": 0.057466738753848605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.3892822265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022962456569075584,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09364325404167176,
      "backward_entropy": 0.05959842602411906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.22089385986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023044750094413757,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09349358081817627,
      "backward_entropy": 0.05683881706661648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.52009582519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02312835492193699,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09334208965301513,
      "backward_entropy": 0.059035023053487144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.25517272949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023209528997540474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09319316148757935,
      "backward_entropy": 0.058742781480153404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.47355651855469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0232900008559227,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0930438756942749,
      "backward_entropy": 0.0757830540339152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.20240020751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0233727116137743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09289108514785767,
      "backward_entropy": 0.05555140641000536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.98443603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023455016314983368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09273677468299865,
      "backward_entropy": 0.055225501457850136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.50442504882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02354193478822708,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09257968664169311,
      "backward_entropy": 0.0549141698413425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.30641174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02363203465938568,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09241876602172852,
      "backward_entropy": 0.0572573807504442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.26712036132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02372499369084835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09225449562072754,
      "backward_entropy": 0.05696845054626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.84127044677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023814259096980095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09209258556365967,
      "backward_entropy": 0.05397398273150126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.49195098876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023897899314761162,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09193381071090698,
      "backward_entropy": 0.05635522471533881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.51454162597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023983387276530266,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09177392721176147,
      "backward_entropy": 0.07566503683725993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.95514678955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02407461777329445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09160953164100646,
      "backward_entropy": 0.05573970741695828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.40605926513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02416279725730419,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09144846200942994,
      "backward_entropy": 0.05542690886391534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.85160827636719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024252112954854965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09128618240356445,
      "backward_entropy": 0.0756217704878913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.43919372558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024340879172086716,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09112536907196045,
      "backward_entropy": 0.0519907275835673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.30459594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024432852864265442,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09096179008483887,
      "backward_entropy": 0.05447546641031901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.7799835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02452823892235756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09079674482345582,
      "backward_entropy": 0.05416442288292779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.93753051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024626286700367928,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09062966704368591,
      "backward_entropy": 0.051033986939324275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.639404296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024720126762986183,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09046502113342285,
      "backward_entropy": 0.0755656295352512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.15829467773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024810878559947014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09030393362045289,
      "backward_entropy": 0.05037066671583387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.1017074584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024898458272218704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09014517664909363,
      "backward_entropy": 0.050025509463416204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.59531021118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02498374693095684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08998978137969971,
      "backward_entropy": 0.049678408437305026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.73242950439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02506253682076931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08984066843986512,
      "backward_entropy": 0.05215686559677124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.77996063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025141684338450432,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08969102501869201,
      "backward_entropy": 0.0489612254831526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.34943389892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02522103860974312,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08954054713249207,
      "backward_entropy": 0.048602031336890325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.99285125732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0252961628139019,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08939257860183716,
      "backward_entropy": 0.05105629232194689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.06531524658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025369932875037193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08924599289894104,
      "backward_entropy": 0.0753910740216573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.24485778808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025440072640776634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08910157680511474,
      "backward_entropy": 0.050291114383273654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.3524398803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02551579661667347,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08895287513732911,
      "backward_entropy": 0.04991669787300958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.03810119628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025588015094399452,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08880722522735596,
      "backward_entropy": 0.049531370401382446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.4750747680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02566550113260746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08865723609924317,
      "backward_entropy": 0.04634647236929999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.75574493408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025745755061507225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08850562572479248,
      "backward_entropy": 0.04878689183129205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.35899353027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025821572169661522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08835662603378296,
      "backward_entropy": 0.04560050368309021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.09465026855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02589423581957817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08821135759353638,
      "backward_entropy": 0.04801289571656121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.00354766845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02596636861562729,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08806784749031067,
      "backward_entropy": 0.04761981301837497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.53419494628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026040183380246162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08792427182197571,
      "backward_entropy": 0.04445891247855292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.91648864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026119347661733627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08777657747268677,
      "backward_entropy": 0.044100162055757314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.85932922363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026202918961644173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08762484192848205,
      "backward_entropy": 0.04374602768156263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.27023315429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026286795735359192,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08747371435165405,
      "backward_entropy": 0.07510876655578613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.27916717529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02637122943997383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08732370138168336,
      "backward_entropy": 0.045755485693613686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.7429428100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02645605057477951,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08717344999313355,
      "backward_entropy": 0.042689343293507896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.7587432861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0265393927693367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08702596426010131,
      "backward_entropy": 0.04501138793097602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.56462860107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026627441868185997,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08687571287155152,
      "backward_entropy": 0.04200003213352627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.6146469116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026712922379374504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08672673106193543,
      "backward_entropy": 0.04165210326512655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.39623260498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026796648278832436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08658003807067871,
      "backward_entropy": 0.04130136966705322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.87541198730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026878148317337036,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08643397092819213,
      "backward_entropy": 0.043534417947133384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.619590759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026959914714097977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0862871527671814,
      "backward_entropy": 0.040575755967034235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.28509521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027035973966121674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08614611625671387,
      "backward_entropy": 0.04019749495718214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.74267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027116941288113594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08600020408630371,
      "backward_entropy": 0.04238723715146383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.70414733886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027196716517210007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08585662841796875,
      "backward_entropy": 0.04200629393259684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.00385284423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027277279645204544,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08571299314498901,
      "backward_entropy": 0.07491256793340047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.12356567382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02735435590147972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08557276725769043,
      "backward_entropy": 0.03872319724824694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.81254577636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027432672679424286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08543227910995484,
      "backward_entropy": 0.04085132810804579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.58613586425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027514081448316574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08528971672058105,
      "backward_entropy": 0.04047357704904345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.70817565917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02759828045964241,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0851454496383667,
      "backward_entropy": 0.04010384612613254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.24959945678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027684740722179413,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08499951958656311,
      "backward_entropy": 0.03973895973629422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8945541381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02776273526251316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0848601996898651,
      "backward_entropy": 0.03935109244452582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.54658508300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027843918651342392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08471922874450684,
      "backward_entropy": 0.03654695881737603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.51243591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027926303446292877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08457905650138856,
      "backward_entropy": 0.036191059483422175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.91332244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028017306700348854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08443250656127929,
      "backward_entropy": 0.035858478811052114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.6446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028112102299928665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08428386449813843,
      "backward_entropy": 0.0355337659517924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.72161865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028200261294841766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08414191007614136,
      "backward_entropy": 0.03519132733345032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.027408599853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02829628251492977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08399385809898377,
      "backward_entropy": 0.03724395897653368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.44625854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02838336117565632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08385392427444457,
      "backward_entropy": 0.0345184670554267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.1256332397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028468532487750053,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08371604681015014,
      "backward_entropy": 0.03416601485676236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.64932632446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028556112200021744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08357700705528259,
      "backward_entropy": 0.033820139037238225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.0757942199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028635669499635696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08344526886940003,
      "backward_entropy": 0.03579962584707472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.35828399658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02870999276638031,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08331797122955323,
      "backward_entropy": 0.033085780011283025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.63864135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028785593807697296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08318951725959778,
      "backward_entropy": 0.035039299064212374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.2579116821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028860438615083694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08306210041046143,
      "backward_entropy": 0.03466450505786472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.40296936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02893860638141632,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.082931649684906,
      "backward_entropy": 0.03430201941066318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.02339172363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029015690088272095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0828019142150879,
      "backward_entropy": 0.03393892778290643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.0377082824707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02909654565155506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08267104029655456,
      "backward_entropy": 0.0312884251276652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.84651184082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02917235717177391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08254512548446655,
      "backward_entropy": 0.030936062335968018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.52263641357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029251860454678535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0824178397655487,
      "backward_entropy": 0.030594746271769207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.41384887695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0293289627879858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08229436874389648,
      "backward_entropy": 0.030252307653427124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.64868927001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029405223205685616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08217160701751709,
      "backward_entropy": 0.029905017879274156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.16932678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02948126383125782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08205071687698365,
      "backward_entropy": 0.029562132226096258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.92538452148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02955521270632744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193268775939941,
      "backward_entropy": 0.029218720065222845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.00715637207031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029635051265358925,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08181109428405761,
      "backward_entropy": 0.07441433270772298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.15612030029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971016615629196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08169361352920532,
      "backward_entropy": 0.028556631671057806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.82870483398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02978503331542015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08157718181610107,
      "backward_entropy": 0.030475066767798528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.33252716064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02985983155667782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08146171569824219,
      "backward_entropy": 0.027887947029537626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.83316040039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02993600256741047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08134435415267945,
      "backward_entropy": 0.027556596530808344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.36235809326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030011657625436783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0812269926071167,
      "backward_entropy": 0.029475953843858507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.97551727294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030089152976870537,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08110921382904053,
      "backward_entropy": 0.029156025913026597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.1012954711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03017045557498932,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08099023699760437,
      "backward_entropy": 0.02885048919253879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.72767639160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030254825949668884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08086880445480346,
      "backward_entropy": 0.02855592303805881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.529640197753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03033631294965744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08075094223022461,
      "backward_entropy": 0.028254962629742093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.24388885498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030411407351493835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08063942193984985,
      "backward_entropy": 0.02567627363734775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.92918395996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03048662655055523,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08052893280982971,
      "backward_entropy": 0.07425908909903632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.91864776611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030562112107872963,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08041953444480895,
      "backward_entropy": 0.02731802397304111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.89704895019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03063584864139557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08031241893768311,
      "backward_entropy": 0.02700811293390062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.696067810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03071429766714573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08020362854003907,
      "backward_entropy": 0.0267145832379659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.84077453613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030788861215114594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08009911775588989,
      "backward_entropy": 0.024177778098318312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.193693161010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030869344249367714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07999082803726196,
      "backward_entropy": 0.0239046315352122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.987060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030941490083932877,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07988845109939575,
      "backward_entropy": 0.02584264013502333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.01402282714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031014123931527138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07978593111038208,
      "backward_entropy": 0.02332901292377048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.338077545166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031085345894098282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07968515157699585,
      "backward_entropy": 0.02304233445061578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.22457504272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031151536852121353,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0795890212059021,
      "backward_entropy": 0.024952878554662068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.25761413574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03121323138475418,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07949681282043457,
      "backward_entropy": 0.02246286306116316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.88783264160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03128231316804886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07939907312393188,
      "backward_entropy": 0.07412186596128675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.3211898803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0313483402132988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07930397987365723,
      "backward_entropy": 0.021911013457510207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.2774887084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031417764723300934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0792073130607605,
      "backward_entropy": 0.02379587623808119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.98753356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031494077295064926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07910689115524291,
      "backward_entropy": 0.02353785600927141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.18211364746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03157128766179085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07900785207748413,
      "backward_entropy": 0.021149983008702595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.5556182861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03164885565638542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07890930771827698,
      "backward_entropy": 0.020910759766896565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.82486343383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03173612430691719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0788047194480896,
      "backward_entropy": 0.02068983680672116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.26317596435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031818944960832596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0787043035030365,
      "backward_entropy": 0.02046173479821947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.622066497802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031899526715278625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07860589027404785,
      "backward_entropy": 0.022340151998731825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.005126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03197626397013664,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.078510582447052,
      "backward_entropy": 0.02209535737832387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.56912612915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032051313668489456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07841612696647644,
      "backward_entropy": 0.019745479027430218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.018394470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03212522715330124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07832319736480713,
      "backward_entropy": 0.019505020644929674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.98582458496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032196298241615295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07823320627212524,
      "backward_entropy": 0.02135711411635081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.3292350769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032267045229673386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07814521789550781,
      "backward_entropy": 0.021118529968791537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.19232177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03233591839671135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0780609130859375,
      "backward_entropy": 0.02088544766108195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.33417510986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03240172564983368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07797691822052003,
      "backward_entropy": 0.020647946331236098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.529903411865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03247116133570671,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07789051532745361,
      "backward_entropy": 0.018362189332644146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.06378173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03254032880067825,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07780507802963257,
      "backward_entropy": 0.020203327139218647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.7589340209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0326075553894043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07772227525711059,
      "backward_entropy": 0.017933244506518047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.53961944580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032680392265319824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07763638496398925,
      "backward_entropy": 0.01773454248905182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.35071563720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327540747821331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0775493323802948,
      "backward_entropy": 0.017536335521274142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.90100860595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03283262625336647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07745981216430664,
      "backward_entropy": 0.017349658740891352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.6217041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032913874834775925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07736934423446655,
      "backward_entropy": 0.017170714007483587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.37531280517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03299957513809204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07727724313735962,
      "backward_entropy": 0.019052320056491427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.5335693359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03308546170592308,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07718610763549805,
      "backward_entropy": 0.018889476855595905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.244136810302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033163443207740784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07709971070289612,
      "backward_entropy": 0.0166628360748291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.1533317565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033236511051654816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0770166277885437,
      "backward_entropy": 0.01852849456999037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.50366973876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0333087258040905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07693377733230591,
      "backward_entropy": 0.018344069520632427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.8033218383789,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033386167138814926,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07684854865074157,
      "backward_entropy": 0.0742652416229248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.63064193725586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033464059233665466,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07676242589950562,
      "backward_entropy": 0.07427966594696045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.76815795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03353910148143768,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07667825818061828,
      "backward_entropy": 0.015761653582255047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.79163360595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03361756354570389,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07659313678741456,
      "backward_entropy": 0.015595565239588419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.86640167236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033698670566082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07650691270828247,
      "backward_entropy": 0.015433579683303833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.895145416259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033786240965127945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07641804218292236,
      "backward_entropy": 0.017380088567733765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.4440689086914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03387176990509033,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07633047699928283,
      "backward_entropy": 0.07438962989383274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.48137664794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03396298363804817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07624019384384155,
      "backward_entropy": 0.017106968495580886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.11945724487305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034057438373565674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07614799737930297,
      "backward_entropy": 0.014849179320865206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.93815994262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03414962813258171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07605891227722168,
      "backward_entropy": 0.016860587729348078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.42050170898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03423979505896568,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07597172260284424,
      "backward_entropy": 0.016737275653415255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.528602600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034329820424318314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07588458061218262,
      "backward_entropy": 0.0144447171025806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.446146011352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034418173134326935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07579946517944336,
      "backward_entropy": 0.016493760877185397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.191673278808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03449735417962074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07572021484375,
      "backward_entropy": 0.01417240666018592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.98041915893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03457598388195038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07564226388931275,
      "backward_entropy": 0.014034971594810486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.754737854003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03465423732995987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0755655288696289,
      "backward_entropy": 0.013902283377117582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.86227035522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03472619876265526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07549228072166443,
      "backward_entropy": 0.013762260476748148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.80141830444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03479807451367378,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07541904449462891,
      "backward_entropy": 0.013622926341162788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.227603912353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034869689494371414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07534536123275756,
      "backward_entropy": 0.015701131688223943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.83279418945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03493942320346832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07527283430099488,
      "backward_entropy": 0.01334442612197664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.78620147705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035010918974876404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07519867420196533,
      "backward_entropy": 0.01543931331899431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.011688232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03508618101477623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07512208819389343,
      "backward_entropy": 0.015319461623827616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.05535125732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03515885770320892,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07504629492759704,
      "backward_entropy": 0.015195267068015205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.781978607177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03523356467485428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07497014999389648,
      "backward_entropy": 0.015079445309109159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.766170501708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0353056900203228,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07489463090896606,
      "backward_entropy": 0.014957379963662889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.65744018554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03537748008966446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07481865882873535,
      "backward_entropy": 0.012553226616647508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.03986740112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03545104339718819,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07474190592765809,
      "backward_entropy": 0.014713938037554422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.43348693847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03552095219492912,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07466742396354675,
      "backward_entropy": 0.014592915773391724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.03003692626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03559450805187225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07459023594856262,
      "backward_entropy": 0.012163212729824914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.83961486816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035671841353178024,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0745116114616394,
      "backward_entropy": 0.07483971118927002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.77764892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035748716443777084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07443318963050842,
      "backward_entropy": 0.011928536825709872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.60315704345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035824909806251526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07435466647148133,
      "backward_entropy": 0.011810677746931711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.410484313964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035902246832847595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07427487373352051,
      "backward_entropy": 0.014060644639862908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.00944519042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03597734868526459,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07419639229774475,
      "backward_entropy": 0.011575150820944045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.069271087646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03605584427714348,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07411644458770753,
      "backward_entropy": 0.013859537740548452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.03832244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03613366559147835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07403655648231507,
      "backward_entropy": 0.011351990203062693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.33129119873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03622008487582207,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07395204305648803,
      "backward_entropy": 0.01367860370212131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.85186004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036308664828538895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07386643886566162,
      "backward_entropy": 0.01115663101275762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.70516967773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036400970071554184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07377879619598389,
      "backward_entropy": 0.011064219805929396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.98605728149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03649519756436348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07369070649147033,
      "backward_entropy": 0.01097740564081404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.91404724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03658197075128555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07360706329345704,
      "backward_entropy": 0.010884026686350504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.800004959106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03666747361421585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07352417707443237,
      "backward_entropy": 0.013300668862130906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.1492691040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036746516823768616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07344515323638916,
      "backward_entropy": 0.010695861445532905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.07328033447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0368269719183445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07336530685424805,
      "backward_entropy": 0.010604358381695218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.27584457397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036908261477947235,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07328450679779053,
      "backward_entropy": 0.013068147831492953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.61601257324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03698870539665222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07320403456687927,
      "backward_entropy": 0.010420087311002944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.29313659667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037073809653520584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07312098741531373,
      "backward_entropy": 0.010334770712587569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.184234619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03716325759887695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07303537130355835,
      "backward_entropy": 0.010253844989670647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.997623443603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037249717861413956,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07295278310775757,
      "backward_entropy": 0.012789633538987901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.76429748535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03733367100358009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07287124395370484,
      "backward_entropy": 0.010100126266479492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.4975643157959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03741832077503204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07278871536254883,
      "backward_entropy": 0.012665189802646637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.70589828491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749837726354599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07270908951759339,
      "backward_entropy": 0.009945318930678897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.75770568847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037576086819171906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07263060212135315,
      "backward_entropy": 0.009863908920023177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.31700897216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037653885781764984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07255234718322753,
      "backward_entropy": 0.009787273075845506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.801170349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037737179547548294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07247121334075927,
      "backward_entropy": 0.012414630916383531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.957496643066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781454265117645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07239367365837097,
      "backward_entropy": 0.0096521923939387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.25148010253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037888191640377045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07231823801994323,
      "backward_entropy": 0.009580391148726145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.876426696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03796171396970749,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07224186062812805,
      "backward_entropy": 0.012244019243452284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.26444244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038033775985240936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0721663236618042,
      "backward_entropy": 0.009434342384338379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.807010650634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03811323642730713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07208661437034607,
      "backward_entropy": 0.00936963657538096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.56611251831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03819391503930092,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07200548648834229,
      "backward_entropy": 0.009305208093590207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.32853698730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03827395290136337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07192436456680298,
      "backward_entropy": 0.009239295290576087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.236202239990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03835554048418999,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07184239029884339,
      "backward_entropy": 0.009178357819716135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.9016342163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03843475133180618,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07176174521446228,
      "backward_entropy": 0.009115100734763674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.67817687988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038517165929079056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07167878150939941,
      "backward_entropy": 0.009055706361929575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.00874137878418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038602378219366074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07159380912780762,
      "backward_entropy": 0.008999790582391951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.523860931396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038682762533426285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07151135802268982,
      "backward_entropy": 0.008936040103435516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.97728729248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038762643933296204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07142894268035889,
      "backward_entropy": 0.008871679504712423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.387264251708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03884550556540489,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07134433388710022,
      "backward_entropy": 0.011709728174739413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.69790267944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038925983011722565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07126110792160034,
      "backward_entropy": 0.011661334170235528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.676603317260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0390012264251709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07118165493011475,
      "backward_entropy": 0.008686607910527123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.3308162689209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03907147794961929,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07110468149185181,
      "backward_entropy": 0.011565460926956601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.18071365356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03913877159357071,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07102934718132019,
      "backward_entropy": 0.011514587534798516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.421451568603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03920877352356911,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0709528923034668,
      "backward_entropy": 0.00850092868010203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.60456085205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03927916660904884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07087545394897461,
      "backward_entropy": 0.011425155732366774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.8097152709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03935709223151207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07079247236251832,
      "backward_entropy": 0.008390158414840698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.34048080444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039439622312784195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07070597410202026,
      "backward_entropy": 0.011354936493767632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.201217651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03951992839574814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.070620858669281,
      "backward_entropy": 0.008288658327526517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.028297424316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039594829082489014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07053937911987304,
      "backward_entropy": 0.00823636187447442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.12093353271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03966860845685005,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0704587459564209,
      "backward_entropy": 0.008187544014718797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.44454956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039749570190906525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07037299871444702,
      "backward_entropy": 0.008144521878825294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.3946418762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039835043251514435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07028380632400513,
      "backward_entropy": 0.011198482579655118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.52328109741211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03992141783237457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0701938271522522,
      "backward_entropy": 0.008063599467277527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.58535766601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04000512883067131,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07010557651519775,
      "backward_entropy": 0.01115065316359202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.49040222167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04009309038519859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07001383304595947,
      "backward_entropy": 0.007984402279059092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.09281539916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04017995670437813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06992275714874267,
      "backward_entropy": 0.0079465980331103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.36015319824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04026404768228531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06983335614204407,
      "backward_entropy": 0.007906521360079447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.27808380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04034878686070442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06974290013313293,
      "backward_entropy": 0.007864875925911797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.760868072509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04043598100543022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06965051889419556,
      "backward_entropy": 0.007825349768002829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.38304901123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040522195398807526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06955856084823608,
      "backward_entropy": 0.011006719536251493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.49000549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04060438275337219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06946953535079955,
      "backward_entropy": 0.007750779390335083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.3185806274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040687453001737595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06937935352325439,
      "backward_entropy": 0.007713069518407186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.05601501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040774568915367126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0692856788635254,
      "backward_entropy": 0.00767617341544893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.93606185913086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040860582143068314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0691925346851349,
      "backward_entropy": 0.007639247510168288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.517276763916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04094385355710983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06910016536712646,
      "backward_entropy": 0.007600482967164781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.858596801757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041029706597328186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06900551319122314,
      "backward_entropy": 0.010863478812906478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.1855354309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04110986366868019,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06891541481018067,
      "backward_entropy": 0.01083972884549035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.157257080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0411912277340889,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06882463693618775,
      "backward_entropy": 0.007493042283587986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.55070877075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04127214848995209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.068733811378479,
      "backward_entropy": 0.007458994785944621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.582077026367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04135574772953987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06864055395126342,
      "backward_entropy": 0.00742574863963657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.6423454284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143378511071205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06855162382125854,
      "backward_entropy": 0.007391545507642958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.82541275024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041511647403240204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0684625506401062,
      "backward_entropy": 0.007358002165953319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.385061264038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041592564433813095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06837078332901,
      "backward_entropy": 0.007326002750131819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.31743812561035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04166805371642113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06828324794769287,
      "backward_entropy": 0.007291975948545668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.001792907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04173866659402847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06819958090782166,
      "backward_entropy": 0.00725589609808392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.375736236572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04180960729718208,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.068114972114563,
      "backward_entropy": 0.007218740880489349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.67069625854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041882675141096115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06802834272384643,
      "backward_entropy": 0.010609606073962318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.525341033935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04195600748062134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06794102191925049,
      "backward_entropy": 0.007149155769083235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.354774475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04202653840184212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06785529851913452,
      "backward_entropy": 0.007115623189343346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.358442306518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04209758713841438,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06776898503303527,
      "backward_entropy": 0.007082535988754696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.643585205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04216577112674713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06768474578857422,
      "backward_entropy": 0.010511486894554563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.897518157958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223323613405228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06760081052780151,
      "backward_entropy": 0.007014796137809753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.09242248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04230152815580368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06751564741134644,
      "backward_entropy": 0.010463314751784006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.289615631103516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04237199202179909,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06742806434631347,
      "backward_entropy": 0.07638667689429389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.26161193847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04244131222367287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0673411250114441,
      "backward_entropy": 0.006916712141699261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.23392486572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042515963315963745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06724879741668702,
      "backward_entropy": 0.010392472975783877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.88718032836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042597051709890366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06715017557144165,
      "backward_entropy": 0.0068571749660703875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.2725830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04267596825957298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06705331206321716,
      "backward_entropy": 0.006828588744004567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.743228912353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04275751858949661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06695314049720764,
      "backward_entropy": 0.006800014111730788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.56494903564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04283837601542473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06685330271720887,
      "backward_entropy": 0.006771353797780143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.254838943481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0429186075925827,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06675400733947753,
      "backward_entropy": 0.0067426785826683044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.209049224853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04299510642886162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06665803790092469,
      "backward_entropy": 0.006712825761901008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.03475570678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04307157173752785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06656174659729004,
      "backward_entropy": 0.006685285104645623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.87386703491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04314809665083885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06646528244018554,
      "backward_entropy": 0.006660153882371055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.83635902404785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0432245098054409,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06636868715286255,
      "backward_entropy": 0.006635693212350209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.54520034790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04329773411154747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06627504825592041,
      "backward_entropy": 0.006611709379487568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.380550384521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337109997868538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0661806583404541,
      "backward_entropy": 0.006588426315122181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.24444580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043444618582725525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06608562469482422,
      "backward_entropy": 0.010198775264951918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.43604850769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043527256697416306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06598085165023804,
      "backward_entropy": 0.006542815930313534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.860897064208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04360595718026161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06587990522384643,
      "backward_entropy": 0.006519359019067552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.957914352416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0436842143535614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06577907800674439,
      "backward_entropy": 0.006495929012695949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.21108627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043760478496551514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06567996740341187,
      "backward_entropy": 0.006471821417411168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.016008377075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383813217282295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06557891368865967,
      "backward_entropy": 0.006449061963293288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.539276123046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04391239210963249,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06548109650611877,
      "backward_entropy": 0.07654853661855061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.420515060424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04398529231548309,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06538473963737487,
      "backward_entropy": 0.006405892057551278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.85635757446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04405668377876282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06528957486152649,
      "backward_entropy": 0.0063842299083868665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.15912437438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04412828013300896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06519390344619751,
      "backward_entropy": 0.0063623761137326556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.53500747680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04419858381152153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0650993287563324,
      "backward_entropy": 0.006340640286604564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.374046325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04426923394203186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06500390768051148,
      "backward_entropy": 0.006319272021452586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.774335861206055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044340234249830246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06490771770477295,
      "backward_entropy": 0.006298907101154327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.05813980102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04441002756357193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06481252312660217,
      "backward_entropy": 0.006278959827290641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.65499496459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04448018595576286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06471646428108216,
      "backward_entropy": 0.006259045253197352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.73124313354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04455358535051346,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06461622714996337,
      "backward_entropy": 0.010006460050741831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.634708404541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462702199816704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06451547145843506,
      "backward_entropy": 0.00622059197889434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.411659240722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04469594731926918,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0644197940826416,
      "backward_entropy": 0.006201231645213233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.0031795501709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04476524889469147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0643233060836792,
      "backward_entropy": 0.009965911507606506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.7489128112793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0448334664106369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06422793865203857,
      "backward_entropy": 0.006162225372261471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.11268615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04490656778216362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06412630081176758,
      "backward_entropy": 0.006143297586176131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.759220123291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04498117417097092,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06402227878570557,
      "backward_entropy": 0.009921917484866248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.590293884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505563899874687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0639181911945343,
      "backward_entropy": 0.006107476436429554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.173049926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512995854020119,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0638138473033905,
      "backward_entropy": 0.006090494079722298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.31429672241211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045199695974588394,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06371513605117798,
      "backward_entropy": 0.07664773199293348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.080005645751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045271165668964386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0636137843132019,
      "backward_entropy": 0.009865302178594802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.91230392456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04534130170941353,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06351368427276612,
      "backward_entropy": 0.009850824872652689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.67828369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04541458189487457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0634096086025238,
      "backward_entropy": 0.009836665458149381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.679353713989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04549066349864006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0633012294769287,
      "backward_entropy": 0.006008884145153893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053390804678201675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556489735841751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06319488883018494,
      "backward_entropy": 0.009807397921880087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.983009338378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563158005475998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06309854984283447,
      "backward_entropy": 0.009791354338328043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.293018341064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045701708644628525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06299723386764526,
      "backward_entropy": 0.005962077114317153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.3275032043457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577053338289261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06289714574813843,
      "backward_entropy": 0.005946599774890476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.788021087646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04584398865699768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06279045939445496,
      "backward_entropy": 0.009742844435903762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.34233093261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04591725766658783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06268360018730164,
      "backward_entropy": 0.005916839258538352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.448421478271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045991819351911545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06257468461990356,
      "backward_entropy": 0.00590258174472385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.9675350189209,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046066075563430786,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06246572732925415,
      "backward_entropy": 0.07670463456047906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.114295959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04613718390464783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0623610258102417,
      "backward_entropy": 0.0058748866948816515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.540409088134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04620831832289696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.062255859375,
      "backward_entropy": 0.005861504210366143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.783504486083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046280890703201294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.062148720026016235,
      "backward_entropy": 0.005848681761158837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.662776947021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04635332524776459,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.062041175365447995,
      "backward_entropy": 0.005836118426587846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.932247161865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04642845317721367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061929363012313846,
      "backward_entropy": 0.009607369701067606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.36168670654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04650457203388214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06181570887565613,
      "backward_entropy": 0.005812005036407047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.10074234008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046577319502830505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06170663833618164,
      "backward_entropy": 0.0058002761668629116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.547069549560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046649862080812454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06159752607345581,
      "backward_entropy": 0.005788976947466533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.83091735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672079160809517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061490631103515624,
      "backward_entropy": 0.005777856128083335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.234336853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04679585248231888,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061377179622650144,
      "backward_entropy": 0.009517975979381137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.56799030303955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04687322676181793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0612602710723877,
      "backward_entropy": 0.009499582979414199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.99967956542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046945665031671524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06115044355392456,
      "backward_entropy": 0.009480854703320397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.8594970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702203348278999,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06103415489196777,
      "backward_entropy": 0.005736337767706977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.362283706665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047096360474824905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06092063784599304,
      "backward_entropy": 0.00572661848531829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.593284606933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04716602712869644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06081414222717285,
      "backward_entropy": 0.009423930611875322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.81553649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04723430052399635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06070955991744995,
      "backward_entropy": 0.00940431985590193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.501827239990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047305453568696976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06060000061988831,
      "backward_entropy": 0.0056985049611992305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.200895309448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737778753042221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06048823595046997,
      "backward_entropy": 0.0056894222895304365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.053556442260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04744842275977135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06037878394126892,
      "backward_entropy": 0.009344205260276794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.91492462158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0475161112844944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060273987054824826,
      "backward_entropy": 0.0056713852617475725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.768360137939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047585275024175644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06016635298728943,
      "backward_entropy": 0.0056622881028387285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.76520347595215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047654397785663605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06005843281745911,
      "backward_entropy": 0.005653336230251525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.673295974731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04772074893116951,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05995478630065918,
      "backward_entropy": 0.00925575527879927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.443641662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047784555703401566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05985505580902099,
      "backward_entropy": 0.005636120835940043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.664135932922363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047847453504800797,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05975654125213623,
      "backward_entropy": 0.005627592404683431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.411012649536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047906819730997086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05966360569000244,
      "backward_entropy": 0.005619536257452435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.65664291381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047964390367269516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05957321524620056,
      "backward_entropy": 0.005612031867106755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.23651885986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04802444949746132,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05947779417037964,
      "backward_entropy": 0.005605206721358829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.721293926239014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04808802157640457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.059375953674316403,
      "backward_entropy": 0.0055984002020623945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.384486198425293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04814663529396057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.059282445907592775,
      "backward_entropy": 0.005592110256354014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.660608291625977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04820211976766586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.059194183349609374,
      "backward_entropy": 0.0055860901872317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.919189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0482574924826622,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05910578966140747,
      "backward_entropy": 0.005580234858724806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.068273544311523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048311375081539154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05901998281478882,
      "backward_entropy": 0.009040936827659607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.351896286010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04836660623550415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058931320905685425,
      "backward_entropy": 0.005568363600307041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.126786231994629,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04842167720198631,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.058842909336090085,
      "backward_entropy": 0.07682029406229655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.077421188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048473916947841644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05875939726829529,
      "backward_entropy": 0.0055560556550820666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.052717208862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04852360486984253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05868053436279297,
      "backward_entropy": 0.005549961494074928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.909976959228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048573773354291916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058600080013275144,
      "backward_entropy": 0.008927610185411241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.31396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048629723489284515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05850857496261597,
      "backward_entropy": 0.005539837810728285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.048152923583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048686809837818146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058414673805236815,
      "backward_entropy": 0.008886415097448561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.43968963623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04874754697084427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05831376314163208,
      "backward_entropy": 0.0055306582815117305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.01485061645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04881030321121216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0582084596157074,
      "backward_entropy": 0.005526750451988644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.38475799560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048877421766519547,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05809527635574341,
      "backward_entropy": 0.008827782339519925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.94568157196045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04894314333796501,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05798441767692566,
      "backward_entropy": 0.005518962111737993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.857967376708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04900636896491051,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05787776112556457,
      "backward_entropy": 0.0055157749189270865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.788021087646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04906725138425827,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057775461673736574,
      "backward_entropy": 0.008770021299521128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.352582931518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04913131892681122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05766680836677551,
      "backward_entropy": 0.0055093492070833845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.777591705322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919689521193504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05755492448806763,
      "backward_entropy": 0.005506134695476956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.497023582458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04926136136054993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05744445323944092,
      "backward_entropy": 0.008715318308936225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.41080093383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932333901524544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057338714599609375,
      "backward_entropy": 0.005502673486868541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.32546615600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0493830069899559,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0572376012802124,
      "backward_entropy": 0.008679165608353086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.245651245117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04944062605500221,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057140254974365236,
      "backward_entropy": 0.008659116923809052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.114757537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049496304243803024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057046955823898314,
      "backward_entropy": 0.005493986937734816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.167144775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04954896122217178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056959664821624754,
      "backward_entropy": 0.005489776531855266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.01099681854248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496041402220726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05686708688735962,
      "backward_entropy": 0.005485363718536165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.885528564453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04965640604496002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05678013563156128,
      "backward_entropy": 0.005481114404069053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.656063079833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04970990866422653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056690442562103274,
      "backward_entropy": 0.0054766664074526895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.38792419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04976708069443703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056593024730682374,
      "backward_entropy": 0.005471920387612449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.688445091247559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049828752875328064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056486654281616214,
      "backward_entropy": 0.005466272433598836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.061302185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988819360733032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056384491920471194,
      "backward_entropy": 0.00546148709124989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.515396118164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049950599670410156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05627639293670654,
      "backward_entropy": 0.005456051892704434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.843717575073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05001064017415047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05617281198501587,
      "backward_entropy": 0.005451039307647281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.66912269592285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007243901491165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056064969301223753,
      "backward_entropy": 0.0054472266799873775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.23270034790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013570562005043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0559539794921875,
      "backward_entropy": 0.005443312227725983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.301023483276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020159110426903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05583716630935669,
      "backward_entropy": 0.005439877923991945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.425525665283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050268467515707016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055718278884887694,
      "backward_entropy": 0.005436095926496718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.61602020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050335075706243515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05559947490692139,
      "backward_entropy": 0.0054331885443793405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.254508018493652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05040021613240242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05548295974731445,
      "backward_entropy": 0.00543154196606742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.560392379760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05046146363019943,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055374431610107425,
      "backward_entropy": 0.005430700050459968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.259456634521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05052413418889046,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05526251196861267,
      "backward_entropy": 0.0768789913919237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.081159591674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05058563873171806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055153113603591916,
      "backward_entropy": 0.005429346528318193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.0336971282959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05064353346824646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055051207542419434,
      "backward_entropy": 0.005429174337122176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.92634391784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05070070922374725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0549502968788147,
      "backward_entropy": 0.00542944504155053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.169404983520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05075719952583313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05485054850578308,
      "backward_entropy": 0.008145172562864091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.866738319396973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050816796720027924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05474358797073364,
      "backward_entropy": 0.005430486467149522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.203487396240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05087282508611679,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054644805192947385,
      "backward_entropy": 0.00542994671397739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.868450164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05092708766460419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05454931855201721,
      "backward_entropy": 0.005430390851365196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.73906707763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05098211392760277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054451781511306765,
      "backward_entropy": 0.00543069342772166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.605453491210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051037780940532684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054352748394012454,
      "backward_entropy": 0.005430536965529124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.47205924987793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109407380223274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05425206422805786,
      "backward_entropy": 0.005430540690819423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.07723045349121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051150914281606674,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05414979457855225,
      "backward_entropy": 0.008006840944290161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.441633224487305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05120690539479256,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05404952764511108,
      "backward_entropy": 0.005430109798908234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.066511154174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05126463621854782,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0539451003074646,
      "backward_entropy": 0.007963684697945913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.569537162780762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051322754472494125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05383927822113037,
      "backward_entropy": 0.005429332868920432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.797958374023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137866362929344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05373851656913757,
      "backward_entropy": 0.005428581602043576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.53863525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05143504962325096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05363653898239136,
      "backward_entropy": 0.007897886965009902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.227858543395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05149056389927864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05353671312332153,
      "backward_entropy": 0.005426175892353058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.255385398864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051542945206165314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053443944454193114,
      "backward_entropy": 0.005424719717767503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.178780555725098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051593683660030365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05335475206375122,
      "backward_entropy": 0.007823686632845137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.144399642944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05164307355880737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05326812267303467,
      "backward_entropy": 0.00542256236076355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.05138397216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051692210137844086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05318228006362915,
      "backward_entropy": 0.005420843760172526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.951983451843262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05174245312809944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05309346318244934,
      "backward_entropy": 0.0054194484319951795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.728918075561523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051792439073324203,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053005003929138185,
      "backward_entropy": 0.005417910714944203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890032768249512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051845744252204895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05290855765342713,
      "backward_entropy": 0.0054161519640021855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.476764678955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189613997936249,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05281873941421509,
      "backward_entropy": 0.0054148245188925005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.558606147766113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05194854736328125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05272446870803833,
      "backward_entropy": 0.005412960218058692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.465619087219238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05200047418475151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0526308536529541,
      "backward_entropy": 0.005411381522814433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.032760620117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05205177888274193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.052539104223251344,
      "backward_entropy": 0.005408236549960243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.453998565673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05210492014884949,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05244309902191162,
      "backward_entropy": 0.005404311749670241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.946666717529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05215625464916229,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.052351319789886476,
      "backward_entropy": 0.005400489601824019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.823604583740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052208319306373596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0522574245929718,
      "backward_entropy": 0.005396983689732022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.966214179992676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05226099118590355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0521619975566864,
      "backward_entropy": 0.005393405755360921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.575002670288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05231298506259918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05206840038299561,
      "backward_entropy": 0.007466243373023139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.404435634613037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05236553028225899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051973366737365724,
      "backward_entropy": 0.005384913749165005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.331132888793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05241492763161659,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05188664197921753,
      "backward_entropy": 0.005378766192330254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.573553085327148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05246511101722717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05179785490036011,
      "backward_entropy": 0.00537256399790446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.312990188598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052514903247356415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0517097532749176,
      "backward_entropy": 0.005367024491230647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.724266052246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052567776292562485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05161374807357788,
      "backward_entropy": 0.005362612091832691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.268392562866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052624475210905075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05150840878486633,
      "backward_entropy": 0.005357989834414588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.567105770111084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05268013849854469,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05140528678894043,
      "backward_entropy": 0.005354323734839757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.063210487365723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052731361240148544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05131311416625976,
      "backward_entropy": 0.005350820306274626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.45753288269043,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052782151848077774,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05122136473655701,
      "backward_entropy": 0.07690149545669556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.411726951599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052833449095487595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051128560304641725,
      "backward_entropy": 0.005346464200152291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.21533966064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05288310348987579,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05103945732116699,
      "backward_entropy": 0.005345053142971463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.273658752441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0529334731400013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050948357582092284,
      "backward_entropy": 0.007118648125065697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.761730194091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0529821515083313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050861454010009764,
      "backward_entropy": 0.0070932673083411325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.321229934692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05303379148244858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05076700448989868,
      "backward_entropy": 0.005342065460152096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.045385360717773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053090281784534454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050660479068756106,
      "backward_entropy": 0.005340625014570024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.59698486328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314469337463379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0505585253238678,
      "backward_entropy": 0.00534160766336653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.901230812072754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05319933965802193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05045543909072876,
      "backward_entropy": 0.005343668162822723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.091165542602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05325177311897278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050358432531356814,
      "backward_entropy": 0.005344669851991866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.990952491760254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053303275257349014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050264155864715575,
      "backward_entropy": 0.005344375554058287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.686089515686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05335405096411705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0501714825630188,
      "backward_entropy": 0.005344240201844109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2290282249450684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053402919322252274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050084030628204344,
      "backward_entropy": 0.005342802239788903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.544973373413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344805121421814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05000602006912232,
      "backward_entropy": 0.005342138310273488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.389421463012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05349212512373924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04992996156215668,
      "backward_entropy": 0.005343357308043374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.547324180603027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053541503846645355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049840474128723146,
      "backward_entropy": 0.005343550195296605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35180950164795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05359026417136192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049752557277679445,
      "backward_entropy": 0.0053434305720859105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.20060396194458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05363740026950836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049668872356414796,
      "backward_entropy": 0.005343411945634418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.157792568206787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053682100027799606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049590963125228885,
      "backward_entropy": 0.005344626804192861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.250736236572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05372464284300804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04951811134815216,
      "backward_entropy": 0.005347377724117703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.104349136352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05376820266246796,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04944285452365875,
      "backward_entropy": 0.005348722967836592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045366287231445,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053810618817806244,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04937054216861725,
      "backward_entropy": 0.07691233025656806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.91459846496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05385199934244156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049300861358642575,
      "backward_entropy": 0.005350798782375123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.84615707397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053896769881248474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04922198951244354,
      "backward_entropy": 0.005352225982480579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.744935035705566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05394245684146881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049140334129333496,
      "backward_entropy": 0.005354244261980057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.715102195739746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05398882180452347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04905706942081452,
      "backward_entropy": 0.005355379233757655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.834784984588623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05403484031558037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04897443950176239,
      "backward_entropy": 0.00535694882273674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.557378768920898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05407842993736267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04889813661575317,
      "backward_entropy": 0.005359097487396664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.325194358825684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054121699184179306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04882315993309021,
      "backward_entropy": 0.0053591421908802455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.715569019317627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054166004061698914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04874491393566131,
      "backward_entropy": 0.005360383126470778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.768033981323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05420798808336258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048672789335250856,
      "backward_entropy": 0.005361676216125488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.028836250305176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054253000766038895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048592770099639894,
      "backward_entropy": 0.005361896422174241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.697263717651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429865047335625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0485112190246582,
      "backward_entropy": 0.005361293339067035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.817986488342285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054345957934856415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04842515587806702,
      "backward_entropy": 0.005360813604460822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.433422088623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054393548518419266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048338860273361206,
      "backward_entropy": 0.005358644243743684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.883895874023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05444260686635971,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04824848771095276,
      "backward_entropy": 0.005357239809301164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.732974052429199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05449078977108002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048160722851753233,
      "backward_entropy": 0.005355055133501689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.378473281860352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05453513190150261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048083344101905824,
      "backward_entropy": 0.005352639489703708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.923761367797852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05458012595772743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048004114627838136,
      "backward_entropy": 0.005350266893704732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.544679641723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05462663620710373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04792100191116333,
      "backward_entropy": 0.005347064799732632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.063568115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467252433300018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04783953428268432,
      "backward_entropy": 0.005343807240327199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.21259880065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05471886694431305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04775676727294922,
      "backward_entropy": 0.005340689172347386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.725346565246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05476252734661102,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04768145680427551,
      "backward_entropy": 0.005337209751208623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675060749053955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054805077612400055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04760808050632477,
      "backward_entropy": 0.006155499981509315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.099849700927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0548463799059391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04753810167312622,
      "backward_entropy": 0.0053363533483611215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.055340766906738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0548853874206543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04747491478919983,
      "backward_entropy": 0.005334342519442241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.004168510437012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054922617971897125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04741601943969727,
      "backward_entropy": 0.005334136386712392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.931967735290527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05496012419462204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04735608100891113,
      "backward_entropy": 0.00533435410923428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.324753761291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054998014122247696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04729446768760681,
      "backward_entropy": 0.006037413660022948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.242868423461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05503705516457558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047229593992233275,
      "backward_entropy": 0.006016523473792606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.145529747009277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055076926946640015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.047163113951683044,
      "backward_entropy": 0.005337741639879014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4447286128997803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511777475476265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.047093665599823,
      "backward_entropy": 0.005337783445914586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.584569931030273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515562742948532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04703209400177002,
      "backward_entropy": 0.005339138209819794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.153749465942383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05519363284111023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04696994125843048,
      "backward_entropy": 0.005340691241953108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.089399337768555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055230624973773956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04691099226474762,
      "backward_entropy": 0.005340562098556095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.050768852233887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05526718124747276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046851998567581175,
      "backward_entropy": 0.00534431387980779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.364750623703003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055302996188402176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046795031428337096,
      "backward_entropy": 0.005866788741615083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26246452331543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055336207151412964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04674527943134308,
      "backward_entropy": 0.005847766581508849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.781554222106934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536998063325882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046693772077560425,
      "backward_entropy": 0.005354595267110401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.589951992034912,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05540616437792778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046635448932647705,
      "backward_entropy": 0.005357733203305138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075751304626465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05544072762131691,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046581482887268065,
      "backward_entropy": 0.005361442350678974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0154447555542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055475734174251556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04652602672576904,
      "backward_entropy": 0.0053655414117707145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.636996269226074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05551107972860336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04646956622600555,
      "backward_entropy": 0.005369520021809472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0397644005715847,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055549491196870804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04640479981899261,
      "backward_entropy": 0.00537231895658705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4388580322265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05558423697948456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046349677443504336,
      "backward_entropy": 0.0053769490785068935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04711517319083214,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05561727657914162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04629981815814972,
      "backward_entropy": 0.0053797707789474064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551573276519775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05564693361520767,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04625958204269409,
      "backward_entropy": 0.005680917451779048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.968124389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567630007863045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04622072279453278,
      "backward_entropy": 0.0053817447688844465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.888976097106934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570847913622856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04617333114147186,
      "backward_entropy": 0.005382923202382194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544171333312988,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055742986500263214,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.046119609475135805,
      "backward_entropy": 0.07692211204104954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.265687942504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05577780678868294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0460648387670517,
      "backward_entropy": 0.005383085459470749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.233556747436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055810943245887756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04601495862007141,
      "backward_entropy": 0.005382488585180706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1205859184265137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05584265664219856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045968753099441526,
      "backward_entropy": 0.00538233005338245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386231422424316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05587228015065193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04592793583869934,
      "backward_entropy": 0.005384066866503822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262200355529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590357258915901,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04588221907615662,
      "backward_entropy": 0.005385566916730668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211849212646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05593545734882355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04583471417427063,
      "backward_entropy": 0.005487413456042607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.179264068603516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05596768110990524,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04578666687011719,
      "backward_entropy": 0.07692095968458387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079544544219971,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05600123479962349,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04573491811752319,
      "backward_entropy": 0.07692053582933214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.033837795257568,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05603419616818428,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04568471908569336,
      "backward_entropy": 0.07692011859681872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.973657131195068,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056066714227199554,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04563525915145874,
      "backward_entropy": 0.07692000601026747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.794533729553223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05609980598092079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04558345079421997,
      "backward_entropy": 0.005388765285412471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9474427700042725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056137070059776306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04551935493946076,
      "backward_entropy": 0.005393575876951218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9158883094787598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056172508746385574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04546014070510864,
      "backward_entropy": 0.005353417661454942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.663207054138184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056206345558166504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0454051673412323,
      "backward_entropy": 0.005405267907513512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8681039810180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05624130368232727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045347017049789426,
      "backward_entropy": 0.005410889784495036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.82497239112854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056274302303791046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.045295494794845584,
      "backward_entropy": 0.005307935178279877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.451020240783691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056306060403585434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04524654150009155,
      "backward_entropy": 0.005292996764183044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.509666919708252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05633910372853279,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045193901658058165,
      "backward_entropy": 0.005422149267461564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7456490993499756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056372519582509995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0451399028301239,
      "backward_entropy": 0.00542728023396598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8776458501815796,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056404486298561096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04508962631225586,
      "backward_entropy": 0.0054332829184002345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.867905855178833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056434277445077896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04504520297050476,
      "backward_entropy": 0.005440364281336467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121664047241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05646200850605965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04500649571418762,
      "backward_entropy": 0.005447257310152054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4490580558776855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05649139732122421,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044963094592094424,
      "backward_entropy": 0.0054536863333649105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.212732315063477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05652060732245445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04491974413394928,
      "backward_entropy": 0.005200515190760295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.7133207321167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05655026063323021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04487571120262146,
      "backward_entropy": 0.005465556763940387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1050615310668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05658233165740967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044824281334877016,
      "backward_entropy": 0.005471152149968677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.310161590576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05661467835307121,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04477212429046631,
      "backward_entropy": 0.00547613865799374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.728083610534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0566498339176178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04471209645271301,
      "backward_entropy": 0.005479787372880512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.927589416503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05668586865067482,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04464942216873169,
      "backward_entropy": 0.005483741561571757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.994378089904785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05672188475728035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04458635449409485,
      "backward_entropy": 0.00548883361948861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.809152126312256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05676037073135376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04451615810394287,
      "backward_entropy": 0.005493706299198998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7184271812438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05679841712117195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04444754123687744,
      "backward_entropy": 0.005497732096248203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.690273761749268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05683347210288048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04438788592815399,
      "backward_entropy": 0.005500826570722792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277366638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05686834827065468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04432905316352844,
      "backward_entropy": 0.005502550966209835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.200333595275879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05690397322177887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044268164038658145,
      "backward_entropy": 0.0055038473672337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.50344705581665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05694035068154335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044204697012901306,
      "backward_entropy": 0.005505923595693376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6348963975906372,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056976672261953354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044140559434890744,
      "backward_entropy": 0.0055100272099177046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.578940391540527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05701043829321861,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04408293962478638,
      "backward_entropy": 0.005516900370518367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.184523582458496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05704575031995773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044021394848823545,
      "backward_entropy": 0.005521694819132487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.406136512756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05707935243844986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0439642608165741,
      "backward_entropy": 0.005527764558792114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.131140947341919,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0571146197617054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04390237331390381,
      "backward_entropy": 0.005533721711900499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5760349035263062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05714811012148857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04384526014328003,
      "backward_entropy": 0.005540154874324799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.164170265197754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0571790412068367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04379583299160004,
      "backward_entropy": 0.005545483695136176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09398365020752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05721189081668854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04374058842658997,
      "backward_entropy": 0.0055511196454366045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.012222766876221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05724624916911125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04368165135383606,
      "backward_entropy": 0.00555458085404502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.523748755455017,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05728056654334068,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04362232685089111,
      "backward_entropy": 0.07694909307691786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.369420051574707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05731221288442612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04357098639011383,
      "backward_entropy": 0.005562649418910344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9545416831970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734499543905258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043515369296073914,
      "backward_entropy": 0.005568693909380171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.369292736053467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05737603083252907,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04346524477005005,
      "backward_entropy": 0.005573030147287581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633495330810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05740636587142944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04341722428798676,
      "backward_entropy": 0.0055766308473216165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.302350997924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057438287883996964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04336543083190918,
      "backward_entropy": 0.005577348172664642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.285593032836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05746925249695778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04331701993942261,
      "backward_entropy": 0.005575949947039287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0087175369262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05750350281596184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04325906634330749,
      "backward_entropy": 0.0055747007330258684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4176563024520874,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05753813311457634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04320063591003418,
      "backward_entropy": 0.00557141544090377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.51207971572876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05757013335824013,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04314948618412018,
      "backward_entropy": 0.005568968753019969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.452605724334717,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05760189890861511,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04309967458248139,
      "backward_entropy": 0.00556438085105684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7259039878845215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057633645832538605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04304966032505035,
      "backward_entropy": 0.005560456050766839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016656875610352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057663705199956894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04300461411476135,
      "backward_entropy": 0.0046933165027035605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.250536918640137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057695358991622925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04295530021190643,
      "backward_entropy": 0.005551070388820436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.948073387145996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05772938206791878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04289860129356384,
      "backward_entropy": 0.00554794611202346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.078136444091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05776238441467285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04284449815750122,
      "backward_entropy": 0.004632456849018733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5873119831085205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057797327637672424,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042785263061523436,
      "backward_entropy": 0.005542548994223277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5723190307617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057830508798360825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042730480432510376,
      "backward_entropy": 0.005541846570041444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0492143630981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786183848977089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04268141686916351,
      "backward_entropy": 0.005540720290607876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72104263305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0578930638730526,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04263255000114441,
      "backward_entropy": 0.005539512468708886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7183115482330322,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05792642757296562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042577707767486574,
      "backward_entropy": 0.00553793791267607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.689664602279663,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05795884132385254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042525118589401244,
      "backward_entropy": 0.0055380649864673615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260528087615967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0579901821911335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042475977540016176,
      "backward_entropy": 0.005536990033255683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.814054489135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05802281200885773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04242345094680786,
      "backward_entropy": 0.0044860392808914185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.291790962219238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05805489420890808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04237339794635773,
      "backward_entropy": 0.005530532035562728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.205263137817383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05808887258172035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04231812953948975,
      "backward_entropy": 0.005525269442134433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.494844913482666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05812443420290947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0422589898109436,
      "backward_entropy": 0.005518352819813622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4579966068267822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05815873667597771,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04220299124717712,
      "backward_entropy": 0.005513279802269406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4096288681030273,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058191847056150436,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04215021133422851,
      "backward_entropy": 0.0769269863764445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.496387004852295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05822419002652168,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04209821224212647,
      "backward_entropy": 0.005510091781616211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.345841884613037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05825631693005562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04204654097557068,
      "backward_entropy": 0.005512573652797275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.865635871887207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058287546038627625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04199705719947815,
      "backward_entropy": 0.005516669402519862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.589838027954102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058322031050920486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04193863272666931,
      "backward_entropy": 0.005519674056106144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.307013034820557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05835815146565437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041875264048576354,
      "backward_entropy": 0.005523520211378734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1470139026641846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058393459767103195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04181468486785889,
      "backward_entropy": 0.005526495062642627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2458953857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05842671915888786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04176002144813538,
      "backward_entropy": 0.005529905358950297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.156405448913574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05846019834280014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041704732179641726,
      "backward_entropy": 0.0042536382873853045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.160851001739502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05849318578839302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0416508138179779,
      "backward_entropy": 0.005537368771102693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0555872917175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05852776765823364,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041592267155647275,
      "backward_entropy": 0.0055413080586327445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.032254934310913,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05856022611260414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04154030680656433,
      "backward_entropy": 0.005544143418471019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9928929805755615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05859025940299034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04149484634399414,
      "backward_entropy": 0.005548338095347087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9579782485961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058619316667318344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04145231246948242,
      "backward_entropy": 0.005551704102092319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.788710117340088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05864758789539337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04141180515289307,
      "backward_entropy": 0.005555624763170878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.755643844604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058677591383457184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04136703610420227,
      "backward_entropy": 0.005556590027279324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.864104986190796,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05870864540338516,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041319286823272704,
      "backward_entropy": 0.0041365159882439505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9693431258201599,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05873868986964226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04127417504787445,
      "backward_entropy": 0.00555904499358601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.808119058609009,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058766525238752365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04123489856719971,
      "backward_entropy": 0.005562032676405377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.597391128540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05879354476928711,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04119815230369568,
      "backward_entropy": 0.005564402374956343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7451913356781006,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05882130563259125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041158747673034665,
      "backward_entropy": 0.005568067232767741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.412899017333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05884839966893196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041120871901512146,
      "backward_entropy": 0.005572931634055244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.462113857269287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058876458555459976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041081291437149045,
      "backward_entropy": 0.005573584387699763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9074232578277588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05890494957566261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04104052186012268,
      "backward_entropy": 0.005573778516716427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.632415771484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05893147364258766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041004523634910583,
      "backward_entropy": 0.004017884118689431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.32508659362793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05895741656422615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040969756245613095,
      "backward_entropy": 0.004005185431904263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.593966007232666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05898396298289299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04093338251113891,
      "backward_entropy": 0.0055849336915545994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8818303942680359,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05900953710079193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04090071320533752,
      "backward_entropy": 0.005584908856285943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3555588722229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05903315544128418,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04087374210357666,
      "backward_entropy": 0.005584380278984706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.505408763885498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059057220816612244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040844479203224184,
      "backward_entropy": 0.0055872731738620335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2961816787719727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05908090993762016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040815746784210204,
      "backward_entropy": 0.005591562224758996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2686002254486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05910491570830345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04078553318977356,
      "backward_entropy": 0.00559729751613405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2487757205963135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05912908539175987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040754735469818115,
      "backward_entropy": 0.005602953748570548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.792791366577148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059153083711862564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04072548151016235,
      "backward_entropy": 0.0038936411341031394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6028399467468262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05917837843298912,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040692591667175294,
      "backward_entropy": 0.005604964577489429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.814030110836029,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05920248478651047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04066276550292969,
      "backward_entropy": 0.07693486743503147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.878631591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05922481417655945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040637871623039244,
      "backward_entropy": 0.005608402192592621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608414649963379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059248071163892746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040609884262084964,
      "backward_entropy": 0.005610927939414978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.799299478530884,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05927259102463722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040578645467758176,
      "backward_entropy": 0.005611831943194072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5208128690719604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059297848492860794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0405447781085968,
      "backward_entropy": 0.005614313814375136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.983633279800415,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05932199954986572,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04051336944103241,
      "backward_entropy": 0.005619139307075077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.95281982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059346262365579605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0404813289642334,
      "backward_entropy": 0.005624683366881477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.369887828826904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05937061086297035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04044877588748932,
      "backward_entropy": 0.005630779597494338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8991243839263916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059396129101514816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0404128909111023,
      "backward_entropy": 0.005636129114362929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.982810020446777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05942133069038391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040378719568252563,
      "backward_entropy": 0.005638620919651455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03158578649163246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05944810062646866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04034023880958557,
      "backward_entropy": 0.00563976913690567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4171439409255981,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059472329914569855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04030846953392029,
      "backward_entropy": 0.005642618156141705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3989930152893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05949530005455017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04028036594390869,
      "backward_entropy": 0.005644860366980235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3888109922409058,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059517234563827515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040254834294319156,
      "backward_entropy": 0.005647928764422734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.722385883331299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05953812971711159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040232330560684204,
      "backward_entropy": 0.005650401529338624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3507858514785767,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05956108123064041,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04020362496376038,
      "backward_entropy": 0.005653410322136349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6871755719184875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05958317965269089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04017624855041504,
      "backward_entropy": 0.005660020642810398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9319193363189697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059603750705718994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04015294313430786,
      "backward_entropy": 0.005667217903667026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5980844497680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05962580069899559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04012516438961029,
      "backward_entropy": 0.005674795144134098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210869073867798,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05964821204543114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040095359086990356,
      "backward_entropy": 0.005685202363464568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.180283546447754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05967143177986145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04006267786026001,
      "backward_entropy": 0.005697129915157954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023307841271162033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05969525873661041,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040028083324432376,
      "backward_entropy": 0.005708956884013282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8802807331085205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05971694365143776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039998799562454224,
      "backward_entropy": 0.005722761568095949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4672658443450928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05973821505904198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0399706244468689,
      "backward_entropy": 0.00573601159784529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8367934226989746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05975978448987007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03994099497795105,
      "backward_entropy": 0.005750301397509045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8227943181991577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059781063348054886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03991157114505768,
      "backward_entropy": 0.005765715820921792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6244804859161377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059801965951919556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03988301753997803,
      "backward_entropy": 0.005780617396036784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.964778184890747,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05982130020856857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03985916376113892,
      "backward_entropy": 0.005793403420183394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1886085271835327,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05984148383140564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03983283042907715,
      "backward_entropy": 0.0058050089412265355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6052868962287903,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059860821813344955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03980865478515625,
      "backward_entropy": 0.005816409985224406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7466187477111816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987876281142235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03978847861289978,
      "backward_entropy": 0.005826426462994682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7290406227111816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05989643931388855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03976944088935852,
      "backward_entropy": 0.00583372058139907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7139796018600464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05991391837596893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039751055836677554,
      "backward_entropy": 0.005839366051885817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6941962242126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05993121117353439,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039733397960662845,
      "backward_entropy": 0.005843434068891738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.43408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059948429465293884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03971557021141052,
      "backward_entropy": 0.005847352660364575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.763003349304199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059968311339616776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03968961238861084,
      "backward_entropy": 0.005851847430070241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1109986305236816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059988733381032944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03966269493103027,
      "backward_entropy": 0.005853542437156041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.158698320388794,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06000808626413345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03963906168937683,
      "backward_entropy": 0.005853527949915992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.687307357788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06002773344516754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039613887667655945,
      "backward_entropy": 0.005854794134696324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6031193733215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06004772335290909,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039589107036590576,
      "backward_entropy": 0.005850840359926224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0350397564470768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06006713584065437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03956640362739563,
      "backward_entropy": 0.005844966404967838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0548202991485596,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060084421187639236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03955027163028717,
      "backward_entropy": 0.005836960756116443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0510575771331787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060100946575403214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03953628838062286,
      "backward_entropy": 0.005828691025575002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0357110500335693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06011665612459183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03952516913414002,
      "backward_entropy": 0.005818301604853736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5268676280975342,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0601329579949379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03951167464256287,
      "backward_entropy": 0.005810252080361049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5005509853363037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060149069875478745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039498886466026305,
      "backward_entropy": 0.005801578362782796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.472468376159668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060166049748659134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03948374390602112,
      "backward_entropy": 0.005792684853076935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9903454184532166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06018390133976936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039465850591659545,
      "backward_entropy": 0.0057848551207118565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4654868841171265,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06020110845565796,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039449137449264524,
      "backward_entropy": 0.005779467523097992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.875819206237793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06021809205412865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03943305611610413,
      "backward_entropy": 0.005774196237325668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9680378437042236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0602363757789135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03941332697868347,
      "backward_entropy": 0.005769021809101105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4938304126262665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06025375798344612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03939640522003174,
      "backward_entropy": 0.00576311598221461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.248870849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060269806534051895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039383530616760254,
      "backward_entropy": 0.005756318155262206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48597800731658936,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060287751257419586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03936507403850555,
      "backward_entropy": 0.005750346514913771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2789487838745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06030423566699028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03935129642486572,
      "backward_entropy": 0.005742633508311378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9166859984397888,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060321610420942307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03933470845222473,
      "backward_entropy": 0.005736758725510703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6715643405914307,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060338281095027924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039319825172424314,
      "backward_entropy": 0.005731989940007527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.211181879043579,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06035641208291054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03930005729198456,
      "backward_entropy": 0.005730528798368242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.316933512687683,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06037512794137001,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03927879333496094,
      "backward_entropy": 0.005728622277577718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8784883618354797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060393597930669785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03925769925117493,
      "backward_entropy": 0.005729311870204078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7134019136428833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06041121482849121,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03923904299736023,
      "backward_entropy": 0.005730217529667748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8586885929107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06042906269431114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03921944499015808,
      "backward_entropy": 0.005731888115406036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4337068796157837,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06044615060091019,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03920189142227173,
      "backward_entropy": 0.005734183308151033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4752607345581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06046218052506447,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03918676376342774,
      "backward_entropy": 0.005738638755347993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.234385371208191,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06047973036766052,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03916653394699097,
      "backward_entropy": 0.07692649629380968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2260981798171997,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06049714982509613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039146074652671815,
      "backward_entropy": 0.005756446884738075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0058846473693848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06051423400640488,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03912680447101593,
      "backward_entropy": 0.005765163236194187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8072130084037781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06053198501467705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039105623960494995,
      "backward_entropy": 0.005773412270678414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9640361070632935,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06054890155792236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03908694982528686,
      "backward_entropy": 0.00578079910741912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5558421611785889,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06056642904877663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03906663060188294,
      "backward_entropy": 0.005787108921342426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1571894884109497,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06058413162827492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03904560208320618,
      "backward_entropy": 0.0057938434183597565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7694661617279053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06060158088803291,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03902483582496643,
      "backward_entropy": 0.005801789048645232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7612607479095459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060618311166763306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03900576829910278,
      "backward_entropy": 0.0058104002641306985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7611398100852966,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06063438579440117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03898826837539673,
      "backward_entropy": 0.005819502804014418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7459509372711182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060649577528238297,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03897397518157959,
      "backward_entropy": 0.005824817965428035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1031049489974976,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06066424772143364,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038960784673690796,
      "backward_entropy": 0.005830956415997611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0881892442703247,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06067875772714615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03894821107387543,
      "backward_entropy": 0.005835680084096061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7904735803604126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060693271458148956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038935142755508426,
      "backward_entropy": 0.0058414555258221095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4194811582565308,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060708481818437576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03892036080360413,
      "backward_entropy": 0.0030977043012777963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0598219633102417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060723960399627686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038904708623886106,
      "backward_entropy": 0.005848997582991918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6980959177017212,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060739170759916306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03888996243476868,
      "backward_entropy": 0.005851433508925968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3781794309616089,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06075398251414299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038875311613082886,
      "backward_entropy": 0.005857152243455251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3618847131729126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06076899915933609,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038860267400741576,
      "backward_entropy": 0.005861071248849233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35413020849227905,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060784269124269485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03884447813034057,
      "backward_entropy": 0.005864621864424812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.003555417060852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060798317193984985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03883253335952759,
      "backward_entropy": 0.0058656906088193255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6682964563369751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060812320560216904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0388203501701355,
      "backward_entropy": 0.0058674294915464185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3043879270553589,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060825832188129425,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.038809317350387576,
      "backward_entropy": 0.0030379148407114875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.297234058380127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06083986908197403,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038796079158782956,
      "backward_entropy": 0.005873545590374205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3299015462398529,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060854148119688034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038782316446304324,
      "backward_entropy": 0.005876231524679396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.583517074584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060867562890052795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038770478963851926,
      "backward_entropy": 0.005880575627088547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6348008513450623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06088174507021904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03875646591186523,
      "backward_entropy": 0.005884280635250939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9387718439102173,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06089543178677559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03874353766441345,
      "backward_entropy": 0.005888695518175761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6231839656829834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0609089620411396,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03873116374015808,
      "backward_entropy": 0.005891709278027217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2211464643478394,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06092201545834541,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038719969987869265,
      "backward_entropy": 0.005895007815625932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.506640911102295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060935404151678085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03870785534381867,
      "backward_entropy": 0.005897498793072171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1944369077682495,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06094951927661896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03869366645812988,
      "backward_entropy": 0.005899459951453739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.182358980178833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06096391752362251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03867843747138977,
      "backward_entropy": 0.005901760939094756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4538410902023315,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06097853183746338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03866251111030579,
      "backward_entropy": 0.005903923677073585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4385989904403687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060993898659944534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.038643771409988405,
      "backward_entropy": 0.002959294037686454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.420189380645752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061009861528873444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038622918725013736,
      "backward_entropy": 0.005913456281026204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014250138774514198,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06102638319134712,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03860006332397461,
      "backward_entropy": 0.002951158417595757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.566635251045227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06104128062725067,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03858181834220886,
      "backward_entropy": 0.005925759673118591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1031672954559326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06105541065335274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03856605291366577,
      "backward_entropy": 0.00592963480287128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5496262311935425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06106967851519585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03855002522468567,
      "backward_entropy": 0.00593230128288269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0808361768722534,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06108340620994568,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03853509426116943,
      "backward_entropy": 0.005935906122128169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5385699272155762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06109723076224327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038520348072052,
      "backward_entropy": 0.005937265025244819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27408188581466675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061110515147447586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03850682377815247,
      "backward_entropy": 0.0029163074990113578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7845157384872437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06112286448478699,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0384958803653717,
      "backward_entropy": 0.0029094194372495017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0311188697814941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061135221272706985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03848452568054199,
      "backward_entropy": 0.005943032602469127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2649107277393341,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06114799156785011,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03847160339355469,
      "backward_entropy": 0.005946527752611373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.761949360370636,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061159905046224594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03846096396446228,
      "backward_entropy": 0.005949986891614066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7561864852905273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061171822249889374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03845011591911316,
      "backward_entropy": 0.00595357682969835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.484885811805725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061183664947748184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038439595699310304,
      "backward_entropy": 0.005956188258197572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4954252541065216,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06119653955101967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038426434993743895,
      "backward_entropy": 0.005957244584957759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25087350606918335,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061208974570035934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03841410577297211,
      "backward_entropy": 0.005959382487667931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7248489260673523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06122060865163803,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038403719663619995,
      "backward_entropy": 0.005962173557943768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48458626866340637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06123221293091774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03839336931705475,
      "backward_entropy": 0.005964640114042494,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.3714469971694052,
    "avg_log_Z": -0.060489238910377024,
    "success_rate": 1.0,
    "avg_reward": 84.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.01,
      "1": 0.06,
      "2": 0.93
    },
    "avg_forward_entropy": 0.03915838742256164,
    "avg_backward_entropy": 0.006366997466733059,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}