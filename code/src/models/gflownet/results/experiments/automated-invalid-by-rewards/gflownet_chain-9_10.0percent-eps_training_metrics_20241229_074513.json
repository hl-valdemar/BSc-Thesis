{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.0764417913224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07657550440894233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.98731231689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097861647605896,
      "backward_entropy": 0.07656270927853054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.40325164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978251695632935,
      "backward_entropy": 0.07656531863742405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.94210815429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0001998849620576948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109778892993927,
      "backward_entropy": 0.07658135890960693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.17357635498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029987486777827144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977520942687988,
      "backward_entropy": 0.076570729414622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.02108764648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00038532662438228726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977150201797485,
      "backward_entropy": 0.07658625311321682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.14099884033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004754986730404198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109767484664917,
      "backward_entropy": 0.07657440503438313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.05091094970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005559362471103668,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976345539093017,
      "backward_entropy": 0.07648553450902303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.70858764648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006375836674124002,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097594141960144,
      "backward_entropy": 0.07659167713589138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.2486572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007234339136630297,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975527763366699,
      "backward_entropy": 0.07657877604166667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.664794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008126153843477368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975096225738526,
      "backward_entropy": 0.07659560441970825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.60268783569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009041035664267838,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974652767181396,
      "backward_entropy": 0.07659782303704156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.607177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009727220749482512,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974212884902954,
      "backward_entropy": 0.07659901512993707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.94790649414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010369340889155865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097376823425293,
      "backward_entropy": 0.0765999886724684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011102950666099787,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973296165466309,
      "backward_entropy": 0.07660145229763454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.11939239501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011886018328368664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972801446914673,
      "backward_entropy": 0.07658652464548747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.88327026367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012704191030934453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972288846969605,
      "backward_entropy": 0.0766049755944146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.18553161621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001351934508420527,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097176194190979,
      "backward_entropy": 0.07654787434471978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.40778350830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014403765089809895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971206426620483,
      "backward_entropy": 0.07659158441755506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.0311279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015276490012183785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097063660621643,
      "backward_entropy": 0.07659349838892619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.89875030517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016166650457307696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970051288604736,
      "backward_entropy": 0.07659547196494208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.66203308105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017099729739129543,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10969440937042237,
      "backward_entropy": 0.07661584350797865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.57246398925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018004297744482756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096882700920105,
      "backward_entropy": 0.07661810186174181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.63031768798828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018853386864066124,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968205928802491,
      "backward_entropy": 0.07658643192715114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.60824584960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001973016420379281,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967559814453125,
      "backward_entropy": 0.0766220490137736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.14899444580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00206308183260262,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096688985824585,
      "backward_entropy": 0.07659861776563856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.0028305053711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021554629784077406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966194868087768,
      "backward_entropy": 0.07660477691226536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.847900390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022447314113378525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965502262115479,
      "backward_entropy": 0.07660921414693196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6017837524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002338946331292391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964775085449219,
      "backward_entropy": 0.0766113731596205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.36019897460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024279681965708733,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964041948318481,
      "backward_entropy": 0.07662264506022136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.94261169433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002522156573832035,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963273048400879,
      "backward_entropy": 0.07662864526112874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.03230285644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002622209256514907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962476730346679,
      "backward_entropy": 0.07663749323950873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.5948715209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027186772786080837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961681604385376,
      "backward_entropy": 0.07662037346098158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.99396514892578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028183721005916595,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960861444473266,
      "backward_entropy": 0.07664706971910265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.97488403320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0029144620057195425,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960041284561158,
      "backward_entropy": 0.07665292421976726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.95588684082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030073216184973717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959219932556152,
      "backward_entropy": 0.0766269498401218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.4998779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003097289940342307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958395004272461,
      "backward_entropy": 0.07662865850660536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.48108673095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003185004461556673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957562923431396,
      "backward_entropy": 0.0766301949818929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.15403747558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032707126811146736,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956722497940063,
      "backward_entropy": 0.07665163940853542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.41914367675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033638624008744955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955846309661865,
      "backward_entropy": 0.07665346728430854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.23765563964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0034608091227710247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954958200454712,
      "backward_entropy": 0.07663534747229682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.50521850585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035651528742164373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954041481018066,
      "backward_entropy": 0.07663780450820923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.65373992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003673628205433488,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10953140258789062,
      "backward_entropy": 0.07666046089596218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.11425018310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037828381173312664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952227115631104,
      "backward_entropy": 0.07664337423112658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.85541534423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038861630018800497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951330661773681,
      "backward_entropy": 0.07666542132695515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.32697296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003991769626736641,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10950404405593872,
      "backward_entropy": 0.07664814260270861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.43098449707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004095312207937241,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949478149414063,
      "backward_entropy": 0.07665036784278022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.97205352783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004197565373033285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948543548583985,
      "backward_entropy": 0.07665247387356228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3542938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004298944491893053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947593450546264,
      "backward_entropy": 0.07667420970069037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.96786499023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004409315530210733,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946581363677979,
      "backward_entropy": 0.07673508591122097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.59379577636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004523298237472773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094552993774414,
      "backward_entropy": 0.0766598383585612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.01455688476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004635495133697987,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094446063041687,
      "backward_entropy": 0.07668183247248332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.40000915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004752808716148138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943348407745361,
      "backward_entropy": 0.07666550742255317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.55511474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004860383924096823,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942264795303344,
      "backward_entropy": 0.07675683498382568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.24063110351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004966915585100651,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941191911697387,
      "backward_entropy": 0.07667006386650933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4482421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00506405858322978,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940150022506714,
      "backward_entropy": 0.07676635185877483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.6402587890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005168485920876265,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093904972076416,
      "backward_entropy": 0.07677112685309516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.40420532226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00527052441611886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937947034835815,
      "backward_entropy": 0.07667547464370728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.51156616210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005367114208638668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936858654022216,
      "backward_entropy": 0.07669619719187419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.32069396972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005459364503622055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935775041580201,
      "backward_entropy": 0.07669752836227417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.549560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005559559911489487,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934624671936036,
      "backward_entropy": 0.07669919066958958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.05538940429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005657717119902372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933473110198974,
      "backward_entropy": 0.0767007138994005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.50342559814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005760402884334326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932272672653198,
      "backward_entropy": 0.07668289873335096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.55995178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005860744509845972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10931072235107422,
      "backward_entropy": 0.07668438222673205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.084228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005965535528957844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929820537567139,
      "backward_entropy": 0.0766860908932156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.9362030029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0060704899951815605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10928540229797364,
      "backward_entropy": 0.0768088764614529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.798458099365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006179050542414188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927183628082275,
      "backward_entropy": 0.07668961418999566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.64053344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00627110106870532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925891399383544,
      "backward_entropy": 0.0766907533009847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.97626495361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006358145736157894,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10924608707427978,
      "backward_entropy": 0.07681990994347467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.51289367675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006447157822549343,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923287868499756,
      "backward_entropy": 0.07669252819485134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.83399200439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006538183428347111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10921930074691773,
      "backward_entropy": 0.07671247588263617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.16226196289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006625432055443525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10920565128326416,
      "backward_entropy": 0.07682976457807753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.9574966430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006711212918162346,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10919194221496582,
      "backward_entropy": 0.07671366797553168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.11363983154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006797061301767826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917791128158569,
      "backward_entropy": 0.07669569386376275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.08911895751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006881607696413994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916380882263184,
      "backward_entropy": 0.07671458191341823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.93812561035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0069649978540837765,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914926528930664,
      "backward_entropy": 0.07684173848893908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.44648742675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00705393822863698,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109134042263031,
      "backward_entropy": 0.07671642965740627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.73233032226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007145521696656942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091183066368103,
      "backward_entropy": 0.0766985019048055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.66255187988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007247275207191706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10910153388977051,
      "backward_entropy": 0.07669999202092488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.38018798828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0073441145941615105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908480882644653,
      "backward_entropy": 0.07685461309221056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.33319091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007447273004800081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906738042831421,
      "backward_entropy": 0.07670275370279948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.6007080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0075536565855145454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10904941558837891,
      "backward_entropy": 0.07670429017808703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.31122589111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007659764960408211,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10903122425079345,
      "backward_entropy": 0.07672603262795342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.91957092285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007756547536700964,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10901349782943726,
      "backward_entropy": 0.07686781220965916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.81343078613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007857954129576683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899505615234376,
      "backward_entropy": 0.0767079922888014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.37841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007958805188536644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10897648334503174,
      "backward_entropy": 0.07673033078511556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.42543029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008070269599556923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10895675420761108,
      "backward_entropy": 0.07671062151590984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.2787857055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008183029480278492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10893666744232178,
      "backward_entropy": 0.07671214474572076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.72859954833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008294090628623962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10891649723052979,
      "backward_entropy": 0.07673602634006077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.26799774169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008398286998271942,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10889663696289062,
      "backward_entropy": 0.07673750983344184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.83997344970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008496559225022793,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10887699127197266,
      "backward_entropy": 0.07671527067820232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.86221313476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008587042801082134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885766744613648,
      "backward_entropy": 0.07671568128797743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.59048461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008686411194503307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10883731842041015,
      "backward_entropy": 0.07674036423365276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.3402099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008782634511590004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10881701707839966,
      "backward_entropy": 0.07671690649456447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.79102325439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00887984037399292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10879629850387573,
      "backward_entropy": 0.07671743631362915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.3269271850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00897517055273056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10877541303634644,
      "backward_entropy": 0.07674275504218207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.85446166992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00906908418983221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1087543249130249,
      "backward_entropy": 0.0769035749965244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.14915466308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009162718430161476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10873314142227172,
      "backward_entropy": 0.07690572076373631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.98193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009260069578886032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10871130228042603,
      "backward_entropy": 0.07671886682510376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0666961669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00935474131256342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10868945121765136,
      "backward_entropy": 0.07671907212999132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.38387298583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009458012878894806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10866644382476806,
      "backward_entropy": 0.07674589422014025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.0746841430664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009556959383189678,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10864338874816895,
      "backward_entropy": 0.0769144164191352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.52386474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009656542912125587,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10861985683441162,
      "backward_entropy": 0.07674698034922282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.87417602539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0097593292593956,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1085956335067749,
      "backward_entropy": 0.07691866159439087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.84227752685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009852989576756954,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10857205390930176,
      "backward_entropy": 0.07692052920659383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.56116485595703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009947314858436584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10854809284210205,
      "backward_entropy": 0.07692236370510525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.67601013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010037384927272797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10852420330047607,
      "backward_entropy": 0.07674796051449245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.53456115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010130973532795906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10849964618682861,
      "backward_entropy": 0.07674801349639893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.94104766845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010230043902993202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10847421884536743,
      "backward_entropy": 0.07674827840593126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.97444152832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010327200405299664,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10844860076904297,
      "backward_entropy": 0.07674835787879096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.1843490600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010423866100609303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10842278003692626,
      "backward_entropy": 0.07674841086069743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.40341186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010518085211515427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1083967924118042,
      "backward_entropy": 0.07674829827414618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.68761444091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010608043521642685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10837090015411377,
      "backward_entropy": 0.07674793402353923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.78556823730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010696514509618282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10834511518478393,
      "backward_entropy": 0.07671896616617839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.75763702392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010777776129543781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10831972360610961,
      "backward_entropy": 0.07674658298492432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.33039855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010858986526727676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10829387903213501,
      "backward_entropy": 0.07674557632870144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.6971206665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010941682383418083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10826752185821534,
      "backward_entropy": 0.07671620448430379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.55244445800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011024200357496738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10824069976806641,
      "backward_entropy": 0.07671520445081922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.79016876220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011102816089987755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10821399688720704,
      "backward_entropy": 0.0767139924897088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.24530029296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011183494701981544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10818667411804199,
      "backward_entropy": 0.07674017879698011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.52798461914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01127511728554964,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10815753936767578,
      "backward_entropy": 0.07694325844446818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.44197845458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011372764594852924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10812703371047974,
      "backward_entropy": 0.07671123743057251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.45211791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011464978568255901,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10809619426727295,
      "backward_entropy": 0.0767102837562561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.94921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011549042537808418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10806593894958497,
      "backward_entropy": 0.07673521836598714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.35585021972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011639051139354706,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10803433656692504,
      "backward_entropy": 0.07694741090138753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.19093322753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011724371463060379,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10800290107727051,
      "backward_entropy": 0.0767319467332628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.68714904785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011820870451629162,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10796928405761719,
      "backward_entropy": 0.0769493513637119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.64122009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01192132942378521,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793466567993164,
      "backward_entropy": 0.07670480675167507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.12843322753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012025292031466961,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10789910554885865,
      "backward_entropy": 0.07695162296295166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.80519104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012139436788856983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10786151885986328,
      "backward_entropy": 0.07670374049080743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.44690704345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012256368063390255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10782287120819092,
      "backward_entropy": 0.07695429854922825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.58169555664062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012371518649160862,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077839970588684,
      "backward_entropy": 0.07695557011498345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.5512237548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01249296497553587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10774358510971069,
      "backward_entropy": 0.07670295238494873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.71565246582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012626265175640583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1077006697654724,
      "backward_entropy": 0.07670325040817261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.92845153808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012752288021147251,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1076585054397583,
      "backward_entropy": 0.076723317305247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.80339050292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012880205176770687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10761545896530152,
      "backward_entropy": 0.07670289940304226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6469955444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012997242622077465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10757369995117187,
      "backward_entropy": 0.07670224375194973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.19264221191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013103930279612541,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10753324031829833,
      "backward_entropy": 0.07672048939598931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.95446014404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013214346952736378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10749157667160034,
      "backward_entropy": 0.07671912511189778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3401641845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01332282368093729,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10744973421096801,
      "backward_entropy": 0.0769656432999505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.6939468383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013432573527097702,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740705728530883,
      "backward_entropy": 0.07669728994369507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.36688232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013538328930735588,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10736457109451295,
      "backward_entropy": 0.07671317789289686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.08015441894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013653633184731007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1073196291923523,
      "backward_entropy": 0.07669444878896077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.28742218017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013765671290457249,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10727487802505493,
      "backward_entropy": 0.07670833004845513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.93070983886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013875745236873627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10722994804382324,
      "backward_entropy": 0.07670546902550592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.29103088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013984779827296734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10718457698822022,
      "backward_entropy": 0.07670231660207112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.93146514892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014097334817051888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10713783502578736,
      "backward_entropy": 0.07668532265557183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.60574340820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0142018748447299,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10709233283996582,
      "backward_entropy": 0.07669552167256673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014308653771877289,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10704616308212281,
      "backward_entropy": 0.07697333229912652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.32140350341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014417649246752262,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10699867010116577,
      "backward_entropy": 0.07697404093212551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.5167007446289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014522610232234001,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10695147514343262,
      "backward_entropy": 0.0769746568467882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.44387817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014626516960561275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10690398216247558,
      "backward_entropy": 0.07667079236772326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.1239776611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014724010601639748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1068575382232666,
      "backward_entropy": 0.07666733529832628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.59214782714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014827152714133263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10680879354476928,
      "backward_entropy": 0.07667088508605957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.01311492919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014931912533938885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10675908327102661,
      "backward_entropy": 0.07666638162400988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.29974365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015036332421004772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10670859813690185,
      "backward_entropy": 0.07666157351599799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.38941192626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015134269371628761,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10665918588638305,
      "backward_entropy": 0.07665356662538317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.11056518554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0152268772944808,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10661039352416993,
      "backward_entropy": 0.0769779019885593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.06903839111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015317583456635475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10656129121780396,
      "backward_entropy": 0.07664500342475043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7772216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015406587161123753,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10651184320449829,
      "backward_entropy": 0.07697830597559611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.34927368164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015493049286305904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10646260976791382,
      "backward_entropy": 0.07663586404588488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.25724792480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01557960920035839,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1064133882522583,
      "backward_entropy": 0.07662611537509495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.12109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01566413976252079,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10636422634124756,
      "backward_entropy": 0.07661954561869304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.86216735839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015758000314235687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10631178617477417,
      "backward_entropy": 0.0766130354669359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0914306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01585567370057106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10625743865966797,
      "backward_entropy": 0.0766149295700921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.08940505981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015953991562128067,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10620207786560058,
      "backward_entropy": 0.07660984992980957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.90432739257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016040731221437454,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10614942312240601,
      "backward_entropy": 0.07697918679979113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.33078002929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0161227248609066,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10609750747680664,
      "backward_entropy": 0.0769790874587165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.26970672607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016212517395615578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10604262351989746,
      "backward_entropy": 0.07659190230899388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.16171264648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01629699394106865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10598877668380738,
      "backward_entropy": 0.07658550474378797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.43743896484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01638062484562397,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1059343695640564,
      "backward_entropy": 0.07657897472381592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.02650451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01647505722939968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10587630271911622,
      "backward_entropy": 0.07657268312242296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.0185317993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016581473872065544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10581414699554444,
      "backward_entropy": 0.07656676901711358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.0781478881836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016678249463438988,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10575423240661622,
      "backward_entropy": 0.07697917355431451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.8084716796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01676897332072258,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10569550991058349,
      "backward_entropy": 0.07652732398774889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.04258728027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01685761846601963,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10563663244247437,
      "backward_entropy": 0.07651837666829427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.85186767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01694997027516365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10557578802108765,
      "backward_entropy": 0.07653823163774279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.35678100585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01705922745168209,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10550906658172607,
      "backward_entropy": 0.07697898811764187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.9973373413086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017160898074507713,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10544413328170776,
      "backward_entropy": 0.07697900136311848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.68513488769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017256485298275948,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1053803563117981,
      "backward_entropy": 0.07651709185706244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.60646057128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017338141798973083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10532052516937256,
      "backward_entropy": 0.0765086743566725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.3881607055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017423545941710472,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10525866746902465,
      "backward_entropy": 0.07650028334723578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.27542877197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017509324476122856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10519598722457886,
      "backward_entropy": 0.07645146052042644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.15876007080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01759033277630806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10513418912887573,
      "backward_entropy": 0.07644014888339573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.78547668457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017671680077910423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10507161617279052,
      "backward_entropy": 0.07647313674290974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.41168975830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01775408536195755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10500904321670532,
      "backward_entropy": 0.07641691631740993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.3124008178711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017838193103671074,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10494518280029297,
      "backward_entropy": 0.07697627279493544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.9264678955078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017919020727276802,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10488193035125733,
      "backward_entropy": 0.07697579595777723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.1360092163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018005233258008957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048161506652832,
      "backward_entropy": 0.07643405596415202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.5048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01808973215520382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10475013256072999,
      "backward_entropy": 0.07636778222190009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.94348907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01817498728632927,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10468305349349975,
      "backward_entropy": 0.07635487450493707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.99884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01825553923845291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10461694002151489,
      "backward_entropy": 0.07634131775961982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.94379806518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01834297925233841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10454747676849366,
      "backward_entropy": 0.07639169030719334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.46324157714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018420230597257614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10448110103607178,
      "backward_entropy": 0.07638023959265815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.26985168457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018502477556467056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10441197156906128,
      "backward_entropy": 0.07636908027860853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.77638244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01857743225991726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10434496402740479,
      "backward_entropy": 0.07635713948143853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.7308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01866348460316658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10427306890487671,
      "backward_entropy": 0.07626876566145155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.23786163330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018747813999652863,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10420099496841431,
      "backward_entropy": 0.07625353336334229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.62519073486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018830852583050728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10412861108779907,
      "backward_entropy": 0.07623774475521511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.6690902709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018912484869360924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1040561318397522,
      "backward_entropy": 0.07622134023242527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.76622009277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018990280106663704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10398437976837158,
      "backward_entropy": 0.07696877585517035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.22726440429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01907498948276043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10390907526016235,
      "backward_entropy": 0.07627489831712511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.04795837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019157104194164276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10383408069610596,
      "backward_entropy": 0.07696757051679823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.7947769165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019248316064476967,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10375463962554932,
      "backward_entropy": 0.07615212599436443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.5630645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019337033852934837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10367538928985595,
      "backward_entropy": 0.07622676425509983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.26832580566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019431935623288155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10359280109405518,
      "backward_entropy": 0.07611637645297581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019528452306985855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10350874662399293,
      "backward_entropy": 0.07609834273656209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.0194091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019629325717687607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10342202186584473,
      "backward_entropy": 0.07608038187026978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.706298828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01973690278828144,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10333161354064942,
      "backward_entropy": 0.07696587509579128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.68842315673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019845450296998024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10323997735977172,
      "backward_entropy": 0.07614427142673069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.55985260009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019951937720179558,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10314840078353882,
      "backward_entropy": 0.0761270523071289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.4937286376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020051829516887665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10305886268615723,
      "backward_entropy": 0.07610886626773411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.90933227539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02015799656510353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10296567678451538,
      "backward_entropy": 0.07609070671929254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.41441345214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02026207186281681,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10287258625030518,
      "backward_entropy": 0.07596646414862739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.08401489257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020375587046146393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10277436971664429,
      "backward_entropy": 0.0759468608432346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.67737579345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02049216255545616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10267384052276611,
      "backward_entropy": 0.07603451940748426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.6940155029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02060551755130291,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10257391929626465,
      "backward_entropy": 0.07601461145612928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.78239440917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020719820633530617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10247262716293334,
      "backward_entropy": 0.07599457105000813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.66175079345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02082867920398712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10237303972244263,
      "backward_entropy": 0.07597258355882433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.752685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020930912345647812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1022757649421692,
      "backward_entropy": 0.07594867547353108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.95840454101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021034516394138336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10217686891555786,
      "backward_entropy": 0.07592394616868761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.43750762939453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0211369376629591,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1020776629447937,
      "backward_entropy": 0.0769604245821635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.09963989257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0212385430932045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10197793245315552,
      "backward_entropy": 0.07695936494403416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.18460083007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021348776295781136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10187301635742188,
      "backward_entropy": 0.07574080096350776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.97174835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02146388776600361,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.101764714717865,
      "backward_entropy": 0.07571650875939263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.1090316772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02156847156584263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10166101455688477,
      "backward_entropy": 0.07569013701544867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.07167053222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021671943366527557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10155694484710694,
      "backward_entropy": 0.07576145066155328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.52970886230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021768782287836075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10145549774169922,
      "backward_entropy": 0.0756342609723409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.1541633605957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021861612796783447,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10135531425476074,
      "backward_entropy": 0.07560408115386963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.34225463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02194356545805931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10126030445098877,
      "backward_entropy": 0.07566301027933757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.5976791381836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0220307856798172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10116150379180908,
      "backward_entropy": 0.07694967587788899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.0749740600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022118158638477325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10106171369552612,
      "backward_entropy": 0.0755918820699056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.32347869873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02220592275261879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10096080303192138,
      "backward_entropy": 0.07555533779991998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.81219482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02229328639805317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10085926055908204,
      "backward_entropy": 0.07543816831376818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.15519714355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022382717579603195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10075570344924926,
      "backward_entropy": 0.07540333933300442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.402099609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022467168048024178,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1006543517112732,
      "backward_entropy": 0.07694039079878065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.125244140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022557366639375687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10054889917373658,
      "backward_entropy": 0.07533040311601427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.54685974121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02264523319900036,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10044400691986084,
      "backward_entropy": 0.07529272635777791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.53252410888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022735608741641045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10033684968948364,
      "backward_entropy": 0.07525461912155151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.18984985351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022823892533779144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10023009777069092,
      "backward_entropy": 0.07527408997217815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.16667938232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022913742810487747,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10012158155441284,
      "backward_entropy": 0.07693065537346734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.27020263671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02299555391073227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10001718997955322,
      "backward_entropy": 0.07518721951378717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.53115844726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02308100461959839,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09990973472595215,
      "backward_entropy": 0.07509065998925103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.64883422851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023161355406045914,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09980471134185791,
      "backward_entropy": 0.07692334387037489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.40070343017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02324838563799858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09969475865364075,
      "backward_entropy": 0.07692109213935004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.75950622558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02333015948534012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0995873212814331,
      "backward_entropy": 0.07495621840159099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.6400146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02341507002711296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09947713613510131,
      "backward_entropy": 0.0749504566192627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.31387329101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023505425080657005,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09936277270317077,
      "backward_entropy": 0.07691378063625759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.2130012512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02359071373939514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09925088286399841,
      "backward_entropy": 0.07480863730112712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.00119018554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02366536483168602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09914525747299194,
      "backward_entropy": 0.07479365666707356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.8625030517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023732684552669525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0990437388420105,
      "backward_entropy": 0.0746938255098131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.1976432800293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02380804345011711,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09893540143966675,
      "backward_entropy": 0.07463553216722277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.60983276367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023874275386333466,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0988323986530304,
      "backward_entropy": 0.07689652178022596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.94981384277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023945480585098267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09872518181800842,
      "backward_entropy": 0.07455450296401978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.84486389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02402089163661003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09861427545547485,
      "backward_entropy": 0.07444954580730861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.53349304199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024100076407194138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09850045442581176,
      "backward_entropy": 0.07442989614274767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.86212158203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024180741980671883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09838663339614868,
      "backward_entropy": 0.07436656289630467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.36469268798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024265658110380173,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09826937317848206,
      "backward_entropy": 0.07425860563913982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.56631469726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024348266422748566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09815313220024109,
      "backward_entropy": 0.07423806190490723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.31303405761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024435795843601227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09803292751312256,
      "backward_entropy": 0.07417151000764635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.90876007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024509422481060028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09792224168777466,
      "backward_entropy": 0.07409954071044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.64720916748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024576101452112198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09781595468521118,
      "backward_entropy": 0.07397868898179796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.42994689941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024637850001454353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09771251678466797,
      "backward_entropy": 0.07394637001885308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.97425842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024709580466151237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09760129451751709,
      "backward_entropy": 0.07386957274542914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.41497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024790950119495392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09748258590698242,
      "backward_entropy": 0.07374940978156196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.15186309814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024876195937395096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09736042022705078,
      "backward_entropy": 0.07367440064748128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.63467407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02495741657912731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09724054932594299,
      "backward_entropy": 0.07364296913146973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.0598602294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025035278871655464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0971224546432495,
      "backward_entropy": 0.07356429100036621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.56304931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02511739358305931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09700061082839966,
      "backward_entropy": 0.07343549860848321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.58726501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025207268074154854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09687263965606689,
      "backward_entropy": 0.07340620623694526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.00437927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02529161609709263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09674828052520752,
      "backward_entropy": 0.07332296503914727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.5048370361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025378763675689697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09662128686904907,
      "backward_entropy": 0.07323841253916423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.23735809326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02546689286828041,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0964930534362793,
      "backward_entropy": 0.07310109668307835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.2666015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02554721012711525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09637024402618408,
      "backward_entropy": 0.07681616147359212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.09506225585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02563336491584778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0962424635887146,
      "backward_entropy": 0.07296576764848497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.874267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0257119070738554,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0961200475692749,
      "backward_entropy": 0.07286942667431301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.22354507446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025791704654693604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09599604606628417,
      "backward_entropy": 0.07277223798963758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.54934692382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025861229747533798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09587960243225098,
      "backward_entropy": 0.07266908884048462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.539306640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025934815406799316,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.095759516954422,
      "backward_entropy": 0.07678593529595269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.17003631591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026010166853666306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09563750624656678,
      "backward_entropy": 0.0724296040005154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.49301147460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02608363889157772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09551652669906616,
      "backward_entropy": 0.07232558727264404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.76481628417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026152104139328003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0953988790512085,
      "backward_entropy": 0.07221816645728217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.5203857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026223137974739075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09527862071990967,
      "backward_entropy": 0.07213489876853095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.83854675292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026295963674783707,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09515643119812012,
      "backward_entropy": 0.07200095388624403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.30384063720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02637014538049698,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09503272771835328,
      "backward_entropy": 0.07188997003767225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.91559600830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02644040435552597,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09491178393363953,
      "backward_entropy": 0.07673817873001099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.98130798339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026507936418056488,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09479256868362426,
      "backward_entropy": 0.07165775034162733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.57737731933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026582971215248108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09466696977615356,
      "backward_entropy": 0.07672462198469374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.50971984863281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02666654996573925,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09453430771827698,
      "backward_entropy": 0.07671974764929877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.86117553710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02674851380288601,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09440265297889709,
      "backward_entropy": 0.07671440309948391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.5491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026822799816727638,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09427711367607117,
      "backward_entropy": 0.07119067509969075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.36370086669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026899663731455803,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09414920806884766,
      "backward_entropy": 0.07106897566053602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.47947692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026973163709044456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09402376413345337,
      "backward_entropy": 0.07093705733617146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.25039672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02705327421426773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09389268159866333,
      "backward_entropy": 0.07080614566802979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.6461410522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0271313413977623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09376307129859925,
      "backward_entropy": 0.07068158520592584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.07379150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02720620669424534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09363583922386169,
      "backward_entropy": 0.07054743501875135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.2886734008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027292462065815926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09349930286407471,
      "backward_entropy": 0.0704024765226576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.51853942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027370646595954895,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09336941242218018,
      "backward_entropy": 0.07028275065951878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.22718048095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027454402297735214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0932348608970642,
      "backward_entropy": 0.07014739513397217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.11685180664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027539459988474846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09309906959533691,
      "backward_entropy": 0.07001121838887532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.23677062988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027622245252132416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09296517968177795,
      "backward_entropy": 0.06987108124627008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.2341079711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027705654501914978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09283052086830139,
      "backward_entropy": 0.06969441307915582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.72332763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02778831124305725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09269654750823975,
      "backward_entropy": 0.06958356168535021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8026580810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027879932895302773,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09255527257919312,
      "backward_entropy": 0.0766309102376302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.65949249267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027978766709566116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0924082100391388,
      "backward_entropy": 0.06925650437672932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.50566864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028076570481061935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09226211309432983,
      "backward_entropy": 0.06916280587514241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.94918823242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028171345591545105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09211862683296204,
      "backward_entropy": 0.07662182384067112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.510009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02826366387307644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09197723865509033,
      "backward_entropy": 0.06880762179692586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.47554016113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028365345671772957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09182842969894409,
      "backward_entropy": 0.0687198903825548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.62479400634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028465425595641136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09168117046356201,
      "backward_entropy": 0.06850442621443006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.26181030273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028560398146510124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09153828620910645,
      "backward_entropy": 0.06834646066029866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.28144836425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028652356937527657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09139814376831054,
      "backward_entropy": 0.06818321016099718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.419189453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02874213643372059,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0912598729133606,
      "backward_entropy": 0.06808749834696452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.44473648071289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028829166665673256,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09112407565116883,
      "backward_entropy": 0.07659214072757298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.792457580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028906237334012985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909970760345459,
      "backward_entropy": 0.0676629212167528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64933013916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028974059969186783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0908781886100769,
      "backward_entropy": 0.06754687097337511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.39075469970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029038943350315094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0907618522644043,
      "backward_entropy": 0.06735263930426703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.536865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02910914085805416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09064093828201295,
      "backward_entropy": 0.0671606461207072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.6616439819336,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029174823313951492,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09052431583404541,
      "backward_entropy": 0.07653443018595378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.2722396850586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029240207746624947,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09040777683258057,
      "backward_entropy": 0.07652184698316786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.48988342285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029307451099157333,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09028971195220947,
      "backward_entropy": 0.07650968101289538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.14060974121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029386239126324654,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09016212224960327,
      "backward_entropy": 0.07650091913011339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.4568099975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029473530128598213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09002772569656373,
      "backward_entropy": 0.06605805291069879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.63196563720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029559427872300148,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08989480137825012,
      "backward_entropy": 0.07648787233564588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.00626373291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02964821644127369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08975982069969177,
      "backward_entropy": 0.06565557585822211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.07923889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029734939336776733,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08962699174880981,
      "backward_entropy": 0.06558715634875828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.24226379394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029828786849975586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08948875665664673,
      "backward_entropy": 0.06538977225621541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.14928436279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029925217851996422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08934884071350098,
      "backward_entropy": 0.065040389696757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.24175262451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030019082129001617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08921157121658325,
      "backward_entropy": 0.06498934162987603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.20636749267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030109841376543045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08907749652862548,
      "backward_entropy": 0.0647802750269572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.79639434814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03020014613866806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08894433975219726,
      "backward_entropy": 0.0643970635202196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.0577392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030290843918919563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08881131410598755,
      "backward_entropy": 0.06435179710388184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.31039047241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03037378005683422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08868550658226013,
      "backward_entropy": 0.06394342581431071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.39602661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030447062104940414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08856843709945679,
      "backward_entropy": 0.06388781468073527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.55734252929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03052937239408493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0884442925453186,
      "backward_entropy": 0.06346155537499322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.221858978271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030604226514697075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08832724094390869,
      "backward_entropy": 0.06341691811879475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.75502014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0306731928139925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08821572661399842,
      "backward_entropy": 0.06316868464152019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.27392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030749352648854256,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08809869289398194,
      "backward_entropy": 0.06270359622107612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.66345977783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03082628920674324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08798120617866516,
      "backward_entropy": 0.06267942984898885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.03907775878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03090553916990757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08786199688911438,
      "backward_entropy": 0.06243467993206448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.34374237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030993176624178886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08773661851882934,
      "backward_entropy": 0.061948411994510226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.24177551269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0310807041823864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0876119613647461,
      "backward_entropy": 0.06169607241948446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.40766906738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031169632449746132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08748705387115478,
      "backward_entropy": 0.061704119046529136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.37964630126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031248444691300392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08737164735794067,
      "backward_entropy": 0.06116163730621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.82978820800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03132546693086624,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08725835084915161,
      "backward_entropy": 0.06117443243662516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.19122314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03139691427350044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08715070486068725,
      "backward_entropy": 0.07627104388342963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.38209533691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03147651255130768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0870369553565979,
      "backward_entropy": 0.06062236759397718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.66807556152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03156166896224022,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08691937923431396,
      "backward_entropy": 0.060353133413526744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.82504653930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031640876084566116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08680732250213623,
      "backward_entropy": 0.06007691224416097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.01812744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03171101212501526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08670369386672974,
      "backward_entropy": 0.05978935294681125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.34929656982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03178055211901665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0866011381149292,
      "backward_entropy": 0.05910113122728136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.64277648925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031852688640356064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08649673461914062,
      "backward_entropy": 0.05879843235015869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.59870910644531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03193025290966034,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08638824224472046,
      "backward_entropy": 0.07616659667756823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.37666320800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03200988844037056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08627858161926269,
      "backward_entropy": 0.058644235134124756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.86876678466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03208598122000694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08617252111434937,
      "backward_entropy": 0.05835405985514323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.0126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03216257318854332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08606637716293335,
      "backward_entropy": 0.0580645932091607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.80547332763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03224336728453636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08595757484436035,
      "backward_entropy": 0.05777869621912638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.46253204345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032327938824892044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08584635257720948,
      "backward_entropy": 0.05705544021394518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.20780944824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03241337463259697,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08573531508445739,
      "backward_entropy": 0.057211498419443764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.8500747680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03249824419617653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08562579154968261,
      "backward_entropy": 0.056471129258473717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.47380828857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03258342668414116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08551716208457946,
      "backward_entropy": 0.05662548542022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.95335388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032659973949193954,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08541628122329711,
      "backward_entropy": 0.056316779719458684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.70272827148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03273024410009384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08532137870788574,
      "backward_entropy": 0.05553085936440362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.70950317382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03279830142855644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08522887229919433,
      "backward_entropy": 0.05567644702063666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.3896713256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032863549888134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08513925075531006,
      "backward_entropy": 0.05486980411741468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.24752044677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032932255417108536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08504725694656372,
      "backward_entropy": 0.0550269881884257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.1024398803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033001530915498734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08495535850524902,
      "backward_entropy": 0.0542147159576416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.53852844238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03307560458779335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08486039638519287,
      "backward_entropy": 0.05389081769519382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.18367385864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03314170986413956,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08477270603179932,
      "backward_entropy": 0.05405539274215698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.96760559082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03320234268903732,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08468965291976929,
      "backward_entropy": 0.053216516971588135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.57223510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03325841575860977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08461099863052368,
      "backward_entropy": 0.05337344275580512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.612548828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03331557661294937,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08453230857849121,
      "backward_entropy": 0.053026404645707875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.25759887695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033369410783052444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08445671796798707,
      "backward_entropy": 0.052161183622148305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.36190032958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03342460095882416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08438068032264709,
      "backward_entropy": 0.05180400609970093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.73918151855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033481597900390625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08430378437042237,
      "backward_entropy": 0.05144954058859083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.0511245727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03353331610560417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0842315137386322,
      "backward_entropy": 0.051612271202935114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.6982192993164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03358723223209381,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08415794372558594,
      "backward_entropy": 0.07575421863132054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.5490493774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033648863434791565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08407957553863525,
      "backward_entropy": 0.05035622914632162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.98290252685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033713456243276596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08399972915649415,
      "backward_entropy": 0.050554507308536105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.25151062011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03378409519791603,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08391576409339904,
      "backward_entropy": 0.05021062824461195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.22843933105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03386130556464195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08382787704467773,
      "backward_entropy": 0.04987206061681112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.66288757324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03394049406051636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0837395429611206,
      "backward_entropy": 0.048893372217814125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.16079711914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03402398154139519,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08364900350570678,
      "backward_entropy": 0.07567380534278022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.42658996582031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03410855680704117,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08355876207351684,
      "backward_entropy": 0.07566686471303304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.44646453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03419964015483856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08346458673477172,
      "backward_entropy": 0.047828892866770424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.49739074707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034289103001356125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0833727777004242,
      "backward_entropy": 0.04747655656602648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.53751373291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03437907621264458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08328133821487427,
      "backward_entropy": 0.04784854915406969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.484657287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03446505591273308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08319404125213622,
      "backward_entropy": 0.046759479575686984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.5133285522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03454604744911194,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08311103582382202,
      "backward_entropy": 0.04712896545728048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.17715454101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03462454676628113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08303062915802002,
      "backward_entropy": 0.046026435163286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.53390502929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03470996394753456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0829460084438324,
      "backward_entropy": 0.04567163520389133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.35537719726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034792203456163406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08286457061767578,
      "backward_entropy": 0.04605538977517022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.71460723876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03487961366772652,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08278059959411621,
      "backward_entropy": 0.04570329189300537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.66547775268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03497274965047836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08269368410110474,
      "backward_entropy": 0.04535817437701755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.49858093261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035060323774814606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0826114296913147,
      "backward_entropy": 0.04424674643410577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.364990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03515145182609558,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08252766132354736,
      "backward_entropy": 0.0438965360323588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.66362762451172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03523750975728035,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08244887590408326,
      "backward_entropy": 0.07559241188897027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.435585021972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035327572375535965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08236801624298096,
      "backward_entropy": 0.04393301076359219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.728485107421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03541218861937523,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08229173421859741,
      "backward_entropy": 0.043569074736701116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.88221740722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035487979650497437,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08222323656082153,
      "backward_entropy": 0.04318831695450677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.00558471679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03556450456380844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08215470910072327,
      "backward_entropy": 0.04204988479614258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.68685913085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03564058244228363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0820874810218811,
      "backward_entropy": 0.04243458641899957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.29954528808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03571464493870735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08202229738235474,
      "backward_entropy": 0.04205602076318529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.36742401123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035782769322395325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196159601211547,
      "backward_entropy": 0.040900349617004395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.63893127441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03584973141551018,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08190220594406128,
      "backward_entropy": 0.041288548045688205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.90245819091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03590921685099602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0818497359752655,
      "backward_entropy": 0.0408895644876692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.456029891967773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03597693517804146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08179205656051636,
      "backward_entropy": 0.039715713924831815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.8069839477539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03603638708591461,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08174093961715698,
      "backward_entropy": 0.07541033294465807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.21733856201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036096516996622086,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08168964982032775,
      "backward_entropy": 0.07538549105326335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.27294158935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03615834563970566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08163785934448242,
      "backward_entropy": 0.07536203993691339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.37472534179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03623122349381447,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08157932758331299,
      "backward_entropy": 0.03896704647276136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.97138977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036314524710178375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08151413202285766,
      "backward_entropy": 0.038627445697784424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.65619659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03640023246407509,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08144798278808593,
      "backward_entropy": 0.03745837675200568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.27508544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03648727759718895,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08138198256492615,
      "backward_entropy": 0.03795947631200155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.30024719238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03656964376568794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08131977319717407,
      "backward_entropy": 0.037620736493004694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.24722290039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03665456920862198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08125625848770142,
      "backward_entropy": 0.03728640741772122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.749881744384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03673939034342766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08119368553161621,
      "backward_entropy": 0.036074426439073354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.10688781738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681766986846924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08113614320755005,
      "backward_entropy": 0.035728014177746244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.3373908996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036888640373945236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08108469247817993,
      "backward_entropy": 0.03625525368584527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.2072982788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036959126591682434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08103376626968384,
      "backward_entropy": 0.03590497374534607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.46405029296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037031352519989014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08098257780075073,
      "backward_entropy": 0.035562879509396024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.42007446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037099432200193405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08093527555465699,
      "backward_entropy": 0.03521441088782416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.8514289855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03716898709535599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08088690638542176,
      "backward_entropy": 0.03395054075453016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.07699966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037237174808979034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0808406949043274,
      "backward_entropy": 0.033593717548582286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.626792907714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03730374202132225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08079556822776794,
      "backward_entropy": 0.03419271773762173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.54252624511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03736715018749237,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08075346946716308,
      "backward_entropy": 0.033852222892973155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.52198028564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037430766969919205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08071142435073853,
      "backward_entropy": 0.03351709577772352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.0060043334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03749646246433258,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08066853284835815,
      "backward_entropy": 0.033187405930625066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.8102912902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03756829351186752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08062223196029664,
      "backward_entropy": 0.031866358386145696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.431419372558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03763987496495247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08057664632797241,
      "backward_entropy": 0.03153317835595873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.746822357177734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037705522030591965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08053611516952515,
      "backward_entropy": 0.07514105902777778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.40755844116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03776947036385536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08049665093421936,
      "backward_entropy": 0.03084837728076511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.77110290527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037832897156476974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08045839071273804,
      "backward_entropy": 0.03158533573150635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.517822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037895310670137405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08042192459106445,
      "backward_entropy": 0.030157725016276043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.7164535522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03795984759926796,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08038505315780639,
      "backward_entropy": 0.03094268176290724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.38619995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03802986815571785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08034444451332093,
      "backward_entropy": 0.02948839134640164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.7438850402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0381021648645401,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08030273914337158,
      "backward_entropy": 0.030353440178765193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.19401550292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03817027434706688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08026520013809205,
      "backward_entropy": 0.030048906803131104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.3954849243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03824508935213089,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08022315502166748,
      "backward_entropy": 0.02976058257950677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.25607681274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03832386061549187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08017925024032593,
      "backward_entropy": 0.029483702447679307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.22908020019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03839518874883652,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08014151453971863,
      "backward_entropy": 0.029189474052853055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.23031616210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0384732261300087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08009984493255615,
      "backward_entropy": 0.028914458221859403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.26602172851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038551729172468185,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08005859851837158,
      "backward_entropy": 0.028640561633639865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.2558364868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03863038867712021,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08001819849014283,
      "backward_entropy": 0.02836342652638753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.44157791137695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038715336471796036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07997404336929322,
      "backward_entropy": 0.02666358980867598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.91218566894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03879386559128761,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0799347460269928,
      "backward_entropy": 0.02784095538987054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.95951843261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03887730464339256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07989307045936585,
      "backward_entropy": 0.027583733201026917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.165035247802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038959864526987076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07985212802886962,
      "backward_entropy": 0.02578036818239424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.79598999023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03903872147202492,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07981415390968323,
      "backward_entropy": 0.02708306908607483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.00480651855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0391276590526104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07977025508880616,
      "backward_entropy": 0.025218514932526484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.28562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03922387957572937,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07972211837768554,
      "backward_entropy": 0.07509774631924099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.59973907470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03931333124637604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0796788215637207,
      "backward_entropy": 0.024703226155704923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.2109260559082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039401717483997345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07963703870773316,
      "backward_entropy": 0.02619052595562405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.32225036621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03948623314499855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07959825992584228,
      "backward_entropy": 0.025961402389738295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.4717025756836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0395713672041893,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0795597791671753,
      "backward_entropy": 0.07513266139560276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.274627685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03966222703456879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07951760292053223,
      "backward_entropy": 0.02364855342441135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.96479797363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03974407538771629,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07948236465454102,
      "backward_entropy": 0.025320225291781955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.70588302612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0398285947740078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07944577932357788,
      "backward_entropy": 0.023133264647589788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.39500427246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039909470826387405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07941198348999023,
      "backward_entropy": 0.024899702933099534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.82923889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039983898401260376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.079383385181427,
      "backward_entropy": 0.024676973621050518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.62076568603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04005517438054085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07935746908187866,
      "backward_entropy": 0.02445072101222144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.5644760131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0401342511177063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07932610511779785,
      "backward_entropy": 0.02208168970213996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.01815795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04021494463086128,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07929399013519287,
      "backward_entropy": 0.024060486091507807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.52616882324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0402979739010334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0792611837387085,
      "backward_entropy": 0.021593497859107122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.1807632446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040379978716373444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07922934293746949,
      "backward_entropy": 0.02367542352941301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.74055099487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04046984389424324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07919334173202515,
      "backward_entropy": 0.023481706778208416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.6210823059082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04055718705058098,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07915976643562317,
      "backward_entropy": 0.023283239867952134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.10982894897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04064057022333145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07912929058074951,
      "backward_entropy": 0.023083014620674983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.97109603881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04072099179029465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07910088300704957,
      "backward_entropy": 0.022886955075793795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.49655151367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079877957701683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07907435894012452,
      "backward_entropy": 0.020114743047290377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.8846321105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04088212549686432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07904441356658935,
      "backward_entropy": 0.022514134645462036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.38819122314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040960893034935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07901769280433654,
      "backward_entropy": 0.022339022821850248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.009864807128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041037555783987045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07899240255355836,
      "backward_entropy": 0.07522190941704644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.7884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04111405462026596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07896738052368164,
      "backward_entropy": 0.0220100912782881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.640804290771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04119463637471199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07893997430801392,
      "backward_entropy": 0.01899700529045529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.53071594238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041270747780799866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07891579866409301,
      "backward_entropy": 0.02170517875088586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.8825569152832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0413535051047802,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07888727188110352,
      "backward_entropy": 0.021568450662824843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.24551391601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04143640398979187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07885867357254028,
      "backward_entropy": 0.021441996097564697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.6961784362793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041528526693582535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07882441282272339,
      "backward_entropy": 0.018216285440656874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.15691375732422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04161427542567253,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07879492044448852,
      "backward_entropy": 0.07529921001858181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.62907409667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041703756898641586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07876313924789428,
      "backward_entropy": 0.021079268720414903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.441165924072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04180039092898369,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07872679233551025,
      "backward_entropy": 0.02097690933280521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.48699951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04189443588256836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07869193553924561,
      "backward_entropy": 0.017521378066804674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.12846755981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041988905519247055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07865700721740723,
      "backward_entropy": 0.020797782474093966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.390865325927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04207686334848404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07862700819969178,
      "backward_entropy": 0.017197529474894207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.21750259399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042165324091911316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0785969614982605,
      "backward_entropy": 0.020591318607330322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.362361907958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04225151613354683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07856844663619995,
      "backward_entropy": 0.020495136578877766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.678855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04233291745185852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07854321002960205,
      "backward_entropy": 0.02039705216884613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.88031768798828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042413607239723206,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07851883172988891,
      "backward_entropy": 0.0754639705022176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.017818450927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042497217655181885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07849313616752625,
      "backward_entropy": 0.020193717545933194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.461990356445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04258265346288681,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0784659743309021,
      "backward_entropy": 0.02009976241323683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.6053466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042660411447286606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0784447193145752,
      "backward_entropy": 0.01999333831999037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.03853607177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042748384177684784,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07841650247573853,
      "backward_entropy": 0.019900888204574585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.432411193847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04284229502081871,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0783838152885437,
      "backward_entropy": 0.01982520686255561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.396968841552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0429348424077034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07835227847099305,
      "backward_entropy": 0.019751050406032138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.2590446472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043025899678468704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07832217216491699,
      "backward_entropy": 0.015446495678689744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.235196113586426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04311723634600639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0782922625541687,
      "backward_entropy": 0.015299911300341288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.58258819580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04319825395941734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07826976776123047,
      "backward_entropy": 0.019501220848825242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.867244720458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04328272119164467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07824574708938599,
      "backward_entropy": 0.014984122580952115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.55168151855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043366286903619766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07822210788726806,
      "backward_entropy": 0.014826696779992845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.04773712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043447982519865036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07819975018501282,
      "backward_entropy": 0.014676585793495178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.934162139892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04353414103388786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07817473411560058,
      "backward_entropy": 0.019139003422525194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.94429016113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043615516275167465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07815310955047608,
      "backward_entropy": 0.01904750367005666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.0279769897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043702710419893265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07812727689743042,
      "backward_entropy": 0.014226641919877794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.39881896972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04379328712821007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0780989408493042,
      "backward_entropy": 0.018895483679241605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.8551025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043884534388780594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07807028889656067,
      "backward_entropy": 0.01882496972878774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.313819885253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043977174907922745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07804032564163207,
      "backward_entropy": 0.018763952785068087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.94313049316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04406870901584625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0780104637145996,
      "backward_entropy": 0.018704422646098666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.00041961669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04415661096572876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07798479795455933,
      "backward_entropy": 0.013566601607534621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.3868408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04424756392836571,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07795670628547668,
      "backward_entropy": 0.013437833223077986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.108604431152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044332053512334824,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07793295383453369,
      "backward_entropy": 0.07576760980818006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.61239242553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04441811516880989,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07790798544883729,
      "backward_entropy": 0.01846133006943597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.58214569091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04450061917304993,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07788567543029785,
      "backward_entropy": 0.07579243845409817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.242008209228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457966983318329,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0778670072555542,
      "backward_entropy": 0.012920118040508695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.174598693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04465616121888161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07784966230392457,
      "backward_entropy": 0.012777438594235314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.29435729980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04473559558391571,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07783020734786987,
      "backward_entropy": 0.018168280522028606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.010990142822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04481690376996994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07780938744544982,
      "backward_entropy": 0.012520254486136966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.76943588256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044900164008140564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07778685092926026,
      "backward_entropy": 0.012397482991218567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.14075469970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04498285427689552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07776530385017395,
      "backward_entropy": 0.017984395225842793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.72339630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04506840929389,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07774131894111633,
      "backward_entropy": 0.017920391427146062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.46625900268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04515007883310318,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07772005796432495,
      "backward_entropy": 0.017841464943355985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.50926971435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04523086175322533,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07770058512687683,
      "backward_entropy": 0.017760965559217665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.06105041503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04531677067279816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07767698764801026,
      "backward_entropy": 0.011748110254605612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.59982681274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04540574550628662,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07765085697174072,
      "backward_entropy": 0.017613511946466234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.582637786865234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04548614099621773,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07763153314590454,
      "backward_entropy": 0.07587129539913601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.361474990844727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556453600525856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07761369347572326,
      "backward_entropy": 0.017475452688005235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.796274185180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04563959687948227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07759835720062255,
      "backward_entropy": 0.01124905546506246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.12968826293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045706506818532944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07758966684341431,
      "backward_entropy": 0.017336595389578078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.007966995239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577641934156418,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07757796049118042,
      "backward_entropy": 0.010995174447695414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.71694564819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04584415629506111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07756812572479248,
      "backward_entropy": 0.017205610871315002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.984275817871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04591509327292442,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.077555912733078,
      "backward_entropy": 0.017150794466336567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.58167266845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04598328843712807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0775468111038208,
      "backward_entropy": 0.01709722148047553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.20439147949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046062447130680084,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07752786874771118,
      "backward_entropy": 0.017056006524297927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.3998794555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04614366218447685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0775079607963562,
      "backward_entropy": 0.010449248055617014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.50545883178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04623096436262131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07748273611068726,
      "backward_entropy": 0.01035666631327735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.49884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046315230429172516,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07746004462242126,
      "backward_entropy": 0.01695316367679172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.94575500488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04640151932835579,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07743551135063172,
      "backward_entropy": 0.010167331331306033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.76744079589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04648665711283684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07741187810897827,
      "backward_entropy": 0.016888769136534795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.612043380737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046570222824811935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07738912701606751,
      "backward_entropy": 0.01686309278011322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.45063781738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04664786532521248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07737119793891907,
      "backward_entropy": 0.009889788097805448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.12136459350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672970995306969,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07734983563423156,
      "backward_entropy": 0.009802066617541842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.904727935791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04681159928441048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07732845544815063,
      "backward_entropy": 0.01678888996442159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.224388122558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689377173781395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07730652689933777,
      "backward_entropy": 0.01677104499604967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.5977668762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0469781830906868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07728254795074463,
      "backward_entropy": 0.01675976150565677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.96797180175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047062624245882034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07725833654403687,
      "backward_entropy": 0.01675215197934045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.977928161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714535176753998,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0772354245185852,
      "backward_entropy": 0.009409387078550126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.3145637512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04722907021641731,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.077211195230484,
      "backward_entropy": 0.016736408074696858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.93425178527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047312181442976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07718731760978699,
      "backward_entropy": 0.016718023353152804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.95295715332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04738975688815117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07716947793960571,
      "backward_entropy": 0.016698128647274442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.97301483154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047467589378356934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0771505057811737,
      "backward_entropy": 0.009091941018899282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.48564624786377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04755321145057678,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07712457180023194,
      "backward_entropy": 0.01666396525171068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.000211715698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047631099820137024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07710545063018799,
      "backward_entropy": 0.008940658635563321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.250396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0477055199444294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07708929181098938,
      "backward_entropy": 0.01662973231739468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.155418395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0477740503847599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0770781934261322,
      "backward_entropy": 0.008788966470294528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.04499053955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04784133657813072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07706799507141113,
      "backward_entropy": 0.016595794094933405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.301669120788574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047907520085573196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07705886363983154,
      "backward_entropy": 0.016565960314538743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.80009460449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047967977821826935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0770546555519104,
      "backward_entropy": 0.016536990801493328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.832401275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04803309217095375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07704634666442871,
      "backward_entropy": 0.016523059871461656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.85005950927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04810387268662453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07703231573104859,
      "backward_entropy": 0.016517033179601032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.21255111694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04818098247051239,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07701246738433838,
      "backward_entropy": 0.01651041044129266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.30941009521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04825741425156593,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07699351310729981,
      "backward_entropy": 0.01651041044129266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.09123611450195,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04834001883864403,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07696818709373474,
      "backward_entropy": 0.07620521386464436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.98421859741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048422642052173615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07694278955459595,
      "backward_entropy": 0.01651735438240899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.986787796020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048505060374736786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07691800594329834,
      "backward_entropy": 0.016516380839877658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.38505554199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04858344420790672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07689800262451171,
      "backward_entropy": 0.016507974929279752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.327091217041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04866359755396843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07687536478042603,
      "backward_entropy": 0.01651789413558112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.22444534301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048744894564151764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07685112953186035,
      "backward_entropy": 0.016538421312967937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.369075775146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04882698878645897,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07682569026947021,
      "backward_entropy": 0.01656553977065616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.10610580444336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048908255994319916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07680115699768067,
      "backward_entropy": 0.0165779623720381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.07297897338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04898862540721893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07677713632583619,
      "backward_entropy": 0.0077877408928341335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.34136962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04906833916902542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07675329446792603,
      "backward_entropy": 0.007733570204840766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.664634704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049144309014081955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07673271894454955,
      "backward_entropy": 0.00767631580432256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.34640121459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04922700300812721,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07670490741729737,
      "backward_entropy": 0.016613644030359056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.360355377197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04931047186255455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07667622566223145,
      "backward_entropy": 0.0075701019830173915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.206974029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04939361661672592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07664769887924194,
      "backward_entropy": 0.007513515651226044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.351423263549805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049476463347673416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07661929130554199,
      "backward_entropy": 0.01660394503010644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.56009292602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04955780506134033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07659224271774293,
      "backward_entropy": 0.01660412053267161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.816593170166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049644820392131805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0765587866306305,
      "backward_entropy": 0.007353007793426514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.54315948486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04973071441054344,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07652641534805298,
      "backward_entropy": 0.0763965712653266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.92527961730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04981249198317528,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.076498144865036,
      "backward_entropy": 0.007243679629431831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.35467529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04989244416356087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07647230625152587,
      "backward_entropy": 0.016596294111675687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.62527084350586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049971986562013626,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07644636631011963,
      "backward_entropy": 0.07641638649834527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.82469177246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05005301535129547,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0764184832572937,
      "backward_entropy": 0.016568471988042194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.34309196472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050134990364313126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0763891100883484,
      "backward_entropy": 0.016567703750398424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.62314224243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05021575465798378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07636052370071411,
      "backward_entropy": 0.016575405995051067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210817337036133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050296857953071594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07633053064346314,
      "backward_entropy": 0.016585770580503676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.80316162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05037105455994606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07630921602249145,
      "backward_entropy": 0.016593428121672735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.80838966369629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05044234171509743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07629190683364868,
      "backward_entropy": 0.006833297097020679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.843456268310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05051039159297943,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07627724409103394,
      "backward_entropy": 0.006779969566398197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.302310943603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057821050286293,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0762624442577362,
      "backward_entropy": 0.006728937228520711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.11369323730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05064847692847252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07624462842941285,
      "backward_entropy": 0.00667541225751241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.214561462402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05072115361690521,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07622369527816772,
      "backward_entropy": 0.016555862294303045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.506404876708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080002546310425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07619534730911255,
      "backward_entropy": 0.006570827629831102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.282344818115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050879620015621185,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07616597414016724,
      "backward_entropy": 0.07648799154493544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.34048843383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05096045881509781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07613497972488403,
      "backward_entropy": 0.01656705141067505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.251956939697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05104561150074005,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07609913349151612,
      "backward_entropy": 0.006452747931083043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.083820343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113580450415611,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0760576844215393,
      "backward_entropy": 0.0166259507338206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.905122756958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05122213065624237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07602001428604126,
      "backward_entropy": 0.006381117221381929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.5716667175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513053759932518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07598531246185303,
      "backward_entropy": 0.00633435779147678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.360633850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05139043182134628,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07594829797744751,
      "backward_entropy": 0.016633785433239408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.24174880981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051478490233421326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07590766549110413,
      "backward_entropy": 0.01663710508081648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.316526412963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051567453891038895,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07586577534675598,
      "backward_entropy": 0.016640231013298035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.259315490722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05165305361151695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07582691907882691,
      "backward_entropy": 0.016654789447784424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.068986892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051735639572143555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07579130530357361,
      "backward_entropy": 0.006126521776119868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.883838653564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051816102117300034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07575762271881104,
      "backward_entropy": 0.016658355792363484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.038963317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05189523845911026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07572509050369262,
      "backward_entropy": 0.016663711931970384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.68622398376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05197828263044357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07568774223327637,
      "backward_entropy": 0.016676020291116502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.81248664855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052059344947338104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07565234303474426,
      "backward_entropy": 0.016687401466899447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.52824401855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052137430757284164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07561997771263122,
      "backward_entropy": 0.005932838552527958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.72287368774414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05221853032708168,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07558375000953674,
      "backward_entropy": 0.07661072413126628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.56155776977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230019614100456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07554615139961243,
      "backward_entropy": 0.016712094346682232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.35758972167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05237862840294838,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07551199793815613,
      "backward_entropy": 0.01671490404340956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.06867980957031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05246305838227272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07546893358230591,
      "backward_entropy": 0.0766272677315606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.714170455932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05254882574081421,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07542363405227662,
      "backward_entropy": 0.005748107615444396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.24613952636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052633631974458694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07537911534309387,
      "backward_entropy": 0.01678958535194397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.156333923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05271759629249573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07533557415008545,
      "backward_entropy": 0.016818440622753568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.342998504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05279476195573807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07530137896537781,
      "backward_entropy": 0.01684726940260993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.652381896972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05287197604775429,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07526643872261048,
      "backward_entropy": 0.0168943272696601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.82355499267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05295233801007271,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07522697448730468,
      "backward_entropy": 0.005620312773519092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.16254425048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053029730916023254,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0751913070678711,
      "backward_entropy": 0.01697290109263526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.60575866699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0531054250895977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0751578688621521,
      "backward_entropy": 0.00556991125146548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.44468688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053184133023023605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07511948347091675,
      "backward_entropy": 0.01705057422320048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.494556427001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326952040195465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07507134675979614,
      "backward_entropy": 0.005527690880828434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.44728088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05335121229290962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07502808570861816,
      "backward_entropy": 0.01713892651928796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.33095359802246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05343565344810486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07498058080673217,
      "backward_entropy": 0.017176071802775066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.478757858276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053516287356615067,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07493821382522584,
      "backward_entropy": 0.01720980637603336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.314191818237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053594641387462616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07489888668060303,
      "backward_entropy": 0.01723410851425595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.41646957397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05367149040102959,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07486129999160766,
      "backward_entropy": 0.005401295092370775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.72802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0537509061396122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07481930255889893,
      "backward_entropy": 0.005377282698949178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.058208465576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053838569670915604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0747645616531372,
      "backward_entropy": 0.005355972382757399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.00295639038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392266809940338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07471510171890258,
      "backward_entropy": 0.005327733854452769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.710771560668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05400930345058441,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0746612548828125,
      "backward_entropy": 0.017375684446758695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.558246612548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054095398634672165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07460755109786987,
      "backward_entropy": 0.0052721260322464835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.36231994628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05417799949645996,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0745584487915039,
      "backward_entropy": 0.017428831921683416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.4061336517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05426322668790817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07450462579727173,
      "backward_entropy": 0.017456097735299006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.180177688598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054345447570085526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07445513010025025,
      "backward_entropy": 0.01747167772716946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.704551696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05442662537097931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07440621852874756,
      "backward_entropy": 0.01747970614168379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.115903854370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05451086536049843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07435077428817749,
      "backward_entropy": 0.01749402119053735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.49340057373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0545915886759758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07430017590522767,
      "backward_entropy": 0.0051046837535169386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.859031677246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054673563688993454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07424622178077697,
      "backward_entropy": 0.017534406648741827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.87646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476008728146553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07418349981307984,
      "backward_entropy": 0.017560657527711656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.461448669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054848868399858475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07411608695983887,
      "backward_entropy": 0.005030154354042477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.205772399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054935283958911896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0740518569946289,
      "backward_entropy": 0.017619498901897006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.647375106811523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05502449348568916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07398219108581543,
      "backward_entropy": 0.004981051716539595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.123262405395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05510840564966202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07392160892486573,
      "backward_entropy": 0.004948370986514621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.39382553100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05518988147377968,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07386457920074463,
      "backward_entropy": 0.017636863721741572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.83567237854004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055267706513404846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07381339073181152,
      "backward_entropy": 0.01763781077331967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.23213005065918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055344391614198685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07376330494880676,
      "backward_entropy": 0.017649316125445895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.164955139160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055417727679014206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0737187147140503,
      "backward_entropy": 0.017658443914519414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.042133331298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055491454899311066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07367249727249145,
      "backward_entropy": 0.017670871482955083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.332210540771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055562473833560944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0736308217048645,
      "backward_entropy": 0.01768699950642056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.25088882446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05563822016119957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07357951998710632,
      "backward_entropy": 0.017699440320332844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.19840431213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05571483075618744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07352584600448608,
      "backward_entropy": 0.01770314077536265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.933544635772705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579004064202309,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07347373962402344,
      "backward_entropy": 0.0046840500500467085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.77885437011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055859338492155075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07343219518661499,
      "backward_entropy": 0.017723570267359417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.88936996459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05592978000640869,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07338733673095703,
      "backward_entropy": 0.017720517184999254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.69776153564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05600384622812271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07333441972732543,
      "backward_entropy": 0.017722898059421115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.661380767822266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05608115345239639,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07327449321746826,
      "backward_entropy": 0.07683088382085164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.290834426879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056156791746616364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07321710586547851,
      "backward_entropy": 0.017739791009161208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.440589904785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05622950941324234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07316486835479737,
      "backward_entropy": 0.017753773265414767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.128543853759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05630100518465042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07311437129974366,
      "backward_entropy": 0.01776955525080363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.447216033935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05636998638510704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07306829690933228,
      "backward_entropy": 0.017788294288847182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.136869430541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05643884465098381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.073021799325943,
      "backward_entropy": 0.004436717265182071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.181962966918945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0565066859126091,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07297674417495728,
      "backward_entropy": 0.017803397443559434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.105491638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657467246055603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07293077707290649,
      "backward_entropy": 0.004380240622493956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.964597702026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05664534121751785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07287834286689758,
      "backward_entropy": 0.004355041931072871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.602075576782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05671807751059532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07282083630561828,
      "backward_entropy": 0.01783624291419983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.70378303527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05678676813840866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07277115583419799,
      "backward_entropy": 0.004309470454851787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.507034301757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05685654655098915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07271853685379029,
      "backward_entropy": 0.017867760525809392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.443800926208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056923795491456985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07267050743103028,
      "backward_entropy": 0.01787748436133067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.32502555847168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056988440454006195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07262736558914185,
      "backward_entropy": 0.01788421306345198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.203046798706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570521280169487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07258514165878296,
      "backward_entropy": 0.004203992585341136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.09576416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05711560323834419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07254235744476319,
      "backward_entropy": 0.0041790323124991525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.899106979370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05717920884490013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0724982738494873,
      "backward_entropy": 0.017922270629141066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.779613494873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05724397301673889,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07245064973831176,
      "backward_entropy": 0.004137037528885735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.160343170166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057309769093990326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07240002155303955,
      "backward_entropy": 0.017977535724639893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.103260040283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0573810376226902,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07233668565750122,
      "backward_entropy": 0.018012512061331008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.373424530029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05744808167219162,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.072282212972641,
      "backward_entropy": 0.018045309517118666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.28729248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05751684308052063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07222312688827515,
      "backward_entropy": 0.004069538166125615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.15699005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05758601427078247,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0721623420715332,
      "backward_entropy": 0.018143483334117465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.603738784790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0576556958258152,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07209953069686889,
      "backward_entropy": 0.018191407124201458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.122125625610352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05772295221686363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07204148769378663,
      "backward_entropy": 0.018239504761166044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.786571502685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057785943150520325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07199274301528931,
      "backward_entropy": 0.018301203846931458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.403435707092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05785032734274864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07193987965583801,
      "backward_entropy": 0.01836681365966797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.80390167236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05791245773434639,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07189157009124755,
      "backward_entropy": 0.01842505070898268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.87446403503418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05797902122139931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07183201909065247,
      "backward_entropy": 0.018489630685912237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587523460388184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058044277131557465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07177466750144959,
      "backward_entropy": 0.01854258610142602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.5731315612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0581064410507679,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07172397971153259,
      "backward_entropy": 0.003967529783646266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.627103805541992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05817793682217598,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07165093421936035,
      "backward_entropy": 0.01865488953060574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.993206024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058251019567251205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07157322764396667,
      "backward_entropy": 0.0039445873763826154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.883769989013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05832340195775032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07149627208709716,
      "backward_entropy": 0.003929835226800706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.711261749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05839279666543007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07142553329467774,
      "backward_entropy": 0.003914248612191942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.031055450439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05846244841814041,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07135317921638488,
      "backward_entropy": 0.018824592232704163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.652804374694824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05853331834077835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07127684354782104,
      "backward_entropy": 0.01885565949810876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.546378135681152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05860132351517677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07120660543441773,
      "backward_entropy": 0.0038644588655895656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.578380584716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058667514473199844,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0711398720741272,
      "backward_entropy": 0.018925979733467102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.4248104095459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05873537436127663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07106798887252808,
      "backward_entropy": 0.018962368369102478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.950510025024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058804869651794434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0709909439086914,
      "backward_entropy": 0.0038189300232463414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.302032470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05887481942772865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07091169357299805,
      "backward_entropy": 0.019038523236910503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.458980560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058941327035427094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0708402931690216,
      "backward_entropy": 0.019066714578204684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.60687255859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05900679901242256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07077049016952515,
      "backward_entropy": 0.019094877772861056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.836864471435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05907247215509415,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07069907784461975,
      "backward_entropy": 0.003751808156569799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.18574333190918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059134580194950104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07063614130020142,
      "backward_entropy": 0.003734179668956333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.907604217529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059195756912231445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07057458758354188,
      "backward_entropy": 0.003715304864777459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.709643363952637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05925525724887848,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07051651477813721,
      "backward_entropy": 0.019191746910413105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.034374237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05931149050593376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07046646475791932,
      "backward_entropy": 0.003679056548409992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.810089111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059369102120399475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07041165828704835,
      "backward_entropy": 0.01923987434970008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.6757173538208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059426963329315186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07035516500473023,
      "backward_entropy": 0.01927293340365092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.82707405090332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059482697397470474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07030358910560608,
      "backward_entropy": 0.019296560022566054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.439714431762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059543125331401825,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0702383577823639,
      "backward_entropy": 0.019331955247455172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.512733459472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059599053114652634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0701848566532135,
      "backward_entropy": 0.0193680872519811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.429271697998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05965618044137955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0701271116733551,
      "backward_entropy": 0.003582223421997494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.32660484313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05971093103289604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07007496356964112,
      "backward_entropy": 0.019418514437145658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.195276260375977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059765562415122986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07002227306365967,
      "backward_entropy": 0.01943433615896437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.197579383850098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05982179194688797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06996413469314575,
      "backward_entropy": 0.01945526235633426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.980985641479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059877075254917145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06990792751312255,
      "backward_entropy": 0.01948661274380154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.96368408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059934165328741074,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06984571218490601,
      "backward_entropy": 0.019527142246564228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.264543533325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059991903603076935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06978087425231934,
      "backward_entropy": 0.019582072893778484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10897159576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06004525348544121,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06972802877426147,
      "backward_entropy": 0.019633256726794772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.604936599731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060095902532339096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0696821928024292,
      "backward_entropy": 0.003464347372452418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.690139770507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060148175805807114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0696306824684143,
      "backward_entropy": 0.019720842440923054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968822002410889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06020035222172737,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06957854032516479,
      "backward_entropy": 0.019755024049017165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.549162864685059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0602506659924984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06953116059303284,
      "backward_entropy": 0.019798816906081304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.470370292663574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06030077114701271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06948344707489014,
      "backward_entropy": 0.01982944044801924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.616339683532715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06035083159804344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06943495869636536,
      "backward_entropy": 0.019852358433935378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.321791648864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06040032580494881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06938738822937011,
      "backward_entropy": 0.0033768796258502537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.9359130859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06044982746243477,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06933883428573609,
      "backward_entropy": 0.07694436444176568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.154410362243652,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.060501717031002045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06928244233131409,
      "backward_entropy": 0.07694519890679254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.39730167388916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060553938150405884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06922422647476197,
      "backward_entropy": 0.019977425535519917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.002408027648926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060605067759752274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06916850209236144,
      "backward_entropy": 0.003320154837436146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.287084579467773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060656581073999405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06911081671714783,
      "backward_entropy": 0.020054350296656292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.872518539428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060706913471221924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06905593872070312,
      "backward_entropy": 0.020090762111875746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.801158905029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06075698137283325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06900091767311096,
      "backward_entropy": 0.003277415409684181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.471778869628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06080666556954384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06894608736038207,
      "backward_entropy": 0.02012593216366238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.048148155212402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06086093932390213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06887655258178711,
      "backward_entropy": 0.003241064647833506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.549452781677246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06091402471065521,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0688099980354309,
      "backward_entropy": 0.02016780608230167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.470169067382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06096697598695755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06874303817749024,
      "backward_entropy": 0.020189637939135235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.366657733917236,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06101979687809944,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06867563724517822,
      "backward_entropy": 0.07694780826568604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.806337356567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0610697865486145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06861656904220581,
      "backward_entropy": 0.02022715575165219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.185195922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06112142279744148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06855125427246093,
      "backward_entropy": 0.020247603456179302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.153629302978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0611758716404438,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06847652196884155,
      "backward_entropy": 0.02027121517393324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.505264282226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06123015657067299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06840150952339172,
      "backward_entropy": 0.0031278031981653636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.385488510131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06128576025366783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06832155585289001,
      "backward_entropy": 0.0031135713474618066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.917957305908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06134336441755295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06823486089706421,
      "backward_entropy": 0.02037198344866435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.197181701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061399899423122406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0681505024433136,
      "backward_entropy": 0.020406890246603224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.750299453735352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06145734339952469,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06806248426437378,
      "backward_entropy": 0.020441982481214736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.989576816558838,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061513710767030716,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06797686219215393,
      "backward_entropy": 0.0030632226003540885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.578388214111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061566997319459915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06790072321891785,
      "backward_entropy": 0.02048666775226593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.785253524780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061620015650987625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06782455444335937,
      "backward_entropy": 0.02050630251566569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.418645858764648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06167451664805412,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06774280667304992,
      "backward_entropy": 0.020533747143215604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.070959091186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06172861158847809,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06766142845153808,
      "backward_entropy": 0.02055996987554762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.50107192993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06178170070052147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0675828218460083,
      "backward_entropy": 0.020596540636486478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.178323745727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06183553859591484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06750068664550782,
      "backward_entropy": 0.020625692274835374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.90014362335205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06188914179801941,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06741846203804017,
      "backward_entropy": 0.0029644210719399983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.659482002258301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06194135546684265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06734020113945008,
      "backward_entropy": 0.020684556828604803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.784351348876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06199127435684204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0672691822052002,
      "backward_entropy": 0.002938935947087076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.882421493530273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062040288001298904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06720057725906373,
      "backward_entropy": 0.002927381752265824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.18504524230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062089234590530396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06713119745254517,
      "backward_entropy": 0.020792820387416415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.833810806274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062141988426446915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0670479416847229,
      "backward_entropy": 0.020823218756251864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.646506309509277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06219583749771118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06696014404296875,
      "backward_entropy": 0.002889112051990297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.577317237854004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06224951148033142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06687207221984863,
      "backward_entropy": 0.0028770843313799966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.639774322509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062302473932504654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06678564548492431,
      "backward_entropy": 0.002863797048727671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.354555130004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062358755618333817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0666869342327118,
      "backward_entropy": 0.020942376719580755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.31900405883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06241188943386078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06659865379333496,
      "backward_entropy": 0.020966501699553594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.2454195022583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062465403228998184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06650855541229247,
      "backward_entropy": 0.02100450462765164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2335662841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06251897662878036,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06641754508018494,
      "backward_entropy": 0.021049468053711787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149876594543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06256978213787079,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06633571982383728,
      "backward_entropy": 0.021092736058764987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.031920433044434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06261922419071198,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0662580668926239,
      "backward_entropy": 0.021132929457558527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.952975273132324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06266855448484421,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06617980003356934,
      "backward_entropy": 0.021168705489900377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.791528701782227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06271817535161972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06609978079795838,
      "backward_entropy": 0.002772933906979031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.158893346786499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06276863813400269,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06601567268371582,
      "backward_entropy": 0.0212412608994378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.87765121459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06281588226556778,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06594310402870178,
      "backward_entropy": 0.02128350403573778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28700926899909973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06286220252513885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06587321162223816,
      "backward_entropy": 0.021325881282488506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.124977111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06290378421545029,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06582055091857911,
      "backward_entropy": 0.021361697051260207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.188079833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06294932216405869,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0657522737979889,
      "backward_entropy": 0.021389040682050917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.07832145690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06299742311239243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06567373871803284,
      "backward_entropy": 0.02141358455022176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.97201156616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06304807215929031,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06558513045310974,
      "backward_entropy": 0.021440840429729886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5655517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06310074031352997,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06548836827278137,
      "backward_entropy": 0.02146499686770969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.994586944580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0631517693400383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06539698243141175,
      "backward_entropy": 0.021489077144198947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.080942153930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06320390105247498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06530077457427978,
      "backward_entropy": 0.002650240436196327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.683303356170654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06326029449701309,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06518855094909667,
      "backward_entropy": 0.02154424124293857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.694055557250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0633135512471199,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06508749723434448,
      "backward_entropy": 0.02157134148809645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26423168182373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06336802989244461,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06498138308525085,
      "backward_entropy": 0.002615562743610806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.566442489624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06342115253210068,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06487990617752075,
      "backward_entropy": 0.021656355924076505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.79560375213623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06347144395112991,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06478853821754456,
      "backward_entropy": 0.021700673633151583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.715276718139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06352120637893677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0646982491016388,
      "backward_entropy": 0.002586531556314892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.641849517822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06357099860906601,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06460716724395751,
      "backward_entropy": 0.02177724904484219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998693943023682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.063620924949646,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06451491713523864,
      "backward_entropy": 0.021823642982376948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.389298915863037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06366950273513794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06442724466323853,
      "backward_entropy": 0.021868503755993314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.431649208068848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06371552497148514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06434879302978516,
      "backward_entropy": 0.021909008423487347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.96327781677246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06376227736473083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06426690816879273,
      "backward_entropy": 0.00254035492738088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.819748878479004,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06381247192621231,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06417098641395569,
      "backward_entropy": 0.07697469658321804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.222171783447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0638633593916893,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06407147049903869,
      "backward_entropy": 0.022056801451577082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.199779987335205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06391604244709015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06396430730819702,
      "backward_entropy": 0.02209866874747806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.09512996673584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06396634876728058,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06386600732803345,
      "backward_entropy": 0.022149138980441622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.460991859436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06401597708463669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06376953721046448,
      "backward_entropy": 0.022190444999270968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.36075496673584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06406627595424652,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06366961002349854,
      "backward_entropy": 0.02222692800892724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.270135879516602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0641176775097847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06356470584869385,
      "backward_entropy": 0.022270229127671983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4175519943237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06417004764080048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06345537900924683,
      "backward_entropy": 0.00246991113656097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.731436729431152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06422054767608643,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06335280537605285,
      "backward_entropy": 0.0024612624612119463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.366753578186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06427051872015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06325159668922424,
      "backward_entropy": 0.022407649291886225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.58306312561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06432206183671951,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06314328908920289,
      "backward_entropy": 0.022442811065249972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.814517974853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06437639892101288,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06302322149276733,
      "backward_entropy": 0.02247911526097192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.854824066162109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06443130970001221,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06290037035942078,
      "backward_entropy": 0.02252197927898831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.63729190826416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06448262184858322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06279150247573853,
      "backward_entropy": 0.0024130187100834316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.542757034301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06453438103199005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0626800537109375,
      "backward_entropy": 0.022582064072291057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9603376388549805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06458665430545807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06256588101387024,
      "backward_entropy": 0.02261404361989763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.141148567199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06463760137557983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0624566912651062,
      "backward_entropy": 0.02265618907080756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4502453804016113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06468796730041504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06234913468360901,
      "backward_entropy": 0.022697531514697604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4263837337493896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06473476439714432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06225611567497254,
      "backward_entropy": 0.022742922107378643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.11220932006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06477860361337662,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06217517852783203,
      "backward_entropy": 0.022797458701663546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.042558670043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06482390314340591,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06208745241165161,
      "backward_entropy": 0.022855930858188205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53038215637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06487023830413818,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06199456453323364,
      "backward_entropy": 0.02291209167904324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.630914211273193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06491436809301376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0619103729724884,
      "backward_entropy": 0.02296801573700375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.049844741821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06495749950408936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061829793453216556,
      "backward_entropy": 0.00233168030778567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.737407684326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06500379741191864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.061735129356384276,
      "backward_entropy": 0.07698992888132732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.656943321228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06505095213651657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0616361141204834,
      "backward_entropy": 0.023117706179618835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3153865337371826,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0650988519191742,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06153320074081421,
      "backward_entropy": 0.07699093553755018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.566167831420898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06514297425746918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061446082592010495,
      "backward_entropy": 0.02320196893480089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.325582504272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0651887059211731,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061351311206817624,
      "backward_entropy": 0.02322964866956075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.290319919586182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06523171812295914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061267638206481935,
      "backward_entropy": 0.02324922217263116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.282418251037598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06527413427829742,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061186015605926514,
      "backward_entropy": 0.023279069198502436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.194607734680176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06531865894794464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06109461784362793,
      "backward_entropy": 0.023307992352379694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145933151245117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06536493450403214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06099504232406616,
      "backward_entropy": 0.02333319021595849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07448673248291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06541071832180023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06089693307876587,
      "backward_entropy": 0.0022326440860827765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.905712127685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06545630097389221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06079917550086975,
      "backward_entropy": 0.0022217525790135064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.09986686706543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06550359725952148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06069333553314209,
      "backward_entropy": 0.023405310180452134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.547293663024902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06554810702800751,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06059923768043518,
      "backward_entropy": 0.002199306670162413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.518756866455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06559628993272781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06048880815505982,
      "backward_entropy": 0.023440096113416884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.87742805480957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0656466856598854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060368281602859494,
      "backward_entropy": 0.023452179299460515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.691720962524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06569503247737885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060256189107894896,
      "backward_entropy": 0.023461815383699205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.921302556991577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06574247032403946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06014733910560608,
      "backward_entropy": 0.002149502436319987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.896892547607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06578745692968369,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06004911065101624,
      "backward_entropy": 0.02347766525215573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.497189044952393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06582998484373093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059961408376693726,
      "backward_entropy": 0.023487079474661086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.435352802276611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06587240099906921,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05987374186515808,
      "backward_entropy": 0.023498897751172382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.593888759613037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0659148320555687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05978546142578125,
      "backward_entropy": 0.023515502611796062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9927300214767456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06595610082149506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05970180630683899,
      "backward_entropy": 0.023531739910443623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.845569610595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06599472463130951,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059629857540130615,
      "backward_entropy": 0.023556604981422424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966022491455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0660393163561821,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05953103303909302,
      "backward_entropy": 0.0020677196896738475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.429246425628662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06608420610427856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05943022966384888,
      "backward_entropy": 0.02359272539615631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.103121757507324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06612728536128998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05933694839477539,
      "backward_entropy": 0.02359883487224579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.740057945251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0661696344614029,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059246373176574704,
      "backward_entropy": 0.02359644075234731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.284083366394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06621258705854416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05915223360061646,
      "backward_entropy": 0.02359390589925978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.246036052703857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06625440716743469,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059063118696212766,
      "backward_entropy": 0.023597684171464708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525440216064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06629495322704315,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05897940397262573,
      "backward_entropy": 0.0019905103577507865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.68144416809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0663362592458725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05889148116111755,
      "backward_entropy": 0.023606124851438735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375526428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06638338416814804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05877754092216492,
      "backward_entropy": 0.023619489537345037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.054296016693115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06643058359622955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058662796020507814,
      "backward_entropy": 0.00195497688319948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4048895835876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06647656112909317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058553445339202884,
      "backward_entropy": 0.023656179507573444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.391482353210449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06652067601680756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05845259428024292,
      "backward_entropy": 0.02369709975189633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.076090812683105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0665622428059578,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05836290121078491,
      "backward_entropy": 0.02373238404591878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.444880485534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0666046068072319,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058269071578979495,
      "backward_entropy": 0.0019203022950225407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941652297973633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06664692610502243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05817510485649109,
      "backward_entropy": 0.023811355233192444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.803982257843018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06668980419635773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05807797908782959,
      "backward_entropy": 0.023850972453753155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7235572338104248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06673157215118408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05798564553260803,
      "backward_entropy": 0.0018971508575810327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241441249847412,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06677060574293137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05790582299232483,
      "backward_entropy": 0.001890335852901141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.187103271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06680937856435776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05782653689384461,
      "backward_entropy": 0.023988005187776353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.641412258148193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06684813648462296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05774669647216797,
      "backward_entropy": 0.02402960095140669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.150437831878662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06688662618398666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05766791105270386,
      "backward_entropy": 0.001868694813715087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.963552474975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06692316383123398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05759782791137695,
      "backward_entropy": 0.024137356215053134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0061421394348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06696167588233948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0575178325176239,
      "backward_entropy": 0.02418649196624756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.942032337188721,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0669996589422226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05743953585624695,
      "backward_entropy": 0.024222443501154583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.475918769836426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06703787297010422,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057359778881073,
      "backward_entropy": 0.024263506134351093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.598513126373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06707508862018585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05728411674499512,
      "backward_entropy": 0.0018309416870276134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2150797843933105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0671103224158287,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05721780061721802,
      "backward_entropy": 0.02435653242799971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.359852313995361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06714649498462677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057146352529525754,
      "backward_entropy": 0.024404332041740417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.331784248352051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06718242913484573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05707569122314453,
      "backward_entropy": 0.024463173415925767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417354583740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06721789389848709,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05700674653053284,
      "backward_entropy": 0.024525509940253362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.000226974487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06725527346134186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05692815184593201,
      "backward_entropy": 0.024583154254489474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24343204498291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06729307025671005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0568468451499939,
      "backward_entropy": 0.024626360999213323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8619680404663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06732958555221558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056771039962768555,
      "backward_entropy": 0.02466015186574724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4919939041137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06736446917057037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05670263767242432,
      "backward_entropy": 0.024695942799250286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.76838493347168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06739962846040726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05663227438926697,
      "backward_entropy": 0.024733637770016987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1060686111450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06743571162223816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05655727386474609,
      "backward_entropy": 0.024768897228770785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.359950542449951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06747076660394669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05648640990257263,
      "backward_entropy": 0.024798673060205247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.598263263702393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06750603765249252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056414085626602176,
      "backward_entropy": 0.0248301989502377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.36966609954834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0675424113869667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05633599758148193,
      "backward_entropy": 0.024864582551850214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.971389055252075,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06758192181587219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056242382526397704,
      "backward_entropy": 0.0017280076733893817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6934115886688232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06761991232633591,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05615556240081787,
      "backward_entropy": 0.001718479726049635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8933045864105225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06765539199113846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05608028769493103,
      "backward_entropy": 0.024915039539337158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.078790664672852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06769008189439774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05600837469100952,
      "backward_entropy": 0.024925041529867385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696473121643066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06772530823945999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055933821201324466,
      "backward_entropy": 0.0249481780661477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7873001098632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06776300817728043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05584691166877746,
      "backward_entropy": 0.024970298012097675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.936717510223389,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06779991090297699,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05576351284980774,
      "backward_entropy": 0.0016710494334499042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5448014736175537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0678374320268631,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05567696690559387,
      "backward_entropy": 0.025049466225836012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.217075824737549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06787291914224625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05559988021850586,
      "backward_entropy": 0.025092838539017573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.831997871398926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06790976226329803,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055515730381011964,
      "backward_entropy": 0.02512788110309177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.620718240737915,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0679459348320961,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05543416738510132,
      "backward_entropy": 0.0016425448573297924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.732931137084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06798140704631805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05535576343536377,
      "backward_entropy": 0.025178622868325975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.551654577255249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0680168867111206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05527695417404175,
      "backward_entropy": 0.025208988123469882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418121337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06805193424224854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05520000457763672,
      "backward_entropy": 0.025251514381832547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.61724853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06808493286371231,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05513263940811157,
      "backward_entropy": 0.02528411481115553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.673447132110596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06811781227588654,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05506537556648254,
      "backward_entropy": 0.02531063391102685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6233978271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06815165281295776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05499283671379089,
      "backward_entropy": 0.025338083505630493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.735321521759033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06818635016679764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054915624856948855,
      "backward_entropy": 0.025366410613059998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3873636722564697,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06822339445352554,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.054826557636260986,
      "backward_entropy": 0.07698063055674235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.530783176422119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06825879961252213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05474496483802795,
      "backward_entropy": 0.025412023067474365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.363757610321045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06829537451267242,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05465719699859619,
      "backward_entropy": 0.02542391584979163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.400519847869873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0683315172791481,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0545708179473877,
      "backward_entropy": 0.025435133112801447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.271625995635986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06836871802806854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05447946190834045,
      "backward_entropy": 0.025442838668823242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302631378173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0684056207537651,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05438905954360962,
      "backward_entropy": 0.025455638766288757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1708382368087769,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06844502687454224,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054286020994186404,
      "backward_entropy": 0.025464160574807063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1481722593307495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0684811919927597,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05419864654541016,
      "backward_entropy": 0.02546849184566074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1120505332946777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06851509213447571,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0541226863861084,
      "backward_entropy": 0.025485730833477445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.088252067565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06854826956987381,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054049938917160034,
      "backward_entropy": 0.025508332583639357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.987124443054199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06858046352863312,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05398174524307251,
      "backward_entropy": 0.025527455740504794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.987873077392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06861371546983719,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05390804409980774,
      "backward_entropy": 0.02555466526084476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9483580589294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06864677369594574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05383499264717102,
      "backward_entropy": 0.025579430990748935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7863054275512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06867975741624832,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05376187562942505,
      "backward_entropy": 0.025604744752248127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0167946815490723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06871438026428223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05368027687072754,
      "backward_entropy": 0.025636242495642766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.913065195083618,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06874692440032959,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05360866785049438,
      "backward_entropy": 0.07697187529669867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9745376110076904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06877871602773666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05354043245315552,
      "backward_entropy": 0.02568720943397946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8498175144195557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06880902498960495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053479456901550294,
      "backward_entropy": 0.0014400432507197063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9397063255310059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06883952766656876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053417515754699704,
      "backward_entropy": 0.0014347390582164128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9247479438781738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06886866688728333,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05336207151412964,
      "backward_entropy": 0.025810499986012776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.784879207611084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06889645755290985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05331295728683472,
      "backward_entropy": 0.025853554407755535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1409993171691895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06892413645982742,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05326415896415711,
      "backward_entropy": 0.0259025858508216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.874573826789856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06895476579666138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053199803829193114,
      "backward_entropy": 0.02594083547592163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291646957397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06898398697376251,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05314212441444397,
      "backward_entropy": 0.02597843607266744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9897590279579163,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06901483237743378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05307585000991821,
      "backward_entropy": 0.026014675696690876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6623456478118896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06904356926679611,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053019940853118896,
      "backward_entropy": 0.026053574350145128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8087966442108154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06907214969396591,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052964627742767334,
      "backward_entropy": 0.026100754737854004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.620072841644287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06909950077533722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05291516780853271,
      "backward_entropy": 0.02614588538805644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7771999835968018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06912660598754883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052866536378860476,
      "backward_entropy": 0.026193105512195163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5760204792022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06915271282196045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05282254815101624,
      "backward_entropy": 0.026240956452157762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.983134746551514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06917878240346909,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05277848243713379,
      "backward_entropy": 0.02629324131541782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3419981002807617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06920687109231949,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052723705768585205,
      "backward_entropy": 0.0263481338818868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.100888252258301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0692349523305893,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052668309211730956,
      "backward_entropy": 0.02639496988720364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4894051551818848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06926416605710983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052606832981109616,
      "backward_entropy": 0.026447359058592055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.592095375061035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06929288059473038,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0525475025177002,
      "backward_entropy": 0.02650059097343021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2193634510040283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06932371854782104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05247684121131897,
      "backward_entropy": 0.026548756493462458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1825997829437256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06935431808233261,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052406948804855344,
      "backward_entropy": 0.026591178443696763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.392817497253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06938498467206955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05233643054962158,
      "backward_entropy": 0.026636699835459392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.384782552719116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06941505521535873,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052268576622009275,
      "backward_entropy": 0.026686360438664753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6034903526306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06944368779659271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05220743417739868,
      "backward_entropy": 0.026714927620357938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.806372880935669,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06947126984596252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05215136408805847,
      "backward_entropy": 0.026751071214675903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5753058195114136,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06949930638074875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05209238529205322,
      "backward_entropy": 0.026776221063401964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.451518535614014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06952624022960663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.052038758993148804,
      "backward_entropy": 0.0013051395201020772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.269069194793701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06955468654632568,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05197697877883911,
      "backward_entropy": 0.026836845609876845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.653803825378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06958211958408356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0519199013710022,
      "backward_entropy": 0.026856789986292522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.220320701599121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06961055845022202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05185732841491699,
      "backward_entropy": 0.02688386042912801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.897575855255127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06963825970888138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051797914505004886,
      "backward_entropy": 0.026909248696433172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4878627061843872,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06966562569141388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051739740371704104,
      "backward_entropy": 0.02692423595322503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4711638689041138,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06969183683395386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05168725252151489,
      "backward_entropy": 0.02694301472769843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.81298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06971719861030579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05163908004760742,
      "backward_entropy": 0.026971047123273213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.779261589050293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06974262744188309,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05158994197845459,
      "backward_entropy": 0.026994973421096802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.76157546043396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06976638734340668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05154942274093628,
      "backward_entropy": 0.027021113369199965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4191762208938599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06979045271873474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05150676965713501,
      "backward_entropy": 0.027045031388600666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4112862348556519,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06981386989355087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05146709680557251,
      "backward_entropy": 0.02707702252599928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3962831497192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0698363184928894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05143201947212219,
      "backward_entropy": 0.027105692360136244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0312912464141846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06985817849636078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05139966011047363,
      "backward_entropy": 0.027139274610413447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6438615322113037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06987964361906052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05136876702308655,
      "backward_entropy": 0.027163023749987285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9908000230789185,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06990206986665726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051332670450210574,
      "backward_entropy": 0.027197587821218703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3497895002365112,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06992476433515549,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05129500031471253,
      "backward_entropy": 0.001208717520866129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.205277919769287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06994692236185074,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05125981569290161,
      "backward_entropy": 0.027294649018181696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.94672429561615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06997007876634598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051218897104263306,
      "backward_entropy": 0.0012005436130695874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9283486604690552,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06999286264181137,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0511793315410614,
      "backward_entropy": 0.027379479673173692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7268407344818115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07001549005508423,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05114023089408874,
      "backward_entropy": 0.027418964438968234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6979779005050659,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07003997266292572,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05109114646911621,
      "backward_entropy": 0.02746180362171597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4737584590911865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.07006250321865082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05105159282684326,
      "backward_entropy": 0.001181817510061794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0401532649993896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07008536159992218,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051009857654571535,
      "backward_entropy": 0.02752562363942464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6756319999694824,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.07010926306247711,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05096225738525391,
      "backward_entropy": 0.07698371675279406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6672950387001038,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07013162225484848,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050922447443008424,
      "backward_entropy": 0.0275904205110338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3858225345611572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07015284895896912,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05088836550712585,
      "backward_entropy": 0.027632753054300945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2293086051940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07017476111650467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050850188732147215,
      "backward_entropy": 0.027678516176011827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.346968650817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07019571959972382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05081651210784912,
      "backward_entropy": 0.027717490990956623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6456796526908875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07021728157997131,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0507793128490448,
      "backward_entropy": 0.02775721748669942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.307889223098755,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.07023760676383972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05074828267097473,
      "backward_entropy": 0.0011456126554144754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.738325595855713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07025866955518723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05071302056312561,
      "backward_entropy": 0.02784439590242174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.363232374191284,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.07027965039014816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050677675008773806,
      "backward_entropy": 0.027889119254218206,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.3891013330221176,
    "avg_log_Z": -0.06894902288913726,
    "success_rate": 1.0,
    "avg_reward": 18.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.86,
      "2": 0.11
    },
    "avg_forward_entropy": 0.05329752713441849,
    "avg_backward_entropy": 0.024958016965538267,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}