{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13855535984039308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.138374400138855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.5272674560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279912074406943,
      "backward_entropy": 0.13857605457305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.8619384765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278892834981283,
      "backward_entropy": 0.13856039047241211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.22470092773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020006689010187984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277843793233237,
      "backward_entropy": 0.1385761022567749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.06626892089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00030030065681785345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276764949162802,
      "backward_entropy": 0.13837591409683228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.51133728027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003983361821155995,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275662263234457,
      "backward_entropy": 0.13857425451278688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7182159423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004975409246981144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274527788162231,
      "backward_entropy": 0.13857839107513428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.63760375976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005971710197627544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827336549758911,
      "backward_entropy": 0.13837696313858033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.04356384277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006976617150940001,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827217936515808,
      "backward_entropy": 0.13858580589294434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0071563720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007980618975125253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827095945676168,
      "backward_entropy": 0.1383773446083069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.3149871826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008983926963992417,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826971173286438,
      "backward_entropy": 0.13859250545501708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.41017150878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009994105203077197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826843023300171,
      "backward_entropy": 0.13857522010803222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.17762756347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011014370247721672,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267107009887695,
      "backward_entropy": 0.13837735652923583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.13478088378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012043744791299105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18265757958094278,
      "backward_entropy": 0.13857452869415282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.75941467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00130803557112813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18264381090799967,
      "backward_entropy": 0.13837815523147584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.32383728027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014116015518084168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826297640800476,
      "backward_entropy": 0.13837819099426268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.95767211914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015151365660130978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826155185699463,
      "backward_entropy": 0.13837790489196777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1308135986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016177678480744362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826010545094808,
      "backward_entropy": 0.1385722875595093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.67454528808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001719773979857564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825865109761556,
      "backward_entropy": 0.1385714054107666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.39482116699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018209518166258931,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257158994674683,
      "backward_entropy": 0.1385703682899475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9163818359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019168680300936103,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18255684773127237,
      "backward_entropy": 0.13861484527587892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.64833068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0020138011313974857,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254164854685465,
      "backward_entropy": 0.1383690595626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.05044555664062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002109382301568985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825261116027832,
      "backward_entropy": 0.1386169195175171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.18759155273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002206203294917941,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18251025676727295,
      "backward_entropy": 0.1383623957633972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.15330505371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023017702624201775,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249406417210898,
      "backward_entropy": 0.13861855268478393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.12775421142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023983842693269253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824774146080017,
      "backward_entropy": 0.13855981826782227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.18348693847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024912424851208925,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824606458346049,
      "backward_entropy": 0.1386197805404663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1705780029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002581933978945017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244353930155435,
      "backward_entropy": 0.13834410905838013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.92025756835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00267361244186759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242627382278442,
      "backward_entropy": 0.13833837509155272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0998992919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027659933548420668,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240865071614584,
      "backward_entropy": 0.138620924949646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8481903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0028591782320290804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239116668701172,
      "backward_entropy": 0.13832602500915528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8119659423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002952903276309371,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823736031850179,
      "backward_entropy": 0.13831932544708253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4334259033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00304711377248168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235556284586588,
      "backward_entropy": 0.13853855133056642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.73828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003139415755867958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233740329742432,
      "backward_entropy": 0.13853479623794557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.70021057128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003232410177588463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18231797218322754,
      "backward_entropy": 0.1382965087890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.85160064697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003326025791466236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229814370473227,
      "backward_entropy": 0.13852665424346924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.13796997070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003416177351027727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18227773904800415,
      "backward_entropy": 0.13852204084396363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.4662780761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035058308858424425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18225673834482828,
      "backward_entropy": 0.13851709365844728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1555938720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036016511730849743,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18223456541697183,
      "backward_entropy": 0.13862125873565673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.6304931640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036977932322770357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18221201499303183,
      "backward_entropy": 0.13862109184265137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.61607360839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003796529723331332,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18218886852264404,
      "backward_entropy": 0.138620924949646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1717071533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038983982522040606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821649670600891,
      "backward_entropy": 0.13823263645172118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9110565185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003998477943241596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821407675743103,
      "backward_entropy": 0.13822219371795655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.85108947753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004096771590411663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18211615085601807,
      "backward_entropy": 0.1384843111038208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.44528198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004192335531115532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820913553237915,
      "backward_entropy": 0.13819979429244994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.6309356689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004286711569875479,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18206616242726645,
      "backward_entropy": 0.13861942291259766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.59317016601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00438023591414094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18204073111216226,
      "backward_entropy": 0.13846356868743898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.94827270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004473010078072548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18201504151026407,
      "backward_entropy": 0.13845598697662354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.131591796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00456615537405014,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18198871612548828,
      "backward_entropy": 0.13861795663833618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.150146484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046598343178629875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18196195363998413,
      "backward_entropy": 0.1386174201965332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.26023864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004756573121994734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18193453550338745,
      "backward_entropy": 0.13843176364898682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3893280029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004855718929320574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18190630276997885,
      "backward_entropy": 0.13842341899871827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.73117065429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004954592324793339,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818775733311971,
      "backward_entropy": 0.13861603736877443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.53447723388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0050531295128166676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818483273188273,
      "backward_entropy": 0.13807709217071534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.48690795898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005146396812051535,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818195382754008,
      "backward_entropy": 0.13861463069915772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.3887481689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005240252241492271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18179007371266684,
      "backward_entropy": 0.13838629722595214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.72032165527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005336813163012266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18175951639811197,
      "backward_entropy": 0.13861314058303834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.8606414794922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005435658153146505,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817283034324646,
      "backward_entropy": 0.1386125087738037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.5393829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00553770549595356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18169589837392172,
      "backward_entropy": 0.13835625648498534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.02743530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005636720452457666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18166353305180868,
      "backward_entropy": 0.1379776954650879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.73069763183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005735435523092747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18163047234217325,
      "backward_entropy": 0.13796013593673706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.47061157226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005836346186697483,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18159645795822144,
      "backward_entropy": 0.1386103630065918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.08424377441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005940468516200781,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181561549504598,
      "backward_entropy": 0.1379256248474121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.6614227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006046464201062918,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152642250061035,
      "backward_entropy": 0.13830215930938722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.85060119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006149995140731335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18149109681447348,
      "backward_entropy": 0.1382908582687378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.24418640136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006251519545912743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18145575126012167,
      "backward_entropy": 0.1382790684700012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3030242919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0063482304103672504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18142046531041464,
      "backward_entropy": 0.13785171508789062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.48110961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006444913800805807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18138476212819418,
      "backward_entropy": 0.1382532835006714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.05470275878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00654011033475399,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18134868144989014,
      "backward_entropy": 0.13860666751861572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.94715881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006634085904806852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18131234248479208,
      "backward_entropy": 0.13822550773620607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.77784729003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00672061275690794,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18127596378326416,
      "backward_entropy": 0.13860456943511962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.48324584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006809200160205364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18123875061670938,
      "backward_entropy": 0.13819396495819092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.28330993652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006901061162352562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18120058377583823,
      "backward_entropy": 0.1381779909133911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.70071411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006996108219027519,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18116201957066855,
      "backward_entropy": 0.13816205263137818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.0537567138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007088512182235718,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18112250169118246,
      "backward_entropy": 0.13767542839050292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.61599731445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007185142487287521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810821294784546,
      "backward_entropy": 0.13765408992767333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.30868530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00727895088493824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18104171752929688,
      "backward_entropy": 0.13763153553009033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.16224670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007374307606369257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810004711151123,
      "backward_entropy": 0.1380962610244751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.41615295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007467977236956358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18095860878626505,
      "backward_entropy": 0.1380781888961792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.23249816894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007565843872725964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18091545502344766,
      "backward_entropy": 0.13806047439575195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.17774963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007657800335437059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18087281783421835,
      "backward_entropy": 0.13804125785827637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.7341766357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007753659505397081,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808284123738607,
      "backward_entropy": 0.1380218744277954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.16024780273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007846632041037083,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18078386783599854,
      "backward_entropy": 0.13859469890594484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.88526916503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007938348688185215,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18073765436808267,
      "backward_entropy": 0.138593590259552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.30419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008032694458961487,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18068943421045938,
      "backward_entropy": 0.13795771598815917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.85014343261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008125853724777699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18064075708389282,
      "backward_entropy": 0.1379343867301941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.39855194091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008214819245040417,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18059166272481283,
      "backward_entropy": 0.1385897397994995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.15548706054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008297638967633247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18054413795471191,
      "backward_entropy": 0.13858786821365357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.92564392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00838049128651619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1804958979288737,
      "backward_entropy": 0.13785651922225953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.56167602539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00846461858600378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180446187655131,
      "backward_entropy": 0.13782887458801268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.32723999023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008548230864107609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18039526542027792,
      "backward_entropy": 0.13779962062835693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.19027709960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008630238473415375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18034374713897705,
      "backward_entropy": 0.13857994079589844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.2744903564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008714986965060234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18029052019119263,
      "backward_entropy": 0.13857805728912354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.396240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008806295692920685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1802348494529724,
      "backward_entropy": 0.13713219165802001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.62744140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008897794410586357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18017794688542685,
      "backward_entropy": 0.13857508897781373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.21946716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008991092443466187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18011975288391113,
      "backward_entropy": 0.13764536380767822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.09559631347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009082336910068989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.180061936378479,
      "backward_entropy": 0.13702821731567383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.6630096435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009174113161861897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18000316619873047,
      "backward_entropy": 0.1375800609588623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.0337371826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009266476146876812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17994354168574014,
      "backward_entropy": 0.13754634857177733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.7000274658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009363419376313686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798819104830424,
      "backward_entropy": 0.13751330375671386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.93585205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009464201517403126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798181732495626,
      "backward_entropy": 0.13747885227203369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.1445541381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009559789672493935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1797544558842977,
      "backward_entropy": 0.13743956089019777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.83724975585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009650921449065208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17969151337941489,
      "backward_entropy": 0.1373974323272705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.0511474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009740803390741348,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17962849140167236,
      "backward_entropy": 0.13856163024902343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.72384643554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009826801717281342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17956560850143433,
      "backward_entropy": 0.13730595111846924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0363311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009912095032632351,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17950159311294556,
      "backward_entropy": 0.13665394783020018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.8519287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009996656328439713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17943664391835532,
      "backward_entropy": 0.13720507621765138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.582275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010082375258207321,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1793705622355143,
      "backward_entropy": 0.13655426502227783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.3723602294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010171488858759403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1793020764986674,
      "backward_entropy": 0.13709917068481445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.36338806152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01026532705873251,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17923124631245932,
      "backward_entropy": 0.13645694255828858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9419708251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010356510058045387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791605552037557,
      "backward_entropy": 0.1369908332824707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.2549285888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010445421561598778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1790903608004252,
      "backward_entropy": 0.1363529920578003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.24850463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010532188229262829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17901949087778726,
      "backward_entropy": 0.13687524795532227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.1322479248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010618206113576889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17894802490870157,
      "backward_entropy": 0.13681464195251464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.27421569824219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01070504728704691,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17887500921885172,
      "backward_entropy": 0.13853176832199096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.77748107910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010785327292978764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1788034439086914,
      "backward_entropy": 0.13612492084503175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.21979522705078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010860146954655647,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17873360713322958,
      "backward_entropy": 0.13852285146713256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.93563842773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010930812917649746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1786645253499349,
      "backward_entropy": 0.13654396533966065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.25735473632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01100122183561325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17859506607055664,
      "backward_entropy": 0.13592128753662108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.47071838378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011072508990764618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17852383852005005,
      "backward_entropy": 0.1363917112350464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.14659881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011143618263304234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17845221360524496,
      "backward_entropy": 0.13631333112716676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.44363403320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011213130317628384,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17838088671366373,
      "backward_entropy": 0.13849409818649291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.03819274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01128354948014021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17830747365951538,
      "backward_entropy": 0.13615124225616454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.58021545410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011353692971169949,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17823334534962973,
      "backward_entropy": 0.13606741428375244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.18153381347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011426148936152458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17815701166788736,
      "backward_entropy": 0.13548334836959838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.3477554321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011499597690999508,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17807928721110025,
      "backward_entropy": 0.13540995121002197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.62437438964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011570802889764309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1780013640721639,
      "backward_entropy": 0.13580586910247802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.5557403564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011643614619970322,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1779226859410604,
      "backward_entropy": 0.13845854997634888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.24822235107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01171539444476366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17784068981806436,
      "backward_entropy": 0.1351778507232666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.98025512695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011783864349126816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17775901158650717,
      "backward_entropy": 0.13552613258361818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.87635803222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011860063299536705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17767339944839478,
      "backward_entropy": 0.13501830101013185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.2401123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011935710906982422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17758711179097494,
      "backward_entropy": 0.13533784151077272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.96224975585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012013772502541542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1774986187616984,
      "backward_entropy": 0.13524200916290283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.6699981689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012092568911612034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17740883429845175,
      "backward_entropy": 0.13514466285705568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.79608917236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012171468697488308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17731696367263794,
      "backward_entropy": 0.13504340648651122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.26177215576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012247990816831589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17722535133361816,
      "backward_entropy": 0.13493890762329103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.5716094970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01232064701616764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17713435490926108,
      "backward_entropy": 0.1345238447189331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.3244171142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01239282451570034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17704210678736368,
      "backward_entropy": 0.1347171187400818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.0525131225586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012469200417399406,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17694658041000366,
      "backward_entropy": 0.138396692276001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.70089721679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01254209317266941,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17685246467590332,
      "backward_entropy": 0.13448983430862427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9201202392578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012617461383342743,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17675522963205972,
      "backward_entropy": 0.13838435411453248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.69300842285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01269528642296791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1766555905342102,
      "backward_entropy": 0.13405598402023317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.91993713378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012773862108588219,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17655444145202637,
      "backward_entropy": 0.13395988941192627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.32986450195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012853351421654224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1764521598815918,
      "backward_entropy": 0.13386218547821044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.899169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012935017235577106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1763476530710856,
      "backward_entropy": 0.13389458656311035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.54361724853516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013018752448260784,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17624111970265707,
      "backward_entropy": 0.13836064338684081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.6623992919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013099235482513905,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1761344075202942,
      "backward_entropy": 0.1383556604385376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.0260009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013180128298699856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17602574825286865,
      "backward_entropy": 0.1383507013320923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.55270385742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01325853168964386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1759165128072103,
      "backward_entropy": 0.13335027694702148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.51321411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013343475759029388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17580185333887735,
      "backward_entropy": 0.13323986530303955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.91046142578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013429844751954079,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17568461100260416,
      "backward_entropy": 0.13833656311035156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.59829711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013514675199985504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1755671501159668,
      "backward_entropy": 0.13295836448669435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.37728118896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01359938271343708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17544754346211752,
      "backward_entropy": 0.13281179666519166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.80184936523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013681004755198956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1753283143043518,
      "backward_entropy": 0.13265786170959473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.41854858398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013764550909399986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17520654201507568,
      "backward_entropy": 0.132684326171875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.58876037597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013851391151547432,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1750815510749817,
      "backward_entropy": 0.1325657606124878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.4801483154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013939955271780491,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17495489120483398,
      "backward_entropy": 0.13244717121124266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.30077362060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014028270728886127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17482670148213705,
      "backward_entropy": 0.1320273160934448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92511749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014109994284808636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17470153172810873,
      "backward_entropy": 0.1318568229675293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.83585357666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014189301058650017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17457743485768637,
      "backward_entropy": 0.13205658197402953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.80619049072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014261468313634396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1744569937388102,
      "backward_entropy": 0.13149025440216064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.37814331054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014328395016491413,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1743378241856893,
      "backward_entropy": 0.13825204372406005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.64981079101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014396049082279205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1742175022761027,
      "backward_entropy": 0.13108978271484376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.60771179199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014463905245065689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17409515380859375,
      "backward_entropy": 0.13088362216949462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.4668426513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014528876170516014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1739734411239624,
      "backward_entropy": 0.13067002296447755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.41238403320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014595873653888702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17384809255599976,
      "backward_entropy": 0.13045440912246703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.03999328613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014663180336356163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1737208366394043,
      "backward_entropy": 0.13093438148498535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.20033264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014728999696671963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1735924482345581,
      "backward_entropy": 0.1300066351890564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.89073181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014796808362007141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1734608014424642,
      "backward_entropy": 0.13058574199676515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.82191467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014863456599414349,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17332891623179117,
      "backward_entropy": 0.13040266036987305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.00245666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014936564490199089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17318971951802573,
      "backward_entropy": 0.1293023109436035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.670654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01500976923853159,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17304998636245728,
      "backward_entropy": 0.13004257678985595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.82803344726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015087609179317951,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17290558417638144,
      "backward_entropy": 0.13810148239135742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.69487762451172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015165082179009914,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17276068528493246,
      "backward_entropy": 0.13809078931808472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.11062622070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015237345360219479,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17261890570322672,
      "backward_entropy": 0.13807761669158936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.0771026611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015317331068217754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1724695364634196,
      "backward_entropy": 0.12930841445922853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.41384887695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015397690236568451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17231720685958862,
      "backward_entropy": 0.129121994972229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.47775268554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015481850132346153,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17216028769810995,
      "backward_entropy": 0.1380507230758667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.5713348388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01557076908648014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17199790477752686,
      "backward_entropy": 0.12734721899032592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.22718811035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015657760202884674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1718341906865438,
      "backward_entropy": 0.12708919048309325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.75128173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01574954204261303,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17166578769683838,
      "backward_entropy": 0.13803576231002807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.61924743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015839679166674614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17149837811787924,
      "backward_entropy": 0.12658040523529052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.68307495117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015931228175759315,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17132830619812012,
      "backward_entropy": 0.13802759647369384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.65684509277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01602255553007126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17115734020868936,
      "backward_entropy": 0.12605687379837036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01611821912229061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17098148663838705,
      "backward_entropy": 0.1257918119430542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.751220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016216294839978218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17080247402191162,
      "backward_entropy": 0.12552521228790284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.0789031982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016314731910824776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17062107721964517,
      "backward_entropy": 0.1271984100341797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.65167236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016410518437623978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17044041554133096,
      "backward_entropy": 0.12496416568756104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.23696899414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016504039987921715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17026003201802573,
      "backward_entropy": 0.12466795444488525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.4849395751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01659669727087021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17007788022359213,
      "backward_entropy": 0.12435548305511475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.43643951416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016694987192749977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1698890527089437,
      "backward_entropy": 0.1263122081756592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.6057891845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016787152737379074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1697031855583191,
      "backward_entropy": 0.12607706785202027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.91825866699219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016879037022590637,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1695165236790975,
      "backward_entropy": 0.13798172473907472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.81031799316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016964124515652657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.169334610303243,
      "backward_entropy": 0.12297999858856201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.86805725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01705160178244114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16915225982666016,
      "backward_entropy": 0.12261483669281006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.70288848876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017137674614787102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16897024710973105,
      "backward_entropy": 0.12224011421203614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.59964752197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017220743000507355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16878914833068848,
      "backward_entropy": 0.12184962034225463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.19854736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01730111800134182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16860878467559814,
      "backward_entropy": 0.12144492864608765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.0884246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017375975847244263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16843239466349283,
      "backward_entropy": 0.1210237979888916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.32078552246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017454003915190697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16825197140375772,
      "backward_entropy": 0.1378795862197876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.78600311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0175248421728611,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16807695229848227,
      "backward_entropy": 0.12354199886322022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.61050415039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017592228949069977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16790199279785156,
      "backward_entropy": 0.12321088314056397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.48062133789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01766325905919075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16772037744522095,
      "backward_entropy": 0.119246506690979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.7386474609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01773582026362419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16753554344177246,
      "backward_entropy": 0.11878172159194947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.5136947631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017811739817261696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16734651724497476,
      "backward_entropy": 0.12223995923995971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.52471923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017882294952869415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16716082890828451,
      "backward_entropy": 0.11783583164215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.0007095336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01795293018221855,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16697307427724203,
      "backward_entropy": 0.12155653238296509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.9917755126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018017854541540146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16679213444391885,
      "backward_entropy": 0.11683735847473145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.64755249023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018083566799759865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16660812497138977,
      "backward_entropy": 0.12083122730255128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.19578552246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018153196200728416,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16641722122828165,
      "backward_entropy": 0.13765379190444946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.20640563964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018231185153126717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1662160356839498,
      "backward_entropy": 0.12012642621994019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.57550811767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018308443948626518,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1660128434499105,
      "backward_entropy": 0.11977458000183105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.10189056396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018383514136075974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16580969095230103,
      "backward_entropy": 0.1142730951309204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.6148223876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01845540665090084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16560939947764078,
      "backward_entropy": 0.11903643608093262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.3922882080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018530739471316338,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1654040813446045,
      "backward_entropy": 0.1375556468963623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.4264373779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018605774268507957,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1651978095372518,
      "backward_entropy": 0.1375342845916748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.1231231689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0186822060495615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1649874448776245,
      "backward_entropy": 0.13751389980316162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.7234344482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01875825598835945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16477510333061218,
      "backward_entropy": 0.11153078079223633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.99574279785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01883617788553238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1645610531171163,
      "backward_entropy": 0.1374751329421997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.9134063720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01891731098294258,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16434421141942343,
      "backward_entropy": 0.11676024198532105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.61669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019002189859747887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16412011782328287,
      "backward_entropy": 0.10988453626632691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.48986053466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01908244378864765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16389848788579306,
      "backward_entropy": 0.10930615663528442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.26553344726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01916065812110901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16367857654889426,
      "backward_entropy": 0.11558434963226319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.85182189941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019246257841587067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16344849268595377,
      "backward_entropy": 0.10813987255096436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8244400024414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019330723211169243,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16321844855944315,
      "backward_entropy": 0.13738081455230713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.7971649169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01941286027431488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16299116611480713,
      "backward_entropy": 0.1373639702796936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.36687469482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01949620060622692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1627630094687144,
      "backward_entropy": 0.10634899139404297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.82005310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019577020779252052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625360349814097,
      "backward_entropy": 0.10573737621307373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.591552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019658666104078293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16230511665344238,
      "backward_entropy": 0.11310884952545167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.24172973632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019734419882297516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16207613547643027,
      "backward_entropy": 0.11265678405761718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.30197143554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019818099215626717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16183696190516153,
      "backward_entropy": 0.1038317322731018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.10055541992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019905561581254005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16159160931905112,
      "backward_entropy": 0.11179306507110595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.15225219726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019996415823698044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16134067376454672,
      "backward_entropy": 0.10256403684616089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.54468536376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020089026540517807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16108733415603638,
      "backward_entropy": 0.11093682050704956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.82849884033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020180201157927513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16083621978759766,
      "backward_entropy": 0.10129425525665284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.5114288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020265046507120132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160591850678126,
      "backward_entropy": 0.10063393115997314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.75264739990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0203538928180933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034150123596191,
      "backward_entropy": 0.09998447895050049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.3656005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020438214763998985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16009322802225748,
      "backward_entropy": 0.09931385517120361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.28602600097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020518584176898003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15984690189361572,
      "backward_entropy": 0.10854156017303467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.2088165283203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020604833960533142,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1595911681652069,
      "backward_entropy": 0.13714195489883424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.5978240966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020692069083452225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15933485825856528,
      "backward_entropy": 0.10752137899398803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.47716522216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02078496292233467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15907315413157144,
      "backward_entropy": 0.09664254188537598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.43284606933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02087165042757988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15881977478663126,
      "backward_entropy": 0.09597891569137573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.29850769042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020955007523298264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15856499473253885,
      "backward_entropy": 0.09527766108512878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.29005432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021035801619291306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1583108107248942,
      "backward_entropy": 0.10542726516723633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.05918884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02111927978694439,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15805166959762573,
      "backward_entropy": 0.09383281469345092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.6278076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021203670650720596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15779001514116922,
      "backward_entropy": 0.09310944080352783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.48030853271484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021288994699716568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15752674142519632,
      "backward_entropy": 0.13705172538757324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.76055908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021369049325585365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1572716236114502,
      "backward_entropy": 0.09164984226226806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.8277816772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021447252482175827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1570179263750712,
      "backward_entropy": 0.09090293645858764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.15943908691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02152370475232601,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15676487485567728,
      "backward_entropy": 0.13699285984039306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.42713928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021594252437353134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15652159849802652,
      "backward_entropy": 0.0893748641014099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.62107849121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021660849452018738,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15628341833750406,
      "backward_entropy": 0.10091015100479125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.75303649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02173171564936638,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15603707234064737,
      "backward_entropy": 0.1003027081489563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4192657470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021807735785841942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1557808816432953,
      "backward_entropy": 0.0870465874671936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.74047088623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021886980161070824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15551855166753134,
      "backward_entropy": 0.08627417087554931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.5653839111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021964972838759422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15525989731152853,
      "backward_entropy": 0.08550773859024048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.18528366088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022044308483600616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15499780575434366,
      "backward_entropy": 0.09793336391448974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.51052856445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02211570180952549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15474794308344522,
      "backward_entropy": 0.08394500017166137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4564971923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022194145247340202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15448727210362753,
      "backward_entropy": 0.09668374061584473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2860870361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02227460779249668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15422525008519491,
      "backward_entropy": 0.09607361555099488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.0108642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022357817739248276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15395689010620117,
      "backward_entropy": 0.09547253847122192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.327880859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02244398556649685,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1536846955617269,
      "backward_entropy": 0.13673317432403564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.8692855834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022524641826748848,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15341954429944357,
      "backward_entropy": 0.08013011813163758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.13239288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02259860374033451,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15316280722618103,
      "backward_entropy": 0.07933549880981446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.94719696044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022670140489935875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15291021267573038,
      "backward_entropy": 0.13665808439254762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.62238311767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022742774337530136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15265794595082602,
      "backward_entropy": 0.07775782346725464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.19136047363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022813254967331886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15241002043088278,
      "backward_entropy": 0.07697261571884155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.41476440429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02287958562374115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15216525395711264,
      "backward_entropy": 0.07616235017776489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.16520690917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022948933765292168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15191501379013062,
      "backward_entropy": 0.09035371541976929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.37417602539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023019203916192055,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15166138609250387,
      "backward_entropy": 0.13650112152099608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023091942071914673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15140252312024435,
      "backward_entropy": 0.0890468716621399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.80290222167969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023167012259364128,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15114019314448038,
      "backward_entropy": 0.1364531397819519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.24091339111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023241057991981506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15087974071502686,
      "backward_entropy": 0.08775672912597657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.0757293701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02331620082259178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.150620698928833,
      "backward_entropy": 0.08711998462677002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.51446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023397132754325867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15035484234491983,
      "backward_entropy": 0.07062711715698242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.39776611328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02347688004374504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1500933567682902,
      "backward_entropy": 0.06988039016723632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.02995300292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023555023595690727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1498322089513143,
      "backward_entropy": 0.06911751627922058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.5581283569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023630589246749878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14957588911056519,
      "backward_entropy": 0.08457030057907104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.46820068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02370348386466503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14932232101758322,
      "backward_entropy": 0.06756696701049805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.7503662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02377571538090706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1490691900253296,
      "backward_entropy": 0.06678149700164795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.91275787353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02385350689291954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14880677064259848,
      "backward_entropy": 0.06601571440696716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.47882843017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023930273950099945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14854522546132407,
      "backward_entropy": 0.08194324374198914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.03539276123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02400335483253002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14829299847284952,
      "backward_entropy": 0.06449015736579895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.48619079589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024076201021671295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14804325501124063,
      "backward_entropy": 0.08062131404876709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.82928466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024151353165507317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14778811732927957,
      "backward_entropy": 0.07996336221694947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.251163482666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024224309250712395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14753718177477518,
      "backward_entropy": 0.07929248809814453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.8262710571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024290408939123154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14729692538579306,
      "backward_entropy": 0.06143725514411926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.88172912597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024357328191399574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14705955982208252,
      "backward_entropy": 0.07790427803993225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.85903930664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024424299597740173,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14681996901830038,
      "backward_entropy": 0.07722194194793701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6089096069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024494558572769165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14657580852508545,
      "backward_entropy": 0.059190183877944946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.29866790771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02456178516149521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14633731047312418,
      "backward_entropy": 0.05844976902008057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.60060119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024629108607769012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14609764019648233,
      "backward_entropy": 0.05770605802536011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.46339416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0246935673058033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14586305618286133,
      "backward_entropy": 0.07452675104141235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.43162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02475709840655327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14563039938608804,
      "backward_entropy": 0.056210672855377196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.61681365966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024827741086483,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1453899840513865,
      "backward_entropy": 0.05549962520599365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.3988265991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024892354384064674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14516101280848184,
      "backward_entropy": 0.05478260517120361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.6277313232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024954214692115784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14493469397226968,
      "backward_entropy": 0.07182985544204712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.52938079833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025028014555573463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14469096064567566,
      "backward_entropy": 0.07119920253753662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.29054260253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025101661682128906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14444960157076517,
      "backward_entropy": 0.052693653106689456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.32337951660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025173678994178772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14421107371648154,
      "backward_entropy": 0.052019113302230836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.18499755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025250190868973732,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14396427075068155,
      "backward_entropy": 0.05134984254837036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.92464828491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025327684357762337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14371708035469055,
      "backward_entropy": 0.05068249702453613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.64964294433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025400102138519287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14347976446151733,
      "backward_entropy": 0.05001094341278076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.06820678710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547253668308258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1432427167892456,
      "backward_entropy": 0.04934257864952087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.3743896484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0255481768399477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14300215244293213,
      "backward_entropy": 0.04869162142276764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.90825653076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025634033605456352,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14274587233861288,
      "backward_entropy": 0.06621453762054444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.5276336669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02572009153664112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14249010880788168,
      "backward_entropy": 0.04745391309261322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.62500762939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02581258863210678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14222746094067892,
      "backward_entropy": 0.04687575101852417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.27864837646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02590174600481987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1419726014137268,
      "backward_entropy": 0.046289455890655515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.59132385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02599073201417923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14171838760375977,
      "backward_entropy": 0.04569721817970276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.14456939697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026081206277012825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1414636274178823,
      "backward_entropy": 0.0451127290725708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.62551879882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026168525218963623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1412153740723928,
      "backward_entropy": 0.06276594400405884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.82278442382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026260366663336754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14095908403396606,
      "backward_entropy": 0.06219706535339355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.23292541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02634761668741703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14071433742841086,
      "backward_entropy": 0.06161420345306397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.1460952758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02643357403576374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14047406117121378,
      "backward_entropy": 0.04278805255889893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.59595489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02651705965399742,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14023876190185547,
      "backward_entropy": 0.06044315099716187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.1943588256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026594674214720726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14001023769378662,
      "backward_entropy": 0.05983313322067261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.38721466064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026673510670661926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13978076974550882,
      "backward_entropy": 0.05923107862472534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.8716812133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026748869568109512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13955690463383993,
      "backward_entropy": 0.040451779961586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.77149200439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0268244706094265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1393357217311859,
      "backward_entropy": 0.05802019834518433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.00200653076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026897193863987923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13912092645963034,
      "backward_entropy": 0.03931612968444824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.737022399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026965932920575142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1389150619506836,
      "backward_entropy": 0.03875607252120972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.08854675292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027029311284422874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13871775070826212,
      "backward_entropy": 0.05618477463722229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.35665130615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027094239369034767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13852093617121378,
      "backward_entropy": 0.0555780291557312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.9597806930542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027162067592144012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1383210519949595,
      "backward_entropy": 0.037110930681228636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.290916442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027221333235502243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13813191652297974,
      "backward_entropy": 0.036561861634254456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.87013244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02727629989385605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13795024156570435,
      "backward_entropy": 0.036012116074562076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.1982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02733791433274746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13775933782259622,
      "backward_entropy": 0.035482197999954224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.57450103759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027399547398090363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13756761948267618,
      "backward_entropy": 0.05259295701980591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.1079216003418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027464328333735466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13737307985623678,
      "backward_entropy": 0.034449833631515506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.21407318115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02752596326172352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13718384504318237,
      "backward_entropy": 0.03394128084182739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.14198303222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027586357668042183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13699817657470703,
      "backward_entropy": 0.033438628911972045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.36251068115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027645597234368324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13681544860204062,
      "backward_entropy": 0.032940471172332765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.97293853759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02770947478711605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366237203280131,
      "backward_entropy": 0.03244821429252624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.739707946777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027777675539255142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13642390569051108,
      "backward_entropy": 0.04927201867103577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.5939712524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02784227579832077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13622956474622092,
      "backward_entropy": 0.03148305416107178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.862177848815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02790871076285839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603723049163818,
      "backward_entropy": 0.03102068603038788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7694091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027967361733317375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13585580388704935,
      "backward_entropy": 0.030550965666770936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.56959533691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02802957408130169,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567338387171426,
      "backward_entropy": 0.030095118284225463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.13753509521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02809818461537361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13548349340756735,
      "backward_entropy": 0.04667655229568481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.90925598144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028169583529233932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13528976837793985,
      "backward_entropy": 0.029246792197227478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.67011260986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02824350818991661,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13509511947631836,
      "backward_entropy": 0.028839197754859925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.41059112548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028316680341959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13490297396977743,
      "backward_entropy": 0.0284344881772995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.17778015136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02838626131415367,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13471784194310507,
      "backward_entropy": 0.044806578755378725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.3546142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028460131958127022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13452876607577005,
      "backward_entropy": 0.027638226747512817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.33572769165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028531618416309357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13434223333994547,
      "backward_entropy": 0.04389339089393616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.93433380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028599392622709274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1341596245765686,
      "backward_entropy": 0.026840245723724364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.26691436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02866416424512863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1339824398358663,
      "backward_entropy": 0.0429562658071518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.040576934814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028732357546687126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13380233446756998,
      "backward_entropy": 0.026062703132629393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.02899932861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028794430196285248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13363134860992432,
      "backward_entropy": 0.025678882002830507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.17378234863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028860006481409073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1334555447101593,
      "backward_entropy": 0.0416111022233963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.36244201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028924506157636642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13328254222869873,
      "backward_entropy": 0.02494550496339798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.4139404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028993817046284676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13310493032137552,
      "backward_entropy": 0.024596193432807924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.0046615600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02905862219631672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13293461998303732,
      "backward_entropy": 0.024247805774211883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.95134735107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02912692353129387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13275988896687826,
      "backward_entropy": 0.039962223172187804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.50503540039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029198160395026207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1325815717379252,
      "backward_entropy": 0.023585304617881775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.51207733154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029267769306898117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13240707914034525,
      "backward_entropy": 0.03918963968753815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.10044860839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029335716739296913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13223483165105185,
      "backward_entropy": 0.022935612499713896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.47102737426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029406927525997162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1320610245068868,
      "backward_entropy": 0.038422691822052005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.12102508544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029475025832653046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13189204533894858,
      "backward_entropy": 0.13541367053985595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.541221618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02954806014895439,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13172013560930887,
      "backward_entropy": 0.022012391686439516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.79731750488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02961650677025318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13155579566955566,
      "backward_entropy": 0.03731836080551147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.7334976196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029689619317650795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13138588269551596,
      "backward_entropy": 0.03697110116481781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.370662689208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029762906953692436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13121910889943442,
      "backward_entropy": 0.036633601784706114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.07054138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029834406450390816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13105452060699463,
      "backward_entropy": 0.020888945460319518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.80119323730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029907407239079475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13088862101236978,
      "backward_entropy": 0.03596430122852325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.0207405090332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029981879517436028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13072340687115988,
      "backward_entropy": 0.02036276161670685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.77444076538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03005162626504898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1305645008881887,
      "backward_entropy": 0.020100684463977815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.76222610473633,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030119989067316055,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13040821750958762,
      "backward_entropy": 0.1356513738632202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.22871780395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030184390023350716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13025808334350586,
      "backward_entropy": 0.03465606868267059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03024844266474247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1301076610883077,
      "backward_entropy": 0.019320692121982574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.35121154785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030310416594147682,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1299614210923513,
      "backward_entropy": 0.1356859803199768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.0477294921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030373627319931984,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12981697916984558,
      "backward_entropy": 0.13570129871368408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.10099029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03043624758720398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12967248757680258,
      "backward_entropy": 0.018587449193000795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.32855224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03049994446337223,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1295257310072581,
      "backward_entropy": 0.033106690645217894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.89051818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030567679554224014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12937512000401816,
      "backward_entropy": 0.018127134442329405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.45731353759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03063763491809368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12922292947769165,
      "backward_entropy": 0.017909936606884003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.55601501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030708273872733116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12907197078069052,
      "backward_entropy": 0.01770147532224655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.704296112060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030780740082263947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1289196014404297,
      "backward_entropy": 0.01749656945466995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.70946502685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030847614631056786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12877535820007324,
      "backward_entropy": 0.031764835119247437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.583492279052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030911007896065712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12863558530807495,
      "backward_entropy": 0.017085492610931396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.509023666381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030971381813287735,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1285013755162557,
      "backward_entropy": 0.03123452067375183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.5831069946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03102743811905384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12837366263071695,
      "backward_entropy": 0.016684788465499877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.40335845947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03108547255396843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1282462477684021,
      "backward_entropy": 0.030711719393730165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.2602481842041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03114832565188408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12811302145322165,
      "backward_entropy": 0.01630645990371704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.03688049316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03120686672627926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12798655033111572,
      "backward_entropy": 0.030236521363258363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.234899520874023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127012401819229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1278539498647054,
      "backward_entropy": 0.01595149040222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.80253219604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031328823417425156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1277271807193756,
      "backward_entropy": 0.015775410830974577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.76324462890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03138815611600876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1276011566321055,
      "backward_entropy": 0.015607550740242004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.09416198730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03144783899188042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12747485438982645,
      "backward_entropy": 0.015442320704460144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.52458953857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03151367977261543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12734079360961914,
      "backward_entropy": 0.02914092242717743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.25228118896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03157917410135269,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12720786531766257,
      "backward_entropy": 0.015126362442970276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.199302673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031645677983760834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1270719567934672,
      "backward_entropy": 0.014968299865722656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.6263656616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03171196207404137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1269369920094808,
      "backward_entropy": 0.028537946939468383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.43192291259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03178086131811142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12679986159006754,
      "backward_entropy": 0.014666825532913208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.24286651611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0318521223962307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12666049599647522,
      "backward_entropy": 0.028166761994361876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.60883712768555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03192548081278801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12651928265889487,
      "backward_entropy": 0.014379681646823883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.5025749206543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03199807181954384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12638059258460999,
      "backward_entropy": 0.01424230933189392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.69021987915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03206983953714371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12624377012252808,
      "backward_entropy": 0.014107003808021545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.80055236816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032139576971530914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12611067295074463,
      "backward_entropy": 0.02748257517814636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.09777069091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032210323959589005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.125974973042806,
      "backward_entropy": 0.013848230242729187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.4796142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03228037804365158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12584139903386435,
      "backward_entropy": 0.013722068071365357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.33175659179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03235136717557907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12571042776107788,
      "backward_entropy": 0.013600194454193115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.618289947509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03242310881614685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12557599941889444,
      "backward_entropy": 0.013480418920516967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.07876968383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032494306564331055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12544300158818564,
      "backward_entropy": 0.026717564463615416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.91835403442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03256065398454666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12531606356302896,
      "backward_entropy": 0.013249462842941285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.38642501831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032625481486320496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1251902182896932,
      "backward_entropy": 0.026430994272232056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.680213928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03268754482269287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1250680387020111,
      "backward_entropy": 0.013023477792739869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.95189666748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03274867311120033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12494720021883647,
      "backward_entropy": 0.012914787232875823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.496978759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281038627028465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.124825914700826,
      "backward_entropy": 0.012809433043003082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.02777862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03287110850214958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1247057318687439,
      "backward_entropy": 0.0127053365111351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.577789306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032933857291936874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12458320458730061,
      "backward_entropy": 0.012604445219039917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.70649719238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0329970084130764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12446009119351704,
      "backward_entropy": 0.012505559623241425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.324455261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03306202217936516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12433491150538127,
      "backward_entropy": 0.012409837543964386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.17937469482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033121563494205475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12421839435895284,
      "backward_entropy": 0.012316083908081055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.691322326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033181920647621155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12410058577855428,
      "backward_entropy": 0.01222502589225769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.11614227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03323996067047119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12398374080657959,
      "backward_entropy": 0.01213315948843956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.673492431640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03330034017562866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12386463085810344,
      "backward_entropy": 0.012044063955545425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.43511962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03335994854569435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12374705076217651,
      "backward_entropy": 0.024956344068050383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.580326080322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03341754898428917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12363227208455403,
      "backward_entropy": 0.02485131174325943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.29201889038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03347606584429741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12351550658543904,
      "backward_entropy": 0.011786460876464844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.32755661010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03353266045451164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12340219815572102,
      "backward_entropy": 0.0117034450173378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.202964782714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033590372651815414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12328688303629558,
      "backward_entropy": 0.011622097343206406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.081329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033649131655693054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1231704552968343,
      "backward_entropy": 0.01154259592294693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.94236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03370734304189682,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12305460373560588,
      "backward_entropy": 0.13714380264282228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.82260513305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0337679460644722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12293538451194763,
      "backward_entropy": 0.011386743187904358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.83943176269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03382940590381622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12281519174575806,
      "backward_entropy": 0.011312771588563919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.4878921508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03388870880007744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12269842624664307,
      "backward_entropy": 0.024086014926433565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.5746955871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03395030274987221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1225780447324117,
      "backward_entropy": 0.02400165647268295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.460086822509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03401106595993042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12245911359786987,
      "backward_entropy": 0.023916274309158325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.02605438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034071240574121475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1223405400911967,
      "backward_entropy": 0.011027531325817108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.06291580200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0341336689889431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12221887707710266,
      "backward_entropy": 0.010960162431001664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.70539093017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034196723252534866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12209613124529521,
      "backward_entropy": 0.010894013941287995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.28327560424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034261833876371384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12197005748748779,
      "backward_entropy": 0.010829871147871017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.932987213134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034324560314416885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1218487819035848,
      "backward_entropy": 0.010768385231494903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.23340606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0343865305185318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1217283308506012,
      "backward_entropy": 0.023465514183044434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.06902313232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03445061296224594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12160450220108032,
      "backward_entropy": 0.010649428516626359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.90604782104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03451666608452797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12147796154022217,
      "backward_entropy": 0.010591927170753478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.257598876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034584447741508484,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12134834130605061,
      "backward_entropy": 0.023273439705371858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.576908111572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03464815393090248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1212257444858551,
      "backward_entropy": 0.010480783879756927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.844818115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03471381962299347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12110020716985066,
      "backward_entropy": 0.023156937956809998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.167266845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034779880195856094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12097434202829997,
      "backward_entropy": 0.023102638125419617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.59492492675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034844912588596344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12085044384002686,
      "backward_entropy": 0.010325420647859573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.94384002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03491313382983208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12071983019510905,
      "backward_entropy": 0.010274985432624817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.73988723754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03498009219765663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12059140205383301,
      "backward_entropy": 0.022942741215229035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.27271270751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03504875302314758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1204602320988973,
      "backward_entropy": 0.01017725169658661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.377174377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03512442111968994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12031636635462443,
      "backward_entropy": 0.01012808308005333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.459774017333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03520086780190468,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12017119924227397,
      "backward_entropy": 0.022784064710140228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.00166130065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03527519851922989,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12002992630004883,
      "backward_entropy": 0.01003144234418869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.51541519165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03534630686044693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11989408731460571,
      "backward_entropy": 0.022680336236953737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.821043014526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035417284816503525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1197583278020223,
      "backward_entropy": 0.022631511092185974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.221004486083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035485390573740005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11962738633155823,
      "backward_entropy": 0.02258588969707489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.50554656982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035553690046072006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11949487527211507,
      "backward_entropy": 0.009855853766202927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.9251708984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03562486544251442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11935927470525105,
      "backward_entropy": 0.00981416255235672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.61986541748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03569589555263519,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11922311782836914,
      "backward_entropy": 0.0224549800157547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.37415313720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03576543927192688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11908889810244243,
      "backward_entropy": 0.00973455309867859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.36936569213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03584316745400429,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11894011497497559,
      "backward_entropy": 0.022366926074028015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.300514221191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03591874986886978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11879523595174153,
      "backward_entropy": 0.022322927415370942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.16880416870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035993754863739014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11865031719207764,
      "backward_entropy": 0.009614219516515731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.97451400756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036069609224796295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11850353082021077,
      "backward_entropy": 0.009575653821229935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.88991928100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036146193742752075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11835529406865437,
      "backward_entropy": 0.00953703373670578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.795583724975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03621937334537506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11821301778157552,
      "backward_entropy": 0.009500662982463836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.60691452026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03628946468234062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11807578802108765,
      "backward_entropy": 0.022110149264335632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.616374969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03635815903544426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11794048547744751,
      "backward_entropy": 0.009433451294898986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.21709442138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036424219608306885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11780961354573567,
      "backward_entropy": 0.009402704238891602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.88810348510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036490630358457565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11767753958702087,
      "backward_entropy": 0.009371912479400635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.9254150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036558739840984344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11754194895426433,
      "backward_entropy": 0.009340700507164002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.77685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036627013236284256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11740509668986003,
      "backward_entropy": 0.009309852123260498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.4512882232666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036695446819067,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11726675430933635,
      "backward_entropy": 0.02188234031200409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.87987518310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03675992786884308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11713590224583943,
      "backward_entropy": 0.009252168238162994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.67021942138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03682763874530792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11699827512105306,
      "backward_entropy": 0.00922338366508484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.191104888916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03689420223236084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11686259508132935,
      "backward_entropy": 0.009195977449417114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.435333251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036961086094379425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11672556400299072,
      "backward_entropy": 0.02174004018306732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.31893539428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03702690452337265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11658972501754761,
      "backward_entropy": 0.009142909198999405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.7550048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037091758102178574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1164551575978597,
      "backward_entropy": 0.02167012691497803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.61005401611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03715710714459419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11631937821706136,
      "backward_entropy": 0.009092842787504196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.479366302490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03722289949655533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11618218819300334,
      "backward_entropy": 0.02160104364156723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.394014358520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03728639334440231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11604944864908855,
      "backward_entropy": 0.021569353342056275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.748477935791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03734780102968216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11592044432957967,
      "backward_entropy": 0.009024516493082047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.63948440551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03740869089961052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11579181750615437,
      "backward_entropy": 0.009004061669111251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.530921936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03746911138296127,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1156635582447052,
      "backward_entropy": 0.021483877301216127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.42354202270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037529107183218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1155355970064799,
      "backward_entropy": 0.008964910358190536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.9716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037588730454444885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11540796359380086,
      "backward_entropy": 0.008946281671524049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.904800415039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0376507006585598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11527417103449504,
      "backward_entropy": 0.008926720917224884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.91213989257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0377107709646225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1151445706685384,
      "backward_entropy": 0.008909479528665543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.223384857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037774458527565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11500597993532817,
      "backward_entropy": 0.008890236169099808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.86309051513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03783874958753586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11486536264419556,
      "backward_entropy": 0.02130877524614334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.11807632446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03790224343538284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1147279143333435,
      "backward_entropy": 0.008853863179683685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.62691116333008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03796769678592682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11458512147267659,
      "backward_entropy": 0.008835898339748382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.885738372802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03803221508860588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11444367965062459,
      "backward_entropy": 0.008818630874156953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.7627182006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03809988498687744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11429476737976074,
      "backward_entropy": 0.008799511939287186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.314144134521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03817170113325119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11413534482320149,
      "backward_entropy": 0.00877804383635521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.17689895629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03824326768517494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11397573351860046,
      "backward_entropy": 0.008757035434246063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.9764518737793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03831591457128525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11381300290425618,
      "backward_entropy": 0.00873543918132782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.930849075317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838954493403435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1136473019917806,
      "backward_entropy": 0.008713958412408828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.794124603271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03845876827836037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11349172393480937,
      "backward_entropy": 0.008696674555540084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.804141998291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03852532431483269,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11334174871444702,
      "backward_entropy": 0.00868171751499176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879965782165527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03858814015984535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11320024728775024,
      "backward_entropy": 0.020930013060569762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.377105712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03864629939198494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11307001113891602,
      "backward_entropy": 0.008661215752363205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.08291244506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03870425000786781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11293961604436238,
      "backward_entropy": 0.008653795719146729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.5858097076416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03876331448554993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11280585328737895,
      "backward_entropy": 0.008645866811275483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.295724868774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038819413632154465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11267902453740437,
      "backward_entropy": 0.008640484511852264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.949825286865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038874201476573944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11255489786465962,
      "backward_entropy": 0.008636896312236787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7228364944458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0389290452003479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11242958903312683,
      "backward_entropy": 0.008632667362689972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.75381088256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038980018347501755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11231415470441182,
      "backward_entropy": 0.008631685376167297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012508784420788288,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03903145715594292,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11219668388366699,
      "backward_entropy": 0.020789073407649995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.211181640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0390780009329319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.112091859181722,
      "backward_entropy": 0.00863248184323311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.245981216430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03912680223584175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1119802991549174,
      "backward_entropy": 0.008633412420749664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.79787254333496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03917362913489342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11187366644541423,
      "backward_entropy": 0.0207630917429924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.44818878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039220038801431656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1117671529452006,
      "backward_entropy": 0.020755207538604735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.20872116088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039270006120204926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1116504967212677,
      "backward_entropy": 0.02074209749698639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.6365966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03932053595781326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11153165499369304,
      "backward_entropy": 0.008639269322156907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.50665283203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03937287628650665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.111407071352005,
      "backward_entropy": 0.020710106194019317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.962011337280273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039426736533641815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11127724250157674,
      "backward_entropy": 0.008633288741111755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.15315628051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0394781231880188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1111538012822469,
      "backward_entropy": 0.00863092690706253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.28021240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953379765152931,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11101766427357991,
      "backward_entropy": 0.008624600619077683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.990196228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03958812355995178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11088478565216064,
      "backward_entropy": 0.020611268281936646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.118770599365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03964382782578468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11074737707773845,
      "backward_entropy": 0.008612857013940812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.724483489990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039698146283626556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11061316728591919,
      "backward_entropy": 0.008606991171836853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.2156982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039753884077072144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11047420899073283,
      "backward_entropy": 0.008600524812936782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.15861892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03981348127126694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11032408475875854,
      "backward_entropy": 0.008591309189796448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.529783248901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039872683584690094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11017433802286784,
      "backward_entropy": 0.008583268523216248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.705631256103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039928875863552094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11003301541010539,
      "backward_entropy": 0.008577898144721985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.42664337158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998372703790665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10989526907602946,
      "backward_entropy": 0.008574818074703217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.53524398803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040042515844106674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1097454031308492,
      "backward_entropy": 0.008569003641605377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.02584457397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040099624544382095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10959982872009277,
      "backward_entropy": 0.008564454317092896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.47492599487305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0401604101061821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1094428300857544,
      "backward_entropy": 0.008557114005088805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.43892288208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04022061824798584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10928677519162495,
      "backward_entropy": 0.008550363779067992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.34021759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040281590074300766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10912789901097615,
      "backward_entropy": 0.008543337881565093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.17502975463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04034452140331268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1089622974395752,
      "backward_entropy": 0.008534646034240723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.941429138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041052237153053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.108786940574646,
      "backward_entropy": 0.00852399542927742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.748558044433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04047921299934387,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10860282182693481,
      "backward_entropy": 0.13838040828704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.53444290161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04054907709360123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10841457049051921,
      "backward_entropy": 0.008497112989425659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.44277572631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04061990603804588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10822208722432454,
      "backward_entropy": 0.008481816947460174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.958457946777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040690433233976364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.108030100663503,
      "backward_entropy": 0.008467807620763778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.2752685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04076318070292473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10783068339029948,
      "backward_entropy": 0.019880756735801697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.13149070739746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040834225714206696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10763617356618245,
      "backward_entropy": 0.008440707623958588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.207027435302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04090370610356331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10744588573773702,
      "backward_entropy": 0.008431950211524963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.845182418823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04097549989819527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10724764068921407,
      "backward_entropy": 0.019745834171772003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.033966064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041045598685741425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10705393552780151,
      "backward_entropy": 0.019703872501850128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.5560245513916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04111657291650772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10685628652572632,
      "backward_entropy": 0.008404216170310974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.80276870727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04118581861257553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10666314760843913,
      "backward_entropy": 0.00839538425207138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.827980041503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0412585623562336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10645793875058492,
      "backward_entropy": 0.01956275999546051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.126209259033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04133065789937973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10625382264455159,
      "backward_entropy": 0.019512474536895752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.496126174926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04140099510550499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10605468352635701,
      "backward_entropy": 0.008363875746726989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.75121307373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04146847128868103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10586427648862202,
      "backward_entropy": 0.008358503878116607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.53364944458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04153716564178467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10566890239715576,
      "backward_entropy": 0.008353617787361146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.46111297607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041606783866882324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10546924670537312,
      "backward_entropy": 0.019344009459018707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.75033950805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041680898517370224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10525357723236084,
      "backward_entropy": 0.008334969729185104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.646507263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041754160076379776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1050397555033366,
      "backward_entropy": 0.019237138330936432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.585481643676758,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0418228954076767,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10484063625335693,
      "backward_entropy": 0.1383910894393921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.45973587036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04188774898648262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10465452075004578,
      "backward_entropy": 0.008313404023647308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.45681381225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04195398464798927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10446256399154663,
      "backward_entropy": 0.00831131786108017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.543350219726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042022671550512314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10426121950149536,
      "backward_entropy": 0.019074636697769164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.83310317993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04208860918879509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.104068656762441,
      "backward_entropy": 0.008307942003011704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.52824401855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04215563088655472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10387090841929118,
      "backward_entropy": 0.008305449783802033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.234683990478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04222239926457405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10367293159166972,
      "backward_entropy": 0.008302127569913864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04733714833855629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04228658974170685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1034833590189616,
      "backward_entropy": 0.018921023607254027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.041669845581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04234476387500763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10331561168034871,
      "backward_entropy": 0.008307720720767974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.988408088684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04240235313773155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10314881801605225,
      "backward_entropy": 0.008313531428575516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.865589141845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04245707392692566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1029919981956482,
      "backward_entropy": 0.008323156833648681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.44839859008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042510226368904114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10283983747164409,
      "backward_entropy": 0.00833209827542305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.34971237182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042567115277051926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10267278552055359,
      "backward_entropy": 0.008340037614107131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.460573196411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042625922709703445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10249727964401245,
      "backward_entropy": 0.018762220442295075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.98526382446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04268406704068184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10232394933700562,
      "backward_entropy": 0.008350197225809097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.585044860839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04274404048919678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10214126110076904,
      "backward_entropy": 0.008353646844625473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.834388732910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042806774377822876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10194777448972066,
      "backward_entropy": 0.018654006719589233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.495084762573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04286948963999748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1017532745997111,
      "backward_entropy": 0.008350427448749542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.437013626098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042928580194711685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10157199700673421,
      "backward_entropy": 0.008349260687828064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.36881637573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04298454523086548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10140234231948853,
      "backward_entropy": 0.008351623266935348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.5872859954834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043041303753852844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10122851530710857,
      "backward_entropy": 0.008353738486766816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.068885803222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309764876961708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10105559229850769,
      "backward_entropy": 0.008357962220907211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.34147834777832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04315473139286041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10087875525156657,
      "backward_entropy": 0.008361779153347015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.312164306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04321117699146271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10070347785949707,
      "backward_entropy": 0.008364929258823395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.608795166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04326961934566498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10051938891410828,
      "backward_entropy": 0.008368006348609925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.493789672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04332848638296127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10033263762791951,
      "backward_entropy": 0.008369702100753783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.099735260009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04338543489575386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10015297929445903,
      "backward_entropy": 0.008373802155256271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.796043395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04344780743122101,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09995085000991821,
      "backward_entropy": 0.008374013006687164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.954267501831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043514955788850784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09972914059956868,
      "backward_entropy": 0.008369789272546769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.11492156982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043581753969192505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09950811664263408,
      "backward_entropy": 0.008367154747247696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.286027908325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04364927485585213,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09928346673647563,
      "backward_entropy": 0.018028372526168825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.68304443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0437152199447155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09906450907389323,
      "backward_entropy": 0.008362001925706863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.46849822998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04378194361925125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09884155790011089,
      "backward_entropy": 0.008359337598085404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.650707244873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04384942725300789,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09861462314923604,
      "backward_entropy": 0.017875884473323823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.71505355834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391387477517128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09839967886606853,
      "backward_entropy": 0.008353722840547561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.70162010192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04397701472043991,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09818938374519348,
      "backward_entropy": 0.008353962004184723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.531085968017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04403983801603317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09797958532969157,
      "backward_entropy": 0.008351439237594604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.246837615966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044102367013692856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09777005513509114,
      "backward_entropy": 0.008346443623304367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.146480560302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04416264221072197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09756903847058614,
      "backward_entropy": 0.0083466537296772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.04769515991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044220760464668274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0973767638206482,
      "backward_entropy": 0.008349435776472092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.888370513916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04427807778120041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09718753894170125,
      "backward_entropy": 0.008353133499622346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.66135025024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04433584213256836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09699535369873047,
      "backward_entropy": 0.008356856554746628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.568389892578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04439496994018555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09679601589838664,
      "backward_entropy": 0.017408858239650726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.40545082092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04445426166057587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09659503897031148,
      "backward_entropy": 0.008357362449169159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.408008575439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04451364278793335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09639290968577068,
      "backward_entropy": 0.008356458693742751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.673266410827637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044572003185749054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09619436661402385,
      "backward_entropy": 0.008356641978025436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.9356689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462713003158569,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09601017832756042,
      "backward_entropy": 0.008359805494546891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.295438766479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044683024287223816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09582092364629109,
      "backward_entropy": 0.00836620181798935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.631145477294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044737134128808975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09563930829366048,
      "backward_entropy": 0.017110341787338258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.798295974731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04479183256626129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0954541265964508,
      "backward_entropy": 0.008382377028465272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.68147087097168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044845882803201675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09527111053466797,
      "backward_entropy": 0.00838935300707817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.187116622924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04489951208233833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09508489569028218,
      "backward_entropy": 0.008398469537496567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.81679916381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04495382681488991,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09490178028742473,
      "backward_entropy": 0.008405322581529618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.631596088409424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045012034475803375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09469868739446004,
      "backward_entropy": 0.008405555784702302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.79148483276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045065898448228836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09451411167780559,
      "backward_entropy": 0.008410555869340896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.070913314819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512273520231247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09431483348210652,
      "backward_entropy": 0.008415260165929795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.422592163085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045176420360803604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09412992993990581,
      "backward_entropy": 0.008422239124774933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.832990646362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04523053765296936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09394226471583049,
      "backward_entropy": 0.016696670651435853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.303686141967773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045283976942300797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09375713268915813,
      "backward_entropy": 0.008430429548025132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.21837043762207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04533559828996658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09358023603757222,
      "backward_entropy": 0.00843389555811882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07281361520290375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04538571089506149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09340978662172954,
      "backward_entropy": 0.008439029008150101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.059083938598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04543105885386467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09326225519180298,
      "backward_entropy": 0.008448363840579986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.20393753051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04547523334622383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0931200385093689,
      "backward_entropy": 0.008454516530036926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.628519058227539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04552314057946205,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09295860926310222,
      "backward_entropy": 0.13845038414001465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.082275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04556887969374657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09280693531036377,
      "backward_entropy": 0.008467409014701843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.526350021362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04561498761177063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09265246987342834,
      "backward_entropy": 0.00847894251346588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.084774017333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565900191664696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09250821669896443,
      "backward_entropy": 0.008492423593997956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07271113246679306,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04570420831441879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09235717852910359,
      "backward_entropy": 0.008500462770462036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.1536979675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04574526101350784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09222652514775594,
      "backward_entropy": 0.01616072505712509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.460922241210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04579032212495804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09207499027252197,
      "backward_entropy": 0.008526118844747544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.491331100463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04583440721035004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09192778666814168,
      "backward_entropy": 0.008537804335355758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.312074661254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045878924429416656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09177748362223308,
      "backward_entropy": 0.008551574498414993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.297990798950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045922692865133286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0916301707426707,
      "backward_entropy": 0.008567804843187333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.292537689208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045966386795043945,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09148309628168742,
      "backward_entropy": 0.008577565848827361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.10879135131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04601356014609337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09131803115208943,
      "backward_entropy": 0.00858258232474327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.022395133972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046065203845500946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09112993876139323,
      "backward_entropy": 0.008586467057466508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.70692825317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04611428081989288,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0909544825553894,
      "backward_entropy": 0.00859507843852043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.829127311706543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04616643488407135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09076227744420369,
      "backward_entropy": 0.00860207825899124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.632768630981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04621683806180954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09057899316151936,
      "backward_entropy": 0.008609160780906677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.5184383392334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046266864985227585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0903970201810201,
      "backward_entropy": 0.015669919550418854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.573701858520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046316687017679214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09021598100662231,
      "backward_entropy": 0.008628320693969727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.913511276245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046365153044462204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09004177649815877,
      "backward_entropy": 0.008642017841339111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.748428344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04641551524400711,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08985730012257893,
      "backward_entropy": 0.008653149753808976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.821090698242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04646727442741394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08966595927874248,
      "backward_entropy": 0.008657389879226684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.232587814331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04651936888694763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08947251240412395,
      "backward_entropy": 0.00865902304649353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.52774429321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04656974598765373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08928751945495605,
      "backward_entropy": 0.008662541955709457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.402273178100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04662071913480759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08909894029299419,
      "backward_entropy": 0.008665844798088074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.980429649353027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04666882008314133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08892518281936646,
      "backward_entropy": 0.008669062703847884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.719785690307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04671547934412956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08875866731007893,
      "backward_entropy": 0.00867246612906456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.657935619354248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046764206141233444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08858046929041545,
      "backward_entropy": 0.015173123776912689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.292034149169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046809326857328415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08842114607493083,
      "backward_entropy": 0.008682204037904739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.603011608123779,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046854518353939056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08826062083244324,
      "backward_entropy": 0.008689826726913452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.11294174194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689665138721466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08811569213867188,
      "backward_entropy": 0.01503961682319641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.99195671081543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046943411231040955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08794556061426799,
      "backward_entropy": 0.008714324235916138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.887081146240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046989940106868744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08777619401613872,
      "backward_entropy": 0.00872505158185959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.932085037231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04703625291585922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08760762214660645,
      "backward_entropy": 0.008734933286905288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.08933448791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708019644021988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08745044469833374,
      "backward_entropy": 0.008745373785495758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.334064483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712502658367157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08729068438212077,
      "backward_entropy": 0.008750028908252716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.1739559173584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04717181995511055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08711910247802734,
      "backward_entropy": 0.008752003312110901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.689924240112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047220367938280106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0869376262029012,
      "backward_entropy": 0.008751626312732696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.253263473510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0472693033516407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08675427238146464,
      "backward_entropy": 0.008747890591621399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.142297744750977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04731766879558563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08657367030779521,
      "backward_entropy": 0.008744116127490997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.97994613647461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04736550897359848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08639568090438843,
      "backward_entropy": 0.014523577690124512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0816529169678688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0474170558154583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08619753519694011,
      "backward_entropy": 0.008734263479709625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.99046516418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047463707625865936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08602602283159892,
      "backward_entropy": 0.00873389169573784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.541092872619629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04751092940568924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08585129181543986,
      "backward_entropy": 0.008731241524219512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.58913230895996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047556858509778976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08568296829859416,
      "backward_entropy": 0.008732646703720093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.592744827270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04760267212986946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08551437656084697,
      "backward_entropy": 0.008737309277057648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.309846878051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04764914885163307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08534213900566101,
      "backward_entropy": 0.008740068972110748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183480262756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04769422486424446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08517738183339436,
      "backward_entropy": 0.014143294095993042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.128637313842773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04773703217506409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08502487341562907,
      "backward_entropy": 0.008749555796384811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.094232559204102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04777801036834717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08488159378369649,
      "backward_entropy": 0.008760668337345123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.975399017333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04781799763441086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08474441369374593,
      "backward_entropy": 0.008769706636667252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99869441986084,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04785938560962677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08459719022115071,
      "backward_entropy": 0.13844521045684816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.823724746704102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0478987917304039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08446216583251953,
      "backward_entropy": 0.008789890259504319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.27476501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04793832078576088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08432658513387044,
      "backward_entropy": 0.008795735985040664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.630032539367676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047983333468437195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0841594934463501,
      "backward_entropy": 0.008800400048494339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.3831729888916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04802794009447098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08399479587872823,
      "backward_entropy": 0.008803299814462661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.587124824523926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048073314130306244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08382540941238403,
      "backward_entropy": 0.013742828369140625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.12664794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04811736196279526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08366331458091736,
      "backward_entropy": 0.008810421079397201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.43769645690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816225916147232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08349592487017314,
      "backward_entropy": 0.008815425634384155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.120445251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04820580407977104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08333597580591838,
      "backward_entropy": 0.008820858597755433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.756210327148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048249147832393646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08317742745081584,
      "backward_entropy": 0.008826251327991485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.204194068908691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048293258994817734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08301360408465068,
      "backward_entropy": 0.008829865604639053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.822105407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04833634942770004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08285497625668843,
      "backward_entropy": 0.008838683366775513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.725029945373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04837930202484131,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08269678056240082,
      "backward_entropy": 0.008847939223051072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.99914264678955,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04842212051153183,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08253906170527141,
      "backward_entropy": 0.13844766616821289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7013111114501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846367985010147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08238864938418071,
      "backward_entropy": 0.00886605903506279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.805932998657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04850224405527115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08225534359614055,
      "backward_entropy": 0.00887691080570221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6556344032287598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048544976860284805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08209795753161113,
      "backward_entropy": 0.008884673565626144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.815717697143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04858458787202835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08195845286051433,
      "backward_entropy": 0.008894854038953782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6105258464813232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048625051975250244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08181447784105937,
      "backward_entropy": 0.008899975568056107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.087124824523926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04866261035203934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08168773849805196,
      "backward_entropy": 0.008907599747180939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.95384407043457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04870043322443962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08155823747316997,
      "backward_entropy": 0.00891462117433548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.36941909790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04874047264456749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08141531546910603,
      "backward_entropy": 0.008920402079820634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.110687255859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0487813837826252,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08126787841320038,
      "backward_entropy": 0.012976841628551483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.107389450073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882510378956795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08110410471757253,
      "backward_entropy": 0.008924470096826554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.623123168945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04886976629495621,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08093345661958058,
      "backward_entropy": 0.012885370850563049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.523626327514648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04891381040215492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08076685170332591,
      "backward_entropy": 0.008934611827135086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.08685302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04895728453993797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08060369392236073,
      "backward_entropy": 0.008936094492673874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.018250465393066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04899942874908447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08044885595639546,
      "backward_entropy": 0.008938036859035492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.66634464263916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049040310084819794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0803010364373525,
      "backward_entropy": 0.0089401014149189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.883256912231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04907906427979469,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08016579349835713,
      "backward_entropy": 0.00894259661436081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.816215515136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04911687597632408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08003595471382141,
      "backward_entropy": 0.008945135027170181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.629629135131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0491538904607296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07991048196951549,
      "backward_entropy": 0.008948780596256256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.079662322998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919399693608284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07976645231246948,
      "backward_entropy": 0.008951415121555329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.452866077423096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923493415117264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0796173910299937,
      "backward_entropy": 0.008953675627708435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.409181118011475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049273595213890076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07948229213555653,
      "backward_entropy": 0.008954130858182908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.364605903625488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04931019991636276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07935986916224162,
      "backward_entropy": 0.008953016251325607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.657440185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04934500902891159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07924830913543701,
      "backward_entropy": 0.008951525390148162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.453994750976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049381013959646225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07913021246592204,
      "backward_entropy": 0.008948028087615967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.377206802368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04941737279295921,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0790087381998698,
      "backward_entropy": 0.008947256952524185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09927428513765335,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945392534136772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07888484994570415,
      "backward_entropy": 0.008946875482797623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.28449058532715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948689043521881,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07878303031126659,
      "backward_entropy": 0.008948707580566406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1084868907928467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049522146582603455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07866823673248291,
      "backward_entropy": 0.00894635021686554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.074868202209473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955489560961723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0785680611928304,
      "backward_entropy": 0.008946330100297929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.017382621765137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04958721995353699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07846971849600475,
      "backward_entropy": 0.008946884423494339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.876169204711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04961921647191048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07837281624476115,
      "backward_entropy": 0.008949173241853714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.784586906433105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04965273663401604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07826661070187886,
      "backward_entropy": 0.0117892324924469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.676051139831543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968756064772606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0781524380048116,
      "backward_entropy": 0.008952897042036057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.582575798034668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497237853705883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07802900671958923,
      "backward_entropy": 0.00895773470401764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721880912780762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049761079251766205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07789889971415202,
      "backward_entropy": 0.0089623861014843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669027328491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04979758337140083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07777325809001923,
      "backward_entropy": 0.008969459682703018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.277358055114746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049833182245492935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07765321930249532,
      "backward_entropy": 0.008975467085838318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.346482276916504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986987262964249,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07752647995948792,
      "backward_entropy": 0.008981157839298249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6871466636657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049906909465789795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07739639282226562,
      "backward_entropy": 0.008992176502943039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.75328254699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994215816259384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07727716366449992,
      "backward_entropy": 0.009003948420286179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.856105327606201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04997934773564339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07714701195557912,
      "backward_entropy": 0.009013517946004867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.522119522094727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05001373589038849,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07703442871570587,
      "backward_entropy": 0.009022903442382813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.241209030151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004999414086342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0769094427426656,
      "backward_entropy": 0.009028009325265884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.969846725463867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050085488706827164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07678826153278351,
      "backward_entropy": 0.011306443810462951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.447879314422607,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050123803317546844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07665098706881206,
      "backward_entropy": 0.009041432291269302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.065084457397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050160158425569534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07652526100476582,
      "backward_entropy": 0.009048622846603394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.637848854064941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05019558593630791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07640547056992848,
      "backward_entropy": 0.009055140614509582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.7925443649292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05023113265633583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07628475626309712,
      "backward_entropy": 0.011151155829429627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.682161331176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050268515944480896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07615275184313457,
      "backward_entropy": 0.00906791016459465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2463908195495605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05030728876590729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07601317763328552,
      "backward_entropy": 0.009068570286035537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.320649147033691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05034402012825012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07588597138722737,
      "backward_entropy": 0.00907052457332611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.758954048156738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050380509346723557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07576071222623189,
      "backward_entropy": 0.010972198098897934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.161208152770996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050417911261320114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07563008864720662,
      "backward_entropy": 0.009071911871433257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.059609413146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050454918295145035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.075501948595047,
      "backward_entropy": 0.00907018780708313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.4590482711792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05049193650484085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07537190616130829,
      "backward_entropy": 0.009072276949882507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.995959758758545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052964761853218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07523833215236664,
      "backward_entropy": 0.009074241667985917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.831306457519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05056551471352577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0751155416170756,
      "backward_entropy": 0.009079722315073013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.56141471862793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05060121789574623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07499404748280843,
      "backward_entropy": 0.009083540737628936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4732747077941895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05063876509666443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07485996683438619,
      "backward_entropy": 0.00909048318862915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226210117340088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050673842430114746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0747395008802414,
      "backward_entropy": 0.009105028212070465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.443039655685425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050707921385765076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07462725043296814,
      "backward_entropy": 0.00911625251173973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.12097692489624,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073973536491394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07452757159868877,
      "backward_entropy": 0.009132028371095658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.368448257446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077085271477699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07443223396937053,
      "backward_entropy": 0.009144906699657441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.320333480834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080258101224899,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07433190941810608,
      "backward_entropy": 0.00916220024228096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6568732261657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050834525376558304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07423041264216106,
      "backward_entropy": 0.009177365899085998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9383649826049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05086531117558479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07413457334041595,
      "backward_entropy": 0.01049187183380127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.60422420501709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05089519917964935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07404622932275136,
      "backward_entropy": 0.009209264814853669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.581740856170654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05092392489314079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0739644467830658,
      "backward_entropy": 0.00922241285443306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.993162155151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095146968960762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07388988633950551,
      "backward_entropy": 0.009234730899333955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.308481216430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050979774445295334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07381053765614827,
      "backward_entropy": 0.009248640388250351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702639102935791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05100613832473755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07374364137649536,
      "backward_entropy": 0.009262727200984954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82665729522705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05103219300508499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07367906471093495,
      "backward_entropy": 0.009272007644176484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.950170516967773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0510590635240078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07360782225926717,
      "backward_entropy": 0.009281767904758454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.560337066650391,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05108731612563133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07352726658185323,
      "backward_entropy": 0.00928831398487091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.366247177124023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0511152409017086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07344817618529002,
      "backward_entropy": 0.009294405579566956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.705368995666504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051147591322660446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07334227363268535,
      "backward_entropy": 0.00929400771856308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.187434434890747,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051180869340896606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0732318510611852,
      "backward_entropy": 0.00929386094212532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08429326117038727,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0512118823826313,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07313444217046101,
      "backward_entropy": 0.13844239711761475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.299829959869385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051240015774965286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07305391629536946,
      "backward_entropy": 0.009308476746082307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.215231418609619,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05126804858446121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07297282417615254,
      "backward_entropy": 0.009322257339954376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.369558334350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05129489675164223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0728991578022639,
      "backward_entropy": 0.009334707260131836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.23757266998291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05132385715842247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07281278570493062,
      "backward_entropy": 0.009343568235635757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.137779712677002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513540655374527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07271775603294373,
      "backward_entropy": 0.009352478384971618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.08700704574585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05138367787003517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07262747486432393,
      "backward_entropy": 0.009887988865375518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.972743034362793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051412805914878845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07253939906756084,
      "backward_entropy": 0.009367554634809493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.994711399078369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051445264369249344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07243181268374126,
      "backward_entropy": 0.009369587153196334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11330961436033249,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05147687718272209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07232947150866191,
      "backward_entropy": 0.00937129557132721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9539406299591064,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051505085080862045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07224953174591064,
      "backward_entropy": 0.009368643164634705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.010300874710083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051532234996557236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0721751054128011,
      "backward_entropy": 0.009369944036006928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.80100154876709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05155755579471588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07211147745450337,
      "backward_entropy": 0.009373466670513152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.471234321594238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05158296972513199,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07204596201578777,
      "backward_entropy": 0.009381689131259918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.723038196563721,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05161043256521225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07196839650472005,
      "backward_entropy": 0.009385396540164948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.685028553009033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05163769796490669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07189102967580159,
      "backward_entropy": 0.00939246192574501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8087918758392334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166471377015114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07181471586227417,
      "backward_entropy": 0.009401306509971619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.756847858428955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05169044807553291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07174717386563619,
      "backward_entropy": 0.009406528621912002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.569368839263916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171540006995201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07168317834536235,
      "backward_entropy": 0.009416090697050095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7223381996154785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05174024775624275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07162082195281982,
      "backward_entropy": 0.009425800293684006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2957658767700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05176413804292679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0715647041797638,
      "backward_entropy": 0.009434372186660767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.241366863250732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0517888069152832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07150217890739441,
      "backward_entropy": 0.00944320261478424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.210666179656982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051814232021570206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0714335838953654,
      "backward_entropy": 0.009453558921813964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6281800270080566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184001475572586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07136376698811848,
      "backward_entropy": 0.009458119422197342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.34869384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05186460167169571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07130196690559387,
      "backward_entropy": 0.009459133446216583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.044684410095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05188895761966705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07124159733454387,
      "backward_entropy": 0.009217507392168044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.264127254486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191394314169884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07117666800816853,
      "backward_entropy": 0.00945783481001854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934519290924072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051938772201538086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0711129903793335,
      "backward_entropy": 0.009458369761705398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.190829753875732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05196429416537285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07104441026846568,
      "backward_entropy": 0.009461380541324615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1717848777771,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051989536732435226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07097752888997395,
      "backward_entropy": 0.009463980048894882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.137243270874023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05201420933008194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07091561953226726,
      "backward_entropy": 0.009026055037975312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7374444007873535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052040982991456985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07084039847056071,
      "backward_entropy": 0.009456585347652435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.733520269393921,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05206804350018501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07076304157574971,
      "backward_entropy": 0.009452532231807708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08608037233352661,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05209318548440933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07069766521453857,
      "backward_entropy": 0.009449941664934158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.819939613342285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05211583897471428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07064758737881978,
      "backward_entropy": 0.009448704868555069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.755386352539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05214087292551994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07058175404866536,
      "backward_entropy": 0.009450822323560714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.069976806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0521678552031517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07050380607446034,
      "backward_entropy": 0.00945211499929428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.416821002960205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052195947617292404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07041853666305542,
      "backward_entropy": 0.009455124288797379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.932971000671387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222427099943161,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07033216953277588,
      "backward_entropy": 0.00945930927991867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3025288581848145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05225348100066185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07023946940898895,
      "backward_entropy": 0.00946367084980011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.795413970947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05228279158473015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07014549275239308,
      "backward_entropy": 0.009469321370124817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5957688093185425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052312739193439484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07004883885383606,
      "backward_entropy": 0.009472385048866272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.672131538391113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052340708673000336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06996317704518636,
      "backward_entropy": 0.00948210284113884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5790019035339355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05237095430493355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06986349821090698,
      "backward_entropy": 0.009491234272718429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07839012145996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05240034684538841,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06976951162020366,
      "backward_entropy": 0.009500219672918319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9705891609191895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052426937967538834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.069692462682724,
      "backward_entropy": 0.009512381255626678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.90315580368042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05245368555188179,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06961488723754883,
      "backward_entropy": 0.009522762894630433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.423440456390381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05248080939054489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06953395406405131,
      "backward_entropy": 0.008491808176040649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.373230457305908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250728130340576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06945764025052388,
      "backward_entropy": 0.009548065066337586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1798481941223145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0525333434343338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06938321391741435,
      "backward_entropy": 0.009560906887054443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7101030349731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256034433841705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06930318971474965,
      "backward_entropy": 0.009571950882673264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.450693130493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05258745700120926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06922247012456258,
      "backward_entropy": 0.009581626951694488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.834226608276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05261596664786339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06913392742474873,
      "backward_entropy": 0.00958804488182068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.543319225311279,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264316871762276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06905270119508107,
      "backward_entropy": 0.009597411751747132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.769501209259033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052670545876026154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0689692348241806,
      "backward_entropy": 0.009608504176139832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.483863830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05269689857959747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06889083981513977,
      "backward_entropy": 0.009626105427742004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.732658386230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05272529274225235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0688009262084961,
      "backward_entropy": 0.009638268500566483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3949689865112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05275415629148483,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06870895624160767,
      "backward_entropy": 0.009646233171224594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.691730499267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052780862897634506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06863002975781758,
      "backward_entropy": 0.009654705971479416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.672273635864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052806198596954346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06856004397074382,
      "backward_entropy": 0.009661005437374115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3764811754226685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052830226719379425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06849914789199829,
      "backward_entropy": 0.00816768705844879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.334619402885437,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052852317690849304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06845169762770335,
      "backward_entropy": 0.009662139415740966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.341742753982544,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287310108542442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06841086347897847,
      "backward_entropy": 0.009666208922863007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.846137523651123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05289245769381523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06837908923625946,
      "backward_entropy": 0.009669823199510574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.54950213432312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0529116615653038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06834892928600311,
      "backward_entropy": 0.009668131172657014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.006336688995361,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05293047055602074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06831949949264526,
      "backward_entropy": 0.009671386331319809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.973681926727295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05295011028647423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0682839850584666,
      "backward_entropy": 0.009675446897745132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.513559579849243,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05297043174505234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0682436724503835,
      "backward_entropy": 0.009678887575864792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.275181770324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052989937365055084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0682088832060496,
      "backward_entropy": 0.007891403138637542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0685014724731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053008269518613815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06818073987960815,
      "backward_entropy": 0.009683454781770707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.828314781188965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05302795395255089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06814391414324443,
      "backward_entropy": 0.009684138745069504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.427867889404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05304829403758049,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0681024690469106,
      "backward_entropy": 0.009684468805789947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5851974487304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05306799337267876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06806437174479167,
      "backward_entropy": 0.00968690738081932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06071017310023308,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053087662905454636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06802623967329662,
      "backward_entropy": 0.009688839316368103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.677920341491699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310559272766113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06799805164337158,
      "backward_entropy": 0.009696346521377564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6438069343566895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312445014715195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06796288987000783,
      "backward_entropy": 0.009705960750579834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4804022312164307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05314413085579872,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0679218868414561,
      "backward_entropy": 0.007654692232608795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.436676263809204,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053163763135671616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.067881445089976,
      "backward_entropy": 0.00972735658288002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4236741065979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05318364128470421,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06783744196097057,
      "backward_entropy": 0.009742709249258042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1659938097000122,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320349335670471,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06779410441716512,
      "backward_entropy": 0.009757346659898757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3654539585113525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053222231566905975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06775722901026408,
      "backward_entropy": 0.0075826823711395265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2515642642974854,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05324115604162216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06771846115589142,
      "backward_entropy": 0.009796633571386337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.408135414123535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05325952172279358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0676828424135844,
      "backward_entropy": 0.009816619753837585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.298475742340088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05327862501144409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06764193872610728,
      "backward_entropy": 0.00983521193265915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.273374319076538,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532977320253849,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06760143240292867,
      "backward_entropy": 0.009851694852113724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1882524490356445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05331683158874512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06756079196929932,
      "backward_entropy": 0.009865956753492356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.223986864089966,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053335268050432205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0675240010023117,
      "backward_entropy": 0.00987832471728325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1996498107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053353745490312576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06748673816521962,
      "backward_entropy": 0.009889435768127442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.17881178855896,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053372252732515335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06744885941346486,
      "backward_entropy": 0.009899505972862243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.140237331390381,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05339072644710541,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06741136312484741,
      "backward_entropy": 0.00990717187523842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1375269889831543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053408294916152954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06738077104091644,
      "backward_entropy": 0.009906928241252898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0841553211212158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053425803780555725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06735090911388397,
      "backward_entropy": 0.009902625530958175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0498579740524292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344203859567642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.067330797513326,
      "backward_entropy": 0.009895695745944977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.066135883331299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345757678151131,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06731302539507548,
      "backward_entropy": 0.00729127898812294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.035493850708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05347394198179245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06728977958361308,
      "backward_entropy": 0.00989658161997795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0222063064575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05349058657884598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06726386149724324,
      "backward_entropy": 0.00989779382944107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.98311185836792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05350695922970772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06723838051160176,
      "backward_entropy": 0.009903056174516678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9961109161376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05352376401424408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06720842917760213,
      "backward_entropy": 0.009913609176874161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9580295085906982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053540218621492386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06717991828918457,
      "backward_entropy": 0.009925951063632966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.854490756988525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05355675891041756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06715111931165059,
      "backward_entropy": 0.009934969991445542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8517813682556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053574562072753906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06711450219154358,
      "backward_entropy": 0.009940274059772491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8865926265716553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053593140095472336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06707180043061574,
      "backward_entropy": 0.00994836464524269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.931366205215454,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0536116287112236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06702967484792073,
      "backward_entropy": 0.009954803436994553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6903886795043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05362936481833458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06699314713478088,
      "backward_entropy": 0.00995812714099884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9778538346290588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053648363798856735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06694875160853068,
      "backward_entropy": 0.00996238961815834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8035833835601807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053665995597839355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0669131726026535,
      "backward_entropy": 0.009965166449546814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.76420259475708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05368340015411377,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0668798287709554,
      "backward_entropy": 0.009961701184511184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53981876373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05370091646909714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06684502959251404,
      "backward_entropy": 0.009960265457630157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7173802852630615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05371963232755661,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06680235266685486,
      "backward_entropy": 0.009958859533071518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.470282554626465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053738322108983994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0667592187722524,
      "backward_entropy": 0.009959696233272553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9309741258621216,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05375787243247032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0667119026184082,
      "backward_entropy": 0.009955471009016037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.787450909614563,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053775954991579056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06667462984720866,
      "backward_entropy": 0.009949754923582077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7602459192276,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05379331111907959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06664211551348369,
      "backward_entropy": 0.009943006932735443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4513297080993652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053810276091098785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06661068399747212,
      "backward_entropy": 0.00994129702448845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5785205364227295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05382796376943588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06657345096270244,
      "backward_entropy": 0.009942355751991271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.068367004394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053845711052417755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06653497616449992,
      "backward_entropy": 0.0067306943237781525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.54532790184021,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05386516451835632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0664847195148468,
      "backward_entropy": 0.0099491685628891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.978924751281738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05388418212532997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06643804907798767,
      "backward_entropy": 0.009947066754102707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.113926887512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05390460416674614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0663823535044988,
      "backward_entropy": 0.009942013025283813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.258568525314331,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392574891448021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06632266938686371,
      "backward_entropy": 0.009935695677995682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8396714329719543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05394716188311577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06626159449418385,
      "backward_entropy": 0.009933022409677505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.621252179145813,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05396713316440582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06620907783508301,
      "backward_entropy": 0.009934282302856446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.167673349380493,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05398627743124962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06616161266962688,
      "backward_entropy": 0.00993693694472313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8072729706764221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05400565639138222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06611298024654388,
      "backward_entropy": 0.009937611222267152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.100670099258423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054023995995521545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06606952846050262,
      "backward_entropy": 0.00994691401720047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5598706007003784,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05404278635978699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06602295736471812,
      "backward_entropy": 0.00995716154575348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7929030656814575,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406084284186363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06598067283630371,
      "backward_entropy": 0.009967517852783204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2739346027374268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05407777428627014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0659450093905131,
      "backward_entropy": 0.009980139136314393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7790943384170532,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05409470573067665,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06590911249319713,
      "backward_entropy": 0.13837096691131592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5019805431365967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05411061272025108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06587874392668407,
      "backward_entropy": 0.010006853193044663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4877368211746216,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05412614718079567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06585034231344859,
      "backward_entropy": 0.010022753477096557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.907371759414673,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414138734340668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06582332650820415,
      "backward_entropy": 0.010041322559118271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7472801208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0541575588285923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06578898429870605,
      "backward_entropy": 0.010064846277236939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4541429281234741,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05417289957404137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06575869520505269,
      "backward_entropy": 0.01009233221411705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8493237495422363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418788641691208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06573039293289185,
      "backward_entropy": 0.010119765251874923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.128730297088623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054203540086746216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0656979630390803,
      "backward_entropy": 0.01014477238059044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7323009371757507,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05421927943825722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0656644602616628,
      "backward_entropy": 0.010168607532978057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0949110984802246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05423399806022644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06563736001650493,
      "backward_entropy": 0.010190613567829132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.073479652404785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0542488731443882,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06560896833737691,
      "backward_entropy": 0.006383369117975235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0567100048065186,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05426397547125816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06557772060235341,
      "backward_entropy": 0.010233183205127717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3848178386688232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05427926778793335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06554425756136577,
      "backward_entropy": 0.010255923122167587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.381603479385376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429394543170929,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06551557282606761,
      "backward_entropy": 0.010272769629955292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0127131938934326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05430791527032852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06549287339051564,
      "backward_entropy": 0.010280528664588928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.962846040725708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432206392288208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0654683659474055,
      "backward_entropy": 0.01028769239783287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035252466797828674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05433778464794159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06543379028638203,
      "backward_entropy": 0.010290288925170898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025042880326509476,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435200035572052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06540822982788086,
      "backward_entropy": 0.010294398665428162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3117748498916626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05436505004763603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06538840134938557,
      "backward_entropy": 0.010304740816354751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2997087240219116,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05437782406806946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06537017226219177,
      "backward_entropy": 0.01031372845172882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2950868606567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439038947224617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06535266836484273,
      "backward_entropy": 0.010322709381580353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6488098502159119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0544026717543602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06533714135487874,
      "backward_entropy": 0.010329692810773849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5189146995544434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054414451122283936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06532331804434459,
      "backward_entropy": 0.006220269948244095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1122777462005615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054426971822977066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06530522306760152,
      "backward_entropy": 0.01034957692027092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.302894115447998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05444072186946869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06527933478355408,
      "backward_entropy": 0.01035507321357727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8509958982467651,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05445665866136551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06523966789245605,
      "backward_entropy": 0.01036009043455124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8311002254486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0544724315404892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06520131230354309,
      "backward_entropy": 0.010362525284290314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.997074842453003,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05448810011148453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06516371170679729,
      "backward_entropy": 0.010363814979791641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7952014207839966,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05450469255447388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0651201605796814,
      "backward_entropy": 0.010364455729722976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.936203718185425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452108755707741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06507766246795654,
      "backward_entropy": 0.010363846272230148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.480031728744507,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054538317024707794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06502983967463176,
      "backward_entropy": 0.010362737625837327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8729031085968018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054556749761104584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0649746557076772,
      "backward_entropy": 0.010360322892665863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8403193950653076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05457574501633644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06491582592328389,
      "backward_entropy": 0.010356514900922775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3503239154815674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05459519475698471,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06485468645890553,
      "backward_entropy": 0.0060200363397598265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1307027339935303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054615676403045654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06478683153788249,
      "backward_entropy": 0.010346024483442306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.181230306625366,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05463499203324318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06472680469353993,
      "backward_entropy": 0.010340082645416259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2307419776916504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465447157621384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06466477612654369,
      "backward_entropy": 0.01033908873796463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.077316403388977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467475205659866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06459852556387584,
      "backward_entropy": 0.01033501923084259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.558452844619751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469410493969917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0645372321208318,
      "backward_entropy": 0.010335203260183334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.572896122932434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05471189692616463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06448639432589214,
      "backward_entropy": 0.010332340002059936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0457545518875122,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05472925305366516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0644390881061554,
      "backward_entropy": 0.010327336937189102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0288662910461426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05474581941962242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06439636647701263,
      "backward_entropy": 0.005863090977072716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0091450214385986,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05476268008351326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06435101230939229,
      "backward_entropy": 0.010321607440710067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9832077026367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05477907508611679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06430679063002269,
      "backward_entropy": 0.010328027606010436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4207496643066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547957643866539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06426022450129192,
      "backward_entropy": 0.010335952788591386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5102765560150146,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054813798516988754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06420673429965973,
      "backward_entropy": 0.010337319970130921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9157823324203491,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05483052879571915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06416149934132893,
      "backward_entropy": 0.005790262296795845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.899891972541809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054847441613674164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06411489844322205,
      "backward_entropy": 0.010342424362897873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8816406726837158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054864369332790375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06406883895397186,
      "backward_entropy": 0.010342201590538025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6600377559661865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488120764493942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06402438879013062,
      "backward_entropy": 0.010336726903915405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8178046941757202,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05489999055862427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.063967764377594,
      "backward_entropy": 0.010333251953125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9264730215072632,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0549188107252121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06391019622484843,
      "backward_entropy": 0.010333693027496338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9012023210525513,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05493645742535591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06386108199755351,
      "backward_entropy": 0.01032966747879982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46602362394332886,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054953329265117645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06381617983182271,
      "backward_entropy": 0.010329125821590424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1569724082946777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054968949407339096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06377917528152466,
      "backward_entropy": 0.010328869521617889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3073347806930542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05498519539833069,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06373833616574605,
      "backward_entropy": 0.010329234600067138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.689556360244751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05500081926584244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06370346744855244,
      "backward_entropy": 0.010321561247110367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.258745551109314,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0550166517496109,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06366659204165141,
      "backward_entropy": 0.01031607687473297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0497145652770996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05503226816654205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06363041698932648,
      "backward_entropy": 0.010313484072685241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8426584005355835,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05504857003688812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06358899176120758,
      "backward_entropy": 0.010314364731311799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2173389196395874,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0550638809800148,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0635549525419871,
      "backward_entropy": 0.010309581458568574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2028330564498901,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05507892370223999,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06352240840593974,
      "backward_entropy": 0.010305260866880417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41546112298965454,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05509372055530548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06349131464958191,
      "backward_entropy": 0.010301341861486435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5490877628326416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05510757118463516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06346570948759715,
      "backward_entropy": 0.010300860553979874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7775682806968689,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055121853947639465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06343606114387512,
      "backward_entropy": 0.010304737091064452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5165014266967773,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055135756731033325,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06340782841046651,
      "backward_entropy": 0.13837838172912598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4954334497451782,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055150024592876434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06337677439053853,
      "backward_entropy": 0.010325305163860321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022914540022611618,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055164698511362076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0633421540260315,
      "backward_entropy": 0.010340584069490432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39100903272628784,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05517818033695221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06331396599610646,
      "backward_entropy": 0.005426551774144172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4578142166137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05519076809287071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06329165895779927,
      "backward_entropy": 0.005422750115394592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38532692193984985,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05520366504788399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06326788663864136,
      "backward_entropy": 0.010398747026920318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0729386806488037,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05521566420793533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06324960788091023,
      "backward_entropy": 0.010413627326488494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0561295747756958,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522777512669563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06323010722796123,
      "backward_entropy": 0.010429906845092773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7421855926513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524010956287384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06320797403653462,
      "backward_entropy": 0.010451196879148483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3735452890396118,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525314435362816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06318152944246928,
      "backward_entropy": 0.010469281673431396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7022994756698608,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05526665225625038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06315148373444875,
      "backward_entropy": 0.01049046590924263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6911982297897339,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055279530584812164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06312555074691772,
      "backward_entropy": 0.010507730394601822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3612225353717804,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055292923003435135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06309713423252106,
      "backward_entropy": 0.01051901951432228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35743847489356995,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055305276066064835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06307569642861684,
      "backward_entropy": 0.010526736080646516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6599389314651489,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05531669035553932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06306047240893047,
      "backward_entropy": 0.01053217351436615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6643726229667664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05532792583107948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0630447914203008,
      "backward_entropy": 0.010542829334735871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6493409872055054,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055338773876428604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06303142011165619,
      "backward_entropy": 0.010551880300045013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9643744230270386,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0553494431078434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06301798423131307,
      "backward_entropy": 0.010564252734184265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5617088079452515,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536012724041939,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06300462285677592,
      "backward_entropy": 0.010574012249708175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6368201375007629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055371783673763275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06298372149467468,
      "backward_entropy": 0.010587143898010253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5426970720291138,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538303405046463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.062965194384257,
      "backward_entropy": 0.010599355399608611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5196439027786255,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055394917726516724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06294301152229309,
      "backward_entropy": 0.010607218742370606,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.7169764472544193,
    "avg_log_Z": -0.05466327626258135,
    "success_rate": 1.0,
    "avg_reward": 81.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.08,
      "2": 0.9
    },
    "avg_forward_entropy": 0.06460282767812413,
    "avg_backward_entropy": 0.012505123179405928,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}