{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.09891789300101143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0987717935017177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.5655975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691699504852295,
      "backward_entropy": 0.0988679017339434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.2110137939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369079351425171,
      "backward_entropy": 0.09887097563062396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.50711059570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00019873025303240865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368986964225769,
      "backward_entropy": 0.09892606735229492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.15823364257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029820622876286507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368892639875412,
      "backward_entropy": 0.09887696163994926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.7399444580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00039693660801276565,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13687969744205475,
      "backward_entropy": 0.09881003413881574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.49761962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004953977768309414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687002658843994,
      "backward_entropy": 0.09893756253378731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.68801879882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005934818764217198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136860191822052,
      "backward_entropy": 0.09894117287227086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.89198303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006915548001416028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685081899166107,
      "backward_entropy": 0.0989446725164141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.2539520263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007911963039077818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368413120508194,
      "backward_entropy": 0.09889142002378191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.91822814941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008920603431761265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368316411972046,
      "backward_entropy": 0.09895164625985282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.89630889892578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009902601595968008,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368219256401062,
      "backward_entropy": 0.09886105571474348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.47503662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00108631351031363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681212067604065,
      "backward_entropy": 0.09889977318899972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.5271759033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011836678022518754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680219650268555,
      "backward_entropy": 0.09890241282326835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.20220947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012828654143959284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13679204881191254,
      "backward_entropy": 0.09890510354723249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.19886779785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013825256610289216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367817372083664,
      "backward_entropy": 0.09890774318150111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.17682647705078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001479597995057702,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367713212966919,
      "backward_entropy": 0.0988973719733102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.51022338867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015744600677862763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676054775714874,
      "backward_entropy": 0.09891254561288017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.09304809570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016704507870599627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674946129322052,
      "backward_entropy": 0.09891011033739362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.6759796142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017674945993348956,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136738121509552,
      "backward_entropy": 0.09891624110085624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.42648315429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001865528291091323,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672657310962677,
      "backward_entropy": 0.09892218453543526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.0655517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019641995895653963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367148458957672,
      "backward_entropy": 0.09892158848898751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.4200897216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002064583357423544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670280575752258,
      "backward_entropy": 0.09898451396397182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.49911499023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002168415579944849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669046759605408,
      "backward_entropy": 0.09893906116485596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.4649658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002274187048897147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667790591716766,
      "backward_entropy": 0.09892896243504115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.11817932128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023815594613552094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666509091854095,
      "backward_entropy": 0.09893151691981725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.82382202148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024881644640117884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366521716117859,
      "backward_entropy": 0.09893398625510079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9604034423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025926728267222643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663920760154724,
      "backward_entropy": 0.09893630232129778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.5817108154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026949821040034294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662610948085785,
      "backward_entropy": 0.09899759292602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.42333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027967554051429033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13661277294158936,
      "backward_entropy": 0.09894054276602608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.90234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028995301108807325,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659919798374176,
      "backward_entropy": 0.09897191183907646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.94654846191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0030054275412112474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365852952003479,
      "backward_entropy": 0.09900282110486712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.69020080566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003110633697360754,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657131791114807,
      "backward_entropy": 0.09897935390472412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.66082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032150130718946457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655716180801392,
      "backward_entropy": 0.09894847869873047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.12168884277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003318658098578453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365428864955902,
      "backward_entropy": 0.0989859870501927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.07293701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003424304537475109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13652832806110382,
      "backward_entropy": 0.09900852612086705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.80104064941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003530588699504733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365136206150055,
      "backward_entropy": 0.09895379202706474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.16465759277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036360379308462143,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13649889826774597,
      "backward_entropy": 0.09899474893297468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.75169372558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003741833381354809,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13648396730422974,
      "backward_entropy": 0.09899732044764928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.79364013671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003849129192531109,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13646870851516724,
      "backward_entropy": 0.09899974720818656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.14149475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0039591495878994465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645315170288086,
      "backward_entropy": 0.09896012714930943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.42120361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004070390947163105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643740117549896,
      "backward_entropy": 0.09901479312351771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.614501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004179802723228931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13642153143882751,
      "backward_entropy": 0.09896307332175118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.96498107910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004288989584892988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640545308589935,
      "backward_entropy": 0.09901630878448486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3292236328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004397859331220388,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363891363143921,
      "backward_entropy": 0.09900959048952375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.73004150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004505109041929245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13637268543243408,
      "backward_entropy": 0.09896680286952428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6300506591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0046136993914842606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635596632957458,
      "backward_entropy": 0.09896790981292725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.84010314941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004721780773252249,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363389492034912,
      "backward_entropy": 0.09901365212031774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.19000244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004823646973818541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13632211089134216,
      "backward_entropy": 0.09896974052701678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4402618408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004932874348014593,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13630448281764984,
      "backward_entropy": 0.0990193315914699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.31179809570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005039123352617025,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628698885440826,
      "backward_entropy": 0.099016615322658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.67266845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0051463935524225235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13626915216445923,
      "backward_entropy": 0.09897242273603167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8945770263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0052570621483027935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13625088334083557,
      "backward_entropy": 0.09897330829075404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.43502807617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005367080215364695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13623261451721191,
      "backward_entropy": 0.09897411721093315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.82525634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005477762781083584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13621413707733154,
      "backward_entropy": 0.0989748580115182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.22677612304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00558775058016181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13619549572467804,
      "backward_entropy": 0.09897550514766149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.08367919921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005692590028047562,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617698848247528,
      "backward_entropy": 0.09902005536215645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.4420623779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005798468831926584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13615809381008148,
      "backward_entropy": 0.0990208727972848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.73015594482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005902144592255354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361389458179474,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.79393005371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005999349057674408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13611987233161926,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.00897216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006097014527767897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610045611858368,
      "backward_entropy": 0.09897691862923759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.96429443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006201657932251692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13608025014400482,
      "backward_entropy": 0.0989769697189331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.8033447265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006306041497737169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13605980575084686,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.18380737304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006405457854270935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13603928685188293,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6960906982422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0065022483468055725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13601884245872498,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.90771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006598141975700855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13599900901317596,
      "backward_entropy": 0.0989762544631958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.80597686767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0066934674978256226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597893714904785,
      "backward_entropy": 0.09897589683532715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.75559997558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0067853257060050964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13595890998840332,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.813720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006878382991999388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13593846559524536,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.09173583984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0069711944088339806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359177976846695,
      "backward_entropy": 0.09902083873748779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.61077880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007058595307171345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358971744775772,
      "backward_entropy": 0.09897381918770927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.14566040039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007153412327170372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1358756124973297,
      "backward_entropy": 0.09902075358799525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.64221954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007252206560224295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13585355877876282,
      "backward_entropy": 0.09897252491542272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7877197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007345079910010099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13583166897296906,
      "backward_entropy": 0.09897177559988839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3707733154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007439199835062027,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13580945134162903,
      "backward_entropy": 0.09902060883385795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.96051025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007532656192779541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578695058822632,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.68472290039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007625641766935587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357640027999878,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.51508331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007722648326307535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13574013113975525,
      "backward_entropy": 0.09896843773978097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.86138916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007815924473106861,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13571634888648987,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.21759796142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007906773127615452,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13569220900535583,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.9518051147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007992190308868885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356680989265442,
      "backward_entropy": 0.09896530423845563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.72518920898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00807133223861456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13564425706863403,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.12532806396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00815450306981802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13561959564685822,
      "backward_entropy": 0.09896274975367955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.05679321289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008235091343522072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355949193239212,
      "backward_entropy": 0.09896140439169747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.74951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008316482417285442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355697512626648,
      "backward_entropy": 0.09895999091012138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.88619995117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008400354534387589,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355440318584442,
      "backward_entropy": 0.09902053219931466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.297607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008483042009174824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551802933216095,
      "backward_entropy": 0.09895706176757812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.28562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00856821984052658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354915052652359,
      "backward_entropy": 0.09895554610661098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.96409606933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008653641678392887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13546445965766907,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.34820556640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008741048164665699,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354367434978485,
      "backward_entropy": 0.09902095794677734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.33477783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008833589032292366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354081779718399,
      "backward_entropy": 0.09895079476492745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.69853973388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00892878882586956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135378897190094,
      "backward_entropy": 0.0990208727972848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.57211303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009016738273203373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13535013794898987,
      "backward_entropy": 0.09894745690482003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.83642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009109625592827797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13532038033008575,
      "backward_entropy": 0.09902075358799525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.91131591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009196845814585686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352907419204712,
      "backward_entropy": 0.09894393171582903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0343475341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009290480054914951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13525988161563873,
      "backward_entropy": 0.09894216060638428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.57308959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009385029785335064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352284699678421,
      "backward_entropy": 0.0990205066544669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.34768676757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009472362697124481,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13519766926765442,
      "backward_entropy": 0.09893840551376343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.88815307617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009558478370308876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13516676425933838,
      "backward_entropy": 0.09902028526578631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.2767333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009641936048865318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13513600826263428,
      "backward_entropy": 0.09893430130822319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.55409240722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009724593721330166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13510508835315704,
      "backward_entropy": 0.09893218108585902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.09559631347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009809155948460102,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13507318496704102,
      "backward_entropy": 0.09902088982718331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.86952209472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009893191047012806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13504131138324738,
      "backward_entropy": 0.09892782143184117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.8339080810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009974422864615917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13500934839248657,
      "backward_entropy": 0.0989255394254412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.26436614990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010058595798909664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13497677445411682,
      "backward_entropy": 0.09892329147883824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.5918426513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010136938653886318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349448263645172,
      "backward_entropy": 0.09892094135284424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.63186645507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010217946954071522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13491186499595642,
      "backward_entropy": 0.09901872703007289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.74505615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010296851396560669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13487893342971802,
      "backward_entropy": 0.09901845455169678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.90149688720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010376950725913048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348448097705841,
      "backward_entropy": 0.09891353334699358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.77874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010451354086399078,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13481074571609497,
      "backward_entropy": 0.09901784147535052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.705078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010528777725994587,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13477522134780884,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.46573638916016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010603711009025574,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13473910093307495,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.2700653076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010677185840904713,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13470278680324554,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.22735595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010753958486020565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13466517627239227,
      "backward_entropy": 0.09889892169407435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.53233337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010830231010913849,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13462696969509125,
      "backward_entropy": 0.09889568601335798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.8115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010911104269325733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13458770513534546,
      "backward_entropy": 0.0988924333027431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.62506103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010985813103616238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13454891741275787,
      "backward_entropy": 0.09901486124311175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011062508448958397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13450941443443298,
      "backward_entropy": 0.09888551916394915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.67982482910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011139250360429287,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13446949422359467,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.82586669921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011220475658774376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13442793488502502,
      "backward_entropy": 0.09901315825326103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.63148498535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011304625310003757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13438548147678375,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.88812255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011384119279682636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134343221783638,
      "backward_entropy": 0.09887145246778216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.71124267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011462884023785591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343003809452057,
      "backward_entropy": 0.09886754410607475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.52691650390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011543146334588528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13425683975219727,
      "backward_entropy": 0.09901046752929688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.39132690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011622362770140171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13421256840229034,
      "backward_entropy": 0.09885942935943604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.70977783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011701036244630814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13416779041290283,
      "backward_entropy": 0.0988551037652152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.8406982421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011779103428125381,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13412243127822876,
      "backward_entropy": 0.09902088982718331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.70643615722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011851150542497635,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1340775340795517,
      "backward_entropy": 0.09902086428233556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.83196258544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011928821913897991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13403108716011047,
      "backward_entropy": 0.09900588648659843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.7335662841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01200485322624445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1339847445487976,
      "backward_entropy": 0.09883608136858259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.1215057373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012082616798579693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1339375227689743,
      "backward_entropy": 0.09900365556989398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.68035125732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012160032987594604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13388970494270325,
      "backward_entropy": 0.09900246347699847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.75892639160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01223149523139,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13384240865707397,
      "backward_entropy": 0.09902066843850273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.81387329101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012300126254558563,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13379545509815216,
      "backward_entropy": 0.09881484508514404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8595733642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012371568940579891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13374757766723633,
      "backward_entropy": 0.09880919115883964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.99327087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012443740852177143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13369911909103394,
      "backward_entropy": 0.09880352020263672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.46234130859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012514350935816765,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336502581834793,
      "backward_entropy": 0.09902043853487287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.90962982177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012586966156959534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13360001146793365,
      "backward_entropy": 0.09879144600459508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.99929809570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012657993473112583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13354939222335815,
      "backward_entropy": 0.09902031081063407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.30477905273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012731143273413181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334974765777588,
      "backward_entropy": 0.09877848625183105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.49691009521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012806078419089317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13344426453113556,
      "backward_entropy": 0.09898783479418073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.50761413574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01287895068526268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333906352519989,
      "backward_entropy": 0.09876458133969988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.56114196777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01294850092381239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13333725929260254,
      "backward_entropy": 0.09898359434945243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.14453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013018674217164516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332830786705017,
      "backward_entropy": 0.0987494843346732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.53504943847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013085531070828438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13322891294956207,
      "backward_entropy": 0.09874141216278076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.98191833496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013147763907909393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13317537307739258,
      "backward_entropy": 0.09873293127332415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.82748413085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01321299746632576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13312017917633057,
      "backward_entropy": 0.09872428859983172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6065216064453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013286256231367588,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13306200504302979,
      "backward_entropy": 0.09901938268116542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.07667541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013360067270696163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13300329446792603,
      "backward_entropy": 0.09870704582759313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.55033111572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013424557633697987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13294637203216553,
      "backward_entropy": 0.09896513393947057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.09464263916016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013486444018781185,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13288944959640503,
      "backward_entropy": 0.09901893138885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.41081237792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013546538539230824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13283289968967438,
      "backward_entropy": 0.09867782252175468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.59445190429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013604889623820782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1327764093875885,
      "backward_entropy": 0.0989546264920916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.56661987304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013666714541614056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13271799683570862,
      "backward_entropy": 0.09895088842936925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.93511962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013737702742218971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13265661895275116,
      "backward_entropy": 0.09864727088383266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.2940673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013812837190926075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13259318470954895,
      "backward_entropy": 0.09863722324371338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.87409973144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01388102862983942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325315237045288,
      "backward_entropy": 0.0986265880720956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.31466674804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013940425589680672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13247162103652954,
      "backward_entropy": 0.09861503328595843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.13165283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013999945484101772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324111521244049,
      "backward_entropy": 0.0986032315662929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.13934326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014057798311114311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13235077261924744,
      "backward_entropy": 0.09892637389046806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.62528228759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014119628816843033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13228848576545715,
      "backward_entropy": 0.09857898099081856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.6396713256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014177492819726467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.132226824760437,
      "backward_entropy": 0.09856641292572021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.7854461669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01423136331140995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13216538727283478,
      "backward_entropy": 0.09855306148529053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.04388427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014291160739958286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13210098445415497,
      "backward_entropy": 0.0989058188029698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.79783630371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014342812821269035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1320382058620453,
      "backward_entropy": 0.09852510690689087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.59828567504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014396949671208858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13197369873523712,
      "backward_entropy": 0.09889390638896398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.85465240478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014444048516452312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13191118836402893,
      "backward_entropy": 0.09849466596330915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.55458068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014490337111055851,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13184809684753418,
      "backward_entropy": 0.09888048682894025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.89666748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014537875540554523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13178381323814392,
      "backward_entropy": 0.09846187489373344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.76728057861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01458864938467741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1317177712917328,
      "backward_entropy": 0.0988663945879255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.96542358398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01464052964001894,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1316508650779724,
      "backward_entropy": 0.09901239190782819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.20368194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014701005071401596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1315806657075882,
      "backward_entropy": 0.0984116962977818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.14280700683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014755402691662312,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13151198625564575,
      "backward_entropy": 0.09901137011391777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.62254333496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01481583621352911,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13144007325172424,
      "backward_entropy": 0.0988363368170602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.18646240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014878244139254093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313667744398117,
      "backward_entropy": 0.0988284604890006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.07383728027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014942985028028488,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13129255175590515,
      "backward_entropy": 0.09900999069213867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.44454193115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01500352006405592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13121925294399261,
      "backward_entropy": 0.09881184782300677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.33448791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015063820406794548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311449557542801,
      "backward_entropy": 0.09830218553543091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.40020751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015122494660317898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1310708224773407,
      "backward_entropy": 0.09828249897275652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2835693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015186593867838383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13099311292171478,
      "backward_entropy": 0.09826261656624931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.90641784667969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01525417435914278,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13091319799423218,
      "backward_entropy": 0.09900742769241333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.1468963623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015312674455344677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13083557784557343,
      "backward_entropy": 0.09822076559066772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.77979278564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015373424626886845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13075634837150574,
      "backward_entropy": 0.0981987374169486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.27919006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015432246960699558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13067708909511566,
      "backward_entropy": 0.09874442645481654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.59848022460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015502508729696274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13059216737747192,
      "backward_entropy": 0.09873475347246442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.21221923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015575767494738102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13050544261932373,
      "backward_entropy": 0.09813254220145089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.6672821044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015650060027837753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13041791319847107,
      "backward_entropy": 0.09900459221431188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.79603576660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01573248580098152,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13032612204551697,
      "backward_entropy": 0.0990045155797686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.29432678222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015812931582331657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1302344799041748,
      "backward_entropy": 0.09869543143681117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.62515258789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015895335003733635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13014116883277893,
      "backward_entropy": 0.0980440548488072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.340576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015977172181010246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13004669547080994,
      "backward_entropy": 0.09802035774503436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.03601837158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016064222902059555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.129948690533638,
      "backward_entropy": 0.09900414092200142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9725799560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01614462397992611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.129852294921875,
      "backward_entropy": 0.09797077519553048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.74388122558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01622699573636055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1297527551651001,
      "backward_entropy": 0.098641003881182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.67719268798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016307272017002106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12965284287929535,
      "backward_entropy": 0.0979176504271371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.28411865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016385668888688087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12955252826213837,
      "backward_entropy": 0.09788954257965088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.40724182128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01646817848086357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12944915890693665,
      "backward_entropy": 0.09786150285175868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.93125915527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016556376591324806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1293422281742096,
      "backward_entropy": 0.09900300843375069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.53579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016639528796076775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12923593819141388,
      "backward_entropy": 0.09780422278812953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.43003845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016728166490793228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12912596762180328,
      "backward_entropy": 0.0977749228477478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.25804138183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016821691766381264,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12901261448860168,
      "backward_entropy": 0.09900265080588204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.6940155029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016912398859858513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12890011072158813,
      "backward_entropy": 0.09900258268628802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.94576263427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01700250431895256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1287873387336731,
      "backward_entropy": 0.09768550736563546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.1850128173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01708805374801159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12867602705955505,
      "backward_entropy": 0.09765349115644183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.78268432617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01717747189104557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12856228649616241,
      "backward_entropy": 0.09762245416641235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.55662536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0172662902623415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12844790518283844,
      "backward_entropy": 0.097590514591762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.81199645996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017352502793073654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12833371758460999,
      "backward_entropy": 0.09755691460200719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.28176879882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01743624359369278,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12821941077709198,
      "backward_entropy": 0.09900103296552386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.11154174804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017515797168016434,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1281059980392456,
      "backward_entropy": 0.09900015592575073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.14982604980469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01760098524391651,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1279878169298172,
      "backward_entropy": 0.09899932997567314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.70037841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017681842669844627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278703212738037,
      "backward_entropy": 0.09740618297031947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.57251739501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01776452362537384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12774857878684998,
      "backward_entropy": 0.09736509834017072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.94776153564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017840730026364326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12762795388698578,
      "backward_entropy": 0.09831090484346662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.82127380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01791350543498993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12750768661499023,
      "backward_entropy": 0.09828283105577741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.76849365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017990881577134132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1273830533027649,
      "backward_entropy": 0.09825497014181954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.35831451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01806299388408661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12726064026355743,
      "backward_entropy": 0.09717988116400582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.73236846923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018130088225007057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12713977694511414,
      "backward_entropy": 0.09712929385049003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.1470184326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018196793273091316,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12701797485351562,
      "backward_entropy": 0.09898784330912999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.89993286132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01827259361743927,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12688912451267242,
      "backward_entropy": 0.09812910216195243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.87872314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0183469969779253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12675976753234863,
      "backward_entropy": 0.09809658357075282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.05585479736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018424326553940773,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12662778794765472,
      "backward_entropy": 0.0980638861656189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.62533569335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018496135249733925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12649792432785034,
      "backward_entropy": 0.09686899185180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.77822875976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01857447437942028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.126362144947052,
      "backward_entropy": 0.09799490656171526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.531982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01865813322365284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12622034549713135,
      "backward_entropy": 0.09796181746891566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.46208953857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018740011379122734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12607771158218384,
      "backward_entropy": 0.09670939615794591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.70291137695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018818186596035957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12593497335910797,
      "backward_entropy": 0.09665417671203613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.55661010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018892895430326462,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257927417755127,
      "backward_entropy": 0.09785114015851702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.36561584472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018968703225255013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12564866244792938,
      "backward_entropy": 0.09781108583722796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.995849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019034964963793755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12550929188728333,
      "backward_entropy": 0.09646688188825335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.89325714111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019102923572063446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1253672093153,
      "backward_entropy": 0.09639881338391985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.7324676513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01916441135108471,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12522846460342407,
      "backward_entropy": 0.09896477631160192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.26407623291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0192301943898201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1250854730606079,
      "backward_entropy": 0.09625497886112758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.69668579101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019291209056973457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12494425475597382,
      "backward_entropy": 0.09895873069763184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.40414428710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019349008798599243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12480726838111877,
      "backward_entropy": 0.0961008071899414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.47433471679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019405262544751167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12466979771852493,
      "backward_entropy": 0.09746801853179932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.17849731445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01947159878909588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12452276796102524,
      "backward_entropy": 0.09594229289463588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.02032470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019535142928361893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12437551468610764,
      "backward_entropy": 0.09736427239009313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.04254150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019602419808506966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12422394007444382,
      "backward_entropy": 0.09577701772962298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.07547760009766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01967095024883747,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12406964600086212,
      "backward_entropy": 0.09893961463655744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.51023864746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019737286493182182,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12391714006662369,
      "backward_entropy": 0.09893614053726196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.85418701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019809186458587646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12375931441783905,
      "backward_entropy": 0.09714945725032262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.00335693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019883861765265465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12359745055437088,
      "backward_entropy": 0.09543420587267194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.18698120117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019953595474362373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12343905121088028,
      "backward_entropy": 0.09703760487692696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.56515502929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02002449333667755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12327814102172852,
      "backward_entropy": 0.09525087901524135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.56838989257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02009258233010769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12311828136444092,
      "backward_entropy": 0.09691798686981201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.86258697509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02016015537083149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12295755743980408,
      "backward_entropy": 0.09505558013916016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.1383056640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02022753655910492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12279614806175232,
      "backward_entropy": 0.09495573384421212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.43865966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02029004506766796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12263627350330353,
      "backward_entropy": 0.0948496971811567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.6090087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020358586683869362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12247059494256973,
      "backward_entropy": 0.09474531241825648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.85906982421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020428849384188652,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12230318784713745,
      "backward_entropy": 0.09890399660382952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.9728546142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020504476502537727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12213054299354553,
      "backward_entropy": 0.09453703675951276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.7529754638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020580850541591644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12195611000061035,
      "backward_entropy": 0.09443143435886928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.29791259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020659491419792175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1217772513628006,
      "backward_entropy": 0.09639350005558558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.94987487792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020746106281876564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12158986926078796,
      "backward_entropy": 0.09633151122501918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.38700103759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02082623541355133,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12140675634145737,
      "backward_entropy": 0.09889674186706543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.9283447265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020904280245304108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12122337520122528,
      "backward_entropy": 0.09619195120675224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.622314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02098257467150688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1210380345582962,
      "backward_entropy": 0.09611913136073522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.29944610595703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021057233214378357,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1208546906709671,
      "backward_entropy": 0.09888981069837298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.2467041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021126730367541313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12067511677742004,
      "backward_entropy": 0.09595988477979388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.31008911132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0211974885314703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12049303948879242,
      "backward_entropy": 0.09587693214416504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.32427978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021271241828799248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12030662596225739,
      "backward_entropy": 0.093345080103193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.49105834960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02133980393409729,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12012384831905365,
      "backward_entropy": 0.09887543746403285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.71403503417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021402040496468544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1199466735124588,
      "backward_entropy": 0.09560901778084892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.04428100585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02146480232477188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11976900696754456,
      "backward_entropy": 0.09550944396427699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.25747680664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021527400240302086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11958912760019302,
      "backward_entropy": 0.09540832894189018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.91474151611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021585794165730476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11941100656986237,
      "backward_entropy": 0.09530257327216012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.46653747558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021639006212353706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11923827230930328,
      "backward_entropy": 0.09884511572974068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.37187194824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021691646426916122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11906614899635315,
      "backward_entropy": 0.09227583238056727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.12356567382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021743780001997948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11889418959617615,
      "backward_entropy": 0.0921097823551723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.83609008789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021802781149744987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11871269345283508,
      "backward_entropy": 0.09194494996752058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.63601684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021868446841835976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11852391809225082,
      "backward_entropy": 0.09178359167916435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.73051071166992,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02193206548690796,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11833643168210983,
      "backward_entropy": 0.09881223099572319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.86933135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021987948566675186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11815714836120605,
      "backward_entropy": 0.09448736906051636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.49051666259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022043023258447647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11797863245010376,
      "backward_entropy": 0.0912618637084961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.22460174560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022097507491707802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11780095100402832,
      "backward_entropy": 0.09421895231519427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.37049102783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02215108461678028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1176229789853096,
      "backward_entropy": 0.09407930714743477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.25100708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022205639630556107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1174418181180954,
      "backward_entropy": 0.09070985657828194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.01560974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022261084988713264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11725802719593048,
      "backward_entropy": 0.09051769120352608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.59921264648438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022321145981550217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11706696450710297,
      "backward_entropy": 0.09875672204153878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.06520080566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022377977147698402,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11687973141670227,
      "backward_entropy": 0.09874866689954485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.10518646240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022437280043959618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11668720096349716,
      "backward_entropy": 0.08992331368582589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.807373046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022499192506074905,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.116490937769413,
      "backward_entropy": 0.09873476198741368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.80777740478516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022561680525541306,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11629410088062286,
      "backward_entropy": 0.09872843538011823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.67424774169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022619040682911873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11610458046197891,
      "backward_entropy": 0.09290062529700142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.03311157226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02267923392355442,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11591091752052307,
      "backward_entropy": 0.09871281044823783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.31431579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022739442065358162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1157139465212822,
      "backward_entropy": 0.0888758557183402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.30255126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022802716121077538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11551451683044434,
      "backward_entropy": 0.09241076878138951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.86502075195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022870028391480446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11530867964029312,
      "backward_entropy": 0.08844078438622612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.66238403320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022941093891859055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11509770154953003,
      "backward_entropy": 0.09208684308188302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.25218200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02300739288330078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11489087343215942,
      "backward_entropy": 0.08799234458378383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.60948181152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02307768352329731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11467906832695007,
      "backward_entropy": 0.08776295185089111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.06103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023142362013459206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11447714269161224,
      "backward_entropy": 0.0875280669757298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.46087646484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023216817528009415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11426201462745667,
      "backward_entropy": 0.09866740022386823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.73336791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023294545710086823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11404299736022949,
      "backward_entropy": 0.0912232654435294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.41986846923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023376718163490295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11381693929433823,
      "backward_entropy": 0.08684802055358887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.40277099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023459497839212418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11359068751335144,
      "backward_entropy": 0.09088483027049474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.69358825683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02354446053504944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11336123943328857,
      "backward_entropy": 0.08638479028429304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.65055084228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023631619289517403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11312958598136902,
      "backward_entropy": 0.08614879846572876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.7071533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023718522861599922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11289732158184052,
      "backward_entropy": 0.08590473447527204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.15117645263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023805558681488037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11266548931598663,
      "backward_entropy": 0.09017401933670044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.09439086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02388857863843441,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11243826895952225,
      "backward_entropy": 0.08540551151548113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.91167449951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023972248658537865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11221127212047577,
      "backward_entropy": 0.0851476958819798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.45308685302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024056032299995422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11198340356349945,
      "backward_entropy": 0.08488179956163679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.54188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02413361892104149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11176064610481262,
      "backward_entropy": 0.08459557805742536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.79493713378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02421194314956665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11153599619865417,
      "backward_entropy": 0.08911827632359096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024294910952448845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11130519211292267,
      "backward_entropy": 0.08401826449802943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.03549194335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024377841502428055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11107271909713745,
      "backward_entropy": 0.08372602292469569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.69912719726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024458859115839005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11084133386611938,
      "backward_entropy": 0.08843593938010079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.30062103271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024542389437556267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11060726642608643,
      "backward_entropy": 0.08820535455431257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.51104736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024622058495879173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11037726700305939,
      "backward_entropy": 0.08281328848430089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.0889892578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02470427006483078,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11014407873153687,
      "backward_entropy": 0.08772402150290352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.47958374023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02478478103876114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10991253703832626,
      "backward_entropy": 0.08218302045549665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.07650756835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024858271703124046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10969118773937225,
      "backward_entropy": 0.0818497623716082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.52416229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02492508664727211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10947816073894501,
      "backward_entropy": 0.08150226729256767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.64750671386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024989739060401917,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10926647484302521,
      "backward_entropy": 0.09857147932052612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.5302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02505076862871647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10905979573726654,
      "backward_entropy": 0.08078089782169887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.3223648071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025110583752393723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1088552325963974,
      "backward_entropy": 0.08041233675820487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.67765808105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025164755061268806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10865601897239685,
      "backward_entropy": 0.08568721158163888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.43092346191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025220220908522606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10845436155796051,
      "backward_entropy": 0.08536195755004883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.51314544677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025280900299549103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10824805498123169,
      "backward_entropy": 0.0792649473462786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.33938598632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02534414827823639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10803322494029999,
      "backward_entropy": 0.07889582429613386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.02159118652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025412173941731453,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10781663656234741,
      "backward_entropy": 0.08443745544978551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.90985107421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02548404224216938,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10759490728378296,
      "backward_entropy": 0.09844594342367989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.5674591064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025558803230524063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10736652463674545,
      "backward_entropy": 0.08384054899215698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.75089263916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02563672885298729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10713444650173187,
      "backward_entropy": 0.07744529417582921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.4849853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02570958435535431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10690910369157791,
      "backward_entropy": 0.08322854552950178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.70030212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02578800544142723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10667827725410461,
      "backward_entropy": 0.07668995005743844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.87853240966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02586502395570278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10644789785146713,
      "backward_entropy": 0.08260706492832728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.45307922363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025935394689440727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10622823983430862,
      "backward_entropy": 0.07590560402188982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.63893127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026005633175373077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10600978136062622,
      "backward_entropy": 0.07550153562000819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3491668701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026077434420585632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10578857362270355,
      "backward_entropy": 0.0750927243913923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.4593505859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026152528822422028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10556213557720184,
      "backward_entropy": 0.0812436512538365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.65216064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02622726373374462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10533866286277771,
      "backward_entropy": 0.07427979367119926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.18220520019531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026305116713047028,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10511092841625214,
      "backward_entropy": 0.09834114142826625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.08116149902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02637811005115509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10489082336425781,
      "backward_entropy": 0.08019119501113892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.68582916259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02645086869597435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10467245429754257,
      "backward_entropy": 0.0730224677494594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.26898193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02652120590209961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10445720702409744,
      "backward_entropy": 0.07945078611373901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.45868682861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026595361530780792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10423774272203445,
      "backward_entropy": 0.07216925280434745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.00749969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026670971885323524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1040172427892685,
      "backward_entropy": 0.07174813747406006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.93841552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02674221806228161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10380572080612183,
      "backward_entropy": 0.07832807302474976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.29559326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026807738468050957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10360319912433624,
      "backward_entropy": 0.07792216539382935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.4418182373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02687760256230831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10339491069316864,
      "backward_entropy": 0.07042828627995082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.25762939453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02695116214454174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1031816154718399,
      "backward_entropy": 0.07714263030460902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.81050109863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0270302165299654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10296212136745453,
      "backward_entropy": 0.06956901720591954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.08636474609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027104301378130913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10274913161993027,
      "backward_entropy": 0.06912626538957868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.06912994384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02717813290655613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10253815352916718,
      "backward_entropy": 0.06867632269859314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.95236587524414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02725164406001568,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10232862830162048,
      "backward_entropy": 0.09817569596426827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.9315185546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027318760752677917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212741047143936,
      "backward_entropy": 0.07513795580182757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.46147918701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027387725189328194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192164778709412,
      "backward_entropy": 0.06726082733699254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.9371109008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027460642158985138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10171116888523102,
      "backward_entropy": 0.07429747922079903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.19831848144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02753138728439808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10150481760501862,
      "backward_entropy": 0.07386940717697144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.35504913330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027597779408097267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10130234062671661,
      "backward_entropy": 0.09809398651123047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.67436981201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027664367109537125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10110045969486237,
      "backward_entropy": 0.06529392514910017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.35865783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027730843052268028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10089506208896637,
      "backward_entropy": 0.0725342971937997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.45468139648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02779575251042843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10069243609905243,
      "backward_entropy": 0.06426633255822319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.11890411376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027857569977641106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10049629211425781,
      "backward_entropy": 0.06374517934662956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.44818878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027916723862290382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10030660033226013,
      "backward_entropy": 0.07113288981573922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.1927261352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02797529473900795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10011887550354004,
      "backward_entropy": 0.06269505194255284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.28050231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028036940842866898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09992563724517822,
      "backward_entropy": 0.06217351981571743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.720458984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028101762756705284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09973126649856567,
      "backward_entropy": 0.06970688700675964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.02519226074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028164993971586227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09953805804252625,
      "backward_entropy": 0.061144194432667325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.66702270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02822711132466793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09934693574905396,
      "backward_entropy": 0.06061426230839321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.96339797973633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0282883420586586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09915831685066223,
      "backward_entropy": 0.06824998344693865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.59843444824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02834508940577507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09897847473621368,
      "backward_entropy": 0.06773728132247925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.44355773925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028403321281075478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09879632294178009,
      "backward_entropy": 0.05900189706257412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.8552017211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02845892496407032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09861724823713303,
      "backward_entropy": 0.05845616544995989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.8702621459961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028516365215182304,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09843605756759644,
      "backward_entropy": 0.09772740091596331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.79397583007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02857339382171631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09825632721185684,
      "backward_entropy": 0.057383988584790914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.63026428222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02863384783267975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09807164967060089,
      "backward_entropy": 0.05685153177806309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.399635314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028693538159132004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09788794070482254,
      "backward_entropy": 0.05631712930543082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.15036964416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028746847063302994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09771540015935898,
      "backward_entropy": 0.06418131078992571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.382286071777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028790686279535294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09755979478359222,
      "backward_entropy": 0.06361113701547895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.42206573486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028832146897912025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09740909188985825,
      "backward_entropy": 0.054614671639033725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.68447875976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028880685567855835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09724640101194382,
      "backward_entropy": 0.054069233792168755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.403072357177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02892976440489292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09708201140165329,
      "backward_entropy": 0.05352388960974557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.64508056640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02897574007511139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09692376852035522,
      "backward_entropy": 0.06141580854143415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029026616364717484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09675905108451843,
      "backward_entropy": 0.05244241441999163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.11166763305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029076073318719864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09659665077924728,
      "backward_entropy": 0.06035849452018738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.27238464355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029122374951839447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09643998742103577,
      "backward_entropy": 0.05981232438768659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.2686767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029171643778681755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09628094732761383,
      "backward_entropy": 0.0508293126310621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.61344146728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02922171726822853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09612177312374115,
      "backward_entropy": 0.05873819759913853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.49178314208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02927630953490734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09595678746700287,
      "backward_entropy": 0.049764973776681085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.211597442626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029333198443055153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09579017758369446,
      "backward_entropy": 0.04924596633229937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.66385650634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02938060648739338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09563865512609482,
      "backward_entropy": 0.04870543735367911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.824317932128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0294272992759943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09548977017402649,
      "backward_entropy": 0.04817113706043789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.70075225830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02947147935628891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09534648060798645,
      "backward_entropy": 0.056043812206813266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.31973266601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02952302247285843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09519468247890472,
      "backward_entropy": 0.047120524304253716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.62272644042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029582872986793518,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09503135830163956,
      "backward_entropy": 0.055024964468819756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.348876953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029641134664416313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09487392008304596,
      "backward_entropy": 0.0461436893258776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.49788665771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029707293957471848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09470688551664352,
      "backward_entropy": 0.045682630368641446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.1609992980957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029774922877550125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09453989565372467,
      "backward_entropy": 0.04522592680794852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.47348403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029837939888238907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09437890350818634,
      "backward_entropy": 0.04476400784083775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.88003540039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029896484687924385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0942213386297226,
      "backward_entropy": 0.04427905593599592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.57694244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0299681443721056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09404663741588593,
      "backward_entropy": 0.04383229357855661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.9406967163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030038589611649513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09387483447790146,
      "backward_entropy": 0.043377510138920376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.031188011169434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030106106773018837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09370875358581543,
      "backward_entropy": 0.05113133788108826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.52432250976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03016144409775734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0935625433921814,
      "backward_entropy": 0.04241347312927246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.2871322631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030218949541449547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09340925514698029,
      "backward_entropy": 0.04192602208682469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.53739166259766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030274970456957817,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09325814247131348,
      "backward_entropy": 0.09696765456880842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.82894134521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030329352244734764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09310762584209442,
      "backward_entropy": 0.040959809507642476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.698246002197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03038608282804489,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09295054525136948,
      "backward_entropy": 0.04048017944608416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.40701675415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0304394643753767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09279724955558777,
      "backward_entropy": 0.03999492100306919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.47195434570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03048790991306305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09265276789665222,
      "backward_entropy": 0.039500560079302104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.21996307373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030543146654963493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09249749779701233,
      "backward_entropy": 0.03902474897248404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.7742919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030599307268857956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09234403073787689,
      "backward_entropy": 0.04657558458192008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.44890594482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030663568526506424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09218090772628784,
      "backward_entropy": 0.03812324149268014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.27359771728516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03073509782552719,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09201060980558395,
      "backward_entropy": 0.09684339591435023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.9037857055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03080923482775688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09183614701032639,
      "backward_entropy": 0.03730389050074986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.64028549194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030883915722370148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09166060388088226,
      "backward_entropy": 0.03688727532114301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.16585159301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030955377966165543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09148882329463959,
      "backward_entropy": 0.0364517867565155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.79253387451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03102419711649418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09132187813520432,
      "backward_entropy": 0.036009946039744785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.69132995605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031090812757611275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09115970134735107,
      "backward_entropy": 0.0355727630002158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.98761749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03115539625287056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09100081026554108,
      "backward_entropy": 0.035134728465761454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.93733978271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03121419996023178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09084939956665039,
      "backward_entropy": 0.03468213975429535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.71713256835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127908334136009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09068828821182251,
      "backward_entropy": 0.034255066088267734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.095069885253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031345974653959274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0905274748802185,
      "backward_entropy": 0.03384062222072056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.65603637695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031409088522195816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09037616848945618,
      "backward_entropy": 0.04120213644845145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.9444580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03147240728139877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09022398293018341,
      "backward_entropy": 0.03300801983901432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.45766067504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03153962641954422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09006445109844208,
      "backward_entropy": 0.04033276012965611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.80946731567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03160487115383148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0899081826210022,
      "backward_entropy": 0.032215318509510586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.82121276855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03166879341006279,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08976052701473236,
      "backward_entropy": 0.031826476965631754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.1115951538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03172733634710312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08961983770132065,
      "backward_entropy": 0.03903009210314069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.1663589477539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031788621097803116,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08947579562664032,
      "backward_entropy": 0.09674177850995745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.246337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0318521186709404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08932649344205856,
      "backward_entropy": 0.030656403728893826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.72953033447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03191443160176277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08918243646621704,
      "backward_entropy": 0.037760368415287564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.01874542236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198262304067612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08903023600578308,
      "backward_entropy": 0.029917578612055098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.363670349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03204907476902008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08888223767280579,
      "backward_entropy": 0.03696846536227635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.07610321044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032112110406160355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08874130994081497,
      "backward_entropy": 0.03655768718038287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.2157974243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03217223286628723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08860740065574646,
      "backward_entropy": 0.028828005705560957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.33037567138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032233044505119324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08846914768218994,
      "backward_entropy": 0.02846583298274449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.024991989135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032296426594257355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08832526206970215,
      "backward_entropy": 0.028110780886241367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.20242691040039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03235306590795517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08819179981946945,
      "backward_entropy": 0.0349102829183851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.26785278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032405607402324677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08806563913822174,
      "backward_entropy": 0.027372094137328013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.1196517944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03246532753109932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08792738616466522,
      "backward_entropy": 0.027026091303144182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.44786071777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032525982707738876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08778947591781616,
      "backward_entropy": 0.03370058962277004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.58332061767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03258373215794563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0876537561416626,
      "backward_entropy": 0.033310147268431525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.92582702636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0326480008661747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08750654757022858,
      "backward_entropy": 0.026011618120329722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.70369338989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270721063017845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08736618608236313,
      "backward_entropy": 0.025673640625817434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.13481903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03276406601071358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08723068982362747,
      "backward_entropy": 0.032192187649863105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.408050537109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032822225242853165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08709146082401276,
      "backward_entropy": 0.03182119982583182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.62345886230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032878197729587555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08695781975984573,
      "backward_entropy": 0.024674158011163985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.45247650146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032935742288827896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08682164549827576,
      "backward_entropy": 0.024354628154209683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.81684494018555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033000435680150986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08667787909507751,
      "backward_entropy": 0.024062607969556535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.837432861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033062562346458435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08654224127531052,
      "backward_entropy": 0.023771298783166066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.60987091064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03312406316399574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08640815317630768,
      "backward_entropy": 0.023483252951077054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.51266479492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033186912536621094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0862734392285347,
      "backward_entropy": 0.029752197010176524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.642208099365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03325264900922775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08613534271717072,
      "backward_entropy": 0.022929495998791287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.90553283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03331531211733818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08599871397018433,
      "backward_entropy": 0.022647700139454434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.53365325927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03338446840643883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08585283160209656,
      "backward_entropy": 0.022384451968329295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.338685989379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03346278890967369,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08569248020648956,
      "backward_entropy": 0.022147604397365024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.40963745117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03353338688611984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08554422855377197,
      "backward_entropy": 0.02188955247402191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.90045166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033605996519327164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08539114892482758,
      "backward_entropy": 0.021636079464639937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.62322998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03368226811289787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0852336660027504,
      "backward_entropy": 0.021392238991601125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.49677276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033768847584724426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08506222814321518,
      "backward_entropy": 0.021176346710750034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.85280990600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03385600075125694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08489232510328293,
      "backward_entropy": 0.027221368891852244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.61311721801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033940136432647705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0847269743680954,
      "backward_entropy": 0.020746959107262746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.02935791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03402161970734596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08456569910049438,
      "backward_entropy": 0.0205277396099908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.62506866455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03410250321030617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08440552651882172,
      "backward_entropy": 0.020310350826808383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.98527145385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0341842882335186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08424130082130432,
      "backward_entropy": 0.02009535687310355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.43805694580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03426375612616539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08408193290233612,
      "backward_entropy": 0.01988003296511514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.2411880493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034342728555202484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0839231014251709,
      "backward_entropy": 0.019664521728243147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.45850372314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034421224147081375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08376391232013702,
      "backward_entropy": 0.019451952406338284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.5380744934082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03450106456875801,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08360143005847931,
      "backward_entropy": 0.019243617142949785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.733192443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03457508981227875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08344677090644836,
      "backward_entropy": 0.01902506181171962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.467278480529785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03464576229453087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08329686522483826,
      "backward_entropy": 0.02477929847581046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.81717300415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034708213061094284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08316066861152649,
      "backward_entropy": 0.01857092125075204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.53460693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03477019444108009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08302310109138489,
      "backward_entropy": 0.018340238503047397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.95668029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034831952303647995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08288787305355072,
      "backward_entropy": 0.01811458809035165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.24630355834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03489694371819496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08274674415588379,
      "backward_entropy": 0.017900694693837847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.09848403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03496138006448746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08260534703731537,
      "backward_entropy": 0.017691727195467268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.925682067871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03502529859542847,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08246491849422455,
      "backward_entropy": 0.09694305488041469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.37618637084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03508877754211426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0823260247707367,
      "backward_entropy": 0.01728100542511259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.63473129272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035148508846759796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08219339698553085,
      "backward_entropy": 0.0170726871916226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.57524871826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03520819544792175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08205944299697876,
      "backward_entropy": 0.022508691464151655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.34415817260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03527148813009262,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08192071318626404,
      "backward_entropy": 0.016670564455645426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.01559829711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0353362038731575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08177883923053741,
      "backward_entropy": 0.01647964119911194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.814308166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03540244698524475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08163580298423767,
      "backward_entropy": 0.021839548434529985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.657833099365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03546658903360367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08149847388267517,
      "backward_entropy": 0.016114248761108944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.55903625488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03553059324622154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08136151731014252,
      "backward_entropy": 0.015936751450811113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.0904312133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03559600189328194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08121918141841888,
      "backward_entropy": 0.021205459322248186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.81934356689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566787391901016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08106773346662521,
      "backward_entropy": 0.021020208086286272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.13703155517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03574399650096893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0809113010764122,
      "backward_entropy": 0.015461157475199019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.14628791809082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035817064344882965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0807599276304245,
      "backward_entropy": 0.01531033537217549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.48686218261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03588572144508362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08061613142490387,
      "backward_entropy": 0.015154556504317693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.38502502441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03595542535185814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08046846091747284,
      "backward_entropy": 0.020298187221799577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.75861358642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03603271767497063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08030809462070465,
      "backward_entropy": 0.02013785924230303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.33879089355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03611195087432861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08014467358589172,
      "backward_entropy": 0.0147285738161632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.88218688964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0361880287528038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07998865842819214,
      "backward_entropy": 0.01459386306149619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.756980895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036262910813093185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07983634620904922,
      "backward_entropy": 0.014460561530930656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.12242126464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036336615681648254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07968389987945557,
      "backward_entropy": 0.014326965170247214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.12909698486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036411065608263016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07953083515167236,
      "backward_entropy": 0.014197581580707006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.19831848144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036489337682724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07936903089284897,
      "backward_entropy": 0.014074636357171195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.49437713623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03656615689396858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07920949161052704,
      "backward_entropy": 0.013951562345027924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.802547454833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03664005920290947,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0790557861328125,
      "backward_entropy": 0.01890291486467634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.85172271728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03671305254101753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07890473306179047,
      "backward_entropy": 0.018752887845039368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.291379928588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03679334372282028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07873965799808502,
      "backward_entropy": 0.013592820082392012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.25484085083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036866992712020874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07858572155237198,
      "backward_entropy": 0.013474809271948678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.78743362426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036939799785614014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07843436300754547,
      "backward_entropy": 0.013358629175594874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.727962493896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037010107189416885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07828648388385773,
      "backward_entropy": 0.013240388461521693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.79916763305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037073224782943726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07815124094486237,
      "backward_entropy": 0.013115474155970983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.902793884277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03713648393750191,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07801541686058044,
      "backward_entropy": 0.09745541640690394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.50682067871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03719492629170418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07788719236850739,
      "backward_entropy": 0.0128651995744024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.551109313964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0372539758682251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0777558907866478,
      "backward_entropy": 0.012740968593529292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.64388275146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03731521964073181,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07761915028095245,
      "backward_entropy": 0.01741742023399898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.39022827148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037381842732429504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07747507095336914,
      "backward_entropy": 0.01728326507977077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.652082443237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0374532975256443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07732406258583069,
      "backward_entropy": 0.012412258556910924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.481014251708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0375208742916584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07717818021774292,
      "backward_entropy": 0.012308682714189802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.60586166381836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037583332508802414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0770406574010849,
      "backward_entropy": 0.09751207487923759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.34632873535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037649381905794144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07689613103866577,
      "backward_entropy": 0.012096233665943146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.16115188598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03771381825208664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07675473392009735,
      "backward_entropy": 0.011992581188678741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.88397216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03778167814016342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07660704851150513,
      "backward_entropy": 0.016519816858427867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.69842529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03785422816872597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07645110785961151,
      "backward_entropy": 0.016406849026679993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.34613037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037929385900497437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07628969848155975,
      "backward_entropy": 0.01629695083413805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.19768524169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03800845891237259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07612094283103943,
      "backward_entropy": 0.011634124176842826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.31675338745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038089483976364136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07594986259937286,
      "backward_entropy": 0.01155609211751393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.93155288696289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038169071078300476,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07578150928020477,
      "backward_entropy": 0.09768051760537284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.65674591064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03824889287352562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07560965418815613,
      "backward_entropy": 0.011401957699230738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.16253662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03833530470728874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07542720437049866,
      "backward_entropy": 0.011332765221595764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.56944274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038422901183366776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07524296641349792,
      "backward_entropy": 0.011265846235411507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.479270935058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03850835934281349,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07506164163351059,
      "backward_entropy": 0.09781817878995623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.18342208862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03858716040849686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07489357888698578,
      "backward_entropy": 0.011125798736299788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.330705642700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03866474702954292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07472845911979675,
      "backward_entropy": 0.011053915534700667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.32185745239258,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03873647376894951,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07457460463047028,
      "backward_entropy": 0.09788572788238525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.1843147277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038806088268756866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07442311942577362,
      "backward_entropy": 0.01090079971722194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.055912017822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0388738252222538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07427491992712021,
      "backward_entropy": 0.010823596801076616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.79693603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038939882069826126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07412814348936081,
      "backward_entropy": 0.010745900017874581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.41567993164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03900758922100067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07397858798503876,
      "backward_entropy": 0.014997105513300215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.661048889160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03907989710569382,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07381964474916458,
      "backward_entropy": 0.010601620588983809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.86845779418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03915010392665863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07366447150707245,
      "backward_entropy": 0.014821785901274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.7049674987793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039219994097948074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07350942492485046,
      "backward_entropy": 0.010461983936173576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.540863037109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039289601147174835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0733545571565628,
      "backward_entropy": 0.010393929268632616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.888662338256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0393589623272419,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07320061326026917,
      "backward_entropy": 0.010326758027076721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.00654983520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03942498937249184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07305461168289185,
      "backward_entropy": 0.010258409593786513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.882015228271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039489589631557465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07291127741336823,
      "backward_entropy": 0.010189945144312722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.449161529541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03955291584134102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07276852428913116,
      "backward_entropy": 0.010121801069804601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.90293884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03961198776960373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07263512909412384,
      "backward_entropy": 0.010051983807768141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.632179260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03967345878481865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07249616086483002,
      "backward_entropy": 0.014111151652676719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.61946487426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03973552584648132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07235720008611679,
      "backward_entropy": 0.009922751358577184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.48611450195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03980124741792679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07221022248268127,
      "backward_entropy": 0.013944159661020552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.15717697143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03987329825758934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07204938679933548,
      "backward_entropy": 0.009809121489524841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.98801040649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03994491323828697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07188952714204788,
      "backward_entropy": 0.009756838636738914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.99154281616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04001615196466446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0717296451330185,
      "backward_entropy": 0.013735393328326089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.49467086791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040082450956106186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07157962769269943,
      "backward_entropy": 0.013662693755967277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.756572723388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04015194624662399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07142318785190582,
      "backward_entropy": 0.009598915066037859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.654890060424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04021816328167915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07127565145492554,
      "backward_entropy": 0.009546118123190743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.56200408935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040281470865011215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07113444805145264,
      "backward_entropy": 0.009492108864443643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.648983001708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04034217447042465,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07099853456020355,
      "backward_entropy": 0.013368151017597743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.96153259277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040406618267297745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0708548054099083,
      "backward_entropy": 0.00938613819224494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.39518737792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040477436035871506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07069754600524902,
      "backward_entropy": 0.013229710715157645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.86975860595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04055546596646309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07052399963140488,
      "backward_entropy": 0.0092995251928057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.754650592803955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04063096642494202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07035656273365021,
      "backward_entropy": 0.0092583852154868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.86592102050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040699608623981476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07020561397075653,
      "backward_entropy": 0.00921352207660675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.894859313964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040769655257463455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0700509175658226,
      "backward_entropy": 0.009170961167131151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.781002044677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04083636775612831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06990498304367065,
      "backward_entropy": 0.00912681860583169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.21479034423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04090018942952156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06976541876792908,
      "backward_entropy": 0.009082402501787459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.61390495300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04096298664808273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06962603330612183,
      "backward_entropy": 0.00903948290007455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.039572715759277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04102323204278946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06949323415756226,
      "backward_entropy": 0.008995510637760162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.339595794677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04107971861958504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0693691074848175,
      "backward_entropy": 0.008950019521372659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.48030471801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04113737493753433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06924165040254593,
      "backward_entropy": 0.00890609622001648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.66863250732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041200581938028336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06909996271133423,
      "backward_entropy": 0.008866792810814721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.78166961669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041262734681367874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06896129250526428,
      "backward_entropy": 0.008827608078718185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.42939758300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04133274033665657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0688064843416214,
      "backward_entropy": 0.008793320506811142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.581016540527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04140547290444374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06864501535892487,
      "backward_entropy": 0.008761346872363771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.2447509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0414777435362339,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06848397850990295,
      "backward_entropy": 0.00872994480388505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.49142837524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04155389964580536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06831340491771698,
      "backward_entropy": 0.008701175983463014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.88821411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04163062945008278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06814321875572205,
      "backward_entropy": 0.008672891982964106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.0568962097168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041712213307619095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06796140968799591,
      "backward_entropy": 0.008647957018443517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.555580139160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0417938157916069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06777965277433395,
      "backward_entropy": 0.008623210447175162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.52361297607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041872646659612656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06760300695896149,
      "backward_entropy": 0.00859828878726278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.314865112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041950326412916183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06742921471595764,
      "backward_entropy": 0.008573351161820548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.174232482910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0420253686606884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06726282089948654,
      "backward_entropy": 0.01201190905911582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.006103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04209805279970169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0671028345823288,
      "backward_entropy": 0.008517628269536155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.97812557220459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0421702079474926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06694328784942627,
      "backward_entropy": 0.011915072798728943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.685794830322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223748296499252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0667954832315445,
      "backward_entropy": 0.008460143847124917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.662439346313477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04230475798249245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06664668023586273,
      "backward_entropy": 0.00843161450965064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.654823303222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04237043112516403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06650228798389435,
      "backward_entropy": 0.008401729166507721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.724248886108398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04243334010243416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06636430323123932,
      "backward_entropy": 0.00837120892746108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.28437042236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04249235987663269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0662352591753006,
      "backward_entropy": 0.011657134762832097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.840403079986572,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04255077615380287,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06610801070928574,
      "backward_entropy": 0.0985018355505807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572604179382324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04260426387190819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06599302589893341,
      "backward_entropy": 0.008276599326304026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.72197341918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04265475645661354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06588482856750488,
      "backward_entropy": 0.008243466062205178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.16905975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042706865817308426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06577150523662567,
      "backward_entropy": 0.008212110293763024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.12127113342285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042757656425237656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06566055119037628,
      "backward_entropy": 0.008181436785629817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.69751739501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04280709847807884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06555333733558655,
      "backward_entropy": 0.011327864868300301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.607542037963867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0428568534553051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0654449313879013,
      "backward_entropy": 0.008119749703577586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.72715759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290686175227165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06533756852149963,
      "backward_entropy": 0.008090094264064516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.00090026855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0429600290954113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06522159278392792,
      "backward_entropy": 0.008063615964991706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.85712814331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0430145263671875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06510218977928162,
      "backward_entropy": 0.008037909333195006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594415664672852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043070320039987564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06497888267040253,
      "backward_entropy": 0.008013814687728882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043121498078107834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06486760824918747,
      "backward_entropy": 0.007987942014421736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.977622985839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04317423328757286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06475237756967545,
      "backward_entropy": 0.010983104152338845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.89054298400879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04322976991534233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06463002413511276,
      "backward_entropy": 0.00793962978890964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.781097412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0432850606739521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06450793147087097,
      "backward_entropy": 0.007917085928576333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.92335510253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04334016516804695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06438599526882172,
      "backward_entropy": 0.007895893284252711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.827078819274902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04339917004108429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06425449997186661,
      "backward_entropy": 0.007876742631196976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.749011993408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04345463216304779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06413286924362183,
      "backward_entropy": 0.007855901760714394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.67314338684082,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04350709915161133,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06401844322681427,
      "backward_entropy": 0.09853104182652064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.347867965698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356120526790619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06389857828617096,
      "backward_entropy": 0.007817854306527547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.910301208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04361102357506752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06378965079784393,
      "backward_entropy": 0.007799591336931501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.835920333862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04365960508584976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06368456780910492,
      "backward_entropy": 0.007780119776725769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.999483108520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043707117438316345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06358276307582855,
      "backward_entropy": 0.007759896772248405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.89227294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043755095452070236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06347988545894623,
      "backward_entropy": 0.007739803620747158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.18684387207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0438036173582077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06337565183639526,
      "backward_entropy": 0.007721117564610073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.8496322631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043855346739292145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0632622241973877,
      "backward_entropy": 0.010451830923557281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.89969253540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043916940689086914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06312325596809387,
      "backward_entropy": 0.007693819169487272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.151838302612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04398014768958092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06298182904720306,
      "backward_entropy": 0.007681425128664289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.67704772949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04403819516301155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06285378336906433,
      "backward_entropy": 0.007668238665376391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.40822219848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04410124197602272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06271153688430786,
      "backward_entropy": 0.007658793990101133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.121450424194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044167280197143555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06256406009197235,
      "backward_entropy": 0.007648977317980358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.013277053833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04423201456665993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06241878867149353,
      "backward_entropy": 0.007640568273408073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.822330474853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044295474886894226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062277138233184814,
      "backward_entropy": 0.007632306643894741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.75743865966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044360432773828506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06213231384754181,
      "backward_entropy": 0.007623844913073948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.35253143310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04442421346902847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06198972091078758,
      "backward_entropy": 0.0101971977523395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.27308654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04449086636304855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061840496957302094,
      "backward_entropy": 0.00760794963155474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.552804946899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04455869272351265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06168823316693306,
      "backward_entropy": 0.007599879588399615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.289684295654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044623684138059616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06154303625226021,
      "backward_entropy": 0.007592344922678811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.852120399475098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04468730837106705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0614018514752388,
      "backward_entropy": 0.01009389225925718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.2867488861084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04474556818604469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061275213956832886,
      "backward_entropy": 0.0075736865401268005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.221559524536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0448019802570343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061152711510658264,
      "backward_entropy": 0.0075643786362239295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.53542137145996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04485662281513214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06103484332561493,
      "backward_entropy": 0.0075553421463285175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.774517059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04491238296031952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060913749039173126,
      "backward_entropy": 0.007547509457383837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.29039764404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04496750235557556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.060795385390520096,
      "backward_entropy": 0.009948354746614183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.80036926269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502357169985771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060674212872982025,
      "backward_entropy": 0.007527857486690793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.009212493896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04508164897561073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06054867058992386,
      "backward_entropy": 0.007517307996749878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.914560317993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514046758413315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060420747846364975,
      "backward_entropy": 0.007508242768900735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.26264953613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045199621468782425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060293108224868774,
      "backward_entropy": 0.0074978577239172796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.10750961303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04526075720787048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06015925854444504,
      "backward_entropy": 0.007489865911858422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.48212432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045326270163059235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060013547539711,
      "backward_entropy": 0.007484005498034614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.2180290222168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045389119535684586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05987463518977165,
      "backward_entropy": 0.007478547415563038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99724197387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545455053448677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059729840606451035,
      "backward_entropy": 0.0074722378381661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.477327346801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04552233964204788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0595790296792984,
      "backward_entropy": 0.007465781910078866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.425668716430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045584313571453094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05944474786520004,
      "backward_entropy": 0.0074567826730864385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.01721954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0456412248313427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05932413414120674,
      "backward_entropy": 0.007447076163121632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.27149200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04570028930902481,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059197306632995605,
      "backward_entropy": 0.007440267929009029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.52091598510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04575852304697037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059072792530059814,
      "backward_entropy": 0.0074337731514658245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.041019439697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04582253843545914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05893264710903168,
      "backward_entropy": 0.007429712052856173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.953468322753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458902046084404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058783385902643204,
      "backward_entropy": 0.007425020315817424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.84098243713379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045955900102853775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05863963067531586,
      "backward_entropy": 0.007417843810149601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.13627243041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046019747853279114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05850476026535034,
      "backward_entropy": 0.00740713466491018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.425028800964355,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04608604311943054,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05836149677634239,
      "backward_entropy": 0.09877644266401019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.198150634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04614950716495514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05822540819644928,
      "backward_entropy": 0.007387381047010422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.218311309814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046207550913095474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058105066418647766,
      "backward_entropy": 0.007375583584819522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.27702522277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04626211151480675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05799431353807449,
      "backward_entropy": 0.007363085235868182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.130149841308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046318914741277695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057876117527484894,
      "backward_entropy": 0.009282197271074568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.03887367248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04637494683265686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05776038020849228,
      "backward_entropy": 0.007344329463584083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.002128601074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04643134027719498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057644426822662354,
      "backward_entropy": 0.007333071104117802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.71727752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648447036743164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05753745138645172,
      "backward_entropy": 0.0073217616549560004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.63704490661621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04653869569301605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057426877319812775,
      "backward_entropy": 0.007313542600188937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.26432418823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465935617685318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05731495842337608,
      "backward_entropy": 0.007304733885186059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.92936325073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046651553362607956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057194750756025314,
      "backward_entropy": 0.00729611303125109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.228723526000977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04671357572078705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057064302265644073,
      "backward_entropy": 0.007288848715169089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.287572860717773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046775419265031815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0569349080324173,
      "backward_entropy": 0.007280777075460979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.46535873413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046835850924253464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0568094477057457,
      "backward_entropy": 0.00727183957185064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.056781768798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046893347054719925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05669412761926651,
      "backward_entropy": 0.007258150194372449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.1964693069458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04694991558790207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05658160150051117,
      "backward_entropy": 0.007245145205940519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.19454574584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04700469225645065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0564727783203125,
      "backward_entropy": 0.007235792598554066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.73153305053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047061461955308914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05635811761021614,
      "backward_entropy": 0.007229596376419067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.312814712524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711742326617241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05624517425894737,
      "backward_entropy": 0.00722422929746764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.60306739807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04717351123690605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05613333731889725,
      "backward_entropy": 0.00721597990819386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.78963851928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047228265553712845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056027255952358246,
      "backward_entropy": 0.0072029099932738715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.337900161743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047286953777074814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05591126158833504,
      "backward_entropy": 0.007188602217606136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.661041259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0473443940281868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05579947307705879,
      "backward_entropy": 0.0071733881320272174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.56242847442627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04739978536963463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055692173540592194,
      "backward_entropy": 0.007160904152052743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.875240325927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04745347425341606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055588338524103165,
      "backward_entropy": 0.007152267332587924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988237380981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04751156270503998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05547226965427399,
      "backward_entropy": 0.007146856614521572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.050453186035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0475662425160408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05536521598696709,
      "backward_entropy": 0.00714223672236715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.14471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04762383922934532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05525039881467819,
      "backward_entropy": 0.007138669490814209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4418768882751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04768112674355507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05513840913772583,
      "backward_entropy": 0.007130472787788936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.124771118164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04773402586579323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055037036538124084,
      "backward_entropy": 0.007124844406332288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.335330963134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04778900370001793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0549294576048851,
      "backward_entropy": 0.007121706647532327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.27777862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784346744418144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054822225123643875,
      "backward_entropy": 0.007121676845209939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.21500015258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04789714887738228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05471748113632202,
      "backward_entropy": 0.007121298462152481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.887626647949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795505478978157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05460130423307419,
      "backward_entropy": 0.007123173347541264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.969947814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04801023751497269,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054494306445121765,
      "backward_entropy": 0.0071202537843159264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.64832305908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048064522445201874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05439002811908722,
      "backward_entropy": 0.00711707877261298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.784500122070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812251031398773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0542769655585289,
      "backward_entropy": 0.0071121081709861755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.509628295898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04817913845181465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05416739732027054,
      "backward_entropy": 0.007105717701571328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.77484893798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048233602195978165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05406414344906807,
      "backward_entropy": 0.0070999786257743835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.689674377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828951880335808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05395890027284622,
      "backward_entropy": 0.007093860102551324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.310335159301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834796115756035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05384596437215805,
      "backward_entropy": 0.007088766034160342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.358196258544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0484037920832634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05374088138341904,
      "backward_entropy": 0.0070817651493208745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.106132507324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846047982573509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05363549292087555,
      "backward_entropy": 0.0070706504796232495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.032814025878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048515044152736664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.053534917533397675,
      "backward_entropy": 0.09879929678780693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.857255935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856965318322182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05343499779701233,
      "backward_entropy": 0.007051891514233181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.889206886291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04862462356686592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05333346500992775,
      "backward_entropy": 0.007044420710631779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.33362579345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04867754131555557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053237348794937134,
      "backward_entropy": 0.007038201604570661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.587437629699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04873420298099518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05313160642981529,
      "backward_entropy": 0.007032198033162526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.787027359008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04878992959856987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053027570247650146,
      "backward_entropy": 0.007029061338731221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.738918781280518,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04884254187345505,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.052931077778339386,
      "backward_entropy": 0.09880038670131139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9548094272613525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048892341554164886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05284137651324272,
      "backward_entropy": 0.007030239062649863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727107524871826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893803969025612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05276351422071457,
      "backward_entropy": 0.007029493472405842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.11966323852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048981085419654846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052694015204906464,
      "backward_entropy": 0.007025809692484992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.647724628448486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049024589359760284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052622128278017044,
      "backward_entropy": 0.0070257846798215595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.405370712280273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04906564950942993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052557848393917084,
      "backward_entropy": 0.007022363798958915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.29639434814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04910958558320999,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052484795451164246,
      "backward_entropy": 0.007631540830646243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.83535385131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04915601387619972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05240444839000702,
      "backward_entropy": 0.0070249853389603755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.02797508239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049202267080545425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052324678748846054,
      "backward_entropy": 0.007027618587017059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.701387405395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04925083369016647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05223758518695831,
      "backward_entropy": 0.007033215037414006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347623825073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0492987260222435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052154190838336945,
      "backward_entropy": 0.00703444704413414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.63756561279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04934404417872429,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.052077338099479675,
      "backward_entropy": 0.09881607123783656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.847663879394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049391720443964005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05199335515499115,
      "backward_entropy": 0.00704031011887959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.42032241821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04943784326314926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051914021372795105,
      "backward_entropy": 0.007043709712369102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2191643714904785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049485944211483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05183004215359688,
      "backward_entropy": 0.007047207227775029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.64377212524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049531154334545135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0517548993229866,
      "backward_entropy": 0.007047787840877261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.453662872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049577392637729645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0516759529709816,
      "backward_entropy": 0.007049843668937683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.0040922164917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04962707683444023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05158701539039612,
      "backward_entropy": 0.007056724812303271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.845305442810059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04967595264315605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05150112509727478,
      "backward_entropy": 0.007060834339686802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.963592529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04972453787922859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05141538754105568,
      "backward_entropy": 0.007066967231886727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.14277458190918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04977040737867355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051336828619241714,
      "backward_entropy": 0.007072506206376212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.90968132019043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049816884100437164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051258064806461334,
      "backward_entropy": 0.007074458790676934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8265252113342285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986065253615379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05118701234459877,
      "backward_entropy": 0.007074131497314998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.443387985229492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04990225285291672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05112138390541077,
      "backward_entropy": 0.007269081792661122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.020150184631348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994744434952736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051045626401901245,
      "backward_entropy": 0.00707901269197464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.330718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0499916635453701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05097118765115738,
      "backward_entropy": 0.007086608558893204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.326775550842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05003560334444046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05089820548892021,
      "backward_entropy": 0.007091869200978961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.459129333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007880926132202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05082963779568672,
      "backward_entropy": 0.007089739399296897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.328079223632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050122689455747604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050760358572006226,
      "backward_entropy": 0.007084026400532041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.039978981018066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050167351961135864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0506894625723362,
      "backward_entropy": 0.007077505545956748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.318042755126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05021146312355995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05062122642993927,
      "backward_entropy": 0.007068445639950889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.4779109954834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0502573661506176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05054913088679314,
      "backward_entropy": 0.007053381630352565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.405867576599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050307340919971466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050464875996112823,
      "backward_entropy": 0.007053988320486886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.552389144897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035458132624626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05038728564977646,
      "backward_entropy": 0.007051584443875721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.490317344665527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504000186920166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05031481385231018,
      "backward_entropy": 0.007047311003719058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.651302337646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050443828105926514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05024736747145653,
      "backward_entropy": 0.0070414745381900245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.308737754821777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05048796162009239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0501810684800148,
      "backward_entropy": 0.007030179458005088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.374834060668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050530970096588135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05011671781539917,
      "backward_entropy": 0.00702229088970593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.187117576599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057483911514282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050049789249897,
      "backward_entropy": 0.007015309163502285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16783079504966736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061882361769676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049981676042079926,
      "backward_entropy": 0.007012930299554553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.018878936767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0506582036614418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04992625117301941,
      "backward_entropy": 0.007008927209036691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.018391609191895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05070111155509949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049860551953315735,
      "backward_entropy": 0.0070076387907777515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.05430269241333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074464902281761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04979407787322998,
      "backward_entropy": 0.007004317428384509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.865177154541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05078577250242233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04973418638110161,
      "backward_entropy": 0.007000463881662914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.866230010986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05082685872912407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04967439919710159,
      "backward_entropy": 0.006997111652578626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.26422882080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050867415964603424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04961778596043587,
      "backward_entropy": 0.006988448756081718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.620784759521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05091221630573273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049549683928489685,
      "backward_entropy": 0.0069826846676213404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8180108070373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095668509602547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049481987953186035,
      "backward_entropy": 0.006978827395609447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.11952781677246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05099892616271973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049419425427913666,
      "backward_entropy": 0.00697798069034304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.231304168701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05104317516088486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0493512898683548,
      "backward_entropy": 0.00697934627532959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.275833129882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05108791962265968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04928247630596161,
      "backward_entropy": 0.006979428231716156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.536989212036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05113248527050018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049213312566280365,
      "backward_entropy": 0.0069830593253885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.206063270568848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117976665496826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049136772751808167,
      "backward_entropy": 0.006988840443747384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266190528869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051225997507572174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0490645132958889,
      "backward_entropy": 0.006990757903882435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.253796577453613,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051271069794893265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04899352416396141,
      "backward_entropy": 0.09881240980965751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.582290172576904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051314786076545715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0489257350564003,
      "backward_entropy": 0.007007668593100139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.882848739624023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05135578289628029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04886621981859207,
      "backward_entropy": 0.007012645048754556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.837108612060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051396388560533524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04880858585238457,
      "backward_entropy": 0.007014498646770205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8044016361236572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051433686167001724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048760123550891876,
      "backward_entropy": 0.0070138781198433465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.546504974365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051468100398778915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048719167709350586,
      "backward_entropy": 0.0070121389414582935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.02246856689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05150577425956726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048670776188373566,
      "backward_entropy": 0.007009267807006836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.26727867126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05154743790626526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04861266911029816,
      "backward_entropy": 0.007006591452019555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.717021942138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159180611371994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04854761064052582,
      "backward_entropy": 0.006245827036244529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.364531517028809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05163944512605667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048474691808223724,
      "backward_entropy": 0.007002643176487514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.746829986572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05168605595827103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04840487241744995,
      "backward_entropy": 0.006998964718409947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.692688941955566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051733095198869705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04833303764462471,
      "backward_entropy": 0.006998871586152485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.5654239654541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05178019776940346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04826139658689499,
      "backward_entropy": 0.006998342062745776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.96682357788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05182924121618271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04818546026945114,
      "backward_entropy": 0.006997137197426387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13601842522621155,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0518774688243866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048110589385032654,
      "backward_entropy": 0.006999318088803973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.03981876373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05192095413804054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04804755747318268,
      "backward_entropy": 0.007002311625650951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.571465492248535,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0519617423415184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04799215495586395,
      "backward_entropy": 0.09882256814411708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.765957832336426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05200427398085594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047931864857673645,
      "backward_entropy": 0.007002462233815875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.775667190551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05204595997929573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0478750541806221,
      "backward_entropy": 0.006999190364565168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.25515365600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052089884877204895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04781336337327957,
      "backward_entropy": 0.006994765251874924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873996257781982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052135080099105835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0477486327290535,
      "backward_entropy": 0.005973022431135178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.713003158569336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052177272737026215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04769224673509598,
      "backward_entropy": 0.006985391889299665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.14427947998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05221995338797569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0476345494389534,
      "backward_entropy": 0.006980648530381066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.29891586303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052265316247940063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04756899178028107,
      "backward_entropy": 0.0069822317787579125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.673669815063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052309583872556686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04750710353255272,
      "backward_entropy": 0.006981022123779569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.04087257385254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235123261809349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04745161905884743,
      "backward_entropy": 0.006979815129722867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.820760726928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05239618942141533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047387801110744476,
      "backward_entropy": 0.006980577217681068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.546575546264648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05243935436010361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047328583896160126,
      "backward_entropy": 0.006981060973235539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.512236595153809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05248009413480759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047275055199861526,
      "backward_entropy": 0.0069828395332608905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.081851959228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05251864343881607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04722631722688675,
      "backward_entropy": 0.006985560059547424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.366403341293335,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05255923792719841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04717174917459488,
      "backward_entropy": 0.006993300148418972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.97519302368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052596308290958405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04712687432765961,
      "backward_entropy": 0.006996200553008488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.70454216003418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05263499543070793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04707848280668259,
      "backward_entropy": 0.006997959422213691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.555169105529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526745542883873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047027166932821274,
      "backward_entropy": 0.007002741630588259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.38551664352417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052713777869939804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046976663172245026,
      "backward_entropy": 0.007007599409137454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.374628067016602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05275190621614456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046928372234106064,
      "backward_entropy": 0.0070138004209314075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.49403190612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05278882011771202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04688328504562378,
      "backward_entropy": 0.007018494818891797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.34290599822998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052827268838882446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046835172921419144,
      "backward_entropy": 0.00702073158962386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2169771194458,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052867405116558075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04678229242563248,
      "backward_entropy": 0.098841164793287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.126993179321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05290718749165535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046729981899261475,
      "backward_entropy": 0.007031521626881191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.105844497680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05294587090611458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04667961969971657,
      "backward_entropy": 0.007039884371416909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.170414447784424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05298582836985588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046626877039670944,
      "backward_entropy": 0.007045763411692211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.831473350524902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053023118525743484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046582069247961044,
      "backward_entropy": 0.007045936371598925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0118489265441895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05306350812315941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04653056338429451,
      "backward_entropy": 0.007044655936104911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.113993167877197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310172587633133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04648369550704956,
      "backward_entropy": 0.0070455436195646015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.683206558227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05313720554113388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04644593968987465,
      "backward_entropy": 0.0070384325725691655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.901987314224243,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317355692386627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04640526324510574,
      "backward_entropy": 0.007033768509115491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.811636447906494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053208235651254654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04636730998754501,
      "backward_entropy": 0.007033115518944604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.732287406921387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053241923451423645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04633156955242157,
      "backward_entropy": 0.007031851048980441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.12708568572998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053274933248758316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04629726707935333,
      "backward_entropy": 0.007032487541437149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.685772895812988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053310591727495193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0462568998336792,
      "backward_entropy": 0.00703295533146177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.98293399810791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05334513634443283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04621943086385727,
      "backward_entropy": 0.0070324673184326714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.78780198097229,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05338180810213089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04617813974618912,
      "backward_entropy": 0.09884076459067208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.611614227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0534164160490036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04614170268177986,
      "backward_entropy": 0.0070236362516880035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115928649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053449664264917374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046109702438116074,
      "backward_entropy": 0.007013787116323199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.008350372314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05348346009850502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04607754200696945,
      "backward_entropy": 0.007001454276697976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.162945747375488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05351796746253967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046043865382671356,
      "backward_entropy": 0.006989666393824986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82277774810791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053555794060230255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04600198566913605,
      "backward_entropy": 0.006980870983430317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.17280101776123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05359413102269173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04595823585987091,
      "backward_entropy": 0.006974568856613976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.249856948852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053634658455848694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045908503234386444,
      "backward_entropy": 0.0069720558822155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.166763782501221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053673774003982544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04586154222488403,
      "backward_entropy": 0.006972170301846096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852039337158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05371183156967163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04581593722105026,
      "backward_entropy": 0.006977100457463946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.243277549743652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05374939367175102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04577159136533737,
      "backward_entropy": 0.006981894373893738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0864434242248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05378732085227966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045729175209999084,
      "backward_entropy": 0.006976790726184845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.060936450958252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053823940455913544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04568956792354584,
      "backward_entropy": 0.006973239992346082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.000434398651123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05385926365852356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04565304517745972,
      "backward_entropy": 0.006969711610249111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3924741744995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053893525153398514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045618683099746704,
      "backward_entropy": 0.006967424814190183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.547915458679199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053925804793834686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04558936879038811,
      "backward_entropy": 0.006963490375450679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.412153482437134,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05395787954330444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04556107521057129,
      "backward_entropy": 0.006957846028464181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.11060619354248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053987737745046616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04553976655006409,
      "backward_entropy": 0.006945364709411349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.27126407623291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05402019992470741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04551182687282562,
      "backward_entropy": 0.006935081311634609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.310859680175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05405097454786301,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04548810422420502,
      "backward_entropy": 0.006925819175583976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.784237384796143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054081905633211136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045463282614946365,
      "backward_entropy": 0.006919122167995998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.798616409301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05411185696721077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04544153809547424,
      "backward_entropy": 0.006910005318267005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666627883911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054144132882356644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045414768159389496,
      "backward_entropy": 0.006899906056267875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.025505065917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0541771724820137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045385777950286865,
      "backward_entropy": 0.006892061659267971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547399520874023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054213523864746094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04534800723195076,
      "backward_entropy": 0.006890395922320229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.534113883972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05425009876489639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045309919863939285,
      "backward_entropy": 0.006888918578624725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.42517614364624,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0542854480445385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04527405649423599,
      "backward_entropy": 0.006889427346842629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.356651306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432097986340523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045238807797431946,
      "backward_entropy": 0.006887402385473251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.849503040313721,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054356660693883896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04520343244075775,
      "backward_entropy": 0.0068842752703598565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.596195220947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439181998372078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04516930878162384,
      "backward_entropy": 0.00688179475920541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5888103246688843,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.054428111761808395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.045132458209991455,
      "backward_entropy": 0.09876930713653564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.055108070373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05446133762598038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045103345066308975,
      "backward_entropy": 0.006878154618399484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.301046848297119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05449511110782623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04507221281528473,
      "backward_entropy": 0.006877662880080087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.87426495552063,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452755093574524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04504500329494476,
      "backward_entropy": 0.006875186094215938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.573631286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054558269679546356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04502154141664505,
      "backward_entropy": 0.006873713540179389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.526801586151123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0545886792242527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044999439269304276,
      "backward_entropy": 0.006869461387395859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.094814777374268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05461880564689636,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.044978633522987366,
      "backward_entropy": 0.004510297306946346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.604036331176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05464838817715645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04495811089873314,
      "backward_entropy": 0.006859105080366135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.086610317230225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054681215435266495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04492935538291931,
      "backward_entropy": 0.0068607596414429805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.081750869750977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054712772369384766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044904060661792755,
      "backward_entropy": 0.006860141243253436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.246869087219238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547429583966732,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044882990419864655,
      "backward_entropy": 0.0068546491009848455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.216763496398926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054773181676864624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04486134648323059,
      "backward_entropy": 0.006851857261998313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.158878326416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480331555008888,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044839899986982346,
      "backward_entropy": 0.0068500978606087825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.379976272583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05483642965555191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04481101781129837,
      "backward_entropy": 0.006851382553577423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.103536605834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054869748651981354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04478197172284126,
      "backward_entropy": 0.006851510277816227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287860870361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054902419447898865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04475495219230652,
      "backward_entropy": 0.0068493857979774475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.006176948547363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054935090243816376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04472881555557251,
      "backward_entropy": 0.006843906428132739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7494421005249023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05496716499328613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04470457136631012,
      "backward_entropy": 0.006836613906281335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.868851184844971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05499810725450516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.044682882726192474,
      "backward_entropy": 0.004266788916928428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.966859340667725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05502894148230553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0446605458855629,
      "backward_entropy": 0.006826498678752354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.806251049041748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055060580372810364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044635314494371414,
      "backward_entropy": 0.006828681698867253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6118762493133545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05509180203080177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04461131989955902,
      "backward_entropy": 0.0042139411504779544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.68942928314209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055121954530477524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044589847326278687,
      "backward_entropy": 0.006830954658133643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.674435138702393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055152036249637604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04456799477338791,
      "backward_entropy": 0.006834063678979874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2794743776321411,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055181827396154404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044547103345394135,
      "backward_entropy": 0.006835924727576119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5396928787231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055209312587976456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04453137144446373,
      "backward_entropy": 0.006837562790938786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737340450286865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05523563548922539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04451954737305641,
      "backward_entropy": 0.00683304135288511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6776604652404785,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055263470858335495,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04450394585728645,
      "backward_entropy": 0.0987410204751151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3400778770446777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055292654782533646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044485487043857574,
      "backward_entropy": 0.006827590720994132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1727005243301392,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05532136559486389,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.044466711580753326,
      "backward_entropy": 0.0987411652292524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.222236156463623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055348314344882965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04445063695311546,
      "backward_entropy": 0.006840638816356659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2923665046691895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05537433177232742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04443555325269699,
      "backward_entropy": 0.006854848670107978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.336519241333008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05540092661976814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04441803693771362,
      "backward_entropy": 0.006874023271458489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2005701065063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542737618088722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044401563704013824,
      "backward_entropy": 0.006889187863894871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.225876331329346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05545356124639511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04438480734825134,
      "backward_entropy": 0.006907712135996137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.258674621582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055479928851127625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04436740279197693,
      "backward_entropy": 0.006926210331065314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.138235330581665,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05550980567932129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044341929256916046,
      "backward_entropy": 0.0069450704114777705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.15546178817749,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05553815886378288,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04431966692209244,
      "backward_entropy": 0.09880001204354423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.144364595413208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055566102266311646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04429905116558075,
      "backward_entropy": 0.0069779029914311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.075260877609253,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05559290200471878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044282179325819016,
      "backward_entropy": 0.006985749517168317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.991654634475708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05561898648738861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04426674544811249,
      "backward_entropy": 0.006992839808974948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9566378593444824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05564526841044426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04425019770860672,
      "backward_entropy": 0.007001988057579313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.921658754348755,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567171797156334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04423268884420395,
      "backward_entropy": 0.007012910076550075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.969715118408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05569830164313316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04421430826187134,
      "backward_entropy": 0.003977772912808827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007538318634033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055724143981933594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04419767111539841,
      "backward_entropy": 0.0070363182042326245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.834547996520996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055748675018548965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04418398067355156,
      "backward_entropy": 0.007046098687819072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7882168292999268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055773381143808365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044169723987579346,
      "backward_entropy": 0.007055466196366719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.668570041656494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579834058880806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044154319912195206,
      "backward_entropy": 0.007066123187541962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.969010829925537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05582413822412491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.044136613607406616,
      "backward_entropy": 0.003935160115361214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.601498126983643,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0558483824133873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04412313178181648,
      "backward_entropy": 0.007084941757576806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.797078847885132,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05587339773774147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04410771280527115,
      "backward_entropy": 0.0070917244468416485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8284597396850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055897753685712814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044093698263168335,
      "backward_entropy": 0.007097175610916955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.482759475708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05592108890414238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044083476066589355,
      "backward_entropy": 0.007095300725528172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.470145225524902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055945251137018204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04407116770744324,
      "backward_entropy": 0.00709418420280729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7539970874786377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05596994236111641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04405801743268967,
      "backward_entropy": 0.007090724472488675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5259714126586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05599357187747955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04404855892062187,
      "backward_entropy": 0.00708112759249551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.757698893547058,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05601726844906807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04403863847255707,
      "backward_entropy": 0.007072453520127705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4637138843536377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604023113846779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04402884095907211,
      "backward_entropy": 0.007070503064564296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5804715156555176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056063320487737656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.044018667191267014,
      "backward_entropy": 0.0037808561963694437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7881731986999512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05608612298965454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044008124619722366,
      "backward_entropy": 0.0070701172309262416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.114525318145752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05610765516757965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04400084912776947,
      "backward_entropy": 0.007068655852760587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3091485500335693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05613064765930176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04398868978023529,
      "backward_entropy": 0.007074708385126931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.890660285949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0561540424823761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043975070118904114,
      "backward_entropy": 0.007083787981952939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4821527004241943,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05617886781692505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043957822024822235,
      "backward_entropy": 0.007094055946384158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.812252044677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05620309337973595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04394179955124855,
      "backward_entropy": 0.007104368614298957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9763967990875244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056228525936603546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04392313212156296,
      "backward_entropy": 0.0071139830563749585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4118568897247314,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056254543364048004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043902818113565445,
      "backward_entropy": 0.007124570863587516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.444803714752197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056279804557561874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04388408735394478,
      "backward_entropy": 0.007134835102728435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1040737628936768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056306589394807816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04386240988969803,
      "backward_entropy": 0.0071423522063664025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.31429386138916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05633319541811943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043840743601322174,
      "backward_entropy": 0.0071509358073983875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.315990686416626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056359149515628815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04381980001926422,
      "backward_entropy": 0.0071621132748467585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.048153877258301,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05638430267572403,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.043800629675388336,
      "backward_entropy": 0.09885819469179426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9545862674713135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056409090757369995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.043782901018857956,
      "backward_entropy": 0.0036605335772037506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9630014896392822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056434039026498795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04376382380723953,
      "backward_entropy": 0.007189187620367322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8113144040107727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056458815932273865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04374505952000618,
      "backward_entropy": 0.007198644003697804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.931966781616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05648173391819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043730370700359344,
      "backward_entropy": 0.0072078002350670954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.503819227218628,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05650445073843002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043716911226511,
      "backward_entropy": 0.007212798510278974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8532962799072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05652596428990364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04370616376399994,
      "backward_entropy": 0.007216195975031171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.284866809844971,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05654759705066681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04369507357478142,
      "backward_entropy": 0.007219267742974418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.161388397216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657169595360756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04368006810545921,
      "backward_entropy": 0.007215160344328199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0900771617889404,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05659479275345802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043667715042829514,
      "backward_entropy": 0.007207626742976052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4148950576782227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056617386639118195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04365579038858414,
      "backward_entropy": 0.007202919040407453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3707160949707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056640416383743286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043642908334732056,
      "backward_entropy": 0.007197645093713488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0167036056518555,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05666260048747063,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.043630748987197876,
      "backward_entropy": 0.09885773488453456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3326828479766846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056684460490942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043618932366371155,
      "backward_entropy": 0.007200484297105244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7805846333503723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05670567974448204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043606992810964584,
      "backward_entropy": 0.007209537816899163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9739632606506348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05672498419880867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043600499629974365,
      "backward_entropy": 0.007212689944675991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2876789569854736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05674412474036217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043593935668468475,
      "backward_entropy": 0.007217375295502799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3560222387313843,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05676349252462387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04358866810798645,
      "backward_entropy": 0.007212939006941659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5593602657318115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05678185820579529,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04358584061264992,
      "backward_entropy": 0.007206782698631287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5145509243011475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0568004809319973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043582431972026825,
      "backward_entropy": 0.007200231509549277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9336861371994019,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05681953206658363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04357746243476868,
      "backward_entropy": 0.007196200745446342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10315985977649689,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05683805048465729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043574362993240356,
      "backward_entropy": 0.00718881083386285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.064363718032837,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056854717433452606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04357513412833214,
      "backward_entropy": 0.007182260709149497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6779974102973938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056872326880693436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04357413947582245,
      "backward_entropy": 0.007175556250980922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.597074270248413,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05688880756497383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043575286865234375,
      "backward_entropy": 0.007170937423195157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.792433261871338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05690676346421242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043572984635829926,
      "backward_entropy": 0.0071655213832855225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8361096382141113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05692487582564354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043569013476371765,
      "backward_entropy": 0.0071662286562579015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9078197479248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05694255977869034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04356669262051582,
      "backward_entropy": 0.007164217531681061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7559006214141846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696135014295578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04356095939874649,
      "backward_entropy": 0.007166351590837751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2394951581954956,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056980106979608536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04355479031801224,
      "backward_entropy": 0.007172249257564545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.772345781326294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05699776113033295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0435519702732563,
      "backward_entropy": 0.0033034533262252808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2684085369110107,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05701502040028572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04355056956410408,
      "backward_entropy": 0.007171600524868284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1614079475402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05703279748558998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04354747012257576,
      "backward_entropy": 0.00717269309929439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7597222328186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057050030678510666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04354497417807579,
      "backward_entropy": 0.007176917578492846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1682324409484863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570683628320694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04353934898972511,
      "backward_entropy": 0.007184884377888271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.661137342453003,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05708581209182739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043536022305488586,
      "backward_entropy": 0.007190893803324018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6468936204910278,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057103231549263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043532177805900574,
      "backward_entropy": 0.007199084120137351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6919195652008057,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057120613753795624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04352802783250809,
      "backward_entropy": 0.0072090231946536475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6212194561958313,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05713875964283943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04352226108312607,
      "backward_entropy": 0.007217348154102053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1832451820373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057155437767505646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04352039098739624,
      "backward_entropy": 0.0072221362165042335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.074267029762268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05717315152287483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351711645722389,
      "backward_entropy": 0.007220985633986337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0902189016342163,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05719037353992462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351396858692169,
      "backward_entropy": 0.007224057401929583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0808666944503784,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057206884026527405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351247847080231,
      "backward_entropy": 0.007227136620453426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0635876655578613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057222750037908554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351241514086723,
      "backward_entropy": 0.007230190826313836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0277483463287354,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057238124310970306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351305589079857,
      "backward_entropy": 0.007234610617160797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5354994535446167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05725410208106041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351182281970978,
      "backward_entropy": 0.007241111780915942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5046038627624512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057269349694252014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04351109266281128,
      "backward_entropy": 0.007252671356712069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0056339502334595,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057284802198410034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04350930452346802,
      "backward_entropy": 0.007266836506979806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.431992292404175,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05730003863573074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04350704699754715,
      "backward_entropy": 0.00728490948677063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.533797562122345,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057316407561302185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043501757085323334,
      "backward_entropy": 0.007304061736379351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4259324073791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05733179673552513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043498337268829346,
      "backward_entropy": 0.007323855800288064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.406125783920288,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734792724251747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04349389672279358,
      "backward_entropy": 0.007339262004409518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8288052082061768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736470967531204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043488506227731705,
      "backward_entropy": 0.0073505959340504235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.249239444732666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05738270655274391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.043480366468429565,
      "backward_entropy": 0.003151800749557359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4200297594070435,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057402338832616806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0434684082865715,
      "backward_entropy": 0.007370493773903165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9008009433746338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05742146819829941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043457433581352234,
      "backward_entropy": 0.007379644151244845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3991130590438843,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05744009464979172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04344910755753517,
      "backward_entropy": 0.003131994977593422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9239466190338135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057458218187093735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04344187676906586,
      "backward_entropy": 0.007378551576818738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.355423092842102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057475678622722626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04343532770872116,
      "backward_entropy": 0.0073805563151836395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1910321712493896,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05749291554093361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04342874139547348,
      "backward_entropy": 0.007384144301925387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8970317840576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05751093849539757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04341978579759598,
      "backward_entropy": 0.00738964495914323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1790573596954346,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575282946228981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04341166839003563,
      "backward_entropy": 0.007397650607994625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1570653915405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057546067982912064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043403178453445435,
      "backward_entropy": 0.007402093814952033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4824983775615692,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057564206421375275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0433942973613739,
      "backward_entropy": 0.007403292826243809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8771358132362366,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05758095160126686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04338861256837845,
      "backward_entropy": 0.00740359936441694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.652370572090149,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05759697034955025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04338421672582626,
      "backward_entropy": 0.007404271513223648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4764694571495056,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057613473385572433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04337780177593231,
      "backward_entropy": 0.003052324056625366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8160829544067383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057628657668828964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04337482154369354,
      "backward_entropy": 0.007411310183150428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5634565353393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057645637542009354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04336727038025856,
      "backward_entropy": 0.007415426628930228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2293813228607178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057665176689624786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043353576213121414,
      "backward_entropy": 0.007421507899250303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9808210134506226,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057684045284986496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04334142059087753,
      "backward_entropy": 0.0074260128395898005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1723097562789917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0577031746506691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04332900047302246,
      "backward_entropy": 0.00742860564163753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9135926961898804,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05772198736667633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04331637918949127,
      "backward_entropy": 0.007434900317873273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1675963401794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05774128437042236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.043302249163389206,
      "backward_entropy": 0.003008553758263588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.241666078567505,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057759977877140045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04328948259353638,
      "backward_entropy": 0.007449959005628314,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.2795931993424894,
    "avg_log_Z": -0.056844478733837606,
    "success_rate": 1.0,
    "avg_reward": 81.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.08,
      "2": 0.9
    },
    "avg_forward_entropy": 0.04364913240075111,
    "avg_backward_entropy": 0.0087476696819067,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}