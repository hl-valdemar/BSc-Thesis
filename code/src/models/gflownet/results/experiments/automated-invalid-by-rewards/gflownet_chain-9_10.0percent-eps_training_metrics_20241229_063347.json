{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.07686141464445326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.81593322753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109585702419281,
      "backward_entropy": 0.0768393145667182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.7980499267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959365367889404,
      "backward_entropy": 0.07695147063997057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.1841278076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020013077300973237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960147380828858,
      "backward_entropy": 0.07686707708570692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.72325134277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00029896863270550966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960913896560669,
      "backward_entropy": 0.0768471293979221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.69825744628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.000398133706767112,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961669683456421,
      "backward_entropy": 0.07696191469828288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.6615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000497946166433394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962414741516113,
      "backward_entropy": 0.07685205671522352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.19114685058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005976591492071748,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963153839111328,
      "backward_entropy": 0.07696831226348877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.59910583496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006979051977396011,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963889360427856,
      "backward_entropy": 0.07687988546159533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.9997100830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007978940848261118,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964616537094116,
      "backward_entropy": 0.076974266105228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.18975830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008987303590402007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096534013748169,
      "backward_entropy": 0.07686180538601345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.4102020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010008645476773381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966057777404785,
      "backward_entropy": 0.07688750823338826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.4487762451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001098974491469562,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966751575469971,
      "backward_entropy": 0.0768665870030721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.744873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001198173500597477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967438220977783,
      "backward_entropy": 0.07689184612698025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.86383056640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012974580749869347,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096811294555664,
      "backward_entropy": 0.07698705461290148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.00088500976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013953486923128366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968773365020752,
      "backward_entropy": 0.07698918713463677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.24398803710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014950749464333057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096942663192749,
      "backward_entropy": 0.07689768738216823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.40948486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015931957168504596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970064401626586,
      "backward_entropy": 0.07687682575649685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.74530029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016918596811592579,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970690250396728,
      "backward_entropy": 0.07690103848775227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.12557983398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017891464522108436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971302986145019,
      "backward_entropy": 0.07690242926279704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.21568298339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001886061392724514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971901416778565,
      "backward_entropy": 0.07699806822670831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.5884246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001982814632356167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972487926483154,
      "backward_entropy": 0.07690483993954128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.27427673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002080181846395135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973063707351685,
      "backward_entropy": 0.07688391208648682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.99044799804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021774794440716505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973626375198364,
      "backward_entropy": 0.0769069857067532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.48439025878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002271289238706231,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097416877746582,
      "backward_entropy": 0.07688601811726888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.09963989257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002366151660680771,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974702835083008,
      "backward_entropy": 0.07688691880967882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.0857391357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024602217599749565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975232124328613,
      "backward_entropy": 0.07688768704732259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.50457763671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025502145290374756,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975733995437623,
      "backward_entropy": 0.07700594266255696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.3974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026419737841933966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976231098175049,
      "backward_entropy": 0.07690934340159099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.92724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027342168614268303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976718664169312,
      "backward_entropy": 0.07688905133141412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.37745666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028269817121326923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097719430923462,
      "backward_entropy": 0.07690944936540392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.91465759277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029168385080993176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977659225463868,
      "backward_entropy": 0.07688956790500218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.8895721435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00300420168787241,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978107452392578,
      "backward_entropy": 0.07688954141404894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.67222595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030893452931195498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978538990020752,
      "backward_entropy": 0.07690805196762085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.14315795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031758034601807594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978964567184449,
      "backward_entropy": 0.07688900497224596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.30755615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003262303303927183,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979379415512085,
      "backward_entropy": 0.07688862747616237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.27960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033479526173323393,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979781150817872,
      "backward_entropy": 0.07690536975860596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.46566772460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034328638575971127,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098016619682312,
      "backward_entropy": 0.07688747511969672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.9431610107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035202675499022007,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980545282363892,
      "backward_entropy": 0.07701132032606336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.16273498535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003608758794143796,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980914831161499,
      "backward_entropy": 0.07688629627227783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.33061218261719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036985957995057106,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981272459030152,
      "backward_entropy": 0.07701180378595988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.53175354003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003784897504374385,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981612205505371,
      "backward_entropy": 0.07701198922263251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2366180419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038727496284991503,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981938838958741,
      "backward_entropy": 0.07701216803656684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.99021911621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0039598699659109116,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982251167297363,
      "backward_entropy": 0.07701232035954793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.99462890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00404729600995779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982543230056763,
      "backward_entropy": 0.07689135604434544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.056396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004136310424655676,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982822179794312,
      "backward_entropy": 0.07688918378618029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.33319091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004225643817335367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983084440231324,
      "backward_entropy": 0.07687839534547594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.1241455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0043149786069989204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983330011367798,
      "backward_entropy": 0.07688450813293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.42649841308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004404827486723661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983562469482422,
      "backward_entropy": 0.0768820842107137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.09894561767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004496159963309765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983784198760986,
      "backward_entropy": 0.07687399784723918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.23150634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004582289606332779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983988046646118,
      "backward_entropy": 0.07687674628363715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.06895446777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046701580286026,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984181165695191,
      "backward_entropy": 0.077012923028734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.81056213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004759384319186211,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984363555908203,
      "backward_entropy": 0.07686846786075169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.5664520263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004846157506108284,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984532833099366,
      "backward_entropy": 0.07701290316051906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.09764099121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004934550262987614,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984690189361572,
      "backward_entropy": 0.07686428229014079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.18467712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005024493671953678,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984835624694825,
      "backward_entropy": 0.07686099741193983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.33975219726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0051146685145795345,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098496675491333,
      "backward_entropy": 0.07701279057396783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.11663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005207247566431761,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985085964202881,
      "backward_entropy": 0.07685427533255683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.65541076660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005298373755067587,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985190868377685,
      "backward_entropy": 0.07685597737630208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.88800811767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005391090642660856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985281467437744,
      "backward_entropy": 0.07685375213623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.59678649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005478410515934229,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985356569290161,
      "backward_entropy": 0.07684340079625447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.41122436523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005563468672335148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985416173934937,
      "backward_entropy": 0.076848480436537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.83807373046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005643985699862242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985462665557862,
      "backward_entropy": 0.07683485084109837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.37513732910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005724126938730478,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985497236251832,
      "backward_entropy": 0.07701204220453899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.76953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005804062355309725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098551869392395,
      "backward_entropy": 0.07682524787055121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.00596618652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0058814361691474915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985527038574219,
      "backward_entropy": 0.07701160510381062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.68588256835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005962903145700693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985521078109742,
      "backward_entropy": 0.07683294349246556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.80409240722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006046907044947147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985500812530517,
      "backward_entropy": 0.07682976457807753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.24004364013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006131947971880436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985461473464966,
      "backward_entropy": 0.07680673069424099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6230926513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006214046850800514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985405445098877,
      "backward_entropy": 0.07680193583170573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.49026489257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0062949564307928085,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985332727432251,
      "backward_entropy": 0.07701061169306438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.30068969726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006372993346303701,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985245704650878,
      "backward_entropy": 0.07681568463643391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.43814086914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006449813023209572,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985143184661865,
      "backward_entropy": 0.07681174410714044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.5846939086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006531300488859415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985019207000732,
      "backward_entropy": 0.07680789629618327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.64837646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006608485709875822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984882116317748,
      "backward_entropy": 0.07680375046200222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.45631408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006684440653771162,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098473072052002,
      "backward_entropy": 0.07679952515496148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.68170166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006759906653314829,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984562635421753,
      "backward_entropy": 0.07676272922092015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.17645263671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006836185697466135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984375476837158,
      "backward_entropy": 0.07700847254859076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.68173217773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006909855175763369,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984175205230713,
      "backward_entropy": 0.0767864121331109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.6388702392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006987110245972872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983952283859252,
      "backward_entropy": 0.07674437099032932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.46925354003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007063437253236771,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983712673187256,
      "backward_entropy": 0.0767379535569085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.32708740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007142874877899885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983449220657349,
      "backward_entropy": 0.07673152287801106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.50253295898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007224131375551224,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983164310455322,
      "backward_entropy": 0.07700681686401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.71630096435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0073120989836752415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982848405838012,
      "backward_entropy": 0.07676548428005642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.41806030273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007396675646305084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982524156570435,
      "backward_entropy": 0.07671280701955159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.60577392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007481192238628864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982179641723633,
      "backward_entropy": 0.07675704691145155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.92913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0075701456516981125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981804132461548,
      "backward_entropy": 0.07675296730465359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.3791046142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007661205716431141,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981402397155762,
      "backward_entropy": 0.0770062075720893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.13783264160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007755741477012634,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980969667434692,
      "backward_entropy": 0.07700624730851915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.1195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007851429283618927,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980517864227295,
      "backward_entropy": 0.07674132453070746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.11602020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0079403817653656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980064868927002,
      "backward_entropy": 0.0766763687133789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.73866271972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008022353984415531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979608297348023,
      "backward_entropy": 0.07666881879170735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.25517272949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008104648441076279,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979132652282715,
      "backward_entropy": 0.07672564188639323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.10101318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008182812482118607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978647470474243,
      "backward_entropy": 0.07671901914808485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.59506225585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008261601440608501,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978138446807861,
      "backward_entropy": 0.07700520091586643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.56346130371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008339207619428635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977615118026733,
      "backward_entropy": 0.07670505841573079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.23995971679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008415763266384602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977070331573487,
      "backward_entropy": 0.07669757472144233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.82339477539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008491764776408672,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976500511169433,
      "backward_entropy": 0.07700400220023261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.8600616455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008568438701331615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975914001464844,
      "backward_entropy": 0.07668145497639973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.43441772460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008648605085909367,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975291728973388,
      "backward_entropy": 0.07700309488508436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.16986083984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008727503940463066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974650382995606,
      "backward_entropy": 0.07666480541229248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.04185485839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008808568120002747,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973975658416749,
      "backward_entropy": 0.07700207498338488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.39605712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00889415293931961,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973258018493652,
      "backward_entropy": 0.07664755980173747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.76499938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008982667699456215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109725022315979,
      "backward_entropy": 0.07655581500795153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.27288818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009071853943169117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971715450286865,
      "backward_entropy": 0.07663030094570583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.56939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009160764515399933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970903635025024,
      "backward_entropy": 0.07662110858493382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.18760681152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009254656732082367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970039367675781,
      "backward_entropy": 0.07661228709750706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.13482666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00934589747339487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969159603118897,
      "backward_entropy": 0.07651475403043959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.82526397705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009430701844394207,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968284606933594,
      "backward_entropy": 0.07659263081020778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.0744171142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009511160664260387,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967404842376709,
      "backward_entropy": 0.07699882984161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.03543090820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009592265821993351,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966495275497437,
      "backward_entropy": 0.07657030555937025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.52774047851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009673962369561195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965554714202881,
      "backward_entropy": 0.0764667722913954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5265350341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009761996567249298,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964550971984863,
      "backward_entropy": 0.07654808627234565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.37744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00985002238303423,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963518619537353,
      "backward_entropy": 0.07653699980841742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.38650512695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00993483979254961,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962473154067993,
      "backward_entropy": 0.07699655161963569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01001371257007122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961437225341797,
      "backward_entropy": 0.07641671763526069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.07708740234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010097459889948368,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096034049987793,
      "backward_entropy": 0.0769952999220954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.53137969970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010181166231632233,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095921277999878,
      "backward_entropy": 0.07699469725290935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1377410888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010262624360620975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958070755004883,
      "backward_entropy": 0.0769940349790785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.58795166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010344553738832474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956878662109375,
      "backward_entropy": 0.07635773552788629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.19688415527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010429957881569862,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955617427825928,
      "backward_entropy": 0.07699293560451931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.95729064941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010515688918530941,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954312086105347,
      "backward_entropy": 0.07643227444754706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8593292236328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010602501221001148,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952956676483154,
      "backward_entropy": 0.07699204153484768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.54266357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010692168958485126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951536893844604,
      "backward_entropy": 0.07640457153320312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01077968254685402,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095009446144104,
      "backward_entropy": 0.07638994852701823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.12176513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010871232487261295,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10948578119277955,
      "backward_entropy": 0.07699097527398004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.7113494873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010965014807879925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946999788284302,
      "backward_entropy": 0.07636120584275988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.87274169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011059910990297794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945364236831664,
      "backward_entropy": 0.07623393005794948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.37379455566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011154170148074627,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943663120269775,
      "backward_entropy": 0.07699031300014919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.82827758789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011250258423388004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941882133483886,
      "backward_entropy": 0.07619987593756782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.74897003173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011346853338181973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940039157867432,
      "backward_entropy": 0.07618161042531331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.79852294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011439412832260132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938184261322022,
      "backward_entropy": 0.07628424300087823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.31729125976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011522537097334862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936381816864013,
      "backward_entropy": 0.07626540131039089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.66030883789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011610180139541626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934479236602783,
      "backward_entropy": 0.07611879375245836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.97242736816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011695995926856995,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10932544469833375,
      "backward_entropy": 0.07698727316326565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.01348876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011783279478549957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930541753768921,
      "backward_entropy": 0.07620834641986424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.79034423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011876484379172325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928423404693603,
      "backward_entropy": 0.07605087757110596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.61085510253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011974688619375229,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926191806793213,
      "backward_entropy": 0.07698610093858507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.9742431640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01207023300230503,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10923939943313599,
      "backward_entropy": 0.0761527352862888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.0557632446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01216195896267891,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10921680927276611,
      "backward_entropy": 0.0761322710249159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.60816955566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012249601073563099,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919418334960937,
      "backward_entropy": 0.07595515251159668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.67770385742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012337226420640945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917103290557861,
      "backward_entropy": 0.07698350482516819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.93186950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012424204498529434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10914739370346069,
      "backward_entropy": 0.07606493102179633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.08575439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01250982005149126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912342071533203,
      "backward_entropy": 0.07586998409695095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.0791778564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012602314352989197,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10909792184829711,
      "backward_entropy": 0.07698104116651747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.04678344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012693787924945354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10907198190689087,
      "backward_entropy": 0.07581109470791286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.8740005493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0127830496057868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904579162597657,
      "backward_entropy": 0.07596977551778157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.70343017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012868747115135193,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10901955366134644,
      "backward_entropy": 0.07594339715109931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.67706298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012957350350916386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899231433868409,
      "backward_entropy": 0.07571251524819268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.4054412841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01304728165268898,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10896427631378174,
      "backward_entropy": 0.07697661055458917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.79600524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013135302811861038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10893597602844238,
      "backward_entropy": 0.075644228193495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.56256103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013226503506302834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10890662670135498,
      "backward_entropy": 0.07561047871907552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.85069274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01331527903676033,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10887702703475952,
      "backward_entropy": 0.07557437817255656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.60218811035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01340804435312748,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10884612798690796,
      "backward_entropy": 0.07697305414411756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.2717742919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013498487882316113,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10881500244140625,
      "backward_entropy": 0.07697191503312853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.67523193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013590089976787567,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087830662727356,
      "backward_entropy": 0.07546297046873304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.84661865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013686870224773884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874969959259033,
      "backward_entropy": 0.07568779256608751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.53639221191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013780788518488407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10871630907058716,
      "backward_entropy": 0.07538704077402751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.0945816040039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013876889832317829,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10868184566497803,
      "backward_entropy": 0.0769687361187405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.37916564941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013967822305858135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10864777565002441,
      "backward_entropy": 0.07559163040584987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.91957092285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014061256311833858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1086125135421753,
      "backward_entropy": 0.07526728179719713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.4389190673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014152691699564457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10857702493667602,
      "backward_entropy": 0.07522658507029216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.2192840576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01424246747046709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10854120254516601,
      "backward_entropy": 0.07518506050109863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4833526611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01433049701154232,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10850510597229004,
      "backward_entropy": 0.07696365647845799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.53233337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014421235769987106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846774578094483,
      "backward_entropy": 0.07509895165761311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.46372985839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014511573128402233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842978954315186,
      "backward_entropy": 0.0750544203652276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.82025146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014601555652916431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839121341705323,
      "backward_entropy": 0.07533207204606798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.23330688476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014694184064865112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10835133790969849,
      "backward_entropy": 0.07529209057490031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.10011291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014785314910113811,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1083111047744751,
      "backward_entropy": 0.07525078455607097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.15240478515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014874187298119068,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10827070474624634,
      "backward_entropy": 0.07695797416898939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.3215789794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014965967275202274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10822887420654297,
      "backward_entropy": 0.0751643180847168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.0382080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015059963800013065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10818573236465454,
      "backward_entropy": 0.07476904657151964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.46864318847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015153246931731701,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10814203023910522,
      "backward_entropy": 0.07471859455108643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.34893798828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015245110727846622,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10809850692749023,
      "backward_entropy": 0.07695446411768596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.82456970214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015341216698288918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10805363655090332,
      "backward_entropy": 0.07498455047607422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.57093811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015443557873368263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10800644159317016,
      "backward_entropy": 0.07494099934895833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.2879180908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015544051304459572,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10795892477035522,
      "backward_entropy": 0.07695314619276258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.69009399414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015646575018763542,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10791015625,
      "backward_entropy": 0.07695297400156657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.86166381835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015740904957056046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10786268711090088,
      "backward_entropy": 0.07439223925272624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.0159683227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01583915762603283,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10781329870223999,
      "backward_entropy": 0.07433398564656575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.52072143554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01593204215168953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10776464939117432,
      "backward_entropy": 0.07427295049031575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.71490478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016024554148316383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1077152967453003,
      "backward_entropy": 0.07464199595981175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.05724334716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016122302040457726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10766359567642211,
      "backward_entropy": 0.07414910528394911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.52761840820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016215257346630096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10761226415634155,
      "backward_entropy": 0.07408228185441759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.56178283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016307439655065536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10755994319915771,
      "backward_entropy": 0.07447595066494411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.53765869140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01640513353049755,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10750503540039062,
      "backward_entropy": 0.0769451724158393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.28021240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01650181971490383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10744949579238891,
      "backward_entropy": 0.07436290714475843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.09925842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01659734547138214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10739333629608154,
      "backward_entropy": 0.07380791505177815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.22891235351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01669066958129406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10733697414398194,
      "backward_entropy": 0.07373416423797607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.07330322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016786128282546997,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10727893114089966,
      "backward_entropy": 0.07417998048994276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.69566345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016887838020920753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10721786022186279,
      "backward_entropy": 0.07358611954583062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.60626220703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016993746161460876,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10715440511703492,
      "backward_entropy": 0.0769414570596483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.34498596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01709611527621746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10709114074707031,
      "backward_entropy": 0.07400001419915093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.39834594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017195044085383415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10702803134918212,
      "backward_entropy": 0.07393352190653484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.80418395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01728997938334942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10696543455123901,
      "backward_entropy": 0.07327121496200562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.46469116210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017383525148034096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10690222978591919,
      "backward_entropy": 0.07318252987331814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.83099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017480909824371338,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10683667659759521,
      "backward_entropy": 0.07371801800198025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.33076477050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01757510006427765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10677118301391601,
      "backward_entropy": 0.0736420022116767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.349891662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017665382474660873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10670620203018188,
      "backward_entropy": 0.07290850745307074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.1957015991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017746003344655037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10664416551589966,
      "backward_entropy": 0.07347366544935438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.35517883300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017822887748479843,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10658280849456787,
      "backward_entropy": 0.07270063294304742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.76397705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017896005883812904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10652202367782593,
      "backward_entropy": 0.07259147034751044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.120361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017970113083720207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10645978450775147,
      "backward_entropy": 0.07247983747058445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.80502319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018043803051114082,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10639677047729493,
      "backward_entropy": 0.07309443420834011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.95834350585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01811804622411728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10633234977722168,
      "backward_entropy": 0.07224742571512859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.44383239746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018191879615187645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10626717805862426,
      "backward_entropy": 0.07212507062488133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.02545166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018269937485456467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10619921684265136,
      "backward_entropy": 0.07279303338792589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.5246124267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01835009828209877,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10612932443618775,
      "backward_entropy": 0.07689608467949761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.00726318359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01843550056219101,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1060562252998352,
      "backward_entropy": 0.07689360777537028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.71681213378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018522515892982483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1059814453125,
      "backward_entropy": 0.07164000140296088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.38787841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018608123064041138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1059064507484436,
      "backward_entropy": 0.07151575220955743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.7907943725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018695466220378876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1058296799659729,
      "backward_entropy": 0.0713904963599311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.84471130371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01877833716571331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10575413703918457,
      "backward_entropy": 0.07126129335827297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.89997863769531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01886010356247425,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10567817687988282,
      "backward_entropy": 0.07688123650021023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0167465209961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018939025700092316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10560251474380493,
      "backward_entropy": 0.07194936275482178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.44752502441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019015666097402573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10552703142166138,
      "backward_entropy": 0.07084978951348199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.64008331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019095147028565407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10544925928115845,
      "backward_entropy": 0.07070929474300808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.1924591064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019171353429555893,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10537183284759521,
      "backward_entropy": 0.07157831721835667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.50770568847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019247576594352722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10529361963272095,
      "backward_entropy": 0.0714459949069553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.3884048461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019325142726302147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10521382093429565,
      "backward_entropy": 0.0713125467300415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.47393798828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019398851320147514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10513503551483154,
      "backward_entropy": 0.07117325729793972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.83551788330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019476665183901787,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1050529956817627,
      "backward_entropy": 0.07103529241349962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.30642700195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019550746306777,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1049720287322998,
      "backward_entropy": 0.06977761454052395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.99708557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019624562934041023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10489037036895751,
      "backward_entropy": 0.06960752275254992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.58362579345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019697878509759903,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10480780601501465,
      "backward_entropy": 0.07059481408860949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.51651000976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019770102575421333,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10472502708435058,
      "backward_entropy": 0.0768319500817193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.4155158996582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01983918435871601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10464304685592651,
      "backward_entropy": 0.06907531950208876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.28199768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019900649785995483,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10456479787826538,
      "backward_entropy": 0.07011593712700738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.80608367919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019966254010796547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10448315143585205,
      "backward_entropy": 0.07681292957729763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.3126220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020031025633215904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10440109968185425,
      "backward_entropy": 0.06849957836998834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.30245971679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020097749307751656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10431666374206543,
      "backward_entropy": 0.06829951206843059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.92158508300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020164761692285538,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10423083305358886,
      "backward_entropy": 0.06944194104936388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.09426879882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020230699330568314,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10414466857910157,
      "backward_entropy": 0.07678937911987305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.86245727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020297031849622726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10405718088150025,
      "backward_entropy": 0.06766460339228313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.63733673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020360883325338364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10397036075592041,
      "backward_entropy": 0.06890048583348592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.70559692382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0204240120947361,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10388306379318238,
      "backward_entropy": 0.06721588638093737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.4356231689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02049003541469574,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10379312038421631,
      "backward_entropy": 0.07676276895734999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.89685821533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020556222647428513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10370190143585205,
      "backward_entropy": 0.06675887107849121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.18272399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020619846880435944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10361143350601196,
      "backward_entropy": 0.06652021408081055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.43272399902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020687837153673172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10351734161376953,
      "backward_entropy": 0.0767432451248169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.46287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0207567997276783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10342210531234741,
      "backward_entropy": 0.06773563226064046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.27572631835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02082623541355133,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10332553386688233,
      "backward_entropy": 0.06753486394882202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.25685119628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02089717984199524,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10322657823562623,
      "backward_entropy": 0.07672789361741808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.66522216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020970182493329048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10312532186508179,
      "backward_entropy": 0.06713165177239312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.60950469970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021047979593276978,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10302014350891113,
      "backward_entropy": 0.06693229410383436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.74868774414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02112199179828167,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10291658639907837,
      "backward_entropy": 0.07671680715348986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.56592559814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021196434274315834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1028120756149292,
      "backward_entropy": 0.06458641423119439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.01425170898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02126455493271351,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10271023511886597,
      "backward_entropy": 0.07670553525288899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.52366638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02133866399526596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10260212421417236,
      "backward_entropy": 0.06405989991294013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.67875671386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021417632699012756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10248959064483643,
      "backward_entropy": 0.06379887130525377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.93603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021494662389159203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10237745046615601,
      "backward_entropy": 0.06563590632544623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.44026184082031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021575994789600372,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1022611379623413,
      "backward_entropy": 0.07669060760074192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.96986389160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021655168384313583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10214550495147705,
      "backward_entropy": 0.06299651993645562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.3164825439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021728036925196648,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10203413963317871,
      "backward_entropy": 0.06271699402067396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.5436782836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021804751828312874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10191917419433594,
      "backward_entropy": 0.06471182902654012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.5350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02187924087047577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10180463790893554,
      "backward_entropy": 0.06215718719694349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.53866577148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02194858342409134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10169289112091065,
      "backward_entropy": 0.0641976727379693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.87721252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022024547681212425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10157499313354493,
      "backward_entropy": 0.06156620052125719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.91532897949219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02210325561463833,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10145388841629029,
      "backward_entropy": 0.07664950026406182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.7476806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022175196558237076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10133742094039917,
      "backward_entropy": 0.06095630592770047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1460418701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022246280685067177,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10122101306915283,
      "backward_entropy": 0.07663261890411377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.5936279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02232370525598526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10109845399856568,
      "backward_entropy": 0.06287027729882134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3937225341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022402703762054443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10097399950027466,
      "backward_entropy": 0.06002212895287408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.67523193359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022480681538581848,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10084904432296753,
      "backward_entropy": 0.07661490970187718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.11814880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022562989965081215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1007195234298706,
      "backward_entropy": 0.062052408854166664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.40711975097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022646406665444374,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10058865547180176,
      "backward_entropy": 0.07660630014207628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.01400756835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022729773074388504,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10045753717422486,
      "backward_entropy": 0.07660182317097981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.8527069091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022812414914369583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10032624006271362,
      "backward_entropy": 0.058423764175838895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.25663757324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02289934642612934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10019073486328126,
      "backward_entropy": 0.06092527839872572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.98292541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02298373356461525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10005702972412109,
      "backward_entropy": 0.06063451369603475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.88565063476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02306879125535488,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09992290735244751,
      "backward_entropy": 0.05746129486295912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.33642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0231560580432415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.099785977602005,
      "backward_entropy": 0.06005525588989258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8296356201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023238081485033035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09965349435806274,
      "backward_entropy": 0.056800511148240834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.83306121826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02332291752099991,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0995177149772644,
      "backward_entropy": 0.059459560447269015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.18536376953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02340412698686123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09938461780548095,
      "backward_entropy": 0.05613245566685995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.92528533935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023489156737923622,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0992470622062683,
      "backward_entropy": 0.05884925524393717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.08355712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023566721007227898,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09911558628082276,
      "backward_entropy": 0.058525919914245605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.6747055053711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023651909083127975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0989766240119934,
      "backward_entropy": 0.07653734419080946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.0860137939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023732494562864304,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09884077310562134,
      "backward_entropy": 0.05470028850767347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.2903289794922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023814352229237556,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09870306849479675,
      "backward_entropy": 0.07651903894212511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.52269744873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02389562502503395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.098565274477005,
      "backward_entropy": 0.05722445911831326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.37248992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023975051939487457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09842857122421264,
      "backward_entropy": 0.056883242395189076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.8024673461914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024052834138274193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09829261302947997,
      "backward_entropy": 0.07648978630701701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.05864715576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02413090504705906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0981554627418518,
      "backward_entropy": 0.056188477410210505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.78290557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02420274168252945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09802364110946656,
      "backward_entropy": 0.055826922257741295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.2292709350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02427494153380394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09789053201675416,
      "backward_entropy": 0.052010556062062584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.04673767089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024344515055418015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09775899648666382,
      "backward_entropy": 0.05160161521699694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.99859619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024419939145445824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09762113094329834,
      "backward_entropy": 0.05120617813534207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.10882568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024502048268914223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09747642278671265,
      "backward_entropy": 0.05438398321469625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.39016723632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02458699606359005,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09732820987701415,
      "backward_entropy": 0.050454003943337336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.61996459960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024676207453012466,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09717555046081543,
      "backward_entropy": 0.05371043748325772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.6654281616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024766510352492332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09702174663543701,
      "backward_entropy": 0.053375555409325495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.40802764892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024852322414517403,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09687190055847168,
      "backward_entropy": 0.053023450904422335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.26446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024937594309449196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09672216773033142,
      "backward_entropy": 0.05266671048270331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.47051239013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025030091404914856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0965651035308838,
      "backward_entropy": 0.052325944105784096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.271728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025116300210356712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09641404151916504,
      "backward_entropy": 0.048207620779673256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.66249084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025205111131072044,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09626007676124573,
      "backward_entropy": 0.05161320169766744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.0924301147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025295987725257874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09610369801521301,
      "backward_entropy": 0.04744138651423984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.5933380126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02538413181900978,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09594981670379639,
      "backward_entropy": 0.05090176396899753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.82830047607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025474704802036285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09579317569732666,
      "backward_entropy": 0.05054447385999891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.13389587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025563018396496773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09563911557197571,
      "backward_entropy": 0.05017828279071384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.5615005493164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025653764605522156,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09548227190971374,
      "backward_entropy": 0.07636068926917182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.30945587158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025738926604390144,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09533123970031739,
      "backward_entropy": 0.07635295391082764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.74324035644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025820542126893997,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0951836884021759,
      "backward_entropy": 0.04509168201022678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.78485107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025898698717355728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09503940343856812,
      "backward_entropy": 0.044669522179497614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.5350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0259846281260252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09488669037818909,
      "backward_entropy": 0.04828219281302558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.70886993408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026074832305312157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09472970366477966,
      "backward_entropy": 0.0438740419016944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.63864135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026164203882217407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09457361698150635,
      "backward_entropy": 0.043479068411721125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.78672790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02625325880944729,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09441821575164795,
      "backward_entropy": 0.043088555335998535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.69379425048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02634318917989731,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09426193237304688,
      "backward_entropy": 0.042698790629704796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.99491882324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026427611708641052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09411170482635497,
      "backward_entropy": 0.042291770378748574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.82063293457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02650868333876133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09396513700485229,
      "backward_entropy": 0.04187722669707404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.82891845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02658936381340027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0938184916973114,
      "backward_entropy": 0.041453533702426486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.9979248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026675662025809288,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09366542100906372,
      "backward_entropy": 0.045252200629976064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.86094665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026759495958685875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09351490139961242,
      "backward_entropy": 0.04060245553652445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.41476440429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026847096160054207,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09336022138595582,
      "backward_entropy": 0.04446873068809509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.20026779174805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026930976659059525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09321008920669556,
      "backward_entropy": 0.07623343335257636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.4413833618164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027009058743715286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09306718111038208,
      "backward_entropy": 0.07621763812171088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.62476348876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027087703347206116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09292382001876831,
      "backward_entropy": 0.03885743353101942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.45512390136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027163727208971977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09278358817100525,
      "backward_entropy": 0.038417554563946195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.16543579101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027237413451075554,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09264612197875977,
      "backward_entropy": 0.03797620866033766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.6600341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027316559106111526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09250257015228272,
      "backward_entropy": 0.04198961125479804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.9069061279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02739567868411541,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0923593819141388,
      "backward_entropy": 0.04158084922366672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.81694412231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02747790515422821,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09221296310424805,
      "backward_entropy": 0.04118020666970147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.48576354980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027554377913475037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09207379817962646,
      "backward_entropy": 0.036254680818981595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.5210952758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027631431818008423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09193440675735473,
      "backward_entropy": 0.03582596116595798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.48490905761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027708888053894043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09179489612579346,
      "backward_entropy": 0.03993229733573066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.09481811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027784438803792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0916583776473999,
      "backward_entropy": 0.034965187311172485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.535888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02786114811897278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09152122139930725,
      "backward_entropy": 0.0390984680917528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.43962860107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027934784069657326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09138877391815185,
      "backward_entropy": 0.07603453265296088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.50697326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028006121516227722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09125909805297852,
      "backward_entropy": 0.033721215195126004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.17811584472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02808431349694729,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09112173318862915,
      "backward_entropy": 0.07600575023227268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.7448959350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02816767245531082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09097932577133179,
      "backward_entropy": 0.03292745020654467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.7364044189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028251072391867638,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09083793163299561,
      "backward_entropy": 0.037106596761279635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.58912658691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028336910530924797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09069426655769348,
      "backward_entropy": 0.03672694828775194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.36820983886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028424525633454323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09054991006851196,
      "backward_entropy": 0.03174321519003974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.27366638183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028510678559541702,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09040831327438355,
      "backward_entropy": 0.03598463204171923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.11666870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028599990531802177,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09026445150375366,
      "backward_entropy": 0.03098555737071567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.78875732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02869146130979061,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09011898040771485,
      "backward_entropy": 0.035270869731903076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.62898254394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028784047812223434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08997353315353393,
      "backward_entropy": 0.030250079101986356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8711700439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028876129537820816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08982985019683838,
      "backward_entropy": 0.034574018584357366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.07492065429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028971755877137184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08968337178230286,
      "backward_entropy": 0.029527366161346436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.85529327392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02906521037220955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08954070210456848,
      "backward_entropy": 0.02917067872153388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.4627456665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029156729578971863,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08940134644508362,
      "backward_entropy": 0.03355113002989027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.39894104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02924317680299282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08926849365234375,
      "backward_entropy": 0.02844302521811591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.36288833618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02933119423687458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08913471698760986,
      "backward_entropy": 0.03284456332524618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.28904724121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02941299043595791,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08900891542434693,
      "backward_entropy": 0.03248090876473321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.61921691894531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029496587812900543,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08888134956359864,
      "backward_entropy": 0.07598757743835449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.06497192382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02958209440112114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08875117301940919,
      "backward_entropy": 0.031783723168902926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.66998291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02966754510998726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08862139582633972,
      "backward_entropy": 0.026621591713693406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.77941131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029758814722299576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08848599791526794,
      "backward_entropy": 0.03111960490544637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.9031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029850561171770096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0883509635925293,
      "backward_entropy": 0.030795600679185655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.02085876464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029939472675323486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08822048902511596,
      "backward_entropy": 0.025587389866511028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.27374267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030031170696020126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08808817863464355,
      "backward_entropy": 0.030150297615263198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.29218292236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03012685291469097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08795305490493774,
      "backward_entropy": 0.029845959610409208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.61878967285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030223563313484192,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.087818443775177,
      "backward_entropy": 0.02955128749211629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.95281219482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030321869999170303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08768330812454224,
      "backward_entropy": 0.029256367021136813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.87110137939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03041892871260643,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08755083084106445,
      "backward_entropy": 0.028956605328453913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.58928680419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03051149658858776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08742485642433166,
      "backward_entropy": 0.02865884370274014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.8325080871582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03059934824705124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08730490207672119,
      "backward_entropy": 0.023368620210223727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.4507064819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030681606382131577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08719195127487182,
      "backward_entropy": 0.0280395680003696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.11325073242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03076186776161194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08708211183547973,
      "backward_entropy": 0.022727967964278326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.07893371582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03083966299891472,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0869754672050476,
      "backward_entropy": 0.027412452631526522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.40489959716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030918670818209648,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08686842918395996,
      "backward_entropy": 0.022082805633544922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.21619415283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0309947170317173,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08676570653915405,
      "backward_entropy": 0.026802299751175776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.50675201416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03107340633869171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08666107654571534,
      "backward_entropy": 0.026505988505151536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.4363784790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03115057572722435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08655913472175598,
      "backward_entropy": 0.02115456263224284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.2220458984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03122883103787899,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08645685911178588,
      "backward_entropy": 0.02591842578517066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.8351821899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03130388632416725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08635882139205933,
      "backward_entropy": 0.02562191254562802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.73113250732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031382035464048386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08625874519348145,
      "backward_entropy": 0.025340613391664293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.8620376586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03145718574523926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08616281151771546,
      "backward_entropy": 0.01994267437193129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.50373077392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031532641500234604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08606778383255005,
      "backward_entropy": 0.024785243802600436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.00623321533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03160853311419487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08597322702407836,
      "backward_entropy": 0.01937581764327155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.86477661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03168511018157005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08587901592254639,
      "backward_entropy": 0.02427891559071011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.73539733886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03176071122288704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08578696250915527,
      "backward_entropy": 0.02403747042020162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.4719467163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03183693066239357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08569545745849609,
      "backward_entropy": 0.023806326919131808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.59648895263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031910765916109085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08560743331909179,
      "backward_entropy": 0.01835749712255266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.55931854248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031985167413949966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08551985621452332,
      "backward_entropy": 0.02334961626264784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3181610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03205700218677521,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08543565273284912,
      "backward_entropy": 0.017861372894710965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.96479034423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03213376924395561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08534759283065796,
      "backward_entropy": 0.02289983133474986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.1038360595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03221365064382553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0852576494216919,
      "backward_entropy": 0.017392648590935603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.90380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03229725360870361,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08516520857810975,
      "backward_entropy": 0.017164099547598097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.93213653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032381199300289154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08507398366928101,
      "backward_entropy": 0.01695202456580268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.5497589111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03246519714593887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0849840760231018,
      "backward_entropy": 0.022131231096055772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.31708526611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032553184777498245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08489187955856323,
      "backward_entropy": 0.021968061725298565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.14781951904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032639894634485245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08480174541473388,
      "backward_entropy": 0.02179150117768182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.37610626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327288955450058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08471088409423828,
      "backward_entropy": 0.016158456603686016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.3046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281707689166069,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0846219778060913,
      "backward_entropy": 0.015964617331822712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.58706665039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032905444502830505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0845339059829712,
      "backward_entropy": 0.015766690174738567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.92768096923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03299451991915703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08444647789001465,
      "backward_entropy": 0.015574536389774747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.97686004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308045119047165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08436318635940551,
      "backward_entropy": 0.015387657615873549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.0233383178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033163297921419144,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08428363800048828,
      "backward_entropy": 0.020837315254741244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.3380126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03324311971664429,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08420772552490234,
      "backward_entropy": 0.02068550553586748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.39009857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03332090377807617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08413486480712891,
      "backward_entropy": 0.014833051297399733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.47148895263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033396605402231216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08406469225883484,
      "backward_entropy": 0.014655573500527276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.06458282470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033473070710897446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08399461507797241,
      "backward_entropy": 0.014482928646935357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.70939636230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03355050086975098,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08392460346221924,
      "backward_entropy": 0.02015900943014357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.556556701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03362971544265747,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0838538646697998,
      "backward_entropy": 0.020040093196762934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.15054321289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03370227292180061,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08378978967666625,
      "backward_entropy": 0.013983527819315592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.71404266357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033779844641685486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08372213840484619,
      "backward_entropy": 0.019779120882352192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.10005187988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033859606832265854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08365366458892823,
      "backward_entropy": 0.01966578761736552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.98033905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033942367881536484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08358360528945923,
      "backward_entropy": 0.019559214512507122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.84371948242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03402525559067726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08351437449455261,
      "backward_entropy": 0.013357236153549619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.7033462524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034108132123947144,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08344601988792419,
      "backward_entropy": 0.019355217615763348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.736839294433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03419088199734688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0833785891532898,
      "backward_entropy": 0.0192487637201945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.87184143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03427107259631157,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08331411480903625,
      "backward_entropy": 0.0191432966126336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.015928268432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03435026481747627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08325119018554687,
      "backward_entropy": 0.012753644751177894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.94194412231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03442271426320076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0831945776939392,
      "backward_entropy": 0.018921198116408453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.05636978149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034492503851652145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08314090967178345,
      "backward_entropy": 0.018810760643747117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.61612701416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03455952927470207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0830898940563202,
      "backward_entropy": 0.01228433930211597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.29954528808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03462616354227066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.083039391040802,
      "backward_entropy": 0.012121804886394076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.62508010864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03469427675008774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0829879879951477,
      "backward_entropy": 0.018460232350561354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.9296646118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034758418798446655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08293945193290711,
      "backward_entropy": 0.01834169526894887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.7301025390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03482277691364288,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08289055228233337,
      "backward_entropy": 0.011639239887396494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.66071319580078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03489171713590622,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08283780217170715,
      "backward_entropy": 0.07627956072489421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.22419738769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03496580198407173,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08278102874755859,
      "backward_entropy": 0.01800697710778978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.05838394165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03503540903329849,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08272871971130372,
      "backward_entropy": 0.017896418770154316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.66793823242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03510113060474396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.082680344581604,
      "backward_entropy": 0.017784845497873094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.918601989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035168908536434174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08263049125671387,
      "backward_entropy": 0.01768395470248328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.41571044921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03523172810673714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08258554935455323,
      "backward_entropy": 0.010748509731557634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3157730102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0352955237030983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08253998160362244,
      "backward_entropy": 0.010612077183193631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.83280181884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035361114889383316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08249324560165405,
      "backward_entropy": 0.017401145564185247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.2638168334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035428959876298904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08244501352310181,
      "backward_entropy": 0.017324906256463792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.8744125366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035502396523952484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08239268064498902,
      "backward_entropy": 0.010232270591788821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.15338897705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03557542338967323,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0823412835597992,
      "backward_entropy": 0.010112015737427605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.038185119628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0356501005589962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08228893280029297,
      "backward_entropy": 0.017126099930869207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8773422241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035721585154533386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08223966360092164,
      "backward_entropy": 0.017061511675516765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.8714599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03579452633857727,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08218975067138672,
      "backward_entropy": 0.01700236565536923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.11595916748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03586423024535179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08214290142059326,
      "backward_entropy": 0.016930841737323336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.14287567138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035936854779720306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08209406137466431,
      "backward_entropy": 0.00954666237036387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.92485809326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03601108863949776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08204454183578491,
      "backward_entropy": 0.009443735082944235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.425174713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03608677536249161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08199431896209716,
      "backward_entropy": 0.009347712828053368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.48234558105469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03616160899400711,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08194533586502076,
      "backward_entropy": 0.0763806700706482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.37477111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036232296377420425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08190014362335205,
      "backward_entropy": 0.00917593389749527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.15633392333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03630192205309868,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08185617923736573,
      "backward_entropy": 0.009089413616392348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.48246765136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03637324646115303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08181101679801941,
      "backward_entropy": 0.009004972875118256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.6192398071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03644711896777153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08176417350769043,
      "backward_entropy": 0.01668328709072537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.384883880615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03652465343475342,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08171488046646118,
      "backward_entropy": 0.016666190491782293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.3649787902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03659908473491669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08166840672492981,
      "backward_entropy": 0.016646984550688002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.3136100769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03667037561535835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08162472248077393,
      "backward_entropy": 0.01661675837304857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.08981704711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03674093261361122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08158183097839355,
      "backward_entropy": 0.01659963693883684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.1540298461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036811068654060364,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08153966069221497,
      "backward_entropy": 0.008491795923974779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.55621337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03688548877835274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08149441480636596,
      "backward_entropy": 0.016606784529156156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.08198547363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036962732672691345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08144700527191162,
      "backward_entropy": 0.016622578104337055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.10054779052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03704126924276352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08139886856079101,
      "backward_entropy": 0.008295873800913492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3961181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0371219739317894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08134934902191163,
      "backward_entropy": 0.016670246918996174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.45856475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037209637463092804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08129519820213318,
      "backward_entropy": 0.016693067219522264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.90845489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037297170609235764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08124148249626159,
      "backward_entropy": 0.016711970170338947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.812259674072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037378016859292984,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08119330406188965,
      "backward_entropy": 0.016720535026656255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.77989959716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03745715692639351,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08114665150642394,
      "backward_entropy": 0.016734932859738667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.52721405029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03753555566072464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08110069036483765,
      "backward_entropy": 0.007954229083326127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.20132446289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03761463612318039,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0810543179512024,
      "backward_entropy": 0.00789154569307963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.0511245727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03769465535879135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08100736737251282,
      "backward_entropy": 0.016752825842963323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.10700988769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0377751886844635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08096012473106384,
      "backward_entropy": 0.01675600144598219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.694091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03785349056124687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08091472387313843,
      "backward_entropy": 0.016750617159737483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.99003601074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03793899714946747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08086429834365845,
      "backward_entropy": 0.0076447998483975725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.82306671142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038019854575395584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08081761598587037,
      "backward_entropy": 0.007588444484604729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.19548225402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03809710219502449,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08077387809753418,
      "backward_entropy": 0.007526129484176636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.23055267333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03816862776875496,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0807348370552063,
      "backward_entropy": 0.016747517718209162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.94802856445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03824315965175629,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08069344758987426,
      "backward_entropy": 0.07676418622334798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.906005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038320496678352356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08065001964569092,
      "backward_entropy": 0.016757024659050837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.1391372680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03839593008160591,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08060799241065979,
      "backward_entropy": 0.01675853133201599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.864501953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03847184404730797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08056557774543763,
      "backward_entropy": 0.01677805847591824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.00401306152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03855108469724655,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08052059412002563,
      "backward_entropy": 0.07679859797159831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.631656646728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0386320985853672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08047420978546142,
      "backward_entropy": 0.016792954670058355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.0655517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038709938526153564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08043034076690674,
      "backward_entropy": 0.007073790662818485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.11621856689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038785722106695175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08038804531097413,
      "backward_entropy": 0.007013518777158525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.27977752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038863930851221085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08034379482269287,
      "backward_entropy": 0.006956443190574646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.61825561523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03894541412591934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08029696941375733,
      "backward_entropy": 0.01678106188774109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.312345504760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03902841731905937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08024886846542359,
      "backward_entropy": 0.006844330165121291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.03781509399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03910520300269127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08020588159561157,
      "backward_entropy": 0.0067842453718185425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.50334167480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03918077424168587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08016376495361328,
      "backward_entropy": 0.006730729093154271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.66224670410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03925725445151329,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08012077212333679,
      "backward_entropy": 0.016757367385758296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.9827880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039342090487480164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08007146120071411,
      "backward_entropy": 0.006624770661195119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.446842193603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039426982402801514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08002197742462158,
      "backward_entropy": 0.006573062804010179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.37837219238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0395091213285923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07997441291809082,
      "backward_entropy": 0.016742426488134596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.84307098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03959008306264877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07992771863937378,
      "backward_entropy": 0.00645864713523123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.95254516601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03966648504137993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07988485097885131,
      "backward_entropy": 0.016708564427163865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.74838256835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039745479822158813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07983984351158142,
      "backward_entropy": 0.006352023118072086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.52582931518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03982490301132202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07979402542114258,
      "backward_entropy": 0.006300537122620476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.36986541748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03990103304386139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07975081205368043,
      "backward_entropy": 0.006247277061144511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.23312759399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03997430205345154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07970982193946838,
      "backward_entropy": 0.01668309337562985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.38585662841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04004500061273575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07967082262039185,
      "backward_entropy": 0.016671551598442927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.79585266113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04012119770050049,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07962701320648194,
      "backward_entropy": 0.016672145989206102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.45309066772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040195927023887634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07958422899246216,
      "backward_entropy": 0.016675351394547358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.079519271850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04027051851153374,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07954127788543701,
      "backward_entropy": 0.016679624716440838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.31541442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040340133011341095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07950257658958435,
      "backward_entropy": 0.005955771439605289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.38899230957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04040874168276787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07946450114250184,
      "backward_entropy": 0.005910768691036437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.42598724365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040475551038980484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07942777872085571,
      "backward_entropy": 0.01670657263861762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.838741302490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0405438095331192,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07938936948776246,
      "backward_entropy": 0.07688726319207086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.67939758300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040611203759908676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07935146093368531,
      "backward_entropy": 0.016711788045035467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.3501968383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04067781940102577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07931379079818726,
      "backward_entropy": 0.00573303136560652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.310237884521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074726998806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07927339673042297,
      "backward_entropy": 0.005686123338010576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.8299331665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04081622511148453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07923321723937989,
      "backward_entropy": 0.016715460353427462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.00619888305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04088777303695679,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07919027209281922,
      "backward_entropy": 0.016716821326149836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.831295013427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04095832630991936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07914782762527466,
      "backward_entropy": 0.016722063223520916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.1142463684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04102807492017746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0791058897972107,
      "backward_entropy": 0.016734126541349623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.14623260498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041098274290561676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07906318306922913,
      "backward_entropy": 0.016752175158924527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.355674743652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04117255285382271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07901638150215148,
      "backward_entropy": 0.016776649488343134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.50871658325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041245270520448685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07897064685821534,
      "backward_entropy": 0.005414408942063649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.9083023071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04131803289055824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07892449498176575,
      "backward_entropy": 0.016811923848258123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.540000915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041393425315618515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07887549996376038,
      "backward_entropy": 0.005346614867448807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.12755584716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041466157883405685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07882869839668274,
      "backward_entropy": 0.0053144097328186035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.26650619506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04154007136821747,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07878031134605408,
      "backward_entropy": 0.016886389917797513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.452491760253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04161137714982033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07873412370681762,
      "backward_entropy": 0.016909271478652954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.2662239074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04168311506509781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07868711352348327,
      "backward_entropy": 0.016942118604977924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.05582046508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04175495728850365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07863951921463012,
      "backward_entropy": 0.01697495745288001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.856021881103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04182697832584381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07859128713607788,
      "backward_entropy": 0.005163895587126414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.60299301147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04189906269311905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07854251265525818,
      "backward_entropy": 0.005135968327522278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.43787956237793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041970137506723404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0784943163394928,
      "backward_entropy": 0.005109426875909169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.22346115112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04203761741518974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07844949960708618,
      "backward_entropy": 0.017114695575502183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.217273712158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042106837034225464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07840234041213989,
      "backward_entropy": 0.01714817186196645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.67227172851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042173005640506744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07835811376571655,
      "backward_entropy": 0.005027680347363154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.154178619384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04224235191941261,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07830998897552491,
      "backward_entropy": 0.017235043976042006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.782318115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04230720177292824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07826626300811768,
      "backward_entropy": 0.004980548388428158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.8397159576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042370397597551346,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07822361588478088,
      "backward_entropy": 0.0173230552011066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.118629455566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042430948466062546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07818338871002198,
      "backward_entropy": 0.004931360069248412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.97746276855469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042492568492889404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07814123630523681,
      "backward_entropy": 0.07696415318383111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.721656799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042559701949357986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07809245586395264,
      "backward_entropy": 0.017429909772343107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.756128311157227,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04262757673859596,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07804202437400817,
      "backward_entropy": 0.0769674645529853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.682735443115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042691271752119064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07799618244171143,
      "backward_entropy": 0.017507880926132202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.42495727539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0427546389400959,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07795016169548034,
      "backward_entropy": 0.07697137196858723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.5427360534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042821116745471954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0778998851776123,
      "backward_entropy": 0.004779135187466939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.184207916259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288967698812485,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07784665822982788,
      "backward_entropy": 0.0047575972146458095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.073482513427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04295757785439491,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0777936577796936,
      "backward_entropy": 0.01767896446916792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.87590789794922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04302739351987839,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07773782014846801,
      "backward_entropy": 0.07697980933719212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.145633697509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309571534395218,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07768309116363525,
      "backward_entropy": 0.004696870843569438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.085872650146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316442087292671,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07762720584869384,
      "backward_entropy": 0.004673608889182408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53470611572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04323093965649605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07757350206375122,
      "backward_entropy": 0.017844340867466398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.62425994873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04330042377114296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07751551866531373,
      "backward_entropy": 0.017879986100726657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.33940315246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043373677879571915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07745233774185181,
      "backward_entropy": 0.004602942201826308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.40170669555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043443065136671066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07739347815513611,
      "backward_entropy": 0.01794680456320445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.62385177612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04351380094885826,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07733217477798462,
      "backward_entropy": 0.017976504233148363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.46165466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04358375072479248,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07727131247520447,
      "backward_entropy": 0.018017806940608554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.717741012573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043652649968862534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07721112370491028,
      "backward_entropy": 0.01805761953194936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.44516372680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043717145919799805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0771562933921814,
      "backward_entropy": 0.004490892506308026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.4737777709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04378335550427437,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07709845304489135,
      "backward_entropy": 0.018136857284439936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.51400375366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043853066861629486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07703514695167542,
      "backward_entropy": 0.018157260285483465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.7249870300293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04391820728778839,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07697768211364746,
      "backward_entropy": 0.01818070477909512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.363567352294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043985214084386826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07691695690155029,
      "backward_entropy": 0.004393098254998525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.280094146728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044048331677913666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07686119079589844,
      "backward_entropy": 0.018254983756277297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.07651138305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04411300644278526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07680246829986573,
      "backward_entropy": 0.018284602297676936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.9587516784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044178374111652374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07674205899238587,
      "backward_entropy": 0.004328252126773198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.68792724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04424292594194412,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07668201923370362,
      "backward_entropy": 0.018344188729921978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.62745666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04430784657597542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07662066221237182,
      "backward_entropy": 0.004278263698021571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.972052574157715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04437190666794777,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07655978202819824,
      "backward_entropy": 0.018373289042048983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.69780731201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04443195089697838,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07650429606437684,
      "backward_entropy": 0.018386815985043842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.91805648803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04448989778757095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07645145654678345,
      "backward_entropy": 0.004200079374843174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.783893585205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044549014419317245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07639613151550292,
      "backward_entropy": 0.018445907367600337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.55335998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04460461065173149,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07634564638137817,
      "backward_entropy": 0.004154956589142482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.343017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04466208443045616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07629176378250122,
      "backward_entropy": 0.01852591832478841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.907501220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471737891435623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07624072432518006,
      "backward_entropy": 0.004119584957758586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.418880462646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044771891087293625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07618995308876038,
      "backward_entropy": 0.00410251153839959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.0837345123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04482679069042206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07613810896873474,
      "backward_entropy": 0.018672961327764723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.002485275268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04487975686788559,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07608890533447266,
      "backward_entropy": 0.018720181451903448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.633785247802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044930823147296906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07604200839996338,
      "backward_entropy": 0.00404779240489006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.86425018310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04498595744371414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07598786354064942,
      "backward_entropy": 0.018798010216818914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.71059799194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04504108056426048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07593293190002441,
      "backward_entropy": 0.01882160372204251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.85240936279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0450967401266098,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07587656974792481,
      "backward_entropy": 0.018855194250742596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.67953872680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04515814408659935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07581005692481994,
      "backward_entropy": 0.01888111068142785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.40693664550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045222535729408264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07573842406272888,
      "backward_entropy": 0.0039396364655759596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.701566696166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04528975486755371,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07566158175468445,
      "backward_entropy": 0.003918712751732932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.24466323852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535495862364769,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.075586998462677,
      "backward_entropy": 0.01896025240421295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.566328048706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04541686922311783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07551733255386353,
      "backward_entropy": 0.018981743190023635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.830894470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04547357186675072,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07545599341392517,
      "backward_entropy": 0.003852594643831253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.64476013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045531295239925385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0753921091556549,
      "backward_entropy": 0.019008232487572566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.654212951660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04559024050831795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07532532215118408,
      "backward_entropy": 0.01902576618724399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.592247009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565119743347168,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07525429129600525,
      "backward_entropy": 0.003781766113307741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.0560417175293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045715250074863434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07517728209495544,
      "backward_entropy": 0.01906384030977885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.65416145324707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04577963799238205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07509881258010864,
      "backward_entropy": 0.01908256279097663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.712646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04584196209907532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07502312660217285,
      "backward_entropy": 0.01909417576260037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.444175720214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04590576887130737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07494381666183472,
      "backward_entropy": 0.0036903139617707995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.245399475097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04597006365656853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07486284971237182,
      "backward_entropy": 0.01910934845606486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.03398513793945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04603259637951851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07478432655334473,
      "backward_entropy": 0.019126051002078585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.83149719238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046095579862594604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07470418810844422,
      "backward_entropy": 0.019141453835699294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.734195709228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0461590401828289,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0746225118637085,
      "backward_entropy": 0.019159154759513006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.701765060424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0462220124900341,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07454105615615844,
      "backward_entropy": 0.019187173909611173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.87881851196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046283334493637085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07446203827857971,
      "backward_entropy": 0.019220448202557035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.02004623413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04634729400277138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07437703609466553,
      "backward_entropy": 0.019245295061005488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.29279136657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04641173779964447,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07429041862487792,
      "backward_entropy": 0.01927688717842102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.60347366333008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04647443816065788,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07420640587806701,
      "backward_entropy": 0.003511980175971985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.10130310058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046537432819604874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0741208016872406,
      "backward_entropy": 0.01934828029738532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.53720474243164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046602312475442886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0740307867527008,
      "backward_entropy": 0.07700139284133911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.73450469970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046666424721479416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0739413321018219,
      "backward_entropy": 0.01944668425454034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.603912353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04672835022211075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0738551914691925,
      "backward_entropy": 0.01948494381374783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.030635833740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046788521111011505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0737716794013977,
      "backward_entropy": 0.00343461065656609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.39364242553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04684821516275406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07368821501731873,
      "backward_entropy": 0.019555815392070346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.70909118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046908579766750336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07360231876373291,
      "backward_entropy": 0.003401184661520852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.539974212646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0469687283039093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07351595759391785,
      "backward_entropy": 0.01963587270842658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.950624465942383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047028373926877975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07342984676361083,
      "backward_entropy": 0.0033718434472878775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.010658264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047086529433727264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07334597110748291,
      "backward_entropy": 0.019722599122259352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.327880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714649170637131,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07325701713562012,
      "backward_entropy": 0.0033416209949387442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.5660400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04720381647348404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07317314743995666,
      "backward_entropy": 0.01980111002922058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.743837356567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0472598597407341,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07309106588363648,
      "backward_entropy": 0.019842005438274808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.775457382202148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04731576517224312,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0730082631111145,
      "backward_entropy": 0.01988114251030816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.448223114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04736832529306412,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0729324221611023,
      "backward_entropy": 0.019920107391145494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.655932426452637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04742122441530228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07285481691360474,
      "backward_entropy": 0.0032648597326543597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.34966278076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04747099429368973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07278388738632202,
      "backward_entropy": 0.0032492613212929834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.863731384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04752231389284134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.072707998752594,
      "backward_entropy": 0.020042366451687284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.27177429199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04757298529148102,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07263299226760864,
      "backward_entropy": 0.020084432429737516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.032005310058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047627124935388565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07254887819290161,
      "backward_entropy": 0.020118675298160978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.493568420410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04768437147140503,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0724565863609314,
      "backward_entropy": 0.0031853730065955054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.535953521728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04773993417620659,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0723669946193695,
      "backward_entropy": 0.020160981350474887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.25898742675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04779871553182602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07226893305778503,
      "backward_entropy": 0.020184786783324346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.168709754943848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047858159989118576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07216842174530029,
      "backward_entropy": 0.0031319701423247657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.929277420043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04791402444243431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07207605838775635,
      "backward_entropy": 0.020249418086475797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.783336639404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04796967655420303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07198301553726197,
      "backward_entropy": 0.020284208986494277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.38225555419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04802548140287399,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07188904285430908,
      "backward_entropy": 0.02033272882302602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.4610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048083193600177765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07178967595100402,
      "backward_entropy": 0.020378695593939886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.1177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048140548169612885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07168995141983033,
      "backward_entropy": 0.0030627910875611836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04819856584072113,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.071587473154068,
      "backward_entropy": 0.020467379026942782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.23729705810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04825204983353615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0714961588382721,
      "backward_entropy": 0.020516163773006864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.844331741333008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04830457270145416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07140645980834961,
      "backward_entropy": 0.020567390653822158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.99974822998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04835714399814606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07131556272506714,
      "backward_entropy": 0.0030117755134900412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.89194869995117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048408687114715576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07122637033462524,
      "backward_entropy": 0.020660686824056838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.12889289855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0484623983502388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0711302936077118,
      "backward_entropy": 0.020700847109158833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.652875900268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04851410537958145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07103887796401978,
      "backward_entropy": 0.002971572387549612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.95270538330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048565056174993515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07094869017601013,
      "backward_entropy": 0.02079826593399048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.648921966552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048614129424095154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07086271047592163,
      "backward_entropy": 0.020848014288478427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.838926315307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04866674542427063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07076616287231445,
      "backward_entropy": 0.0029351073834631178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.198040962219238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048719607293605804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07066802978515625,
      "backward_entropy": 0.020956204997168645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.01389694213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04876946657896042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0705774962902069,
      "backward_entropy": 0.021018756760491267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.082545280456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04882045090198517,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07048269510269164,
      "backward_entropy": 0.021069453822241888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.852155685424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04886854067444801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07039529085159302,
      "backward_entropy": 0.021121679080857172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.136201858520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04891582950949669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07030913233757019,
      "backward_entropy": 0.0211631887488895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.6409969329834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04896356910467148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07022069096565246,
      "backward_entropy": 0.02120151784684923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.20573425292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049010735005140305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07013300061225891,
      "backward_entropy": 0.002849217504262924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.114273071289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04905951768159866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07003976106643676,
      "backward_entropy": 0.02128266625934177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.59540557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04910650476813316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06995084881782532,
      "backward_entropy": 0.021320616205533344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.20857810974121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04915387183427811,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06985992193222046,
      "backward_entropy": 0.021351532803641424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.10172462463379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04920068010687828,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06976975202560425,
      "backward_entropy": 0.021383133199479844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.394620895385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049246978014707565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0696802020072937,
      "backward_entropy": 0.0027775849319166606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.895692825317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049294598400592804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06958563327789306,
      "backward_entropy": 0.021437075403001573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.37239074707031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049342017620801926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06949114203453063,
      "backward_entropy": 0.021479507287343342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.783893585205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0493929348886013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06938495635986328,
      "backward_entropy": 0.021522849798202515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.637348175048828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04944399371743202,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06927785873413086,
      "backward_entropy": 0.07701502243677776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.5548152923584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04949510097503662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0691703200340271,
      "backward_entropy": 0.002712603865398301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.310386657714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04954732209444046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06905820965766907,
      "backward_entropy": 0.02166209618250529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.194738388061523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049598440527915955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06894851922988891,
      "backward_entropy": 0.021707488430870905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.130831718444824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964862018823624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06884121298789977,
      "backward_entropy": 0.002678064836396111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.91901969909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049695923924446106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06874228119850159,
      "backward_entropy": 0.02180183596081204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.86568832397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0497436597943306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06864047646522523,
      "backward_entropy": 0.021851244899961684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.43827819824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049790967255830765,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06853951811790467,
      "backward_entropy": 0.002645917236804962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.77795696258545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049840886145830154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06842958927154541,
      "backward_entropy": 0.02198015484544966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.211793899536133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049889128655195236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06832440495491028,
      "backward_entropy": 0.022056938873396978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.230558395385742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04993898794054985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0682132065296173,
      "backward_entropy": 0.02214678294128842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.64871597290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04998914897441864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.068100106716156,
      "backward_entropy": 0.022241471542252436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.195289611816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004110187292099,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0679797351360321,
      "backward_entropy": 0.0026175599131319257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.785322189331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0500955693423748,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06784977316856385,
      "backward_entropy": 0.022373181250360277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.629779815673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0501498281955719,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06771961450576783,
      "backward_entropy": 0.022435973087946575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.81654167175293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05020368844270706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06758968830108643,
      "backward_entropy": 0.022495357526673213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.84684753417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05025625228881836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06746320724487305,
      "backward_entropy": 0.02255409624841478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.36256408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05031242221593857,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06732348203659058,
      "backward_entropy": 0.02260666423373752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.568029403686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05036972090601921,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06717861890792846,
      "backward_entropy": 0.02264597349696689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.902605056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050426971167325974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0670325517654419,
      "backward_entropy": 0.022670454449123807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.67300796508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05048539862036705,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06688115596771241,
      "backward_entropy": 0.022695134083429973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.044097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0505412332713604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06673788428306579,
      "backward_entropy": 0.022732868790626526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.227703094482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050595566630363464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.066598778963089,
      "backward_entropy": 0.002511243439382977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.984474182128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050651177763938904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06645383834838867,
      "backward_entropy": 0.02281163301732805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.049270629882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050703614950180054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0663195013999939,
      "backward_entropy": 0.02286552886168162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.210959434509277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050755418837070465,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06618607044219971,
      "backward_entropy": 0.02290311290158166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.759538650512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050805043429136276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0660596251487732,
      "backward_entropy": 0.022941248284445867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.04135513305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05085435509681702,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06593309044837951,
      "backward_entropy": 0.002452720370557573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697931289672852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050901588052511215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06581381559371949,
      "backward_entropy": 0.0024388030999236638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.119060516357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0509461835026741,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06570358276367187,
      "backward_entropy": 0.0024257790711190966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.22679328918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05098985135555267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0655953049659729,
      "backward_entropy": 0.023036160402827792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.91423797607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05103415995836258,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06548349261283874,
      "backward_entropy": 0.023064793811904058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.493233680725098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0510779544711113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06537309885025025,
      "backward_entropy": 0.0023843879914946025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.40047836303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05111924186348915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06527170538902283,
      "backward_entropy": 0.02312450607617696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.281454086303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051164768636226654,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06515278816223144,
      "backward_entropy": 0.023142430517408583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.600858688354492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05120659992098808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06504763960838318,
      "backward_entropy": 0.023152843117713928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.47771453857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05124881863594055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06493992805480957,
      "backward_entropy": 0.023155740565723844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.280777931213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05129144713282585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06482957601547241,
      "backward_entropy": 0.023156088259485032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.247398376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051332950592041016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06472316980361939,
      "backward_entropy": 0.002292893413040373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.129520416259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05137611925601959,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06460928320884704,
      "backward_entropy": 0.023202170928319294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.094922065734863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0514175146818161,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06450145244598389,
      "backward_entropy": 0.023215106791920133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.871837615966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05145677179098129,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06440168619155884,
      "backward_entropy": 0.02323479950428009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.677112579345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05149656906723976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0642986238002777,
      "backward_entropy": 0.023243039846420288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.63651466369629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05153803154826164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06418788433074951,
      "backward_entropy": 0.002220150497224596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.031131267547607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051579996943473816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06407424807548523,
      "backward_entropy": 0.023271007670296565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.555643081665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05161871016025543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06397340297698975,
      "backward_entropy": 0.0021909959614276886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.637506484985352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051657456904649734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06387183666229249,
      "backward_entropy": 0.002177706609169642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.765888690948486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05169517919421196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06377367973327637,
      "backward_entropy": 0.0021647943390740287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.641874313354492,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05173099413514137,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06368262767791748,
      "backward_entropy": 0.07701298263337877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.437618255615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05176954343914986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06357894539833069,
      "backward_entropy": 0.0021380020512474906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.073209762573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05180688947439194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06347969770431519,
      "backward_entropy": 0.002123593870136473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.457107543945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05184771120548248,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06336447596549988,
      "backward_entropy": 0.023403912782669067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8489127159118652,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05189020559191704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06324182748794556,
      "backward_entropy": 0.07701196935441759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.493131637573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05192965641617775,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0631320059299469,
      "backward_entropy": 0.0234711401992374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.382844924926758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051969487220048904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06301943063735962,
      "backward_entropy": 0.023496988746854994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.64101505279541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05200990289449692,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06290349960327149,
      "backward_entropy": 0.02352322803603278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.548020362854004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052049871534109116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06278828382492066,
      "backward_entropy": 0.023547237118085224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3009562492370605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05208943039178848,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06267433166503907,
      "backward_entropy": 0.023568391799926758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.815741539001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052126821130514145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0625694990158081,
      "backward_entropy": 0.023587092757225037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.821903228759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05216327682137489,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.062468111515045166,
      "backward_entropy": 0.02361177404721578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.200133323669434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05220067501068115,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06236169338226318,
      "backward_entropy": 0.0019992695500453315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05223802104592323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06225479245185852,
      "backward_entropy": 0.02367854780620999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.91228675842285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05227537825703621,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0621472418308258,
      "backward_entropy": 0.02372088862790002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.038583278656006,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052316274493932724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.062023240327835086,
      "backward_entropy": 0.001969480680094825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.691009521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052354976534843445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061908602714538574,
      "backward_entropy": 0.02381950616836548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.749502182006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052395038306713104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0617867648601532,
      "backward_entropy": 0.023860893315739103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.285669326782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052434615790843964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06166630983352661,
      "backward_entropy": 0.023897685938411288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.207881927490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05247317627072334,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061550086736679076,
      "backward_entropy": 0.023946947521633573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.818193435668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05251032114028931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06143931150436401,
      "backward_entropy": 0.023980177111095853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.774096965789795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05254799500107765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061325037479400636,
      "backward_entropy": 0.024003518952263728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.90355110168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052583951503038406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061218428611755374,
      "backward_entropy": 0.024040699005126953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.5081787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05262152850627899,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06110345721244812,
      "backward_entropy": 0.024075897203551397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.895549774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265999212861061,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06098381280899048,
      "backward_entropy": 0.0018788387791977988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.20928192138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05269750952720642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060868507623672484,
      "backward_entropy": 0.024186515145831637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.965100288391113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052739217877388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06073265075683594,
      "backward_entropy": 0.024253181285328336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.42034339904785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05278043448925018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060598564147949216,
      "backward_entropy": 0.001859101156393687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.771832466125488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05282370746135712,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06045424938201904,
      "backward_entropy": 0.024400744173261855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.543700218200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05286617949604988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06031330227851868,
      "backward_entropy": 0.024472463462087844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.583176612854004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05290724337100983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06017833948135376,
      "backward_entropy": 0.024551212787628174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.582284927368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05294763296842575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06004578471183777,
      "backward_entropy": 0.0018361012140909831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2059285640716553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052988313138484955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0599109947681427,
      "backward_entropy": 0.0246893134382036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.227257251739502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053026266396045685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0597893238067627,
      "backward_entropy": 0.024776639209853277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.288850784301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05306229740381241,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059676462411880495,
      "backward_entropy": 0.024864484866460163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.168039321899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053099967539310455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05955471992492676,
      "backward_entropy": 0.02495270636346605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082679748535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05313974991440773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059421765804290774,
      "backward_entropy": 0.0250308182504442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.942012786865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05317823588848114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05929455757141113,
      "backward_entropy": 0.02510640687412686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.892241477966309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053216852247714996,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05916569232940674,
      "backward_entropy": 0.02516104777654012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.725686073303223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053255222737789154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05903737545013428,
      "backward_entropy": 0.02522467076778412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.515474319458008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05329400673508644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058906280994415285,
      "backward_entropy": 0.025285704268349543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.382221221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05333380028605461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0587692379951477,
      "backward_entropy": 0.025333484013875324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.242597579956055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05337442457675934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05862720608711243,
      "backward_entropy": 0.025365130768881902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.792930603027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053416021168231964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058479541540145875,
      "backward_entropy": 0.02539663513501485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.166548728942871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345487222075462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058345073461532594,
      "backward_entropy": 0.025410797860887315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13315349817276,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053493715822696686,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05820971727371216,
      "backward_entropy": 0.02541085746553209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426115989685059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0535288043320179,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058093327283859256,
      "backward_entropy": 0.0254182368516922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.367386817932129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05356279015541077,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05798180103302002,
      "backward_entropy": 0.025423293312390644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.036157608032227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05359584093093872,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05787457823753357,
      "backward_entropy": 0.025430386265118916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.961461067199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05362910404801369,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057765746116638185,
      "backward_entropy": 0.0254529250992669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.576312065124512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053662434220314026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057655942440032956,
      "backward_entropy": 0.0254813896285163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.139825820922852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05369638279080391,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057542192935943606,
      "backward_entropy": 0.025501746270391677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.69106101989746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05372932553291321,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05743287801742554,
      "backward_entropy": 0.025517741839090984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.023326873779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05376433581113815,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057311993837356565,
      "backward_entropy": 0.02551736103163825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.965510845184326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053798168897628784,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05719655752182007,
      "backward_entropy": 0.025512018137507968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.908807277679443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05383124202489853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05708476305007935,
      "backward_entropy": 0.025518892539872065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.006304740905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05386350676417351,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05697698593139648,
      "backward_entropy": 0.02553134991063012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.470636367797852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053896572440862656,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05686394572257995,
      "backward_entropy": 0.025546474589241877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.663344383239746,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05393108353018761,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05674270391464233,
      "backward_entropy": 0.07701493634117974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.205846786499023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053963225334882736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05663399696350098,
      "backward_entropy": 0.0015706728316015666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.638073921203613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05399542301893234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05652450323104859,
      "backward_entropy": 0.025623445709546406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.544058799743652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05402863025665283,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05640929937362671,
      "backward_entropy": 0.025669879383511014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.053337097167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0540623776614666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056290429830551145,
      "backward_entropy": 0.025707872377501592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.154987335205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054094426333904266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05618028044700622,
      "backward_entropy": 0.025746838914023504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.263134956359863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054130107164382935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05605010390281677,
      "backward_entropy": 0.0015269460984402234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.570867538452148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05416616424918175,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05591750741004944,
      "backward_entropy": 0.025796393553415935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.0580415725708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054203204810619354,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05577899813652039,
      "backward_entropy": 0.025815188884735107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.955053329467773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05424016714096069,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05564021468162537,
      "backward_entropy": 0.025817968779140048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.15867280960083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05427716672420502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05550062656402588,
      "backward_entropy": 0.025812940465079412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.750591278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054312773048877716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05536820888519287,
      "backward_entropy": 0.025808380709754095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.652451515197754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05434847250580788,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055234593152999875,
      "backward_entropy": 0.025796115398406982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.264303207397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05438448488712311,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055098962783813474,
      "backward_entropy": 0.0014492383019791709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.984273910522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054419953376054764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054965919256210326,
      "backward_entropy": 0.025790032413270738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.855713367462158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05445707216858864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05482348203659058,
      "backward_entropy": 0.025785088539123535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024025917053223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0544927679002285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05468847751617432,
      "backward_entropy": 0.025782999065187242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.943987846374512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054528046399354935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05455546379089356,
      "backward_entropy": 0.025790949662526447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869872093200684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05456282198429108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054424834251403806,
      "backward_entropy": 0.0013948872478471862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.455348968505859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054597314447164536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05429564714431763,
      "backward_entropy": 0.02582278847694397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11131414771080017,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05462999641895294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05417623519897461,
      "backward_entropy": 0.025851074192259047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.7884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465921014547348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0540755569934845,
      "backward_entropy": 0.001366843572921223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.353487968444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054689113050699234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053970319032669065,
      "backward_entropy": 0.02586664425002204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.430067539215088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05471765622496605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05387240648269653,
      "backward_entropy": 0.025878942675060697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.641223907470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05474594235420227,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053775978088378903,
      "backward_entropy": 0.025913890865114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.330513000488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05477577820420265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05367027521133423,
      "backward_entropy": 0.02594600783454047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.396979331970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05480498448014259,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053567564487457274,
      "backward_entropy": 0.025984138250350952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.319757461547852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05483507364988327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053459537029266355,
      "backward_entropy": 0.0013149110600352287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.256031036376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054866112768650055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05334619283676147,
      "backward_entropy": 0.026088929838604398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125278949737549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05489843338727951,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053225362300872804,
      "backward_entropy": 0.026146137052112155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07682991027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05492911860346794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053113633394241334,
      "backward_entropy": 0.026205473475986056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.008225440979004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05495987460017204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05300132632255554,
      "backward_entropy": 0.026274739040268794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.81955337524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499045178294182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.052889710664749144,
      "backward_entropy": 0.0012860935595300463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.93443489074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05502288416028023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05276687741279602,
      "backward_entropy": 0.0012796058629949887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.035529613494873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05505434796214104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05264920592308044,
      "backward_entropy": 0.0012733512040641573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.570717811584473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05508367717266083,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052543675899505614,
      "backward_entropy": 0.026508380969365437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.259450912475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055114615708589554,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052428847551345824,
      "backward_entropy": 0.02658687366379632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.738010883331299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055148057639598846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052299559116363525,
      "backward_entropy": 0.026655051443311904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.265681266784668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055180490016937256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05217582583427429,
      "backward_entropy": 0.026730080445607502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.79238224029541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05521382391452789,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05204659104347229,
      "backward_entropy": 0.026792585849761963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.758992910385132,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524549260735512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05192679762840271,
      "backward_entropy": 0.001243841213484605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10613534599542618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05527547746896744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05181629657745361,
      "backward_entropy": 0.02693279915385776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.699582815170288,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05530237406492233,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05172309875488281,
      "backward_entropy": 0.026985930071936712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.456688404083252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055328045040369034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051636552810668944,
      "backward_entropy": 0.02703827288415697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10326461493968964,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055353354662656784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05155171155929565,
      "backward_entropy": 0.0012198333731955951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.382313251495361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05537620559334755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051480728387832644,
      "backward_entropy": 0.027148756715986464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.095487594604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05539868026971817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05141124725341797,
      "backward_entropy": 0.0012061906357606251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5735716819763184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0554216094315052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0513385534286499,
      "backward_entropy": 0.027223158213827345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.905861854553223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05544346943497658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05127159357070923,
      "backward_entropy": 0.027245048019621108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.661872863769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05546873062849045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05118436217308044,
      "backward_entropy": 0.02727567321724362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.894652843475342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055494729429483414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05109257698059082,
      "backward_entropy": 0.02729442384507921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.526358604431152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055520981550216675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05099914669990539,
      "backward_entropy": 0.0273200703991784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.111345291137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05554823949933052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05089992880821228,
      "backward_entropy": 0.027358750502268474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.728315830230713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055574931204319,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050803649425506595,
      "backward_entropy": 0.02740160624186198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6732177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05560161918401718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050706946849823,
      "backward_entropy": 0.02743691537115309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249480247497559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05562824010848999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05061016082763672,
      "backward_entropy": 0.027461907929844327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.562124729156494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055655404925346375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05050977468490601,
      "backward_entropy": 0.027474835515022278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.505887985229492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055682603269815445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050408953428268434,
      "backward_entropy": 0.027491698662439983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09134512394666672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055709823966026306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05030785202980041,
      "backward_entropy": 0.02751362489329444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.667206883430481,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05573457479476929,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05022099018096924,
      "backward_entropy": 0.027549263503816392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.352959156036377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05575760081410408,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05014389753341675,
      "backward_entropy": 0.027585961752467685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.30577278137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05578109622001648,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05006391406059265,
      "backward_entropy": 0.027627941634919908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.800655841827393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055805057287216187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04998100996017456,
      "backward_entropy": 0.00109002904759513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.327550888061523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05583018437027931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04989131093025208,
      "backward_entropy": 0.02774183452129364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.21671199798584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055857982486486435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.049785947799682616,
      "backward_entropy": 0.027797722154193454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58981466293335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055888108909130096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04966699182987213,
      "backward_entropy": 0.02784015072716607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519591808319092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05591719225049019,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04955389499664307,
      "backward_entropy": 0.027878079149458144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.502043724060059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055946558713912964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.049438902735710145,
      "backward_entropy": 0.027909404701656766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.459381580352783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055975090712308884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.049328786134719846,
      "backward_entropy": 0.027948704030778673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.418200969696045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0560026578605175,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04922387599945068,
      "backward_entropy": 0.027980433570014104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.37807035446167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05602918565273285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04912459850311279,
      "backward_entropy": 0.0279952155219184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757546901702881,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05605514347553253,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04902861714363098,
      "backward_entropy": 0.02802016668849521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.30045223236084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05608120933175087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048931735754013064,
      "backward_entropy": 0.028055025471581355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.655860424041748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05610678717494011,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04883754849433899,
      "backward_entropy": 0.028101086616516113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.986367702484131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05613243579864502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0487429141998291,
      "backward_entropy": 0.028150359789530437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.763201713562012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05615886673331261,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0486436665058136,
      "backward_entropy": 0.028209785620371502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.263527870178223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056188683956861496,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048525071144104,
      "backward_entropy": 0.028250830041037664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.108036994934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05622110515832901,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04839191436767578,
      "backward_entropy": 0.028289205498165555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7265799045562744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05625404417514801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048255935311317444,
      "backward_entropy": 0.028326991531584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.001371383666992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05628491938114166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04813199639320374,
      "backward_entropy": 0.028358555502361722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9577462673187256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056314803659915924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04801378548145294,
      "backward_entropy": 0.028402841753429837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3607087135314941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05634383112192154,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04790036082267761,
      "backward_entropy": 0.028461400005552504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8805296421051025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05637075752019882,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04779898226261139,
      "backward_entropy": 0.028524729940626357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.097037315368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056396834552288055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04770236313343048,
      "backward_entropy": 0.028582221931881376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.288171768188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05642273649573326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047606554627418515,
      "backward_entropy": 0.028634733623928495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.228416442871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056449174880981445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047507557272911075,
      "backward_entropy": 0.028690401050779555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.382057189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0564759224653244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04740658402442932,
      "backward_entropy": 0.028737700647777982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.508431434631348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056503526866436005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04730059802532196,
      "backward_entropy": 0.028777635759777494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.218105792999268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05653242766857147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04718721508979797,
      "backward_entropy": 0.028808424870173138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.962256908416748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05656219646334648,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047068935632705686,
      "backward_entropy": 0.02885241640938653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.730041980743408,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056591931730508804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04695095419883728,
      "backward_entropy": 0.07701635360717773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.678975582122803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05662108212709427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04683631360530853,
      "backward_entropy": 0.028935028447045222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.755529403686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05664953589439392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04672543704509735,
      "backward_entropy": 0.028965036074320476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.450350284576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05667819082736969,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04661344885826111,
      "backward_entropy": 0.0009265441654456987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.189659595489502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056705646216869354,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04650852084159851,
      "backward_entropy": 0.029031763474146526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.671535968780518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05673107132315636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046415284276008606,
      "backward_entropy": 0.029064234760072496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4238057136535645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056757211685180664,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04631766378879547,
      "backward_entropy": 0.029082725445429485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.527874946594238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056783050298690796,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046221685409545896,
      "backward_entropy": 0.029102087020874023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2033605575561523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05680953338742256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04612196087837219,
      "backward_entropy": 0.029109812445110746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.227914571762085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05683458596467972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04603039622306824,
      "backward_entropy": 0.029123703638712566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2356181144714355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05685901641845703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04594226479530335,
      "backward_entropy": 0.029150393274095323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.188350200653076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05688333138823509,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0458545446395874,
      "backward_entropy": 0.02918151683277554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.148011207580566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056907691061496735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.045766472816467285,
      "backward_entropy": 0.029226925637986925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.121462821960449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05693192034959793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0456791341304779,
      "backward_entropy": 0.029274076223373413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0634522438049316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05695696920156479,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04558719396591186,
      "backward_entropy": 0.029312067561679415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.988900661468506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056981295347213745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04549932181835174,
      "backward_entropy": 0.029354519314236112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9496989250183105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05700644850730896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04540678858757019,
      "backward_entropy": 0.029392013947168987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9636452198028564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05703173205256462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.045313560962677,
      "backward_entropy": 0.029420690404044256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.837220191955566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570562444627285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045224475860595706,
      "backward_entropy": 0.0008451470898257361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8996102809906006,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05708102881908417,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04513382911682129,
      "backward_entropy": 0.0770158502790663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.86930513381958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05710501968860626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04504752159118652,
      "backward_entropy": 0.029520193735758465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9938210844993591,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05712823569774628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04496554136276245,
      "backward_entropy": 0.07701581716537476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.987826943397522,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05714983120560646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04489260613918304,
      "backward_entropy": 0.0008252754083110227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.78951096534729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05716980993747711,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04482868909835815,
      "backward_entropy": 0.02962954839070638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6548514366149902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05718918517231941,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04476785659790039,
      "backward_entropy": 0.029648880163828533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9610578417778015,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05720869451761246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044706255197525024,
      "backward_entropy": 0.029665827751159668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.591228485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057226747274398804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04465265274047851,
      "backward_entropy": 0.029678179158104792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8086261749267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057244956493377686,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04459766149520874,
      "backward_entropy": 0.02968230512407091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3885722160339355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057262666523456573,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044545316696166994,
      "backward_entropy": 0.029706610573662653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.495307207107544,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05728128179907799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044487661123275755,
      "backward_entropy": 0.029736687739690144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6120595932006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05730003863573074,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04442921280860901,
      "backward_entropy": 0.029759214984046087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.112757205963135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0573185496032238,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0443718820810318,
      "backward_entropy": 0.029784798622131348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5612239837646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057338226586580276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044307729601860045,
      "backward_entropy": 0.029805501302083332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5385682582855225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057357657700777054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04424484670162201,
      "backward_entropy": 0.029837727546691895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5142507553100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057376716285943985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044183841347694396,
      "backward_entropy": 0.029869162374072604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.298845052719116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05739543214440346,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04412453174591065,
      "backward_entropy": 0.029899640215767756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.071762561798096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05741438642144203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044063761830329895,
      "backward_entropy": 0.02993475728564792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.441147804260254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05743381381034851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.044000068306922914,
      "backward_entropy": 0.029957741498947144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.989401340484619,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05745289474725723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04393813610076904,
      "backward_entropy": 0.029985937807295058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.727205276489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05747256055474281,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04387282133102417,
      "backward_entropy": 0.030012120803197224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.366898536682129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057493146508932114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.043802297115325926,
      "backward_entropy": 0.030030581686231825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3401639461517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05751320719718933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04373447895050049,
      "backward_entropy": 0.030051300923029583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0696768760681152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05753293260931969,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04366846084594726,
      "backward_entropy": 0.03008523914549086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.526256561279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05755273997783661,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04360179305076599,
      "backward_entropy": 0.030124300056033664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5290977954864502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05757367983460426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04352880716323852,
      "backward_entropy": 0.030174450741873846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2426810264587402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057593684643507004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.043461018800735475,
      "backward_entropy": 0.030231181118223403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2173478603363037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057613227516412735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04339571297168732,
      "backward_entropy": 0.030287434657414753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.625556707382202,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057632483541965485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04333192706108093,
      "backward_entropy": 0.030354344182544284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7589347958564758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057652153074741364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.043265828490257265,
      "backward_entropy": 0.030410610967212252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.251632213592529,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05767054483294487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04320662021636963,
      "backward_entropy": 0.0006997110839519235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.206422805786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768979340791702,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043142575025558474,
      "backward_entropy": 0.0006962029470337762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1036367416381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05770980194211006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04307405352592468,
      "backward_entropy": 0.030552367369333904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4354941844940186,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0577293336391449,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.043008023500442506,
      "backward_entropy": 0.03058697779973348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7289011478424072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0577491894364357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04294010698795318,
      "backward_entropy": 0.030614746941460505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3765267133712769,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057768814265728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04287336468696594,
      "backward_entropy": 0.030632608466678195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3188910484313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057787299156188965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042812669277191163,
      "backward_entropy": 0.030641042523913913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6999607086181641,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057806313037872314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042749032378196716,
      "backward_entropy": 0.0006706447133587466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9685187339782715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0578237846493721,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042693495750427246,
      "backward_entropy": 0.03066433138317532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.314778447151184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05784095823764801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042639505863189694,
      "backward_entropy": 0.03067778878741794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.557413339614868,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0578574500977993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04258908927440643,
      "backward_entropy": 0.03069887227482266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5313966274261475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05787401273846626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042538204789161684,
      "backward_entropy": 0.030711746878094144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1170358657836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0578906387090683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042486909031867984,
      "backward_entropy": 0.030717803372277155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8688511848449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05790797993540764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04243170022964478,
      "backward_entropy": 0.03073431717024909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.450172185897827,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057925060391426086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04237773716449737,
      "backward_entropy": 0.030758526590135362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.233609914779663,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05794234946370125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04232243597507477,
      "backward_entropy": 0.030789742867151897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3998303413391113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05795905366539955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04227022528648376,
      "backward_entropy": 0.03083670801586575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.957995653152466,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057975903153419495,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042217135429382324,
      "backward_entropy": 0.03088232543733385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3485915660858154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05799322575330734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04216127991676331,
      "backward_entropy": 0.0006266661609212557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.323575019836426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05801065266132355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042104750871658325,
      "backward_entropy": 0.030960996945699055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7319412231445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05802808329463005,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.042048105597496034,
      "backward_entropy": 0.03099744187461005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8303792476654053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058045316487550735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04199243187904358,
      "backward_entropy": 0.0006175324734714297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.246093511581421,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05806294083595276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04193454086780548,
      "backward_entropy": 0.03109134568108453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.766387462615967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05808059871196747,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04187639057636261,
      "backward_entropy": 0.031134810712602403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1966147422790527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058098580688238144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041816437244415285,
      "backward_entropy": 0.0006085685971710417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7004458904266357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05811633914709091,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041757476329803464,
      "backward_entropy": 0.031193474928538006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.718358039855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058134470134973526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041696485877037046,
      "backward_entropy": 0.031218098269568548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1513242721557617,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058153726160526276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04162949323654175,
      "backward_entropy": 0.07701573769251506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.084713935852051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05817355960607529,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04155938029289245,
      "backward_entropy": 0.03126629855897692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0468932390213013,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05819318816065788,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041490438580513,
      "backward_entropy": 0.03129639228185018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.525308132171631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05821191146969795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04142633080482483,
      "backward_entropy": 0.03133922815322876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.002293348312378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058231547474861145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04135746359825134,
      "backward_entropy": 0.03137298425038656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0091722011566162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05825095996260643,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04128982722759247,
      "backward_entropy": 0.031411810053719416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.340396404266357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05826922878623009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0412282794713974,
      "backward_entropy": 0.0005805407547288471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.86184024810791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058289166539907455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.041158059239387514,
      "backward_entropy": 0.03146567940711975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03828316554427147,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058309659361839294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04108499586582184,
      "backward_entropy": 0.03149747186236911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8715265989303589,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05832827836275101,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04102173447608948,
      "backward_entropy": 0.03153732087877062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3889665603637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058346476405858994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040960651636123654,
      "backward_entropy": 0.03156177202860514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8190706968307495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05836428701877594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04090156853199005,
      "backward_entropy": 0.031602962149514094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.235743522644043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058381933718919754,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04084333181381226,
      "backward_entropy": 0.031643301248550415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5027964115142822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058399733155965805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040784263610839845,
      "backward_entropy": 0.031676024198532104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.747361660003662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058418940752744675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04071800410747528,
      "backward_entropy": 0.0317157506942749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.298820972442627,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05843773111701012,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04065383970737457,
      "backward_entropy": 0.07701603571573894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.450297474861145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05845590680837631,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040592968463897705,
      "backward_entropy": 0.03178599807951185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.676547646522522,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05847283825278282,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04053843021392822,
      "backward_entropy": 0.03183337383800083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6531345844268799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058489542454481125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04048500955104828,
      "backward_entropy": 0.03187222613228692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6316802501678467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058506108820438385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04043225646018982,
      "backward_entropy": 0.03190995587242974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6086961030960083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0585225410759449,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0403801441192627,
      "backward_entropy": 0.03194598025745816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.368044376373291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05853892117738724,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04032819271087647,
      "backward_entropy": 0.03198643194304572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1844375133514404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05855578929185867,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040273737907409665,
      "backward_entropy": 0.03201639652252197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9262830018997192,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058572132140398026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.040221947431564334,
      "backward_entropy": 0.03204666905932956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.526035189628601,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05858861282467842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04016940593719483,
      "backward_entropy": 0.03207104073630439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7739047408103943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05860491842031479,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04011768400669098,
      "backward_entropy": 0.03209528658125135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8490771055221558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05862021446228027,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04007108807563782,
      "backward_entropy": 0.032107936011420354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1077393293380737,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058635760098695755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04002317786216736,
      "backward_entropy": 0.032120744387308754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5039079189300537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05865087732672691,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03997735679149628,
      "backward_entropy": 0.03213703632354736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4277418851852417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058667074888944626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03992595672607422,
      "backward_entropy": 0.03216306699646844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.719436526298523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05868304893374443,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03987584114074707,
      "backward_entropy": 0.03218471341662937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3892812728881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05869821831583977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03982970118522644,
      "backward_entropy": 0.03220977054701911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7022271752357483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05871324986219406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0397840678691864,
      "backward_entropy": 0.03223081098662482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0221514701843262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05872748792171478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03974228799343109,
      "backward_entropy": 0.0005061837016708321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3567243814468384,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05874139443039894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03970213830471039,
      "backward_entropy": 0.03227129909727308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6773428320884705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05875438079237938,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0396664559841156,
      "backward_entropy": 0.0005007566263278326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3024723529815674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05876673385500908,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03963388502597809,
      "backward_entropy": 0.0004980050855212741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2926735877990723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05877937749028206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039599621295928956,
      "backward_entropy": 0.0004956211584309737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.274117350578308,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05879202485084534,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03956530690193176,
      "backward_entropy": 0.03238214717970954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5678855180740356,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05880484730005264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.039529988169670106,
      "backward_entropy": 0.03241287999682956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.24565851688385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058818086981773376,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.039492517709732056,
      "backward_entropy": 0.032443732023239136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5280948877334595,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05883131921291351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03945494592189789,
      "backward_entropy": 0.00048568047997024324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9176742434501648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05884497985243797,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03941512703895569,
      "backward_entropy": 0.03250407841470507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.492674708366394,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05885828286409378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03937702775001526,
      "backward_entropy": 0.032535682121912636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0527398586273193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058871813118457794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03933767676353454,
      "backward_entropy": 0.032557934522628784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31094789505004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058886051177978516,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.039294904470443724,
      "backward_entropy": 0.03256319297684564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4340556859970093,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05889931693673134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03925662636756897,
      "backward_entropy": 0.032576908667882286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5822169780731201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058912720531225204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.039217418432235716,
      "backward_entropy": 0.03257870342996386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.119605541229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058925382792949677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03918168544769287,
      "backward_entropy": 0.03257647818989224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6455409526824951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05893808230757713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03914564549922943,
      "backward_entropy": 0.03257880608240763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8210569024085999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05895131081342697,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03910687863826752,
      "backward_entropy": 0.03257620665762159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8143522143363953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05896436423063278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.039068931341171266,
      "backward_entropy": 0.03259238931867811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7999025583267212,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05897689238190651,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03903343677520752,
      "backward_entropy": 0.032593866189320884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0455790758132935,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058989208191633224,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.038998973369598386,
      "backward_entropy": 0.03260437316364712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2825188636779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059001509100198746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03896440863609314,
      "backward_entropy": 0.0326126946343316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0161954164505005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059014130383729935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03892816007137299,
      "backward_entropy": 0.03262268172370063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.002729058265686,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05902675911784172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03889177143573761,
      "backward_entropy": 0.03263737426863776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7468631863594055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059039290994405746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03885578215122223,
      "backward_entropy": 0.03264733155568441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9741130471229553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059051498770713806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03882123231887817,
      "backward_entropy": 0.03265792793697781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49078094959259033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059063706547021866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03878658413887024,
      "backward_entropy": 0.03267045815785726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1782618761062622,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05907544121146202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03875421583652496,
      "backward_entropy": 0.03269388278325399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3913413286209106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059087567031383514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03871988356113434,
      "backward_entropy": 0.032723443375693426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24642504751682281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059100113809108734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03868339657783508,
      "backward_entropy": 0.03274060951338874,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.8484295369312167,
    "avg_log_Z": -0.058353384621441365,
    "success_rate": 1.0,
    "avg_reward": 19.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.86,
      "2": 0.12
    },
    "avg_forward_entropy": 0.04098785471916199,
    "avg_backward_entropy": 0.02878335041200949,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}