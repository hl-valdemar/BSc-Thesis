{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.0768704613049825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07689526345994738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.89988708496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10986028909683228,
      "backward_entropy": 0.07694574859407213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.43856811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985997915267945,
      "backward_entropy": 0.07694633801778157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.40945434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00019932669238187373,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098595380783081,
      "backward_entropy": 0.07689817746480306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.8050994873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002985376340802759,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985898971557617,
      "backward_entropy": 0.0769473049375746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.19850158691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039765454130247235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098583459854126,
      "backward_entropy": 0.07694772879282634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.74652099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000497368338983506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985758304595947,
      "backward_entropy": 0.0769481791390313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.87522888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005967698525637388,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098567008972168,
      "backward_entropy": 0.07690346240997314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.68821716308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006949962698854506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985572338104248,
      "backward_entropy": 0.07690467437108357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.07235717773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007933449232950807,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985462665557862,
      "backward_entropy": 0.07689451509051853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.88783264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008925602305680513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985342264175416,
      "backward_entropy": 0.07694963614145915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.36013793945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009923260658979416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985209941864013,
      "backward_entropy": 0.0769499937693278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.9777374267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010895979357883334,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985069274902344,
      "backward_entropy": 0.07690241601732042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.96546936035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011879387311637402,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984916687011718,
      "backward_entropy": 0.07690482669406468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.35887145996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012861929135397077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984752178192139,
      "backward_entropy": 0.07690707842508952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.30604553222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013843034394085407,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984575748443604,
      "backward_entropy": 0.07690929041968451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4551544189453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001483298372477293,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984389781951905,
      "backward_entropy": 0.07691147592332628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.2147979736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0015821756096556783,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098419189453125,
      "backward_entropy": 0.07691363493601482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.65257263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016826654318720102,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098398208618164,
      "backward_entropy": 0.07695153024461535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.59999084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017855032347142696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098375916481018,
      "backward_entropy": 0.07691612508561876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.34194946289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018882470903918147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983524322509766,
      "backward_entropy": 0.07691708538267347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.72567749023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001992461970075965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109832763671875,
      "backward_entropy": 0.07691807217068142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.24887084960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002097833901643753,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983015298843384,
      "backward_entropy": 0.07692439026302761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.22901916503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021998784504830837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098274827003479,
      "backward_entropy": 0.07695380846659343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.419189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023034720215946436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098246693611145,
      "backward_entropy": 0.07695433828565809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.90460205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024048560298979282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982178449630738,
      "backward_entropy": 0.07695479525460137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.32347106933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002509273588657379,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981874465942383,
      "backward_entropy": 0.07692241668701172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.65765380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002614053199067712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981558561325074,
      "backward_entropy": 0.07695584826999241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.30523681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00271844444796443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109812331199646,
      "backward_entropy": 0.07695636484358045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.5517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028221849352121353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980895757675171,
      "backward_entropy": 0.07695685492621528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.67535400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029210986103862524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980556011199952,
      "backward_entropy": 0.07692537705103557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.50812530517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003018032293766737,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980206727981567,
      "backward_entropy": 0.07694118552737766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.20347595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003110824851319194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979855060577393,
      "backward_entropy": 0.07695786158243816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7906951904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032024276442825794,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097949504852295,
      "backward_entropy": 0.07694411277770996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.82699584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032938900403678417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979121923446655,
      "backward_entropy": 0.07695817947387695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.42351531982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00338394520804286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097874402999878,
      "backward_entropy": 0.07692726453145345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.87022399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003470559837296605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978375673294068,
      "backward_entropy": 0.07692743009991115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.84356689453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035578554961830378,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109779953956604,
      "backward_entropy": 0.0769493513637119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.32618713378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036457746755331755,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977606773376465,
      "backward_entropy": 0.07695053683386908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.13291931152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003735624486580491,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977206230163575,
      "backward_entropy": 0.07692783408694798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.91639709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038270042277872562,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976793766021728,
      "backward_entropy": 0.07692797316445245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.40525817871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003915829584002495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976375341415405,
      "backward_entropy": 0.07695778873231676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.46710205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004004760645329952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097594141960144,
      "backward_entropy": 0.0769575900501675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.85084533691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004096098709851503,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975489616394044,
      "backward_entropy": 0.07695739799075657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.5611267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0041894689202308655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975019931793213,
      "backward_entropy": 0.07695721255408393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.7863311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0042886435985565186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974524021148682,
      "backward_entropy": 0.07692858907911512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.15267944335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004388047847896814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974019765853882,
      "backward_entropy": 0.07695967621273464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.42282104492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004490779712796211,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973496437072754,
      "backward_entropy": 0.07696084181467693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.30764770507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004588321782648563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972979068756103,
      "backward_entropy": 0.07695700062645806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.03736877441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004682617727667093,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972458124160767,
      "backward_entropy": 0.07696290810902913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.48052978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004780909977853298,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971918106079101,
      "backward_entropy": 0.0769297546810574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.69699096679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004878457169979811,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971369743347167,
      "backward_entropy": 0.07696492142147487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.42343139648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004975056275725365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097081184387207,
      "backward_entropy": 0.07692993349499172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.70614624023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005071106366813183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970244407653809,
      "backward_entropy": 0.07695590125189887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.22718811035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005167882423847914,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969667434692383,
      "backward_entropy": 0.07696771621704102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.99378967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005266199819743633,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096907377243042,
      "backward_entropy": 0.07695543766021729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.049072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005363384261727333,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968466997146606,
      "backward_entropy": 0.07692996660868327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.58114624023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005463299807161093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967843532562256,
      "backward_entropy": 0.07693003283606635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.50242614746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005563489161431789,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096720814704895,
      "backward_entropy": 0.07697130574120416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.03904724121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005664725787937641,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966557264328003,
      "backward_entropy": 0.07697217994266087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3090362548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005762217566370964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965902805328369,
      "backward_entropy": 0.07693009244071113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.39511108398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005857654381543398,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965243577957154,
      "backward_entropy": 0.07697375615437825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.78204345703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00595691567286849,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964558124542237,
      "backward_entropy": 0.07697455750571357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.66592407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006054883822798729,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963882207870483,
      "backward_entropy": 0.07695305347442627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5029754638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006156709045171738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963189601898193,
      "backward_entropy": 0.07695270909203424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.43357849121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006254768930375576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962498188018799,
      "backward_entropy": 0.07697685559590657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.1640167236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006354278419166803,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961792469024659,
      "backward_entropy": 0.07692953613069323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.77552795410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006455345544964075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961074829101562,
      "backward_entropy": 0.07695167594485813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.85739135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006557414773851633,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096034049987793,
      "backward_entropy": 0.07695140441258748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.4721221923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00665715616196394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959606170654297,
      "backward_entropy": 0.07695108652114868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.94403076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006758330389857292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958857536315918,
      "backward_entropy": 0.0769507951206631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.277587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006855853833258152,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958110094070435,
      "backward_entropy": 0.07692910565270318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.62982940673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006952495779842138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957351922988892,
      "backward_entropy": 0.07694996727837457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.31466674804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007044593337923288,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095659852027893,
      "backward_entropy": 0.07692848311530219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.0787353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007135502528399229,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955842733383178,
      "backward_entropy": 0.07692805926005046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.31369018554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007223487365990877,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095508098602295,
      "backward_entropy": 0.07698386245303684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.95498657226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00731020700186491,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095430850982666,
      "backward_entropy": 0.07698437902662489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.59841918945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007393264211714268,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953550338745117,
      "backward_entropy": 0.07698484261830647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.90733337402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00747431768104434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952792167663575,
      "backward_entropy": 0.07692570818795098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.3705291748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007561262231320143,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952000617980957,
      "backward_entropy": 0.07692511876424153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.928466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00764558557420969,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951201915740967,
      "backward_entropy": 0.076943834622701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.8759307861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007733023259788752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950376987457275,
      "backward_entropy": 0.07692386044396295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.86143493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007821637205779552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10949527025222779,
      "backward_entropy": 0.07692331075668335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.99468994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007912907749414444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948653221130371,
      "backward_entropy": 0.07692280080583361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.77798461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008005155250430107,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947760343551635,
      "backward_entropy": 0.07692229085498387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.64170837402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008098076097667217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946843624114991,
      "backward_entropy": 0.07692177428139581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.788330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008189359679818153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945919752120972,
      "backward_entropy": 0.07693841060002644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.68724060058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008277698419988155,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10944994688034057,
      "backward_entropy": 0.07698971033096313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6091766357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008368775248527527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944044589996338,
      "backward_entropy": 0.07693625158733791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.34466552734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008461195975542068,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943076610565186,
      "backward_entropy": 0.076990630891588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.35687255859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008551829494535923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942097902297973,
      "backward_entropy": 0.07691840993033515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.62811279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00864366628229618,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10941098928451538,
      "backward_entropy": 0.07691769467459784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.22837829589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008733050897717476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940107107162475,
      "backward_entropy": 0.07699192894829644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.5565490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008821513503789902,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939109325408936,
      "backward_entropy": 0.07699232631259495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.628662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008917482569813728,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938050746917724,
      "backward_entropy": 0.07699278328153822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.54473876953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00901396106928587,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936969518661499,
      "backward_entropy": 0.07699322700500488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.37359619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00911029800772667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935870409011841,
      "backward_entropy": 0.07692762878206041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.91119384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00921112485229969,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934733152389527,
      "backward_entropy": 0.07691311836242676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.68870544433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0093107083812356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933581590652466,
      "backward_entropy": 0.07691236999299791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.64947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009411690756678581,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932415723800659,
      "backward_entropy": 0.07691163486904568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.2060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00951391365379095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093123197555542,
      "backward_entropy": 0.07692364851633708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.96632385253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009617334231734276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930025577545166,
      "backward_entropy": 0.07691025733947754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.33985900878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00971829891204834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928819179534913,
      "backward_entropy": 0.07690952883826362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.08934020996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00981808826327324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10927600860595703,
      "backward_entropy": 0.07690877384609646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.23695373535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00991934072226286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10926352739334107,
      "backward_entropy": 0.07690811157226562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.43312072753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010023158974945545,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925068855285644,
      "backward_entropy": 0.07690749565760295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3994903564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010125687345862389,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10923779010772705,
      "backward_entropy": 0.07690680689281887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.70616149902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010227059945464134,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10922478437423706,
      "backward_entropy": 0.07699855168660481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.40235137939453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01033107191324234,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10921143293380738,
      "backward_entropy": 0.07699902852376302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5269317626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010429796762764454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10919826030731201,
      "backward_entropy": 0.07690452204810248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.95126342773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01052630040794611,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918502807617188,
      "backward_entropy": 0.07691288656658596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3400421142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01061837188899517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917197465896607,
      "backward_entropy": 0.07691144943237305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.30364227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01071392185986042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10915842056274414,
      "backward_entropy": 0.07690132988823785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.25537109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010805019177496433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10914499759674072,
      "backward_entropy": 0.07690005169974433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.8118133544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010899703949689865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913108587265015,
      "backward_entropy": 0.07690689298841688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.29830932617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010997671633958817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911669731140136,
      "backward_entropy": 0.07690536975860596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.92416381835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011094621382653713,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10910211801528931,
      "backward_entropy": 0.07690370745129055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.3770980834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011194798164069653,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10908713340759277,
      "backward_entropy": 0.07690211137135823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011290253140032291,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10907238721847534,
      "backward_entropy": 0.07700248559315999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.4150848388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011382097378373146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10905756950378417,
      "backward_entropy": 0.07689830329683092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.03916931152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011472616344690323,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10904271602630615,
      "backward_entropy": 0.07700294918484157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.08636474609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011560351587831974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10902785062789917,
      "backward_entropy": 0.0768939389122857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.65576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0116481464356184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090126872062683,
      "backward_entropy": 0.07688673337300618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.6879425048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011739718727767467,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10899688005447387,
      "backward_entropy": 0.07688498497009277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.46806335449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011829901486635208,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10898104906082154,
      "backward_entropy": 0.07688312398062812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.80320739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011914834380149841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896553993225097,
      "backward_entropy": 0.07688379287719727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.19540405273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012002954259514809,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10894954204559326,
      "backward_entropy": 0.07700403531392415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.7122802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01209015492349863,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10893341302871704,
      "backward_entropy": 0.0768766270743476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.77332305908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012173502705991268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1089171051979065,
      "backward_entropy": 0.07687387201521131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.58770751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012252165004611015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10890090465545654,
      "backward_entropy": 0.0768698255221049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.76620483398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012329594232141972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10888460874557496,
      "backward_entropy": 0.07686568631066217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.56971740722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012408207170665264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10886781215667725,
      "backward_entropy": 0.07686467965443929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.17664337158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012493248097598553,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10885002613067626,
      "backward_entropy": 0.07700395584106445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.68092346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012572094798088074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10883246660232544,
      "backward_entropy": 0.07685302363501655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.7057876586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012655062600970268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10881421566009522,
      "backward_entropy": 0.07685481177435981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.15782165527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012734277173876762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10879580974578858,
      "backward_entropy": 0.07684393723805745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.91265869140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012819666415452957,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10877634286880493,
      "backward_entropy": 0.07700354523128933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.8319549560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012907854281365871,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10875610113143921,
      "backward_entropy": 0.07700342602199978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.69044494628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012995153665542603,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10873575210571289,
      "backward_entropy": 0.07700330681271023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.10775756835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013089152984321117,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1087143063545227,
      "backward_entropy": 0.07700322733985053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.49195861816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013184085488319397,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10869243144989013,
      "backward_entropy": 0.07700314786699083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.28997802734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013280270621180534,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10867019891738891,
      "backward_entropy": 0.07700306839413112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.13975524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013381934724748135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10864678621292115,
      "backward_entropy": 0.07680833339691162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.98973083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01348339207470417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10862284898757935,
      "backward_entropy": 0.07680291599697536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.6474151611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013582458719611168,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10859889984130859,
      "backward_entropy": 0.07700293593936497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.8158721923828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01368169579654932,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10857443809509278,
      "backward_entropy": 0.07700286971198188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.31488037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013781292364001274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10854951143264771,
      "backward_entropy": 0.07681205537584093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.59681701660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013879956677556038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10852432250976562,
      "backward_entropy": 0.07677886883417766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.22239685058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013975442387163639,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10849936008453369,
      "backward_entropy": 0.07680251200993855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.56471252441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014070425182580948,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.108473801612854,
      "backward_entropy": 0.07700240612030029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.30702209472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01416485570371151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844775438308715,
      "backward_entropy": 0.07675876882341173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.18789672851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014257725328207016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10842156410217285,
      "backward_entropy": 0.07678678300645617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.0334014892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014355257153511047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10839412212371827,
      "backward_entropy": 0.07674464914533827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.59735107421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014452071860432625,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10836633443832397,
      "backward_entropy": 0.07700179682837592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.21356201171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014548351056873798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10833821296691895,
      "backward_entropy": 0.07677030563354492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.65708923339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014649111777544022,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10830893516540527,
      "backward_entropy": 0.07700159814622667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4052276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01474860217422247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10827925205230712,
      "backward_entropy": 0.07671540975570679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.64402770996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014844496734440327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10824966430664062,
      "backward_entropy": 0.07670723729663426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.55380249023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014941513538360596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10821967124938965,
      "backward_entropy": 0.0766991310649448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.12413024902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015043020248413086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10818848609924317,
      "backward_entropy": 0.0766911572880215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.8375244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015141033567488194,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1081575632095337,
      "backward_entropy": 0.07700088289048937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.96084594726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015231425873935223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1081273913383484,
      "backward_entropy": 0.07667356729507446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.28231811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015320317819714546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10809686183929443,
      "backward_entropy": 0.076663785510593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.35087585449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015413249842822552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10806511640548706,
      "backward_entropy": 0.07671080695258246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.32581329345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015502032823860645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10803371667861938,
      "backward_entropy": 0.0767027669482761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.04104614257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015585650689899921,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10800280570983886,
      "backward_entropy": 0.07663265864054362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.642822265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01566583663225174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10797197818756103,
      "backward_entropy": 0.07668489880032009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.58667755126953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015741601586341858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10794147253036498,
      "backward_entropy": 0.07699813445409139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.61053466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01581483520567417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10791099071502686,
      "backward_entropy": 0.07666472593943278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.99224090576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015896357595920563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1078783392906189,
      "backward_entropy": 0.0765831470489502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.60922241210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01597520522773266,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10784611701965333,
      "backward_entropy": 0.07699642578760783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67318725585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016056250780820847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10781304836273194,
      "backward_entropy": 0.07655776209301418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.2672882080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01613502949476242,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10777952671051025,
      "backward_entropy": 0.07699538601769342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.91038513183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016219111159443855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1077445387840271,
      "backward_entropy": 0.07653095324834187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.48275756835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016301944851875305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10770890712738038,
      "backward_entropy": 0.07651674747467041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.35284423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016387108713388443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10767245292663574,
      "backward_entropy": 0.07650262779659694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.56407165527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0164699275046587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1076358437538147,
      "backward_entropy": 0.07648759418063694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.88134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01655585691332817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.107597815990448,
      "backward_entropy": 0.07647216320037842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.56182861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016639476642012596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10755974054336548,
      "backward_entropy": 0.07645716932084826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.1114501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016724182292819023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10752122402191162,
      "backward_entropy": 0.07644248008728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.7470245361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016805488616228104,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10748299360275268,
      "backward_entropy": 0.07699106799231635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.49480056762695,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016888592392206192,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10744341611862182,
      "backward_entropy": 0.0769904653231303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.39297485351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01696224883198738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740519762039184,
      "backward_entropy": 0.07639302147759332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.00799560546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017034627497196198,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10736657381057739,
      "backward_entropy": 0.07698853810628255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.27717590332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017107956111431122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1073276162147522,
      "backward_entropy": 0.07635578844282362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.20787048339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01717892475426197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10728870630264283,
      "backward_entropy": 0.07633621162838405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.30945587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017254536971449852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10724803209304809,
      "backward_entropy": 0.07631598578559028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.03631591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017327243462204933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072072982788086,
      "backward_entropy": 0.07629443539513482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.13926696777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017399126663804054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1071666955947876,
      "backward_entropy": 0.07641049226125081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.9422607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01747828722000122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10712382793426514,
      "backward_entropy": 0.07639420694775051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.1145782470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017560163512825966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10707981586456299,
      "backward_entropy": 0.07622908221350776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.420654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01764274202287197,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10703487396240234,
      "backward_entropy": 0.07636174890730116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.75462341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017725853249430656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10698896646499634,
      "backward_entropy": 0.07618345154656304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.32643127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017808228731155396,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10694254636764526,
      "backward_entropy": 0.07615926530626085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.7509002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01789005845785141,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1068956732749939,
      "backward_entropy": 0.07613427771462335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.8397674560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01797294430434704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10684806108474731,
      "backward_entropy": 0.07610899209976196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.56427001953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018055349588394165,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10680004358291625,
      "backward_entropy": 0.07626956039004856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.61671447753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018139872699975967,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10675069093704223,
      "backward_entropy": 0.07697639200422499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9263458251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01822209730744362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1067011833190918,
      "backward_entropy": 0.07622869809468587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.91709899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018302153795957565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1066514253616333,
      "backward_entropy": 0.0762065119213528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.26454162597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018388506025075912,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10659900903701783,
      "backward_entropy": 0.07597088813781738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.75794219970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018473828211426735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10654618740081787,
      "backward_entropy": 0.07594152291615804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.92535400390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018553849309682846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10649406909942627,
      "backward_entropy": 0.07697162363264295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.37604522705078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018637683242559433,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10644060373306274,
      "backward_entropy": 0.07697064346737331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.39984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018718164414167404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10638821125030518,
      "backward_entropy": 0.07584504286448161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.34902954101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018802525475621223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10633413791656494,
      "backward_entropy": 0.07581239938735962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.87452697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018892742693424225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1062773585319519,
      "backward_entropy": 0.0760415858692593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.30795288085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01898154616355896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10622034072875977,
      "backward_entropy": 0.07601663139131334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.058837890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01907031051814556,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.106162428855896,
      "backward_entropy": 0.07696608040067884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8999786376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01916208676993847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10610301494598388,
      "backward_entropy": 0.0756779048177931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.00025939941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01925085484981537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10604376792907715,
      "backward_entropy": 0.07696342468261719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.56614685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0193399079144001,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10598384141921997,
      "backward_entropy": 0.07560465070936415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.45712280273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019429326057434082,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10592331886291503,
      "backward_entropy": 0.07588687870237562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.79998016357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019517429172992706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1058624267578125,
      "backward_entropy": 0.07552915149264866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.29331970214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01960008032619953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10580257177352906,
      "backward_entropy": 0.0754875938097636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.5357208251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019680442288517952,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10574240684509277,
      "backward_entropy": 0.07579653792911106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.6477279663086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019760634750127792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10568177700042725,
      "backward_entropy": 0.07695289452870686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.8387451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019836165010929108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10562200546264648,
      "backward_entropy": 0.07535213894314235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.4837646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01991492509841919,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1055606484413147,
      "backward_entropy": 0.07569510406917995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.09320068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0199894942343235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10550037622451783,
      "backward_entropy": 0.07525710927115546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.7877655029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020066987723112106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10543802976608277,
      "backward_entropy": 0.07562222083409627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.86834716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020143378525972366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10537574291229249,
      "backward_entropy": 0.07515837748845418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.46165466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02022283710539341,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1053116798400879,
      "backward_entropy": 0.07554810576968723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.3200454711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020301833748817444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10524661540985107,
      "backward_entropy": 0.07505768537521362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.61517333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020377688109874725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10518181324005127,
      "backward_entropy": 0.07546967930263943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.88821411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020456688478589058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10511516332626343,
      "backward_entropy": 0.07494923803541395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.80274963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02052784152328968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10505023002624511,
      "backward_entropy": 0.07488952080408733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.38819885253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02059812657535076,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10498477220535278,
      "backward_entropy": 0.07692482736375597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.67027282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020667748525738716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10491887331008912,
      "backward_entropy": 0.07529396480984157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.47679138183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02073667384684086,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10485239028930664,
      "backward_entropy": 0.07691755559709337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.07447814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020813727751374245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10478209257125855,
      "backward_entropy": 0.0746382474899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.6649932861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02089650370180607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10470882654190064,
      "backward_entropy": 0.07457967599232991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.20059204101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020981844514608383,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10463378429412842,
      "backward_entropy": 0.07452269395192464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.2378692626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02107192762196064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10455594062805176,
      "backward_entropy": 0.0744667715496487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.27851104736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021160928532481194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10447794198989868,
      "backward_entropy": 0.07440887557135688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.18531799316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02124592289328575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10440077781677246,
      "backward_entropy": 0.07434652249018352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.99713134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021328367292881012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10432329177856445,
      "backward_entropy": 0.07428007655673557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.7304458618164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021417390555143356,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10424219369888306,
      "backward_entropy": 0.07690648900138007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.24220275878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021502511575818062,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10416218042373657,
      "backward_entropy": 0.07690459489822388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.84632873535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021585598587989807,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10408239364624024,
      "backward_entropy": 0.07690227031707764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.57984924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021666651591658592,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1040024995803833,
      "backward_entropy": 0.07476458284589979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.3662872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021748604252934456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10392096042633056,
      "backward_entropy": 0.0739342901441786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.91650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02183302864432335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10383749008178711,
      "backward_entropy": 0.07386064529418945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.20069885253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02192394621670246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10375034809112549,
      "backward_entropy": 0.0737919807434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.4556121826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022011838853359222,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10366330146789551,
      "backward_entropy": 0.07689150174458821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.74725341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022104335948824883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10357317924499512,
      "backward_entropy": 0.0745046337445577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.15773010253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022196663543581963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10348210334777833,
      "backward_entropy": 0.07357620530658299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.34003448486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022290583699941635,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10339006185531616,
      "backward_entropy": 0.07688901159498426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.76881408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022380024194717407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10329962968826294,
      "backward_entropy": 0.07342633936140272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.85002899169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022469203919172287,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10320736169815063,
      "backward_entropy": 0.07428485817379421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.11247253417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022554174065589905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10311623811721801,
      "backward_entropy": 0.0742214388317532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.74990844726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02263587713241577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10302648544311524,
      "backward_entropy": 0.07415416505601671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.36077880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02272152528166771,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10293385982513428,
      "backward_entropy": 0.07408891121546428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.04676818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022807927802205086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10284008979797363,
      "backward_entropy": 0.07402287589179145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.47889709472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022896355018019676,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10274434089660645,
      "backward_entropy": 0.07687287198172675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.6129379272461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022985156625509262,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10264743566513061,
      "backward_entropy": 0.07687094476487902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.1971664428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023068733513355255,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10255281925201416,
      "backward_entropy": 0.07381533251868354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.48773193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023147400468587875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10245988368988038,
      "backward_entropy": 0.07260668277740479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.6373291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023227348923683167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10236506462097168,
      "backward_entropy": 0.07250172562069362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.27452087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02330709435045719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1022693395614624,
      "backward_entropy": 0.07239370875888401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.28307342529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023388024419546127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10217181444168091,
      "backward_entropy": 0.07228424814012316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.41197204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02346550114452839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10207483768463135,
      "backward_entropy": 0.07216801908281115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.56724548339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023544611409306526,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10197616815567016,
      "backward_entropy": 0.07684085104200575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.2928237915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023622561246156693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10187817811965942,
      "backward_entropy": 0.07193488544887966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.93724822998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02369338646531105,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10178358554840088,
      "backward_entropy": 0.0731170309914483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.22604370117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023760493844747543,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10168993473052979,
      "backward_entropy": 0.07682116826375325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.82748413085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023825759068131447,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1015964388847351,
      "backward_entropy": 0.07153798474205865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.71023559570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02388947643339634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10150281190872193,
      "backward_entropy": 0.07139711909823948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.65951538085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02395438775420189,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10140688419342041,
      "backward_entropy": 0.07266809542973836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.88674926757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024020690470933914,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10130902528762817,
      "backward_entropy": 0.07678600814607409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.87303924560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02408365160226822,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10121209621429443,
      "backward_entropy": 0.07095456123352051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.67727661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02414553426206112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10111544132232667,
      "backward_entropy": 0.07230305671691895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.9438018798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02420744113624096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10101749897003173,
      "backward_entropy": 0.0721756484773424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.84947204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02427278272807598,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10091671943664551,
      "backward_entropy": 0.07205147213406032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.4834442138672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024339625611901283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10081429481506347,
      "backward_entropy": 0.07673887411753337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.78775024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024416621774435043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10070492029190063,
      "backward_entropy": 0.07019449604882134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.60167694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024498242884874344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10059169530868531,
      "backward_entropy": 0.07171034150653416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.49022674560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024576539173722267,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10047940015792847,
      "backward_entropy": 0.07672986057069567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.02916717529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024647733196616173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10037142038345337,
      "backward_entropy": 0.06975936889648438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.25839233398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0247164499014616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10026340484619141,
      "backward_entropy": 0.06959197256300184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.7765350341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024784749373793602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10015473365783692,
      "backward_entropy": 0.06942174832026164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.90758514404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024856843054294586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10004199743270874,
      "backward_entropy": 0.07106775707668728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.78494262695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02492508664727211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09993072748184204,
      "backward_entropy": 0.06907632615831164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.43229675292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024988966062664986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0998227059841156,
      "backward_entropy": 0.06889389620886908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.74871826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025051847100257874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09971523880958558,
      "backward_entropy": 0.06870965162913005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.25444030761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02511773444712162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09960441589355469,
      "backward_entropy": 0.06852528784010145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.3221893310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025182437151670456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09949418306350707,
      "backward_entropy": 0.0683405531777276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.07852172851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025248486548662186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09938119053840637,
      "backward_entropy": 0.06815467278162639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.73431396484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025317352265119553,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09926508665084839,
      "backward_entropy": 0.07663887076907688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.88311004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025386065244674683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09914858937263489,
      "backward_entropy": 0.06778532928890652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.8457489013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025453345850110054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.099033123254776,
      "backward_entropy": 0.06972635454601711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.56324768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02552175149321556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09891527891159058,
      "backward_entropy": 0.06740133629904853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.96934509277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025592776015400887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09879425764083863,
      "backward_entropy": 0.06941715876261394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.8506088256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025669025257229805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09866807460784913,
      "backward_entropy": 0.06926874319712321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.94198608398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02573988027870655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09854546785354615,
      "backward_entropy": 0.06910566488901775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.14443969726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025815889239311218,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09841744899749756,
      "backward_entropy": 0.068948056962755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.0489501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025894057005643845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09828739166259766,
      "backward_entropy": 0.06642060809665257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.08184814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02596958726644516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09815863370895386,
      "backward_entropy": 0.06621609131495158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.25886535644531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026045752689242363,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09802884459495545,
      "backward_entropy": 0.07657988203896417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.96188354492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026119692251086235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09790029525756835,
      "backward_entropy": 0.06579675939348009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.934814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026194050908088684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09776977300643921,
      "backward_entropy": 0.0655783282385932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.31537628173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02626759000122547,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09763900041580201,
      "backward_entropy": 0.06535402933756511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.69346618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02633635327219963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09751238822937011,
      "backward_entropy": 0.06512271695666844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.299072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02640487626194954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09738491773605347,
      "backward_entropy": 0.06488928529951307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.79164123535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02647479809820652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09725548028945923,
      "backward_entropy": 0.07653143670823839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.345458984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02653735689818859,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09713273048400879,
      "backward_entropy": 0.06713849968380398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.9748992919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02659880742430687,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09700964093208313,
      "backward_entropy": 0.07650642262564765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.3990249633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026665011420845985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09688071608543396,
      "backward_entropy": 0.06391698784298366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.65333557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02672547660768032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09675638675689698,
      "backward_entropy": 0.06365507178836399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.24490356445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026788199320435524,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09662929773330689,
      "backward_entropy": 0.06339513593249851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.24984741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026845542713999748,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09650658965110778,
      "backward_entropy": 0.06605304612053765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.61090087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026902543380856514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0963835060596466,
      "backward_entropy": 0.06581681304507786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.73320770263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026960574090480804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09625831842422486,
      "backward_entropy": 0.06557960642708673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.91444396972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02701609581708908,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09613317847251893,
      "backward_entropy": 0.07640179660585192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.14586639404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027075951918959618,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09600362777709961,
      "backward_entropy": 0.06199094984266493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.35890197753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027134770527482033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09587308168411254,
      "backward_entropy": 0.0648581584294637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.00213623046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027197711169719696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0957388162612915,
      "backward_entropy": 0.061423692438337535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.71710205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027264073491096497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09560050368309021,
      "backward_entropy": 0.061150299178229436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.48719024658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027332110330462456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09545982480049134,
      "backward_entropy": 0.06087469392352634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.6282501220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02739729732275009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09532146453857422,
      "backward_entropy": 0.06394348541895549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.52426147460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027467118576169014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09517760276794433,
      "backward_entropy": 0.06030931075414022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.5326690673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02753383293747902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09503607749938965,
      "backward_entropy": 0.06001782417297363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.6746597290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027604950591921806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09488902091979981,
      "backward_entropy": 0.06324221028221978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0672607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027675608173012733,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09474114775657654,
      "backward_entropy": 0.06300388442145453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.14794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027747470885515213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09459133148193359,
      "backward_entropy": 0.05913959609137641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.9703140258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027820710092782974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09444022178649902,
      "backward_entropy": 0.06252733204099867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.8397216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027893783524632454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0942894995212555,
      "backward_entropy": 0.05854981475406223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.68024444580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027969539165496826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09413586854934693,
      "backward_entropy": 0.05826218922932943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.47906494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028042715042829514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09398285150527955,
      "backward_entropy": 0.061800758043924965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.8560333251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028118208050727844,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09382617473602295,
      "backward_entropy": 0.06155457099278768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.45720672607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028194943442940712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09366905689239502,
      "backward_entropy": 0.05735150973002116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.63729858398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02827073633670807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09351159930229187,
      "backward_entropy": 0.06105506420135498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.22311401367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02834455296397209,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09335619807243348,
      "backward_entropy": 0.07624720864825779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.7839126586914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02841632068157196,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09320180416107178,
      "backward_entropy": 0.0762368573082818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.8721694946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028488146141171455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09304769039154052,
      "backward_entropy": 0.060242162810431585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.19347381591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028559941798448563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09289351701736451,
      "backward_entropy": 0.05574672089682685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.50798034667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028631536290049553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09273860454559327,
      "backward_entropy": 0.05968472692701551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.72389221191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02870277687907219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09258282780647278,
      "backward_entropy": 0.05507757928636339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.08372497558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02877531573176384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09242484569549561,
      "backward_entropy": 0.05911835034688314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.69779968261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028849218040704727,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09226514101028442,
      "backward_entropy": 0.05883762571546766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.02783966064453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028919992968440056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09210898876190185,
      "backward_entropy": 0.07617010010613336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.466064453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02898777835071087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09195570945739746,
      "backward_entropy": 0.0761555896864997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.36056900024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029055748134851456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.091801118850708,
      "backward_entropy": 0.053355005052354604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.4361114501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029116330668330193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09165354967117309,
      "backward_entropy": 0.05297726723882887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.76543426513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02918078377842903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09150044918060303,
      "backward_entropy": 0.05260766877068414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.96395874023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029245885089039803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09134507179260254,
      "backward_entropy": 0.07608367337120904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.605224609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029317863285541534,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09118306636810303,
      "backward_entropy": 0.07607575919893053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.9666290283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02938796766102314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09102176427841187,
      "backward_entropy": 0.05633627043830024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.14002990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029459606856107712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09085742235183716,
      "backward_entropy": 0.05118290252155728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.92709350585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029535455629229546,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09068806171417236,
      "backward_entropy": 0.055736144383748375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.40460205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02961086295545101,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09051897525787353,
      "backward_entropy": 0.05543712774912516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.41903686523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029688972979784012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09034690856933594,
      "backward_entropy": 0.05014397700627645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.15784454345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029766082763671875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09017442464828491,
      "backward_entropy": 0.05483800172805786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.0127182006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029836850240826607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09000958800315857,
      "backward_entropy": 0.049416051970587835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.37881469726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029907820746302605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08984458446502686,
      "backward_entropy": 0.04904304610358344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.15283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029982075095176697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0896762490272522,
      "backward_entropy": 0.04868397447797987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.89543151855469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030053094029426575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08951165676116943,
      "backward_entropy": 0.07599497503704494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.91790008544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030124153941869736,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08934586048126221,
      "backward_entropy": 0.07598398129145305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.11199188232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03019518032670021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0891787052154541,
      "backward_entropy": 0.04756637414296468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.06742858886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030263597145676613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08901506662368774,
      "backward_entropy": 0.04718922906451755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.63375854492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03032798506319523,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08885623216629028,
      "backward_entropy": 0.07594353622860378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.8144760131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0303905438631773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08870033025741578,
      "backward_entropy": 0.05181305607159933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.44792175292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030454156920313835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08854273557662964,
      "backward_entropy": 0.05145525932312012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.970577239990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030518822371959686,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08838362097740174,
      "backward_entropy": 0.05109956529405382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.67343139648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0305789727717638,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08823167085647583,
      "backward_entropy": 0.050725420316060386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.23942947387695,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03064030036330223,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08807708621025086,
      "backward_entropy": 0.07584900326199001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.5916862487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030695170164108276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08792892694473267,
      "backward_entropy": 0.04442684517966376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.98878479003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030746115371584892,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08778589963912964,
      "backward_entropy": 0.04400416877534655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.52386474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030804075300693512,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08763522505760193,
      "backward_entropy": 0.049182375272115074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.46174621582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030864844098687172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08747970461845397,
      "backward_entropy": 0.04881585968865289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.47586059570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030925387516617775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08732297420501708,
      "backward_entropy": 0.04282815588845147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.89372253417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030985664576292038,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08716568350791931,
      "backward_entropy": 0.048074811697006226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.68003845214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031040044501423836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08701607584953308,
      "backward_entropy": 0.04768155680762397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.35337829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031103892251849174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0868552565574646,
      "backward_entropy": 0.04732187920146518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.28095245361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031170116737484932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08669006824493408,
      "backward_entropy": 0.04124540752834744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.76437377929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031235819682478905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08652599453926087,
      "backward_entropy": 0.04661473962995741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.38418579101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031303826719522476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08635863661766052,
      "backward_entropy": 0.04048247469796075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.31181716918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0313740037381649,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08618803024291992,
      "backward_entropy": 0.04011188613043891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.96324157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03143893927335739,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.086024808883667,
      "backward_entropy": 0.04556619127591451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.57682800292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031506385654211044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08585882186889648,
      "backward_entropy": 0.03934710224469503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.39990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03157319128513336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08569353818893433,
      "backward_entropy": 0.03897033797370063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.74319458007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03163943439722061,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08552913665771485,
      "backward_entropy": 0.038591096798578896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.04617309570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03170543164014816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0853658676147461,
      "backward_entropy": 0.03821550806363424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.43585205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0317709855735302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08520282506942749,
      "backward_entropy": 0.037840180926852755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.76087951660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03183930739760399,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08503707647323608,
      "backward_entropy": 0.03747546672821045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.2554702758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03191324695944786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.084866201877594,
      "backward_entropy": 0.03713826338450114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.9381561279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031987566500902176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08469517230987549,
      "backward_entropy": 0.042801482809914485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.12957000732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03206372261047363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0845220685005188,
      "backward_entropy": 0.04247930314805773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.94158172607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03213849291205406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08435065746307373,
      "backward_entropy": 0.03611866964234246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.46057891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032212033867836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08418043851852416,
      "backward_entropy": 0.03577083349227905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.42180633544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03228463977575302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08401209115982056,
      "backward_entropy": 0.03542119264602661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.02970886230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03235634043812752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08384462594985961,
      "backward_entropy": 0.03507024049758911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.88206481933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03242873400449753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08367683887481689,
      "backward_entropy": 0.03472582499186198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.42060852050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032503094524145126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08350675106048584,
      "backward_entropy": 0.03438661495844523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.07341766357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032576125115156174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08333700299263,
      "backward_entropy": 0.040142036146587796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.92109680175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03264670819044113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08317017555236816,
      "backward_entropy": 0.033682935767703585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.94219970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032712411135435104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08301059007644654,
      "backward_entropy": 0.03331793347994486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.55894470214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03278215229511261,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08284536600112916,
      "backward_entropy": 0.03908640808529324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.84135437011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03285560756921768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08267511129379272,
      "backward_entropy": 0.03875191344155206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.70092010498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03292769193649292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0825047254562378,
      "backward_entropy": 0.03841128283076816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.30016326904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032995954155921936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0823391854763031,
      "backward_entropy": 0.03188569678200616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.41470336914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033066585659980774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08216978311538696,
      "backward_entropy": 0.037711381912231445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.23532104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03314097225666046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819965660572052,
      "backward_entropy": 0.03118152419726054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.0723648071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033216238021850586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08182475566864014,
      "backward_entropy": 0.030848688549465604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03329048305749893,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08165432214736938,
      "backward_entropy": 0.03672194812032911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.54750061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033369746059179306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08147879838943481,
      "backward_entropy": 0.030191620190938313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.72259521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03344649448990822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08130834102630616,
      "backward_entropy": 0.03608118163214789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.95579528808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03351782634854317,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08114540576934814,
      "backward_entropy": 0.07553833060794407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.92135620117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03359284624457359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08097729682922364,
      "backward_entropy": 0.029217044512430828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.86817932128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03366589546203613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08081374168395997,
      "backward_entropy": 0.028896301984786987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.57333374023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03373422846198082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08065792322158813,
      "backward_entropy": 0.028569320837656658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.45856475830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033802423626184464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08050245642662049,
      "backward_entropy": 0.028242558240890503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.12055206298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03387217968702316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0803466796875,
      "backward_entropy": 0.034055580695470176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.53889083862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0339428186416626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08018859028816223,
      "backward_entropy": 0.033728215429517955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.91808319091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0340072400867939,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0800381362438202,
      "backward_entropy": 0.03338128328323364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.84923553466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034071922302246094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07988732457160949,
      "backward_entropy": 0.026962641212675307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.101234436035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034138455986976624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07973416447639466,
      "backward_entropy": 0.02664796511332194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.03321075439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0342010036110878,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07958677411079407,
      "backward_entropy": 0.07545325491163465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.90178680419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034266915172338486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07943531274795532,
      "backward_entropy": 0.026018518540594313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.91183471679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03433580324053764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07927936911582947,
      "backward_entropy": 0.031716899739371404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.58065795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03440301492810249,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07912516593933105,
      "backward_entropy": 0.031396938694847956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.29953002929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03447139635682106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07896802425384522,
      "backward_entropy": 0.025101966328091092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.18073272705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03454406559467316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07880693078041076,
      "backward_entropy": 0.02480911049577925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.00415802001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03461328148841858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07864959239959717,
      "backward_entropy": 0.02450753582848443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.9740982055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03468099981546402,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07849439978599548,
      "backward_entropy": 0.03016952673594157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.34600067138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03474884480237961,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07833967804908752,
      "backward_entropy": 0.02390781707233853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.3692398071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03481404110789299,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07818900346755982,
      "backward_entropy": 0.02955268488989936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.22026824951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034876748919487,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07804142236709595,
      "backward_entropy": 0.023305568430158827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.67890930175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494027629494667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07789352536201477,
      "backward_entropy": 0.023010325100686815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.06474304199219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03499878942966461,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07775319814682007,
      "backward_entropy": 0.07536653677622478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.85051727294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035059913992881775,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07760995030403137,
      "backward_entropy": 0.028290761841668025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.57376098632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03511899337172508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07746946215629577,
      "backward_entropy": 0.02797803282737732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.85433197021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03518073260784149,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0773262619972229,
      "backward_entropy": 0.027679734759860568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.90967559814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03524162992835045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07718247175216675,
      "backward_entropy": 0.0215660250849194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.92605590820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03530239313840866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07704049944877625,
      "backward_entropy": 0.027085734738243952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.09407043457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03536432608962059,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07689816951751709,
      "backward_entropy": 0.02102504836188422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.50078582763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03542286530137062,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07676022052764893,
      "backward_entropy": 0.07528983222113715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.73421478271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03548151254653931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07662361860275269,
      "backward_entropy": 0.020485273665852018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.77335739135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03553859889507294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07648875713348388,
      "backward_entropy": 0.02591499189535777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.390254974365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035591453313827515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0763595700263977,
      "backward_entropy": 0.019947189423773024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.37432861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035642094910144806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0762340784072876,
      "backward_entropy": 0.025314983394410875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.90991973876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035699374973773956,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07610142230987549,
      "backward_entropy": 0.025043020645777386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.1750259399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03575555980205536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0759710431098938,
      "backward_entropy": 0.024772302971945867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.01017761230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035815104842185974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07583754062652588,
      "backward_entropy": 0.01895926230483585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.3689956665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035878896713256836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07569862604141235,
      "backward_entropy": 0.018740152319272358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.0411376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035941120237112045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07556301355361938,
      "backward_entropy": 0.024033402403195698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.31252670288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036008987575769424,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07542067170143127,
      "backward_entropy": 0.018322014146380954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.98442840576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036073531955480576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0752846360206604,
      "backward_entropy": 0.02357783748043908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.1693115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03613875433802605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07514562606811523,
      "backward_entropy": 0.017917758888668485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.18889617919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03620630130171776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07500416040420532,
      "backward_entropy": 0.017722868257098727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.8427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036274638026952744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07486261129379272,
      "backward_entropy": 0.022926241159439087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.81987762451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03634490817785263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07471787333488464,
      "backward_entropy": 0.01734495825237698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.42662811279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641975298523903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0745672345161438,
      "backward_entropy": 0.017166419161690608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.13227081298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03649881109595299,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07441111803054809,
      "backward_entropy": 0.022359523508283827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.15672302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03658165782690048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07425029873847962,
      "backward_entropy": 0.016841216219796076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.350074768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036663807928562164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07409133911132812,
      "backward_entropy": 0.016681164503097534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.6895751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03674119710922241,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07393985986709595,
      "backward_entropy": 0.01651212904188368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.57234954833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681573644280434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07379339337348938,
      "backward_entropy": 0.016339373257425096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.76856231689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03689039871096611,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07364710569381713,
      "backward_entropy": 0.01617077158557044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.22604751586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03696923330426216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07349504232406616,
      "backward_entropy": 0.016010065873463947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.53136444091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03704511374235153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07334716320037842,
      "backward_entropy": 0.01584760182433658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.69302368164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03711966052651405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07320131659507752,
      "backward_entropy": 0.015684907635052998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.25519561767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03719688579440117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07305126190185547,
      "backward_entropy": 0.015523643957244026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.4036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03727257624268532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07290345430374146,
      "backward_entropy": 0.015360212988323636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.00033569335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03734418377280235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07276152968406677,
      "backward_entropy": 0.015191700723436143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.62654113769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037420373409986496,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07261426448822021,
      "backward_entropy": 0.01503153145313263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.05610656738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037495266646146774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07246929407119751,
      "backward_entropy": 0.014871873789363436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.0365219116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0375661626458168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.072329580783844,
      "backward_entropy": 0.01982703970538245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.54572296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037640269845724106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0721852421760559,
      "backward_entropy": 0.014545129405127631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.22914123535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037717536091804504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07203806638717651,
      "backward_entropy": 0.014394210444556342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.79508209228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03779462352395058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07188985347747803,
      "backward_entropy": 0.014241675535837809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.49981689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0378718227148056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07174246311187744,
      "backward_entropy": 0.014092514912287394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.66677856445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037947747856378555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.071597158908844,
      "backward_entropy": 0.013942478431595696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.039379119873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038026466965675354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07144779562950135,
      "backward_entropy": 0.013794413871235318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.96958541870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03809818625450134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0713082194328308,
      "backward_entropy": 0.013636612229877047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.91638946533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03816501423716545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07117529511451721,
      "backward_entropy": 0.013475139107969072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.57308959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0382315032184124,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07104240655899048,
      "backward_entropy": 0.01829242706298828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.4377212524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03830451890826225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07090159654617309,
      "backward_entropy": 0.013165922628508674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.41634750366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03837805986404419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07076058387756348,
      "backward_entropy": 0.013020053505897522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.26524353027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03844933956861496,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07062275409698486,
      "backward_entropy": 0.01287323898739285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.80438232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038518600165843964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07048805356025696,
      "backward_entropy": 0.01762964990403917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.68682098388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03858884796500206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07035280466079712,
      "backward_entropy": 0.017467349767684937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.6772232055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03865988180041313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07021612524986268,
      "backward_entropy": 0.01731042398346795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.28264617919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03873027488589287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07008016705513001,
      "backward_entropy": 0.012305321792761484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.591064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03880147263407707,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06994311809539795,
      "backward_entropy": 0.012168357769648233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.89246368408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03887612000107765,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06980175375938416,
      "backward_entropy": 0.012038103408283658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.24374389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03895113617181778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0696595311164856,
      "backward_entropy": 0.011908580031659868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.05056762695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03902805596590042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06951589584350586,
      "backward_entropy": 0.011786075101958381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.51403045654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03910662606358528,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06936981678009033,
      "backward_entropy": 0.01166840394337972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.3927001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03918398544192314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06922599077224731,
      "backward_entropy": 0.011550461252530416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.92078399658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03926016762852669,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06908364295959472,
      "backward_entropy": 0.07603147294786242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.8729476928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933943808078766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06893734931945801,
      "backward_entropy": 0.011316243145200942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.590892791748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03942398726940155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06878321170806885,
      "backward_entropy": 0.011207557386822171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.14881134033203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03950141742825508,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06863989830017089,
      "backward_entropy": 0.07608138190375434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.38825988769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03958171606063843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06849312782287598,
      "backward_entropy": 0.01568390429019928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.340206146240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03966068476438522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06834862232208253,
      "backward_entropy": 0.010876307057009803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.47595977783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03973572328686714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0682090699672699,
      "backward_entropy": 0.010765467252996232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.69210815429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039811260998249054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06806902289390564,
      "backward_entropy": 0.015303124984105429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.6878890991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03988853096961975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06792671680450439,
      "backward_entropy": 0.015182296435038248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.1370735168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03996476158499718,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0677853763103485,
      "backward_entropy": 0.010448084937201606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.55097961425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04003879055380821,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06764771938323974,
      "backward_entropy": 0.0149347765578164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.13502502441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040117453783750534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06750449538230896,
      "backward_entropy": 0.010245728823873732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.95006561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04020410776138306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06734979152679443,
      "backward_entropy": 0.010157970090707144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.76542663574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040288787335157394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06719746589660644,
      "backward_entropy": 0.014615827136569552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.58216094970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037167504429817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0670474112033844,
      "backward_entropy": 0.009977868861622281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.70680236816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04045293107628822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06689942479133607,
      "backward_entropy": 0.014405200878779093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.735042572021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04053536057472229,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06674957275390625,
      "backward_entropy": 0.00979475842581855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.92784881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04061240702867508,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06660797595977783,
      "backward_entropy": 0.00970174703333113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.72732925415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04068860039114952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06646844148635864,
      "backward_entropy": 0.00961106518904368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.80807495117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040762610733509064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06633096933364868,
      "backward_entropy": 0.009519441260231866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.48180389404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040841180831193924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06618579626083373,
      "backward_entropy": 0.009431791802247366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.23749542236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040921229869127274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06603821516036987,
      "backward_entropy": 0.009346461958355375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.117820739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04099621996283531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06589869260787964,
      "backward_entropy": 0.009259266985787286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.936912536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0410679392516613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06576429605484009,
      "backward_entropy": 0.009171340200636122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.42302703857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041138023138046265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06563246846199036,
      "backward_entropy": 0.009084229667981466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.03559875488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0412118099629879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0654952883720398,
      "backward_entropy": 0.009001493453979492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.46202087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04129021614789963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06535152196884156,
      "backward_entropy": 0.008923318650987413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.96482849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041366398334503174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06521115899085998,
      "backward_entropy": 0.008845759762658013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.17543029785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041443128138780594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06506946086883544,
      "backward_entropy": 0.013047243158022562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.03091812133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041517771780490875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06493046879768372,
      "backward_entropy": 0.012952203551928202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.09678649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041590526700019836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06479476690292359,
      "backward_entropy": 0.008618454966280196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.625385284423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041665419936180115,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06465641856193542,
      "backward_entropy": 0.008545601533518897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.97602081298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041734516620635986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06452683210372925,
      "backward_entropy": 0.008469433420234256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.77271270751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04180871695280075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06439027786254883,
      "backward_entropy": 0.008398923608991835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.3047981262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041879866272211075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06425778865814209,
      "backward_entropy": 0.008328535490565829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.92823028564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04194948822259903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0641271710395813,
      "backward_entropy": 0.00825768791966968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.56953430175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04202163219451904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06399262547492982,
      "backward_entropy": 0.012324851420190599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.30672836303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04209348186850548,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06385782957077027,
      "backward_entropy": 0.012240565485424466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.213802337646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04216254502534866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06372747421264649,
      "backward_entropy": 0.008055624034669664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.55652618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223167523741722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06359751224517822,
      "backward_entropy": 0.007989977796872457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.88597106933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04230206087231636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06346499919891357,
      "backward_entropy": 0.007925311724344889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.710533142089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04237235337495804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06333228945732117,
      "backward_entropy": 0.007862206962373521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.53263854980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04244258254766464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0631991982460022,
      "backward_entropy": 0.0078010956446329755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.61126708984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04251277819275856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06306647062301636,
      "backward_entropy": 0.007741928928428226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.9391860961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042580414563417435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06293787956237792,
      "backward_entropy": 0.007682771318488651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.02738952636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04265455901622772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06279867887496948,
      "backward_entropy": 0.0076278141803211635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.70668029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427282452583313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06265904903411865,
      "backward_entropy": 0.007572989496919844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.90918731689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042805325239896774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06251424551010132,
      "backward_entropy": 0.007520534098148346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.7802791595459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288295656442642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06236860156059265,
      "backward_entropy": 0.007469154066509671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.083946228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042956043034791946,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06223052740097046,
      "backward_entropy": 0.011352035734388564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.79773712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04302758350968361,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0620951771736145,
      "backward_entropy": 0.007363779677285088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.34809875488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04310396686196327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06195148229598999,
      "backward_entropy": 0.007313847541809082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.51279067993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318346455693245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06180276870727539,
      "backward_entropy": 0.007266595959663391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.392295837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04325953498482704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06166024804115296,
      "backward_entropy": 0.07657956414752537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.22376251220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04333251342177391,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061522841453552246,
      "backward_entropy": 0.007171817951732212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.22722625732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04340145364403725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0613922119140625,
      "backward_entropy": 0.01097750746541553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.01071166992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043471772223711014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061259222030639646,
      "backward_entropy": 0.007078091303507487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.67155456542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04354704171419144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06111762523651123,
      "backward_entropy": 0.007035351461834378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.789390563964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04362797737121582,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060967016220092776,
      "backward_entropy": 0.0069958534505632185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.07378387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04370536282658577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060822528600692746,
      "backward_entropy": 0.010760390096240573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.87897491455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04378695413470268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06067072153091431,
      "backward_entropy": 0.006918566922346751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.06855392456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043871086090803146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0605145275592804,
      "backward_entropy": 0.006882366206910875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.67536926269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04395382106304169,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060360449552536014,
      "backward_entropy": 0.0068459779851966435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.672969818115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044036515057086945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06020690798759461,
      "backward_entropy": 0.006810311641958024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.69219207763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044117946177721024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06005569696426392,
      "backward_entropy": 0.0067748696439796025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.861698150634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044201888144016266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05990034341812134,
      "backward_entropy": 0.006740413192245696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.73546600341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04428200423717499,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05975143909454346,
      "backward_entropy": 0.00670505811770757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.89631271362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04435866326093674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0596081018447876,
      "backward_entropy": 0.006669521331787109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.93284606933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04443465173244476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05946595668792724,
      "backward_entropy": 0.006634439445204205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.937618255615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04451247677206993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05932087898254394,
      "backward_entropy": 0.006600467695130242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.330501556396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04458831995725632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05917898416519165,
      "backward_entropy": 0.006566557619306777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.150447845458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04466360807418823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05903744697570801,
      "backward_entropy": 0.006533459656768375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.98910140991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04473837837576866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05889655351638794,
      "backward_entropy": 0.006500910553667281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.2480239868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044810257852077484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05876075029373169,
      "backward_entropy": 0.01006640245517095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.18142318725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04488318786025047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05862263441085815,
      "backward_entropy": 0.006436520152621799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.43107604980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04495462775230408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05848701000213623,
      "backward_entropy": 0.006405221919218699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.63347625732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502596706151962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058351194858551024,
      "backward_entropy": 0.00637490881813897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.42183685302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045098379254341125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05821335911750793,
      "backward_entropy": 0.006345367679993312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.903526306152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04517177864909172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05807316303253174,
      "backward_entropy": 0.009833757248189714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.877708435058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04524482786655426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057933616638183597,
      "backward_entropy": 0.006287667900323868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.29203796386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04531393572688103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0578016996383667,
      "backward_entropy": 0.006258900794718001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.2874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04538195580244064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057671856880187986,
      "backward_entropy": 0.0062308286627133684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.420326232910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545492306351662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057533162832260135,
      "backward_entropy": 0.006204096807373894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.85867691040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04552276059985161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05740389823913574,
      "backward_entropy": 0.006177053683333927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.42277526855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045589640736579895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0572761595249176,
      "backward_entropy": 0.006150495260953903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.68010330200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04566157981753349,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05713881254196167,
      "backward_entropy": 0.006124724530511432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.35097122192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04573334380984306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05700157880783081,
      "backward_entropy": 0.006099603242344326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.28303146362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04580249264836311,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056869471073150636,
      "backward_entropy": 0.006074335840013292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.24836730957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04587051272392273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0567395031452179,
      "backward_entropy": 0.006049259255329768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.00062561035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0459434874355793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.056599998474121095,
      "backward_entropy": 0.07682292991214329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.831424713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0460137240588665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05646593570709228,
      "backward_entropy": 0.006002485338184569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04608280211687088,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05633355379104614,
      "backward_entropy": 0.00597992953326967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.26802062988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046151965856552124,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056200891733169556,
      "backward_entropy": 0.009218751556343503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907855033874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04622353985905647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.056063538789749144,
      "backward_entropy": 0.005936652421951294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.4202995300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04628894105553627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055938661098480225,
      "backward_entropy": 0.005914871477418476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.125484466552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04635237529873848,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05581756830215454,
      "backward_entropy": 0.009096379081408182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.00433349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0464152954518795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05569744110107422,
      "backward_entropy": 0.005872238841321733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.09921646118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046477656811475754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055578315258026124,
      "backward_entropy": 0.005851635916365517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.7409782409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04653837904334068,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055462431907653806,
      "backward_entropy": 0.005831587645742629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.89798355102539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046598780900239944,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05534688830375671,
      "backward_entropy": 0.07684645387861463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.86067199707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665770009160042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055234283208847046,
      "backward_entropy": 0.005791766362057792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.67910385131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04671890661120415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055116784572601316,
      "backward_entropy": 0.008852086961269379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.22628402709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04677868261933327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05500174760818481,
      "backward_entropy": 0.005755004369550281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.9373550415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04683825373649597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054887163639068606,
      "backward_entropy": 0.005737461149692535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.13701248168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04690118506550789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05476566553115845,
      "backward_entropy": 0.005720554126633538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.25955581665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04696594923734665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054640394449234006,
      "backward_entropy": 0.005703949266009861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.69164276123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047028910368680954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05451866388320923,
      "backward_entropy": 0.0056882260574234855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.54604721069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04709134250879288,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054397952556610105,
      "backward_entropy": 0.0056725384460555184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.980674743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04715341702103615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054277682304382326,
      "backward_entropy": 0.005658268928527832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.75399398803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047211624681949615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054165315628051755,
      "backward_entropy": 0.005644936528470781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.74910354614258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04727093502879143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054050564765930176,
      "backward_entropy": 0.005631399237447315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.63964080810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04732886329293251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05393873453140259,
      "backward_entropy": 0.005617400424347984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.9202766418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047385647892951965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053829073905944824,
      "backward_entropy": 0.0056040667825275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.8614730834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047442562878131866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0537190318107605,
      "backward_entropy": 0.005591460400157505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.31205749511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0475030317902565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05360100269317627,
      "backward_entropy": 0.0055791934331258135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.4352035522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04756566882133484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05347883701324463,
      "backward_entropy": 0.00556866286529435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.38978958129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047631267458200455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05335061550140381,
      "backward_entropy": 0.005557939410209656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.764732360839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047696102410554886,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05322369337081909,
      "backward_entropy": 0.008319712347454496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.340492248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047757916152477264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.053103184700012206,
      "backward_entropy": 0.005537477218442493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.157081604003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047820400446653366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.052981221675872804,
      "backward_entropy": 0.07688415050506592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.156795501708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047883711755275726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05285746455192566,
      "backward_entropy": 0.005517617695861393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.314857482910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04794887453317642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05272948741912842,
      "backward_entropy": 0.008208894067340426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.575565338134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048009708523750305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05261107683181763,
      "backward_entropy": 0.005500831537776523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.280193328857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04807016998529434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05249349474906921,
      "backward_entropy": 0.005491534041033851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.25437545776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812803491950035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05238149762153625,
      "backward_entropy": 0.0054826028645038605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.160945892333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04818476364016533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05227173566818237,
      "backward_entropy": 0.005474592248598735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.060916900634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048240408301353455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0521641731262207,
      "backward_entropy": 0.0054666416512595285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.989099502563477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04829510673880577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05205843448638916,
      "backward_entropy": 0.005459262679020564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.741641998291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04834774509072304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05195692777633667,
      "backward_entropy": 0.0080129388305876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.774999618530273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04840321093797684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05184900164604187,
      "backward_entropy": 0.0054450564914279515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.328556060791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04845774173736572,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05174291133880615,
      "backward_entropy": 0.005438615878423055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.114013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048515837639570236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05162906050682068,
      "backward_entropy": 0.005430385884311464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.033973693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04857722669839859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05150827169418335,
      "backward_entropy": 0.005421818130546146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.35627555847168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04864050820469856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.051383256912231445,
      "backward_entropy": 0.005413590619961421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.24486541748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04870206490159035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05126214027404785,
      "backward_entropy": 0.005406230688095093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.21409606933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048767756670713425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0511320948600769,
      "backward_entropy": 0.005399432861142688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.76152801513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04883600026369095,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0509965181350708,
      "backward_entropy": 0.0077929844458897906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.889345169067383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048903029412031174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05086405277252197,
      "backward_entropy": 0.005385379410452313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.1913833618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04896797239780426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050736111402511594,
      "backward_entropy": 0.0053790054387516445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.669395446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049036551266908646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05060046911239624,
      "backward_entropy": 0.005371512638198005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.78233337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049102697521448135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0504703938961029,
      "backward_entropy": 0.0053629693057801985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.420808792114258,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04916903004050255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.050339943170547484,
      "backward_entropy": 0.07691664165920681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.309873580932617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049233291298151016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05021404027938843,
      "backward_entropy": 0.007618321312798394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.72698211669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929564520716667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050092315673828124,
      "backward_entropy": 0.00533975578016705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.61043930053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935746639966965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0499717116355896,
      "backward_entropy": 0.0053334592117203605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.40764236450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04942094907164574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04984753727912903,
      "backward_entropy": 0.005326561629772186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.203372955322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494859516620636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04971996545791626,
      "backward_entropy": 0.005319455431567298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.41765213012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0495523139834404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049589413404464724,
      "backward_entropy": 0.005312277211083306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.78225326538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04962094873189926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04945398271083832,
      "backward_entropy": 0.005304348137643602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.540489196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969051480293274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04931682646274567,
      "backward_entropy": 0.005296216656764348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.031436920166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04976114258170128,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049177104234695436,
      "backward_entropy": 0.0052902789579497445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.53759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049831219017505646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049039000272750856,
      "backward_entropy": 0.005282027853859795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.37911605834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049899812787771225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04890434145927429,
      "backward_entropy": 0.007315737505753835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.45436096191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04996710643172264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048772776126861574,
      "backward_entropy": 0.005264900210830901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.866727828979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050034355372190475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04864116907119751,
      "backward_entropy": 0.005256678495142195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.598848342895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050099413841962814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0485145777463913,
      "backward_entropy": 0.005249823133150737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.207618713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016118660569191,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0483956515789032,
      "backward_entropy": 0.005242084463437398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.851280212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05022566020488739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048270303010940555,
      "backward_entropy": 0.005234509706497192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.343324661254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050291549414396286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.048141580820083615,
      "backward_entropy": 0.005228406853146023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.48629379272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050354015082120895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04802094697952271,
      "backward_entropy": 0.005221012565824721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.159690856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05041924864053726,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04789369106292725,
      "backward_entropy": 0.007063623931672838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.024253845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050482552498579025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04777065515518188,
      "backward_entropy": 0.00521307604180442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.9378662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054842308163643,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0476417064666748,
      "backward_entropy": 0.005210633493132061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.720176696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061215162277222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04751763343811035,
      "backward_entropy": 0.005208411150508457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.611167907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05067581683397293,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04739410281181335,
      "backward_entropy": 0.005203063289324443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.95512056350708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0507386215031147,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04727259278297424,
      "backward_entropy": 0.0051980507042672895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.88920974731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05079638212919235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0471626341342926,
      "backward_entropy": 0.005195108552773793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.84329605102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05085701867938042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04704590439796448,
      "backward_entropy": 0.005190796736213896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.682400703430176,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05091916024684906,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.04692606925964356,
      "backward_entropy": 0.07693480120764838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.902191162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050977252423763275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046815726161003116,
      "backward_entropy": 0.005180061691337162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.039472579956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05103514343500137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04670571088790894,
      "backward_entropy": 0.005176641460922029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.503013610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109168589115143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04659847021102905,
      "backward_entropy": 0.005174130615260866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.2175178527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051152270287275314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046482259035110475,
      "backward_entropy": 0.005170263763931062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.075490951538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0512131005525589,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046365711092948916,
      "backward_entropy": 0.005163701044188606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.487789154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05127101019024849,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046256011724472045,
      "backward_entropy": 0.005156514959202873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.69183349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051330722868442535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046142247319221494,
      "backward_entropy": 0.00515000687705146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.95083999633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05139099061489105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046027141809463504,
      "backward_entropy": 0.005144011643197801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.734729766845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0514506958425045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04591336250305176,
      "backward_entropy": 0.005138842595948113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.195159912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051507674157619476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04580578804016113,
      "backward_entropy": 0.005133955015076531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.058961868286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05156545713543892,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.045696613192558286,
      "backward_entropy": 0.00653141157494651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.507463455200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051621802151203156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04559072256088257,
      "backward_entropy": 0.005126116176446279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.710880279541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05167563632130623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045490825176239015,
      "backward_entropy": 0.005121520823902554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.355335235595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051730670034885406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04538792371749878,
      "backward_entropy": 0.005118525276581447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.571659088134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05178331583738327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04529066681861878,
      "backward_entropy": 0.005114347984393437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.25657272338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184033885598183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04518356919288635,
      "backward_entropy": 0.005110054380363888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.11061096191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051898110657930374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.045074671506881714,
      "backward_entropy": 0.005106042656633589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.8575553894043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051956385374069214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04496479332447052,
      "backward_entropy": 0.005100423677100075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.11796569824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05201821029186249,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04484718441963196,
      "backward_entropy": 0.005092530200878779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.06353759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05208548158407211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04471808671951294,
      "backward_entropy": 0.005084622651338577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.149017333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05215432867407799,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.044586005806922915,
      "backward_entropy": 0.0050752949383523725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.51492691040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052221715450286865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04445747435092926,
      "backward_entropy": 0.0050682686269283295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.832746505737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0522909089922905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04432511329650879,
      "backward_entropy": 0.0050625767972734236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.69280242919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235852673649788,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04419665038585663,
      "backward_entropy": 0.005057857682307561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.443620681762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05242454633116722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0440723329782486,
      "backward_entropy": 0.005052096727821562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.323650360107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05248820781707764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04395358562469483,
      "backward_entropy": 0.005047040267123116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.23500061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05254973843693733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043839913606643674,
      "backward_entropy": 0.005042603032456504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.047670364379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052611496299505234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04372578263282776,
      "backward_entropy": 0.006038495649894078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.854923248291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526726059615612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.043613046407699585,
      "backward_entropy": 0.005039554503228929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.85926628112793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05273491516709328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04349784255027771,
      "backward_entropy": 0.005039329330126445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.590124130249023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05279519036412239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04338751435279846,
      "backward_entropy": 0.005039133131504059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.00810241699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05285511910915375,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0432776153087616,
      "backward_entropy": 0.005044253336058723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.367687225341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05291826277971268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04316098690032959,
      "backward_entropy": 0.005046721133920882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.615272521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052980199456214905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04304751753807068,
      "backward_entropy": 0.005047652870416641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.222782135009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053038839250802994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04294213652610779,
      "backward_entropy": 0.005045815060536067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.396299362182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310076102614403,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04282974898815155,
      "backward_entropy": 0.005042577783266704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.837743759155273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053159747272729874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04272407293319702,
      "backward_entropy": 0.005041483375761244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.47801208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053217578679323196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04262179136276245,
      "backward_entropy": 0.005035581688086192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.485490798950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05327852815389633,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042513349652290346,
      "backward_entropy": 0.005026006036334568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.707834243774414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053338613361120224,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.042406785488128665,
      "backward_entropy": 0.07693546348147923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.07737731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053396858274936676,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04230446517467499,
      "backward_entropy": 0.005012150853872299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.870040893554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05345720052719116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.042197832465171815,
      "backward_entropy": 0.0050031335817443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.379234313964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05351486802101135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04209718704223633,
      "backward_entropy": 0.005666342460446888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.31272888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05357084795832634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04200050234794617,
      "backward_entropy": 0.004994194540712569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.671552658081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05362740531563759,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.041902965307235716,
      "backward_entropy": 0.004991150564617581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.53969383239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05368131771683693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04181137681007385,
      "backward_entropy": 0.0049881115555763245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.403505325317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05373324826359749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04172396659851074,
      "backward_entropy": 0.004989761445257399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.74302673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05378507822751999,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04163684844970703,
      "backward_entropy": 0.004991386913590961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.353370666503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05383751913905144,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04154886305332184,
      "backward_entropy": 0.00552829686138365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.77416229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053887832909822464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04146566987037659,
      "backward_entropy": 0.00498829906185468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.24534797668457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05394019931554794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04137800335884094,
      "backward_entropy": 0.004987457974089516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.76616096496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053990159183740616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04129612445831299,
      "backward_entropy": 0.005457927783330281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.22792053222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05404031276702881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04121372401714325,
      "backward_entropy": 0.0049832674364248914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.711141586303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05409270524978638,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04112624526023865,
      "backward_entropy": 0.004984800186422136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.924896240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054141975939273834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0410457968711853,
      "backward_entropy": 0.004987570146719615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.524425506591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054193269461393356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04096122980117798,
      "backward_entropy": 0.0053791652123133344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.575077056884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05424540862441063,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04087499380111694,
      "backward_entropy": 0.004991119106610616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.5571403503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0542992539703846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040785229206085204,
      "backward_entropy": 0.004991761926147673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.053253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435565114021301,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04069049954414368,
      "backward_entropy": 0.004992092649141948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.877166748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05441233888268471,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04059557318687439,
      "backward_entropy": 0.004992300437556373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.89561462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05446934700012207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040500155091285704,
      "backward_entropy": 0.004992796729008357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.30941390991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452853441238403,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.040400534868240356,
      "backward_entropy": 0.004992600116464827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.413389205932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054583802819252014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04030980467796326,
      "backward_entropy": 0.004992713116937214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.22502899169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054639268666505814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04021919965744018,
      "backward_entropy": 0.004990238696336746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.210959434509277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469606816768646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04012595415115357,
      "backward_entropy": 0.004987850785255432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.034101486206055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05474879592657089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04004230499267578,
      "backward_entropy": 0.004981408516565959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.06283187866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054799970239400864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03996245265007019,
      "backward_entropy": 0.004973175211085213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.779653549194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054847925901412964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03988986313343048,
      "backward_entropy": 0.004965309467580583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.675243377685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05489517003297806,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03981870412826538,
      "backward_entropy": 0.004961061394876904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.517173767089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05494184419512749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039748549461364746,
      "backward_entropy": 0.004961130519707997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.717637062072754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05498848482966423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0396788090467453,
      "backward_entropy": 0.004958838224411011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.28107261657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05503328889608383,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039613199234008786,
      "backward_entropy": 0.004956007831626468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.95018196105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055078305304050446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03954736292362213,
      "backward_entropy": 0.004951740718550152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.813230514526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055124517530202866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039479199051857,
      "backward_entropy": 0.0049465008907847935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.11526107788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517180263996124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039408981800079346,
      "backward_entropy": 0.004940558224916458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.382022857666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055222202092409134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03933228850364685,
      "backward_entropy": 0.004937472442785899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.643718719482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05527708679437637,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039246794581413266,
      "backward_entropy": 0.004934014545546638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.523760795593262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05533137172460556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03916264176368713,
      "backward_entropy": 0.004932059595982234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.913230895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538225173950195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.039085912704467776,
      "backward_entropy": 0.0049319614966710406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.70319366455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05543681979179382,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03900192379951477,
      "backward_entropy": 0.0049342210921976305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.52254867553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055489473044872284,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038922595977783206,
      "backward_entropy": 0.004933035622040431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.859136581420898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05554085969924927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03884586095809937,
      "backward_entropy": 0.0049347542226314545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.87858772277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0555901825428009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0387734055519104,
      "backward_entropy": 0.004939354956150055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.702047348022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05563938617706299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038701319694519044,
      "backward_entropy": 0.004944473091098998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.67200469970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05568680539727211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03863285183906555,
      "backward_entropy": 0.004953168746497896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.088943481445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05573410913348198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03856494426727295,
      "backward_entropy": 0.004959857298268212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.064505577087402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05578038841485977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03849946558475494,
      "backward_entropy": 0.004965066495868895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123287200927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0558241531252861,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03843901753425598,
      "backward_entropy": 0.004973033650053872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.054769515991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0558650828897953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038385009765625,
      "backward_entropy": 0.004975965867439906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.502286911010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055903613567352295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03833616971969604,
      "backward_entropy": 0.004976597511106067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.636920928955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05594392865896225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038283693790435794,
      "backward_entropy": 0.004977631900045607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.221651077270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05598411336541176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.038231277465820314,
      "backward_entropy": 0.004981137812137604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.112932205200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056026142090559006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03817488849163055,
      "backward_entropy": 0.004988030013110902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.740436553955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05606973543763161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03811522424221039,
      "backward_entropy": 0.004996668133470748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.350780487060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056113503873348236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03805552423000336,
      "backward_entropy": 0.0045137132207552595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.035357475280762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05615651607513428,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037997621297836306,
      "backward_entropy": 0.005007053414980571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.472978591918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05619777739048004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03794371485710144,
      "backward_entropy": 0.005008016609483295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.339448928833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05623916909098625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037890172004699706,
      "backward_entropy": 0.005003900577624639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.450462341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05628083273768425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03783634901046753,
      "backward_entropy": 0.004997538609637154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.067798614501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056323546916246414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037780863046646115,
      "backward_entropy": 0.004987664520740509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.818195343017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05636672303080559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03772435188293457,
      "backward_entropy": 0.004980968104468452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.627707481384277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05640934035181999,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03766883611679077,
      "backward_entropy": 0.004976809438731935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.156246185302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05645039677619934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03761663734912872,
      "backward_entropy": 0.00497368143664466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.593433380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05649438127875328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037559297680854795,
      "backward_entropy": 0.004967196947998471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.364825248718262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05653754994273186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03750371336936951,
      "backward_entropy": 0.004960736880699794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.512781143188477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657821148633957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037453123927116395,
      "backward_entropy": 0.004955130318800609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.445201873779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056620221585035324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03740013241767883,
      "backward_entropy": 0.004949423174063365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2897233963012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05666309967637062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037345987558364865,
      "backward_entropy": 0.004939218362172444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.16437339782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05670229345560074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037299522757530214,
      "backward_entropy": 0.0049267663723892635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.98566246032715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05674200505018234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.037252163887023924,
      "backward_entropy": 0.0049153487715456225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.024930953979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0567840076982975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03720041513442993,
      "backward_entropy": 0.004904809097448985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.7242374420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056825295090675354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0371503621339798,
      "backward_entropy": 0.004893728014495637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.9514799118042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056868087500333786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03709727823734284,
      "backward_entropy": 0.004887093686395221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.773392677307129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05690921097993851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03704749345779419,
      "backward_entropy": 0.004880138155486848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.568880081176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05694969370961189,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03699933588504791,
      "backward_entropy": 0.004872587405973011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.780614852905273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056990377604961395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03695113956928253,
      "backward_entropy": 0.0039139120943016475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.871748447418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057029519230127335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036906111240386966,
      "backward_entropy": 0.00485235783788893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.286500930786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057066578418016434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03686508536338806,
      "backward_entropy": 0.004844349291589525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.950986862182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05710408836603165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03682347536087036,
      "backward_entropy": 0.004834122541877959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.029203414916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05714302510023117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03677942156791687,
      "backward_entropy": 0.0048233821160263484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.18410873413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05718264356255531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036734098196029664,
      "backward_entropy": 0.004816068129407035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2750137746334076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057222019881010056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.036689162254333496,
      "backward_entropy": 0.00374210418926345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.035140037536621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057257261127233505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03665229678153992,
      "backward_entropy": 0.004807149370511373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.321974754333496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05729268863797188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03661500513553619,
      "backward_entropy": 0.004805251128143734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.572045803070068,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05732709914445877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03657984733581543,
      "backward_entropy": 0.004802597893608941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.208579063415527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05735991150140762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03654764294624328,
      "backward_entropy": 0.004801465405358208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.113190650939941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057392045855522156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03651676774024963,
      "backward_entropy": 0.0048003047704696655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.82438659667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0574239082634449,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03648611307144165,
      "backward_entropy": 0.004803708444039027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.0115966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057460565119981766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03644649982452393,
      "backward_entropy": 0.004808234671751658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.994202613830566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057496488094329834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0364080935716629,
      "backward_entropy": 0.0048166025016042925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.528969764709473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05753149092197418,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03637147545814514,
      "backward_entropy": 0.004824903690152698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8012337684631348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057566408067941666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036335182189941403,
      "backward_entropy": 0.004831381556060579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.867892265319824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05759864300489426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03630405962467194,
      "backward_entropy": 0.004836487273375194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.813879013061523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057630132883787155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03627448678016663,
      "backward_entropy": 0.004839310215579139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.274046421051025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05766304209828377,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03624205887317657,
      "backward_entropy": 0.0034995509518517386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.704587936401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057694211602211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0362131267786026,
      "backward_entropy": 0.004847954130835003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.577775955200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057726480066776276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036182254552841187,
      "backward_entropy": 0.004849118904934989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.98223304748535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05776007100939751,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036148840188980104,
      "backward_entropy": 0.004853683627314038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.854534149169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05779550224542618,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03611201047897339,
      "backward_entropy": 0.004858580728371938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.497814178466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0578327514231205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.036071792244911194,
      "backward_entropy": 0.004865635186433792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.858495712280273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786889046430588,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03603371977806091,
      "backward_entropy": 0.004872514141930474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.78915786743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05790930241346359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035987871885299685,
      "backward_entropy": 0.004881958994600508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.99436616897583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0579490102827549,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03594360649585724,
      "backward_entropy": 0.004889266358481513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.261567115783691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05798625946044922,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03590412139892578,
      "backward_entropy": 0.004893172118398879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.556558609008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05802244693040848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03586653769016266,
      "backward_entropy": 0.004898260864946578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.733671188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05805840715765953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035829514265060425,
      "backward_entropy": 0.004902799510293537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.123861312866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058097586035728455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03578681945800781,
      "backward_entropy": 0.004907260338465373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.847227096557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058135323226451874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03574689924716949,
      "backward_entropy": 0.0049103813038931955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.712152481079102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05817461386322975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03570409417152405,
      "backward_entropy": 0.004916933261685901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.676109313964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05821187421679497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03566480278968811,
      "backward_entropy": 0.00492590789993604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.837574005126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058250367641448975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035623586177825926,
      "backward_entropy": 0.004932403564453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.016498565673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05828787386417389,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035583889484405516,
      "backward_entropy": 0.00494297304087215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701176166534424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05832511559128761,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035544675588607785,
      "backward_entropy": 0.004954136494133208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.488685607910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058359645307064056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035510963201522826,
      "backward_entropy": 0.0049544283085399205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.81927490234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058396004140377045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035474690794944766,
      "backward_entropy": 0.004946247157123353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3512773513793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05843210965394974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03543893694877624,
      "backward_entropy": 0.00493963145547443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.656607627868652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058465491980314255,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03540797829627991,
      "backward_entropy": 0.004935004231002595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.70810604095459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058499082922935486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035376366972923276,
      "backward_entropy": 0.0049342769715521075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.400903701782227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05853356793522835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035342955589294435,
      "backward_entropy": 0.004935453749365277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.616722106933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05856620520353317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0353129506111145,
      "backward_entropy": 0.004936669435766008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338886260986328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05860060825943947,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0352800726890564,
      "backward_entropy": 0.07688356770409478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.354511260986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05863429978489876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035248151421546935,
      "backward_entropy": 0.004945697883764903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.3156099319458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05866796523332596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03521624207496643,
      "backward_entropy": 0.0049521227677663164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.245323181152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05870142951607704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035184866189956664,
      "backward_entropy": 0.004955822394953834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.11838722229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05873889476060867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03514687418937683,
      "backward_entropy": 0.0049585530327426065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.858549118041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05877828970551491,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03510580062866211,
      "backward_entropy": 0.0049601660834418405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.994521141052246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05882139503955841,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035058459639549254,
      "backward_entropy": 0.004965764780839284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1695051193237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05886348709464073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.035013020038604736,
      "backward_entropy": 0.004971042275428772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.750428199768066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05890205502510071,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03497384786605835,
      "backward_entropy": 0.004973741041289436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.766436576843262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058940816670656204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03493448793888092,
      "backward_entropy": 0.0049758416910966234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.63503360748291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05897896736860275,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03489627242088318,
      "backward_entropy": 0.0029505716843737494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.924757480621338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05901690199971199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03485899567604065,
      "backward_entropy": 0.004972980254226261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.741083145141602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05905265733599663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03482536971569061,
      "backward_entropy": 0.004968593104018105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.305502891540527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05908713862299919,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03479403853416443,
      "backward_entropy": 0.004963070568111207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626615524291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059122178703546524,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03476178050041199,
      "backward_entropy": 0.0049581825733184814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.564238548278809,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05915609747171402,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03473142683506012,
      "backward_entropy": 0.0768855611483256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.603818893432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0591890923678875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03470265865325928,
      "backward_entropy": 0.004951452215512593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.949605941772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05922430381178856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03467044234275818,
      "backward_entropy": 0.004948881765206655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.139303207397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05926015228033066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03463701605796814,
      "backward_entropy": 0.00494953989982605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389959335327148,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059295717626810074,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.034604054689407346,
      "backward_entropy": 0.0768839783138699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.107255935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05933000147342682,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034573417901992795,
      "backward_entropy": 0.00495438567466206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.315483093261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05936649441719055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034539157152175905,
      "backward_entropy": 0.0049575625194443595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.542202949523926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05940143018960953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03450786173343658,
      "backward_entropy": 0.00495609516898791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.820687294006348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059434548020362854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03447941839694977,
      "backward_entropy": 0.004956327378749847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.719012260437012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059467531740665436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034451228380203244,
      "backward_entropy": 0.004957286434041129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.930713653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059500645846128464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03442258834838867,
      "backward_entropy": 0.004962630156013701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.401866912841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0595351904630661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034391725063323976,
      "backward_entropy": 0.0049680136144161224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.219827651977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0595720149576664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03435713052749634,
      "backward_entropy": 0.004976673258675469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.293382167816162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05960860475897789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034323477745056154,
      "backward_entropy": 0.0049776410063107806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.945449829101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05964352935552597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03429216146469116,
      "backward_entropy": 0.004984859791066911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.254273414611816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05967907980084419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0342597246170044,
      "backward_entropy": 0.0049948493639628095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.27348518371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05971287935972214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03422994613647461,
      "backward_entropy": 0.005007488032182057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.735692977905273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05974655970931053,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034200310707092285,
      "backward_entropy": 0.005021284437841839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.679941415786743,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059780772775411606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03416993618011475,
      "backward_entropy": 0.005034364346000884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596187114715576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0598125085234642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03414338231086731,
      "backward_entropy": 0.005048562669091755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.996020317077637,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05984364449977875,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03411755859851837,
      "backward_entropy": 0.0769118865331014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.117003440856934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987615883350372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.034089839458465575,
      "backward_entropy": 0.0050786348680655164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.823965072631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059906888753175735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03406500816345215,
      "backward_entropy": 0.00508950153986613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.705459594726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059939004480838776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03403822481632233,
      "backward_entropy": 0.005097215374310811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.828856468200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059972528368234634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03400930166244507,
      "backward_entropy": 0.0025869235396385193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21412691473960876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060005683451890945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03398101925849915,
      "backward_entropy": 0.005110679401291741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.396333694458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06003550812602043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03395788669586182,
      "backward_entropy": 0.005115735861990187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.61387825012207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06006423756480217,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03393687009811401,
      "backward_entropy": 0.0051145946813954245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.901432514190674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060093313455581665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03391512632369995,
      "backward_entropy": 0.005116655594772763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.230366230010986,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06012099236249924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033895489573478696,
      "backward_entropy": 0.005118505822287666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78962516784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06014804169535637,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033876991271972655,
      "backward_entropy": 0.0051183390120665235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.74233627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06017424538731575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0338591992855072,
      "backward_entropy": 0.005123712536361482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.80010986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060201652348041534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03383955359458923,
      "backward_entropy": 0.005130102237065633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.76076078414917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06022781506180763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03382181525230408,
      "backward_entropy": 0.0051358818180031246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.752409934997559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06025294214487076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0338054895401001,
      "backward_entropy": 0.0051423969368139906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.224498748779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06027704104781151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0337907612323761,
      "backward_entropy": 0.005148161202669144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.22937774658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060301896184682846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0337746798992157,
      "backward_entropy": 0.0051561105582449175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.404123306274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06033017486333847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033753544092178345,
      "backward_entropy": 0.005162594219048818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.803821563720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06035931408405304,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03373115360736847,
      "backward_entropy": 0.005167864263057709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.251757621765137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06039062887430191,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03370571732521057,
      "backward_entropy": 0.0024167230973641076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.353073120117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060422565788030624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033679401874542235,
      "backward_entropy": 0.005175277590751648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.512371063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06045592948794365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033650833368301394,
      "backward_entropy": 0.005181795607010524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678088188171387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060490913689136505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03362022638320923,
      "backward_entropy": 0.005184739414188597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3167026042938232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06052472069859505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033591315150260925,
      "backward_entropy": 0.005189103384812673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.87766170501709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06055606156587601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0335658997297287,
      "backward_entropy": 0.005195735643307368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.065201759338379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06058795750141144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03353972434997558,
      "backward_entropy": 0.005202224685086144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.565070629119873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060621730983257294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033510985970497134,
      "backward_entropy": 0.00520742932955424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542021751403809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060654059052467346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033484697341918945,
      "backward_entropy": 0.0052081139551268685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.87305450439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06068620830774307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033458560705184937,
      "backward_entropy": 0.005211094601286782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485817909240723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06072067469358444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03342945575714111,
      "backward_entropy": 0.005209724108378093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.306929111480713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06075437739491463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033401668071746826,
      "backward_entropy": 0.005205582827329636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.397757530212402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06078705936670303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03337527513504028,
      "backward_entropy": 0.0052049727075629765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.281414985656738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060820769518613815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03334755301475525,
      "backward_entropy": 0.005204923864867952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.251648902893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06085309013724327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033321982622146605,
      "backward_entropy": 0.005203213956620958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.151613235473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06088627502322197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03329550623893738,
      "backward_entropy": 0.005199516812960307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.023611068725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060921575874090195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03326640725135803,
      "backward_entropy": 0.0051929396059778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.00283145904541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06095876917243004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033234992623329164,
      "backward_entropy": 0.0051832546790440874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.684093475341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060995638370513916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03320423364639282,
      "backward_entropy": 0.005173060629102919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.799520492553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06103496253490448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03317049741744995,
      "backward_entropy": 0.0051622990932729505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.971273422241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0610739141702652,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033137330412864686,
      "backward_entropy": 0.005154341459274292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.767474174499512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06111074984073639,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03310753703117371,
      "backward_entropy": 0.005143069558673435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9651284217834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061146605759859085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03307926058769226,
      "backward_entropy": 0.005132484767172072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.226709365844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06118017062544823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033054298162460326,
      "backward_entropy": 0.005122088723712497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1026480197906494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06121503561735153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033027750253677365,
      "backward_entropy": 0.005110839174853431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595674514770508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06124678999185562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.033005821704864505,
      "backward_entropy": 0.005096064673529731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.888729095458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061277613043785095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03298567533493042,
      "backward_entropy": 0.0050758591128720176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40623664855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061310164630413055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032963162660598753,
      "backward_entropy": 0.005059820082452562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.685657501220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061342161148786545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032941374182701114,
      "backward_entropy": 0.005046256300475862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.796072483062744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06137575954198837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03291746973991394,
      "backward_entropy": 0.005035689307583703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.231969833374023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06140705943107605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032896900177001955,
      "backward_entropy": 0.005021816326512231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.654725074768066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06143792346119881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032876884937286376,
      "backward_entropy": 0.005009861042102178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6188504695892334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061469756066799164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032855620980262755,
      "backward_entropy": 0.0050007109012868665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.797916412353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06150010600686073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032836058735847475,
      "backward_entropy": 0.004998065117332671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2959370613098145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06153064966201782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032816410064697266,
      "backward_entropy": 0.004994058360656102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.319370746612549,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061560288071632385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032797878980636595,
      "backward_entropy": 0.004993152701192432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.27226734161377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06158865615725517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03278129994869232,
      "backward_entropy": 0.00498777793513404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.217328071594238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06161811202764511,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032763391733169556,
      "backward_entropy": 0.004982811295323902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.396053314208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06164649501442909,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03274697959423065,
      "backward_entropy": 0.004976999842458301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.127220630645752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06167745217680931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03272712826728821,
      "backward_entropy": 0.004975323047902849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.018641948699951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0617072768509388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0327088475227356,
      "backward_entropy": 0.004974260926246643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4105331897735596,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06173660606145859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032690885663032535,
      "backward_entropy": 0.004982972310649024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3981130123138428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06176450848579407,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03267471194267273,
      "backward_entropy": 0.004994827426142163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15945053100586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.061791032552719116,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03266023099422455,
      "backward_entropy": 0.07684653997421265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.067343711853027,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.061818137764930725,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03264508247375488,
      "backward_entropy": 0.0768495003382365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.448849201202393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061846014112234116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03262878656387329,
      "backward_entropy": 0.005034794410069783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.049712181091309,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06187387555837631,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.032612425088882444,
      "backward_entropy": 0.07685882515377468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.43913459777832,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06190378591418266,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03259325623512268,
      "backward_entropy": 0.07686563332875569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2160184383392334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061934735625982285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03257271945476532,
      "backward_entropy": 0.005098306056525972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.755364418029785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061964187771081924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032553908228874204,
      "backward_entropy": 0.0051253024074766375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.248228073120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06199260801076889,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03253645896911621,
      "backward_entropy": 0.0017967356575859918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6810150146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062020596116781235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03251971006393432,
      "backward_entropy": 0.0051700712905989755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.655012130737305,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.062046464532613754,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.032505595684051515,
      "backward_entropy": 0.07689730988608466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.093061447143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06207161024212837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03249238431453705,
      "backward_entropy": 0.005205858084890578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.524901866912842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06209677457809448,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.03247910439968109,
      "backward_entropy": 0.0017771441489458084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.098550319671631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06212253496050835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032465067505836484,
      "backward_entropy": 0.00523538308011161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5308966636657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062146954238414764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03245265483856201,
      "backward_entropy": 0.0052476392851935495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.50120735168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06217074766755104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032441020011901855,
      "backward_entropy": 0.005257980277140935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.313348293304443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06219397112727165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032430022954940796,
      "backward_entropy": 0.005266431305143569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.469509601593018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06221802532672882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03241788744926453,
      "backward_entropy": 0.0052752138839827645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5407260656356812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06224129721522331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03240686655044556,
      "backward_entropy": 0.005279377930694156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158877372741699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062263116240501404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032397341728210446,
      "backward_entropy": 0.0052878571053345995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.099275588989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06228596344590187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.032386428117752074,
      "backward_entropy": 0.0017107375380065707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.480599403381348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062309809029102325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032374000549316405,
      "backward_entropy": 0.0053119949168629116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.87789249420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06233486905694008,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03236011564731598,
      "backward_entropy": 0.005323074758052826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9394450187683105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06235885247588158,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03234729766845703,
      "backward_entropy": 0.005336662133534749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598648548126221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06238376349210739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032333099842071535,
      "backward_entropy": 0.005353887048032548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.56869125366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06240849569439888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03231920599937439,
      "backward_entropy": 0.00536688831117418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8796803951263428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06243503466248512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03230310082435608,
      "backward_entropy": 0.005379089050822788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.529154896736145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062459804117679596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03228941857814789,
      "backward_entropy": 0.005383607827954822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7339935302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062482401728630066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03227854371070862,
      "backward_entropy": 0.005382007194889916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.415537357330322,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06250575184822083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03226670026779175,
      "backward_entropy": 0.005380652844905853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.639484882354736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06252896040678024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0322551429271698,
      "backward_entropy": 0.005375485453340743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.910147190093994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06255284696817398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03224263787269592,
      "backward_entropy": 0.005371260560221142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.579073905944824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0625777468085289,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03222903311252594,
      "backward_entropy": 0.00536464403072993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.254239082336426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06260290741920471,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03221533894538879,
      "backward_entropy": 0.0053548092643419904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.175650119781494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06262774020433426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03220217525959015,
      "backward_entropy": 0.005342942972977956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3893533945083618,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06265252083539963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03218894600868225,
      "backward_entropy": 0.005334191852145725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.098238468170166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06267549842596054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03217772841453552,
      "backward_entropy": 0.005328349355194304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15832632780075073,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0626986101269722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03216617703437805,
      "backward_entropy": 0.005325690739684635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695049285888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06271936744451523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03215742707252502,
      "backward_entropy": 0.0053236666652891375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.762066602706909,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062742218375206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032146185636520386,
      "backward_entropy": 0.005324181169271469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.976454734802246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0627647265791893,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03213512897491455,
      "backward_entropy": 0.00532872478167216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.284450650215149,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06279031187295914,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03212044239044189,
      "backward_entropy": 0.07689893245697021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.234750747680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06281433254480362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0321072518825531,
      "backward_entropy": 0.005348905093140072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5136497020721436,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06283959746360779,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0320925235748291,
      "backward_entropy": 0.005364228867822223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8262505531311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06286337971687317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0320796549320221,
      "backward_entropy": 0.005375557061698701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15197177231311798,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06288698315620422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032067102193832395,
      "backward_entropy": 0.005383739454878701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.911591053009033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06290816515684128,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032057395577430724,
      "backward_entropy": 0.005389334426985847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2729233503341675,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06292995065450668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032047080993652347,
      "backward_entropy": 0.005391728546884324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.703107833862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06295019388198853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03203847110271454,
      "backward_entropy": 0.005395021289587021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5512735843658447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06297050416469574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03202989101409912,
      "backward_entropy": 0.005395060612095727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.954936504364014,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06299025565385818,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.03202205300331116,
      "backward_entropy": 0.0769032637278239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.572491645812988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06301212310791016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03201168179512024,
      "backward_entropy": 0.00539004761311743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634791851043701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06303412467241287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.032001107931137085,
      "backward_entropy": 0.0053908439973990125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5037946701049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06305684894323349,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.031989604234695435,
      "backward_entropy": 0.005393957098325093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.649082660675049,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06307961046695709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.03197801113128662,
      "backward_entropy": 0.005398345490296681,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.214993708282709,
    "avg_log_Z": -0.061809899471700194,
    "success_rate": 1.0,
    "avg_reward": 80.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.07,
      "1": 0.04,
      "2": 0.89
    },
    "avg_forward_entropy": 0.03270333617925644,
    "avg_backward_entropy": 0.010099648628383872,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}