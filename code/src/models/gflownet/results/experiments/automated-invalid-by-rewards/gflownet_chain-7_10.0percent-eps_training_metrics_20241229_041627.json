{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09878666911806379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09889069625309535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.88009643554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372014880180359,
      "backward_entropy": 0.09877428838184901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.25381469726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720472157001495,
      "backward_entropy": 0.09877703871045794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.21693420410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0001999695086851716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720780611038208,
      "backward_entropy": 0.0987797464643206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.17991638183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002999301068484783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721072673797607,
      "backward_entropy": 0.09880853550774711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.24342346191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00039988680509850383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721346855163574,
      "backward_entropy": 0.09881535598209926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.10604858398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004990734742023051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372160017490387,
      "backward_entropy": 0.0987874014036996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.55430603027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005985421594232321,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372184157371521,
      "backward_entropy": 0.0988279836518424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.99679565429688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006987538654357195,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722066581249237,
      "backward_entropy": 0.09883400372096471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5457763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007998828077688813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372227668762207,
      "backward_entropy": 0.09890527384621757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.61834716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009017508127726614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372247189283371,
      "backward_entropy": 0.09879692963191442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.04006958007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001003728248178959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722650706768036,
      "backward_entropy": 0.09879945857184273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.8229522705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011041327379643917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372280716896057,
      "backward_entropy": 0.09880173206329346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.03636169433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012031105579808354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372292935848236,
      "backward_entropy": 0.09891191550663539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.4165802001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00129875133279711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723020255565643,
      "backward_entropy": 0.09880528279713222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.44374084472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013914620503783226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723087310791016,
      "backward_entropy": 0.09880639825548444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.74168395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014830627478659153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723134994506836,
      "backward_entropy": 0.09880733489990234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.16287231445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015758186345919967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723161816596985,
      "backward_entropy": 0.09880820342472621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.62139892578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016704390291124582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137231707572937,
      "backward_entropy": 0.09891692229679652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.77276611328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017646545311436057,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723158836364746,
      "backward_entropy": 0.09888848236628942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.55271911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001858703326433897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372312605381012,
      "backward_entropy": 0.09881091117858887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.8182373046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019524600356817245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723072409629822,
      "backward_entropy": 0.09889674186706543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.92723083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002047899179160595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722997903823853,
      "backward_entropy": 0.0989202346120562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.66680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002143902238458395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722917437553406,
      "backward_entropy": 0.098812997341156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.8179931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022390959784388542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372280716896057,
      "backward_entropy": 0.09892165660858154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.2172393798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023337663151323795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722671568393707,
      "backward_entropy": 0.09892222711018153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.50189208984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024290781002491713,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722507655620575,
      "backward_entropy": 0.09891584941319057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.49319458007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025228657759726048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372232288122177,
      "backward_entropy": 0.0988138062613351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.8205108642578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026165940798819065,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722124695777893,
      "backward_entropy": 0.0989224910736084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.4230194091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027075118850916624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721902668476105,
      "backward_entropy": 0.09892381940569196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.19822692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027987556532025337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372166872024536,
      "backward_entropy": 0.09881307397569929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.1904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002890122588723898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721433281898499,
      "backward_entropy": 0.09881268228803362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.42030334472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029840099159628153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721191883087158,
      "backward_entropy": 0.0988125034740993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.0630340576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0030695393215864897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720932602882385,
      "backward_entropy": 0.09892435584749494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.47607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031549357809126377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720659911632538,
      "backward_entropy": 0.09892416000366211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.43280029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032435725443065166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720367848873138,
      "backward_entropy": 0.09894233090536934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.99081420898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003333820728585124,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720056414604187,
      "backward_entropy": 0.09894490242004395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.74530029296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003425587434321642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719722628593445,
      "backward_entropy": 0.09892387901033674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.51071166992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0035163327120244503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371937096118927,
      "backward_entropy": 0.0989236491067069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.27182006835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036086656618863344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718993961811066,
      "backward_entropy": 0.0989234106881278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.43319702148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037034587003290653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718587160110474,
      "backward_entropy": 0.09880637271063668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.18701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037993520963937044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718156516551971,
      "backward_entropy": 0.09880587032863072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.99884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038972697220742702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371769905090332,
      "backward_entropy": 0.09880551270076207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.75897216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003991925157606602,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371721625328064,
      "backward_entropy": 0.09896177904946464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.15325927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004083967301994562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716717064380646,
      "backward_entropy": 0.09880375862121582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.79786682128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004172041546553373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371619701385498,
      "backward_entropy": 0.0988022940499442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.66845703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0042642452754080296,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371564269065857,
      "backward_entropy": 0.09896768842424665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7850799560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0043540699407458305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715074956417084,
      "backward_entropy": 0.09892083917345319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.51980590820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0044443653896451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371447592973709,
      "backward_entropy": 0.09879796845572335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.24588012695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004536271560937166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371384859085083,
      "backward_entropy": 0.09897297620773315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1445770263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004622812382876873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713204860687256,
      "backward_entropy": 0.09891854013715472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.67958068847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004707671701908112,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712544739246368,
      "backward_entropy": 0.09897593941007342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.76220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004792130086570978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711854815483093,
      "backward_entropy": 0.09878967489515032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.7628936767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004878860432654619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371113359928131,
      "backward_entropy": 0.09878720555986677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.176025390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004966696258634329,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371038854122162,
      "backward_entropy": 0.09897996698107038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0372772216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005053950939327478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13709621131420135,
      "backward_entropy": 0.09891261373247419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.21670532226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005143615882843733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708825409412384,
      "backward_entropy": 0.09877978052411761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.84213256835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005229391157627106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370800882577896,
      "backward_entropy": 0.09890988894871303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.23634338378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0053200386464595795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707149028778076,
      "backward_entropy": 0.09877404144832067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.99236297607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005410016980022192,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706271350383759,
      "backward_entropy": 0.09898568902696882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.23272705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005494760815054178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705381751060486,
      "backward_entropy": 0.09890530790601458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.27057647705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005582145880907774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704457879066467,
      "backward_entropy": 0.09876435143607003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.2035675048828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005666070617735386,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13703522086143494,
      "backward_entropy": 0.09898808172770909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.50717163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005755285732448101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370253562927246,
      "backward_entropy": 0.0988997050694057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.94100952148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005846545100212097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701513409614563,
      "backward_entropy": 0.09889778069087438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.85238647460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005938057787716389,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137004554271698,
      "backward_entropy": 0.09889578819274902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0618438720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006033773999661207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699349761009216,
      "backward_entropy": 0.0988938467843192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.33082580566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006129453424364328,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698214292526245,
      "backward_entropy": 0.0989912748336792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.67103576660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0062264553271234035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369704157114029,
      "backward_entropy": 0.09873840638569423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.13551330566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006321891210973263,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695845007896423,
      "backward_entropy": 0.0989924498966762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.991943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006414820905774832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694638013839722,
      "backward_entropy": 0.09872983183179583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.86187744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006506516132503748,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13693401217460632,
      "backward_entropy": 0.09888265814099993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.81210327148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0065958756022155285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369214504957199,
      "backward_entropy": 0.09888012068612236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.22897338867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006685934495180845,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13690854609012604,
      "backward_entropy": 0.09899403367723737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.12417602539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006780295632779598,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689497113227844,
      "backward_entropy": 0.09899439982005528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.2305908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006874700076878071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368810534477234,
      "backward_entropy": 0.09870489154543195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.59756469726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0069647585041821,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368669718503952,
      "backward_entropy": 0.09899498735155378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3209686279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007058108225464821,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685233891010284,
      "backward_entropy": 0.09886642864772252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.6759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0071502928622066975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368374228477478,
      "backward_entropy": 0.0988633292061942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.51457977294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007241331040859222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368221640586853,
      "backward_entropy": 0.09868064096995763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.00686645507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00732881436124444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13680687546730042,
      "backward_entropy": 0.09885650873184204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.50198364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007411313708871603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679155707359314,
      "backward_entropy": 0.09885262591498238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.51409912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007492422126233578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677597045898438,
      "backward_entropy": 0.09865867240088326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8440704345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007573580369353294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675998151302338,
      "backward_entropy": 0.09899519171033587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.3926239013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0076592774130403996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674364984035492,
      "backward_entropy": 0.09864287717001778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.70529174804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007743274327367544,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672733306884766,
      "backward_entropy": 0.09899495329175677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.29522705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007830312475562096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367105096578598,
      "backward_entropy": 0.09883146626608712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.25265502929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007921361364424229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366930603981018,
      "backward_entropy": 0.09861938442502703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.10951232910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00800886657088995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667556643486023,
      "backward_entropy": 0.09861128670828682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.67010498046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008097372949123383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665758073329926,
      "backward_entropy": 0.09899462120873588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.60836791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008186894468963146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663914799690247,
      "backward_entropy": 0.09881306546075004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.75628662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008276077918708324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366204023361206,
      "backward_entropy": 0.09880811827523368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.08084869384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008365890011191368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13660110533237457,
      "backward_entropy": 0.09857692037309919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.8262710571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008452294394373894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658177852630615,
      "backward_entropy": 0.09856745174952916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.61724853515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008532692678272724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656271994113922,
      "backward_entropy": 0.09855728490012032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.98924255371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00861339084804058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365431845188141,
      "backward_entropy": 0.09899284158434186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.12965393066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008698621764779091,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652271032333374,
      "backward_entropy": 0.09853586980274745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.28329467773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008785055950284004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650162518024445,
      "backward_entropy": 0.09877363273075648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.60264587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008874056860804558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13647978007793427,
      "backward_entropy": 0.09851365430014473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.76377868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008966468274593353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645698130130768,
      "backward_entropy": 0.0985022953578404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.46112060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009059103205800056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643357157707214,
      "backward_entropy": 0.09875575133732387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.86007690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009145480580627918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13641072809696198,
      "backward_entropy": 0.09847788299833025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.01011657714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009236007928848267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363869607448578,
      "backward_entropy": 0.09874289376395089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.21458435058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009328662417829037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13636241853237152,
      "backward_entropy": 0.09845371757234846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.64300537109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009422190487384796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13633742928504944,
      "backward_entropy": 0.09873005322047643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1140899658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009509994648396969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363125443458557,
      "backward_entropy": 0.09872290066310338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.56879425048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009597343392670155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13628721237182617,
      "backward_entropy": 0.09841514485222953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.418701171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009681533090770245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136261984705925,
      "backward_entropy": 0.09898897579738072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009763628244400024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362365186214447,
      "backward_entropy": 0.09869917801448277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.60784912109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009846125729382038,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362106204032898,
      "backward_entropy": 0.09898735795702253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.545166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009927553124725819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361844837665558,
      "backward_entropy": 0.0986817819731576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.5072479248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010014018043875694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361573040485382,
      "backward_entropy": 0.09867324999400548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010103141888976097,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13612918555736542,
      "backward_entropy": 0.09898511852536883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5678253173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01019313745200634,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13610033690929413,
      "backward_entropy": 0.0989844458443778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.81219482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010282855480909348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360711306333542,
      "backward_entropy": 0.09864704949515206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.24378967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010373513214290142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13604120910167694,
      "backward_entropy": 0.09827148914337158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.94151306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010463602840900421,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13601034879684448,
      "backward_entropy": 0.09825370992933001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.87362670898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010557593777775764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13597795367240906,
      "backward_entropy": 0.09898184026990618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.57794189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010655046440660954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13594423234462738,
      "backward_entropy": 0.09821925844464983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.90753173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010755348950624466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13590915501117706,
      "backward_entropy": 0.09898122719355992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.84515380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01085534319281578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13587331771850586,
      "backward_entropy": 0.09818337644849505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.0098114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01095506176352501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583670556545258,
      "backward_entropy": 0.09858248914991107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.6031494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011054761707782745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13579942286014557,
      "backward_entropy": 0.0981440714427403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.75923919677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011158708482980728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13576072454452515,
      "backward_entropy": 0.09812475953783308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.43145751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011255253106355667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357230395078659,
      "backward_entropy": 0.09810418742043632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.91317749023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011348792351782322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356850415468216,
      "backward_entropy": 0.09808188676834106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.64891052246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011441650800406933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13564659655094147,
      "backward_entropy": 0.09897822993142265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 285.85260009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011529192328453064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13560853898525238,
      "backward_entropy": 0.09850788116455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.79737854003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011627831496298313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13556763529777527,
      "backward_entropy": 0.09849487032209124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.19349670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011720792390406132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355273425579071,
      "backward_entropy": 0.09798896312713623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1618194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01181009691208601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13548721373081207,
      "backward_entropy": 0.0979641250201634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.76312255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011898644268512726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13544635474681854,
      "backward_entropy": 0.097937958581107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.864402770996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011988166719675064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13540449738502502,
      "backward_entropy": 0.09843408209936959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.8515167236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012066247873008251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13536450266838074,
      "backward_entropy": 0.09788101060049874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.92922973632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012149078771471977,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13532252609729767,
      "backward_entropy": 0.0989702684538705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.96002197265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012231809087097645,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13527971506118774,
      "backward_entropy": 0.09896877833775111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.63108825683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012315046042203903,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352362334728241,
      "backward_entropy": 0.09896739891597203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.14492797851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01239536702632904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13519269227981567,
      "backward_entropy": 0.09834132875714983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.93589782714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012477310374379158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351478099822998,
      "backward_entropy": 0.09772189174379621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.86827087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012561066076159477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13510169088840485,
      "backward_entropy": 0.09768811294010707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.04515075683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012644904665648937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1350543200969696,
      "backward_entropy": 0.09896130221230644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.22235107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012729061767458916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13500598073005676,
      "backward_entropy": 0.09761965274810791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.69253540039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012818903662264347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13495509326457977,
      "backward_entropy": 0.09823933669498988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.96759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01290664728730917,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13490380346775055,
      "backward_entropy": 0.09895698513303484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.00666809082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012995505705475807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13485124707221985,
      "backward_entropy": 0.09751670701163155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.16651916503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013079063035547733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347990781068802,
      "backward_entropy": 0.09747840676988874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.78970336914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013159699738025665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13474689424037933,
      "backward_entropy": 0.09743848868778773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.38694763183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013240654021501541,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13469362258911133,
      "backward_entropy": 0.09894980703081403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.62525939941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013324779458343983,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13463839888572693,
      "backward_entropy": 0.09894791671207973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.29429626464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013406062498688698,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345832198858261,
      "backward_entropy": 0.0980743680681501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.26812744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013495245017111301,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13452491164207458,
      "backward_entropy": 0.0980499301637922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.18190002441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013583632186055183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13446563482284546,
      "backward_entropy": 0.09894243308476039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.32876586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013672254979610443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13440582156181335,
      "backward_entropy": 0.09799887452806745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.16647338867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013758215121924877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13434529304504395,
      "backward_entropy": 0.09713927337101527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.6870574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013852898962795734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13428112864494324,
      "backward_entropy": 0.09709668159484863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.1437530517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013944768346846104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13421669602394104,
      "backward_entropy": 0.09705122028078352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.98118591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01403579581528902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13415133953094482,
      "backward_entropy": 0.09700378349849156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.58712005615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014128806069493294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340835988521576,
      "backward_entropy": 0.09695519719805036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.90969848632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014217591844499111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134015753865242,
      "backward_entropy": 0.09690495899745397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.57244873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014305861666798592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13394685089588165,
      "backward_entropy": 0.09685329028538295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.61663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01439464557915926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13387612998485565,
      "backward_entropy": 0.09679900748389107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.04156494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014484480954706669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13380390405654907,
      "backward_entropy": 0.09674435002463204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.66220092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014573588967323303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1337307244539261,
      "backward_entropy": 0.09770386559622628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.65863037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014665148220956326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13365545868873596,
      "backward_entropy": 0.09766953332083565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.4635009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01475435495376587,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13357993960380554,
      "backward_entropy": 0.09892380237579346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014846011064946651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335022896528244,
      "backward_entropy": 0.09651221547807966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.74246215820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014936528168618679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13342364132404327,
      "backward_entropy": 0.09755939245223999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.08648681640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01502890046685934,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1333427131175995,
      "backward_entropy": 0.09891854013715472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.09165954589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015118607319891453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332615166902542,
      "backward_entropy": 0.09631740195410592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.5328598022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015204686671495438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13318081200122833,
      "backward_entropy": 0.09743677718298775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.21922302246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015283886343240738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13310196995735168,
      "backward_entropy": 0.09738994496209281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.65545654296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015366500243544579,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13302050530910492,
      "backward_entropy": 0.09890622752053398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.62554931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015448682010173798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13293761014938354,
      "backward_entropy": 0.09729507991245814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.64022827148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015531438402831554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13285379111766815,
      "backward_entropy": 0.09593331813812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.9181365966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015614361502230167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13276883959770203,
      "backward_entropy": 0.09585264750889369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.19378662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01569732092320919,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13268236815929413,
      "backward_entropy": 0.09889204161507743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.40998840332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01578020304441452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13259391486644745,
      "backward_entropy": 0.0956852946962629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2816619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015858670696616173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13250641524791718,
      "backward_entropy": 0.09703588485717773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.91928100585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015937775373458862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13241735100746155,
      "backward_entropy": 0.09697859627859932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.01593017578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016017219051718712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13232658803462982,
      "backward_entropy": 0.09541348048618861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.50912475585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016095733270049095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13223516941070557,
      "backward_entropy": 0.0953193051474435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016170162707567215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13214461505413055,
      "backward_entropy": 0.09679410287312099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.59459686279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016242066398262978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1320536583662033,
      "backward_entropy": 0.09672669001988002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.40687561035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016309263184666634,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13196447491645813,
      "backward_entropy": 0.0988497223172869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.28253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016385015100240707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13187019526958466,
      "backward_entropy": 0.09490367344447545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.46847534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016461851075291634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317741870880127,
      "backward_entropy": 0.0948013152394976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.42918395996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016539908945560455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13167662918567657,
      "backward_entropy": 0.09645525898252215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.65162658691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016617219895124435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1315782517194748,
      "backward_entropy": 0.09459337166377477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.96820068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016697082668542862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314772665500641,
      "backward_entropy": 0.09448846748897008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.88197326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016775786876678467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13137538731098175,
      "backward_entropy": 0.09437918663024902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.16082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01685194857418537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312735229730606,
      "backward_entropy": 0.09616985491343907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.2191619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016934441402554512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13116760551929474,
      "backward_entropy": 0.0960987891469683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.29299926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01701897196471691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13105913996696472,
      "backward_entropy": 0.09405159098761422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.87217712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01710989698767662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13094571232795715,
      "backward_entropy": 0.09395079953329903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.09586334228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01719955913722515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13083063066005707,
      "backward_entropy": 0.0938406331198556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.36445617675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01728571020066738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13071641325950623,
      "backward_entropy": 0.0958103963306972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4319610595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01736743375658989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1306040734052658,
      "backward_entropy": 0.09360044343130929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.25161743164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017448438331484795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1304914355278015,
      "backward_entropy": 0.09347653388977051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.65798950195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017530295997858047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13037724792957306,
      "backward_entropy": 0.0987837484904698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.81156921386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017615634948015213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1302592009305954,
      "backward_entropy": 0.0987796698297773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.56216430664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01769603043794632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13014259934425354,
      "backward_entropy": 0.09309408494404384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.42308044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017773866653442383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13002631068229675,
      "backward_entropy": 0.09529087373188563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.4115447998047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017849773168563843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12991051375865936,
      "backward_entropy": 0.09876057079860143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.4299545288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01792684756219387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12979131937026978,
      "backward_entropy": 0.09266588517597743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.20223236083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017996851354837418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296747922897339,
      "backward_entropy": 0.09250947407313756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.1405258178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018065359443426132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12955708801746368,
      "backward_entropy": 0.09234821796417236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.1066131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018129197880625725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12944072484970093,
      "backward_entropy": 0.0947671788079398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.70697021484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01819722354412079,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1293199211359024,
      "backward_entropy": 0.09871578216552734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.90448760986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018265871331095695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1291978359222412,
      "backward_entropy": 0.09184250661305018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.98150634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018332455307245255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290743201971054,
      "backward_entropy": 0.094419036592756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.61553955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01840110868215561,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12894771993160248,
      "backward_entropy": 0.09429713657924108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.316162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01847350411117077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12881718575954437,
      "backward_entropy": 0.0986772094454084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.86317443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01854575239121914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12868517637252808,
      "backward_entropy": 0.09113022259303502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.02674865722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01861800253391266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12855184078216553,
      "backward_entropy": 0.09094652959278651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.63902282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01868836209177971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12841808795928955,
      "backward_entropy": 0.09379441397530693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.81890106201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01875893399119377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128282368183136,
      "backward_entropy": 0.09365999698638916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.98721313476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018827801570296288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12814603745937347,
      "backward_entropy": 0.09036777700696673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.65992736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01889396272599697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12801094353199005,
      "backward_entropy": 0.09016514675957817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.49225616455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018962448462843895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12787246704101562,
      "backward_entropy": 0.0932410614831107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.05844116210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019029835239052773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12773330509662628,
      "backward_entropy": 0.08975638662065778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.95755004882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019095996394753456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1275947093963623,
      "backward_entropy": 0.09295567444392613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.81497192382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019157810136675835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.127458393573761,
      "backward_entropy": 0.08931904179709298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.37881469726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01922256499528885,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12731851637363434,
      "backward_entropy": 0.09855437278747559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.81024169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019287938252091408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12717628479003906,
      "backward_entropy": 0.09249731472560338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.4610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019358603283762932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270274966955185,
      "backward_entropy": 0.08865044798169817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.73548889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01942918635904789,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12687687575817108,
      "backward_entropy": 0.09218905653272357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.91046142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01949852518737316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.126726433634758,
      "backward_entropy": 0.0920280132974897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.2423095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019574642181396484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12656866014003754,
      "backward_entropy": 0.09187365429741996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.95628356933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019653931260108948,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12640716135501862,
      "backward_entropy": 0.09849396773747035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.4606475830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01973302662372589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12624546885490417,
      "backward_entropy": 0.08752477169036865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.70159912109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019811345264315605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12608280777931213,
      "backward_entropy": 0.09848028421401978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.33939361572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019883930683135986,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1259237825870514,
      "backward_entropy": 0.09122991561889648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.25404357910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01995498314499855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12576505541801453,
      "backward_entropy": 0.09104911770139422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.76913452148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0200281273573637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1256035715341568,
      "backward_entropy": 0.08656760624476842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.9109344482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0200998242944479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12544246017932892,
      "backward_entropy": 0.08631681544440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.09051513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020176615566015244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12527522444725037,
      "backward_entropy": 0.09050462927137103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.15895080566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020254449918866158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1251051425933838,
      "backward_entropy": 0.08582404681614467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.0330810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020331813022494316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1249341145157814,
      "backward_entropy": 0.08556925398962838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.96685791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02040395699441433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12476670742034912,
      "backward_entropy": 0.0852997899055481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.70182800292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020477887243032455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12459613382816315,
      "backward_entropy": 0.0850294828414917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.24937438964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020543904975056648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12443532794713974,
      "backward_entropy": 0.08952005420412336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.3655242919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020603502169251442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12428081035614014,
      "backward_entropy": 0.08443309579576765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.62896728515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02067127265036106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12411761283874512,
      "backward_entropy": 0.09833901269095284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.5091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020736875012516975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12395654618740082,
      "backward_entropy": 0.08884366921016149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.03372192382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020804842934012413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12379153072834015,
      "backward_entropy": 0.09830849511282784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.19081115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020870395004749298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12362845242023468,
      "backward_entropy": 0.08838129043579102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.41871643066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020938342437148094,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12346141785383224,
      "backward_entropy": 0.09827685356140137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.57484436035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021005339920520782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12329433858394623,
      "backward_entropy": 0.08260496173586164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.14932250976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021073058247566223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12312527000904083,
      "backward_entropy": 0.08228281566074916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.08493041992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021139873191714287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1229562908411026,
      "backward_entropy": 0.08740064076014928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.9834747314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021206259727478027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12278763949871063,
      "backward_entropy": 0.08714096886771065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.65875244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021274777129292488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12261473387479782,
      "backward_entropy": 0.08128607273101807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.64652252197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021344034001231194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12244032323360443,
      "backward_entropy": 0.08094660724912371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.7838134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021407660096883774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12227238714694977,
      "backward_entropy": 0.0805933049746922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.61449432373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021468646824359894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1221044510602951,
      "backward_entropy": 0.08022357736315046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0034637451172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021528515964746475,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12193550169467926,
      "backward_entropy": 0.09811334099088397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.34292602539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02159210480749607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1217614933848381,
      "backward_entropy": 0.079507691519601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.9857406616211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021658433601260185,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12158232927322388,
      "backward_entropy": 0.09807767186846052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.50148010253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021724475547671318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12140284478664398,
      "backward_entropy": 0.08489319256373815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8946533203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02179482951760292,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12121705710887909,
      "backward_entropy": 0.08460962772369385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.21317291259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021868817508220673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1210254430770874,
      "backward_entropy": 0.08432831083025251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.39886474609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021943096071481705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12083232402801514,
      "backward_entropy": 0.07776469843728202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.59019470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022019078955054283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12063558399677277,
      "backward_entropy": 0.07741308212280273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.6924591064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022099556401371956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12043201923370361,
      "backward_entropy": 0.08347581965582711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.33032989501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02219073846936226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021635472774506,
      "backward_entropy": 0.08322074583598546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.36510467529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02227701060473919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1200060173869133,
      "backward_entropy": 0.07638944898332868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.08197784423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022355224937200546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11980420351028442,
      "backward_entropy": 0.07600611448287964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.8624267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022433314472436905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11960242688655853,
      "backward_entropy": 0.07562300137111119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.98605346679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022507822141051292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11940442025661469,
      "backward_entropy": 0.07521761315209526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.92660522460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022585920989513397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11920218914747238,
      "backward_entropy": 0.0748213359287807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.10845184326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022658759728074074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11900587379932404,
      "backward_entropy": 0.07440563610621861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.71954345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0227286908775568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11881296336650848,
      "backward_entropy": 0.08102609430040632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.08680725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022801056504249573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11861757189035416,
      "backward_entropy": 0.07355449029377528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.35037231445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02287239395081997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11842180788516998,
      "backward_entropy": 0.07313220841544014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.67279815673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02294306457042694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11822833865880966,
      "backward_entropy": 0.07999719040734428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.7978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023009516298770905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11804023385047913,
      "backward_entropy": 0.07227669443402972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.67247009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023079868406057358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178460568189621,
      "backward_entropy": 0.07184205736432757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.25111389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0231526717543602,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11764929443597794,
      "backward_entropy": 0.07892279965536934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.10362243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023225899785757065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11745184659957886,
      "backward_entropy": 0.07856391157422747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.2583999633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02329324558377266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11726294457912445,
      "backward_entropy": 0.07052925654820033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.949337005615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02335517853498459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11708056926727295,
      "backward_entropy": 0.07006278208323888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.15589904785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023406578227877617,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11691074818372726,
      "backward_entropy": 0.0773641722542899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.3739242553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023452196270227432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1167476549744606,
      "backward_entropy": 0.06904136283057076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.09941101074219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023499585688114166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11658249795436859,
      "backward_entropy": 0.09758710861206055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.52228546142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023546766489744186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1164173036813736,
      "backward_entropy": 0.06800893800599235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.06629943847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02359584905207157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11625117063522339,
      "backward_entropy": 0.06750091910362244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.79424285888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023650040850043297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11607890576124191,
      "backward_entropy": 0.07519286870956421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.27528381347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023707035928964615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11590424180030823,
      "backward_entropy": 0.07477704116276332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.41963958740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023757921531796455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11573721468448639,
      "backward_entropy": 0.06604690211159843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.35592651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023809675127267838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11556785553693771,
      "backward_entropy": 0.06554158670561654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.38677978515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023869438096880913,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11538960039615631,
      "backward_entropy": 0.09734749794006348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.84457397460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023935791105031967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11520278453826904,
      "backward_entropy": 0.07307117325919014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.41615295410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024001985788345337,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11501674354076385,
      "backward_entropy": 0.07266126360212054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.13787841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024067694321274757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11483114957809448,
      "backward_entropy": 0.07224367346082415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.14171600341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02413657307624817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11464250087738037,
      "backward_entropy": 0.063197204044887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.99497985839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024202067404985428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11446060985326767,
      "backward_entropy": 0.07140122992651803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.03517150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024264531210064888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11428318917751312,
      "backward_entropy": 0.07096206290381295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4582061767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024328507483005524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1141028180718422,
      "backward_entropy": 0.07052344083786011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.95167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0243957731872797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11391928791999817,
      "backward_entropy": 0.061277764184134345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.54920959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02446565218269825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1137319803237915,
      "backward_entropy": 0.06966079132897514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.34640502929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02453502267599106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11354604363441467,
      "backward_entropy": 0.06922352313995361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.33351135253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0246039517223835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11336135864257812,
      "backward_entropy": 0.059828025954110284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.26318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024670695886015892,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11317958682775497,
      "backward_entropy": 0.06832845721926008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.71095657348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024742182344198227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11299312859773636,
      "backward_entropy": 0.06788673996925354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.56895446777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024807991459965706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11281415820121765,
      "backward_entropy": 0.09705691678183419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.9632568359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02486870251595974,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11264188587665558,
      "backward_entropy": 0.09702559879847936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.41835021972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024925079196691513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11247606575489044,
      "backward_entropy": 0.05727240443229675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.86550903320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024980606511235237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11231003701686859,
      "backward_entropy": 0.06594681314059667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.33384704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02503610961139202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11214697360992432,
      "backward_entropy": 0.0654527587550027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.33059692382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025090157985687256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11198872327804565,
      "backward_entropy": 0.06495799337114606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.01181030273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02514558471739292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11182919889688492,
      "backward_entropy": 0.055165656975337436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.4267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02520395629107952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11166702955961227,
      "backward_entropy": 0.054658902542931695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.95901489257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02526678331196308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11150096356868744,
      "backward_entropy": 0.06350652660642352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.84791564941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02533004805445671,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11133477836847305,
      "backward_entropy": 0.06303330830165318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.69376373291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02538730576634407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11117691546678543,
      "backward_entropy": 0.06253826192447118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.67776489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025447629392147064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1110171526670456,
      "backward_entropy": 0.052670913083212714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.88906478881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02551215887069702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11085332930088043,
      "backward_entropy": 0.052189422505242486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.93498229980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02557196281850338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11069506406784058,
      "backward_entropy": 0.06108812774930682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.35904693603516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025632601231336594,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11053669452667236,
      "backward_entropy": 0.09663428579057966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.24559020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025693656876683235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11037707328796387,
      "backward_entropy": 0.050682476588657925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.5186538696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02575051411986351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11022340506315231,
      "backward_entropy": 0.059593877622059414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.6023406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02580844610929489,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11006884276866913,
      "backward_entropy": 0.049633681774139404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.26293182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025870710611343384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1099102795124054,
      "backward_entropy": 0.05858886241912842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.06302642822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025931987911462784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10975347459316254,
      "backward_entropy": 0.04860905238560268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.09554290771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0259929858148098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10959996283054352,
      "backward_entropy": 0.057594478130340576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.16952896118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026051601395010948,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10945010185241699,
      "backward_entropy": 0.05709038461957659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.04064178466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026106517761945724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1093057245016098,
      "backward_entropy": 0.05657272679465158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.54502868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026162954047322273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.109159454703331,
      "backward_entropy": 0.04655394809586661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.8512954711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026222337037324905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10901077091693878,
      "backward_entropy": 0.04604816436767578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.7362060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02627994492650032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10886576771736145,
      "backward_entropy": 0.045544837202344625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.63528823852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026337310671806335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10872180759906769,
      "backward_entropy": 0.04504387719290597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.67673873901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026391107589006424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.108583003282547,
      "backward_entropy": 0.044531247445515225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.16172790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026441598311066628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10844780504703522,
      "backward_entropy": 0.044007326875414164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.80460357666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026497190818190575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10830622911453247,
      "backward_entropy": 0.052999726363590786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.678253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0265529565513134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1081668883562088,
      "backward_entropy": 0.05249415550913129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.4415283203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02660372294485569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10803373903036118,
      "backward_entropy": 0.0519666246005467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.93878936767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026651356369256973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10790359228849411,
      "backward_entropy": 0.041946900742394586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.3214569091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026701485738158226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10777075588703156,
      "backward_entropy": 0.04142286947795323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.21965789794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026759102940559387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10763290524482727,
      "backward_entropy": 0.050398094313485284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.21839904785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026816587895154953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10749588906764984,
      "backward_entropy": 0.04045170545578003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.74021911621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026877539232373238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10735741257667542,
      "backward_entropy": 0.049419590405055454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.2280044555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026939285919070244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10721839964389801,
      "backward_entropy": 0.039514818361827304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.61233520507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026999004185199738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10708250105381012,
      "backward_entropy": 0.03904263036591666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.22109985351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027060145512223244,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10694608092308044,
      "backward_entropy": 0.09582774979727608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.85320281982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027122704312205315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10681036114692688,
      "backward_entropy": 0.047501598085675924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.67271423339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02718311734497547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10667702555656433,
      "backward_entropy": 0.03765187093189785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.01393127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027241626754403114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10654634237289429,
      "backward_entropy": 0.03718194791248867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.54579162597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027301551774144173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10641548782587051,
      "backward_entropy": 0.03671722752707345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.3376693725586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027361229062080383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1062854677438736,
      "backward_entropy": 0.09569851841245379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.79592895507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027420710772275925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10615652799606323,
      "backward_entropy": 0.03579147372926984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.02826690673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027478603646159172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10602988302707672,
      "backward_entropy": 0.035331866570881436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.99761199951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027537208050489426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1059054583311081,
      "backward_entropy": 0.03488870603697641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.39298248291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027594704180955887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10578414797782898,
      "backward_entropy": 0.03445135056972504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.63850021362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0276572797447443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10565896332263947,
      "backward_entropy": 0.04324146679469517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.11532592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027715181931853294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10554059594869614,
      "backward_entropy": 0.0427876923765455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.17205810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027777941897511482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10541846603155136,
      "backward_entropy": 0.033217274716922214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53427124023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02784864977002144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10529147833585739,
      "backward_entropy": 0.03285423346928188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.62030792236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02791682444512844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10516804456710815,
      "backward_entropy": 0.041568364415849955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.83845520019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027982519939541817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10504724085330963,
      "backward_entropy": 0.0411567006792341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.19819259643555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028050929307937622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1049250066280365,
      "backward_entropy": 0.04075660875865391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.81700134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02811545506119728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10480737686157227,
      "backward_entropy": 0.031328601496560235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.77867126464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02817440778017044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10469432175159454,
      "backward_entropy": 0.03091792336532048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.82015991210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028237033635377884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10457932949066162,
      "backward_entropy": 0.030527598091534207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.66004180908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028301354497671127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10446515679359436,
      "backward_entropy": 0.03908812999725342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.8088607788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028365807607769966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10435362160205841,
      "backward_entropy": 0.038690337112971714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.10330200195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02842876687645912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10424433648586273,
      "backward_entropy": 0.02941355747835977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.4649658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02849128283560276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10413506627082825,
      "backward_entropy": 0.03789354647908892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.51367950439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028557218611240387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10402514040470123,
      "backward_entropy": 0.028686527694974626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.97314453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02862473390996456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10391610115766525,
      "backward_entropy": 0.02834606170654297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.89746856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028693048283457756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10380621254444122,
      "backward_entropy": 0.036764723914010186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.24053955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028759604319930077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10369972884654999,
      "backward_entropy": 0.03638967020171029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.1922836303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028831608593463898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10358874499797821,
      "backward_entropy": 0.036029734781810215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.691795349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028900889679789543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10348007082939148,
      "backward_entropy": 0.03565762085574014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.08164978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02896697074174881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10337604582309723,
      "backward_entropy": 0.02662767469882965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.54547882080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029029661789536476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10327503085136414,
      "backward_entropy": 0.03490596158163888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.55662155151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029092682525515556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10317575931549072,
      "backward_entropy": 0.02594024794442313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.71645736694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02915288880467415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10308055579662323,
      "backward_entropy": 0.025600712214197432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.64288330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029212210327386856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10298702120780945,
      "backward_entropy": 0.02526729873248509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.75200653076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029270660132169724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10289447009563446,
      "backward_entropy": 0.03343441443783896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.456844329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02932531200349331,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280585289001465,
      "backward_entropy": 0.024604265178952898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.1613540649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029377568513154984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10271841287612915,
      "backward_entropy": 0.032686635851860046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.30656433105469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02943597175180912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10262738168239594,
      "backward_entropy": 0.09529983997344971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.22348022460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029490778222680092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10254067927598953,
      "backward_entropy": 0.02362826040812901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.9307861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029546603560447693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10245336592197418,
      "backward_entropy": 0.023312438811574663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.97953796386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02960347756743431,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10236596316099167,
      "backward_entropy": 0.09523773193359375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.53238677978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029658719897270203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10228058695793152,
      "backward_entropy": 0.030958565218108042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.38673400878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029715124517679214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10219520330429077,
      "backward_entropy": 0.022415748664311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.76076889038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029774202033877373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10210929065942764,
      "backward_entropy": 0.0221373907157353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.42406463623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029832912608981133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202442109584808,
      "backward_entropy": 0.021864324808120728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.34339141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029889917001128197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10194247961044312,
      "backward_entropy": 0.029726948056902205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.12776184082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029946913942694664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10186166316270828,
      "backward_entropy": 0.02943459153175354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.24879455566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030005527660250664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10178142040967941,
      "backward_entropy": 0.021091663411685398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.82447052001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03006967157125473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1016976535320282,
      "backward_entropy": 0.020856474127088274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.62342834472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03013751655817032,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10161235928535461,
      "backward_entropy": 0.09522834845951625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.50717163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03020859882235527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10152560472488403,
      "backward_entropy": 0.02840402509484972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.620445251464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030281029641628265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10143817216157913,
      "backward_entropy": 0.028170521770204817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.18033218383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030348947271704674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10135504603385925,
      "backward_entropy": 0.01999183850628989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.08660125732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030415799468755722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10127454996109009,
      "backward_entropy": 0.019779867359570096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.88539123535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030487796291708946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011933833360672,
      "backward_entropy": 0.019586297018187388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.7156982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030558254569768906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10111308097839355,
      "backward_entropy": 0.01939185176576887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.6701774597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03063204325735569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10103105008602142,
      "backward_entropy": 0.0270569452217647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.93952941894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03070286102592945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10095301270484924,
      "backward_entropy": 0.026851258107594082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.33744049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030774854123592377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10087314993143082,
      "backward_entropy": 0.02664500262056078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.7402114868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030852656811475754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10079029202461243,
      "backward_entropy": 0.026454842516354153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.96597290039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030929584056138992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1007082611322403,
      "backward_entropy": 0.018499761819839478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.19307708740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031013520434498787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10062365978956223,
      "backward_entropy": 0.018338486552238464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.56071472167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03109906055033207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10053826123476028,
      "backward_entropy": 0.01817804149218968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.32417297363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031186513602733612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10045402497053146,
      "backward_entropy": 0.0180271714925766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.90765380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03127340227365494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003698855638504,
      "backward_entropy": 0.025569528341293335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.81684112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03135737404227257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10028736293315887,
      "backward_entropy": 0.02539337319987161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.8349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031438544392585754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10020692646503448,
      "backward_entropy": 0.02521109368119921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.86502456665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031518835574388504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10012838244438171,
      "backward_entropy": 0.01737880174602781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.529687881469727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03159371763467789,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10005313903093338,
      "backward_entropy": 0.017206487911088125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.49716186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031662195920944214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09998081624507904,
      "backward_entropy": 0.024635974849973406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.48778533935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031732361763715744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09990791976451874,
      "backward_entropy": 0.024439228432519094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.40565490722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031800009310245514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0998370349407196,
      "backward_entropy": 0.02424338459968567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.7705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03186703845858574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09976828098297119,
      "backward_entropy": 0.016500812556062425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.14951705932617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031934235244989395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09969845414161682,
      "backward_entropy": 0.023865335753985813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.05943298339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031997449696063995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09962989389896393,
      "backward_entropy": 0.02367000494684492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.12264251708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03205863758921623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956204891204834,
      "backward_entropy": 0.01597858326775687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.86369705200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03212519362568855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09949138760566711,
      "backward_entropy": 0.015813325132642473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.44297790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032189249992370605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09942202270030975,
      "backward_entropy": 0.015643964920725142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.28877258300781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03225715830922127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09935131669044495,
      "backward_entropy": 0.015483202678816659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.196998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032324355095624924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09928128868341446,
      "backward_entropy": 0.022757142782211304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.97686767578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03239074721932411,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09921195358037949,
      "backward_entropy": 0.022586618150983537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.95575714111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032456520944833755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09914342314004898,
      "backward_entropy": 0.02242044678756169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.36365509033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03252032399177551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09907635301351547,
      "backward_entropy": 0.014869698456355504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.752960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032585401087999344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09900936484336853,
      "backward_entropy": 0.014727399817534856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.112051010131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03264843672513962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09894317388534546,
      "backward_entropy": 0.014583391802651542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.69644927978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270678222179413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0988788902759552,
      "backward_entropy": 0.014435500970908574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.95307922363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032772552222013474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09881196916103363,
      "backward_entropy": 0.014303492648260934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.78019332885742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03283785283565521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09874507784843445,
      "backward_entropy": 0.014173631157193865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.64295959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03290274739265442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09867849946022034,
      "backward_entropy": 0.02136763504573277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.58779907226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032967206090688705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09861195087432861,
      "backward_entropy": 0.021235702293259755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.1763801574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033034272491931915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09854479134082794,
      "backward_entropy": 0.02111336588859558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.55545425415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033097874373197556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09847920387983322,
      "backward_entropy": 0.020987500037465776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.9529914855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03316286578774452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09841322898864746,
      "backward_entropy": 0.013566720698560988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.24468994140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03322745859622955,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09834636002779007,
      "backward_entropy": 0.0962829760142735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.74945068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033293113112449646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.098280169069767,
      "backward_entropy": 0.013341260807854789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.49774169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03336293622851372,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09821183979511261,
      "backward_entropy": 0.020541063376835415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.21648406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03343642130494118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09814106673002243,
      "backward_entropy": 0.013150831418378013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.465702056884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03350430354475975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09807360172271729,
      "backward_entropy": 0.013052212340491158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.92039489746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03356856480240822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09800697863101959,
      "backward_entropy": 0.012949177197047643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.69639587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03363247215747833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09793998301029205,
      "backward_entropy": 0.012846340026174272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.27066802978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03369623050093651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09787335991859436,
      "backward_entropy": 0.012746657643999373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.03397560119629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03376388177275658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09780426323413849,
      "backward_entropy": 0.019963758332388743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.53409576416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03382799029350281,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09773673117160797,
      "backward_entropy": 0.012549900582858495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.13553237915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389465808868408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09766755998134613,
      "backward_entropy": 0.012454641716820853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.77801513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033962324261665344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09759771078824997,
      "backward_entropy": 0.012362547218799591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.711198806762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034027956426143646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0975286215543747,
      "backward_entropy": 0.019601494073867798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.51537322998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03408990800380707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0974595844745636,
      "backward_entropy": 0.019498905965260098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.31340408325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03415634110569954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09738998115062714,
      "backward_entropy": 0.01941128500870296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.05691528320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03422104939818382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09732076525688171,
      "backward_entropy": 0.019327106220381602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.20933723449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034289661794900894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09724954515695572,
      "backward_entropy": 0.011899444673742567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.83209228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03435341268777847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0971807986497879,
      "backward_entropy": 0.0191707866532462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.990150451660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03441595286130905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09711237251758575,
      "backward_entropy": 0.019097990223339627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.50263977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034475427120923996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09704462438821793,
      "backward_entropy": 0.01901735578264509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.10819625854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03453514724969864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09697654843330383,
      "backward_entropy": 0.011557566268103463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.89165496826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03459662199020386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09690757095813751,
      "backward_entropy": 0.011475701417241777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.169883728027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034653861075639725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0968397706747055,
      "backward_entropy": 0.011389545031956263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.9031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03471064940094948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09677359461784363,
      "backward_entropy": 0.011310121842793055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.06283569335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03477252647280693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0967046320438385,
      "backward_entropy": 0.01124071968453271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.40937042236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03483719006180763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09663322567939758,
      "backward_entropy": 0.011172327612127577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.96122741699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034905996173620224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09656029939651489,
      "backward_entropy": 0.011109889617988042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.14925765991211,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03497552126646042,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09648478776216507,
      "backward_entropy": 0.09685233661106654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.820613861083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03504440188407898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09641021490097046,
      "backward_entropy": 0.010983521384852273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.25597381591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035110242664813995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09633757174015045,
      "backward_entropy": 0.010923021606036596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.5959243774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517457842826843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0962657630443573,
      "backward_entropy": 0.010863555329186576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.22442626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035241447389125824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09619161486625671,
      "backward_entropy": 0.018335052898951938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.083681106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035313356667757034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09611409902572632,
      "backward_entropy": 0.010749062257153648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.08782196044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03538009896874428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09603912383317947,
      "backward_entropy": 0.010687950466360365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.521690368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03544647991657257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09596409648656845,
      "backward_entropy": 0.010628329856055123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.42283630371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03551143780350685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09588997066020966,
      "backward_entropy": 0.010572889021464757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.39144134521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03557492420077324,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09581615775823593,
      "backward_entropy": 0.09709503820964269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.18134307861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03564242646098137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09573961049318314,
      "backward_entropy": 0.010466352105140686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.632137298583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03570801392197609,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09566354006528854,
      "backward_entropy": 0.018073524747576033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.242218017578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03576916828751564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09558911621570587,
      "backward_entropy": 0.010354035667010717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.576881408691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035831812769174576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09551413357257843,
      "backward_entropy": 0.010296715157372611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.50082015991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03589199483394623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09544097632169724,
      "backward_entropy": 0.010242382330553872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.333927154541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035949837416410446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09536854922771454,
      "backward_entropy": 0.010188971246991838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.40896987915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03600238263607025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09529876708984375,
      "backward_entropy": 0.017870996679578508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.366416931152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03605447709560394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09522857517004013,
      "backward_entropy": 0.010063560945647103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.14753532409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03610869124531746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09515617787837982,
      "backward_entropy": 0.009997582861355372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.963050842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03616113215684891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0950842946767807,
      "backward_entropy": 0.009933282222066606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.92784881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03621596843004227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09500981867313385,
      "backward_entropy": 0.009871976716177804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.27759552001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03627016022801399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09493596851825714,
      "backward_entropy": 0.009810581803321838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.40348434448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03633086383342743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09485724568367004,
      "backward_entropy": 0.009757619883332933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.677490234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03639313951134682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09477712213993073,
      "backward_entropy": 0.01753654863153185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.59368896484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03645281493663788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09469865262508392,
      "backward_entropy": 0.00965438676731927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.83329391479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03651004284620285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09462083876132965,
      "backward_entropy": 0.009599838938031877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.609561920166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03656908869743347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09454183280467987,
      "backward_entropy": 0.009544928159032549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.42508316040039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03662998229265213,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09446094930171967,
      "backward_entropy": 0.017373964190483093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.475608825683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036692436784505844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09437784552574158,
      "backward_entropy": 0.017338175858770098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.30296325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036751117557287216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09429775178432465,
      "backward_entropy": 0.009397884564740317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.220943450927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036814428865909576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09421487897634506,
      "backward_entropy": 0.009355928216661726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.45381164550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036877624690532684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09413071721792221,
      "backward_entropy": 0.009313052254063743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.40633773803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03693949431180954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09404710680246353,
      "backward_entropy": 0.009270536048071725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.20036315917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037002913653850555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09396174550056458,
      "backward_entropy": 0.017212441989353726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.478271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0370677225291729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0938747450709343,
      "backward_entropy": 0.009194165468215942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.00729751586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0371350422501564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09378506243228912,
      "backward_entropy": 0.009158714541367121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.344051361083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03719792515039444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09369863569736481,
      "backward_entropy": 0.01716053592307227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.13970184326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03725818172097206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09361404180526733,
      "backward_entropy": 0.009081757494381495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.82461929321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037322696298360825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09352573752403259,
      "backward_entropy": 0.017117595033986226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.3437614440918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03738710284233093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09343697130680084,
      "backward_entropy": 0.01709992012807301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.04917907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03745005279779434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09334877878427505,
      "backward_entropy": 0.008976818195411138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.321284294128418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03751552477478981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09325771033763885,
      "backward_entropy": 0.008941281054701124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.366573333740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0375756174325943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0931713804602623,
      "backward_entropy": 0.017042566623006548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.2979736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03763716295361519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09308217465877533,
      "backward_entropy": 0.008870434015989304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.0804443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037701740860939026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09299030154943466,
      "backward_entropy": 0.00884019210934639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.50645446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037768781185150146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09289559721946716,
      "backward_entropy": 0.008811486618859428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.73739624023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03783412650227547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09280134737491608,
      "backward_entropy": 0.00878253738795008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.22058868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037904292345047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09270313382148743,
      "backward_entropy": 0.008754299687487739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.05413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03797236084938049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09260614216327667,
      "backward_entropy": 0.008724973137889589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.928855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03804381564259529,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09250441193580627,
      "backward_entropy": 0.09781304427555629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.917046546936035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03811291605234146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09240414202213287,
      "backward_entropy": 0.00866834819316864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.40274429321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03817746043205261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0923074260354042,
      "backward_entropy": 0.008637463940041406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.58377075195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03824302926659584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09220997989177704,
      "backward_entropy": 0.008606678141014916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.14448165893555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038314804434776306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09210669249296188,
      "backward_entropy": 0.016896121203899384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.386003494262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0383855402469635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09200262278318405,
      "backward_entropy": 0.01688168091433389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.75991439819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038452912122011185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09190170466899872,
      "backward_entropy": 0.008524237998894282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.292015075683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038519781082868576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09180091321468353,
      "backward_entropy": 0.008496487779276711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.392340660095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03858736529946327,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09169778227806091,
      "backward_entropy": 0.01683653678212847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.869422912597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03865053504705429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09159954637289047,
      "backward_entropy": 0.008439124694892339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.247550010681152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038714710623025894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09149918705224991,
      "backward_entropy": 0.008408353797027044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624458312988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038774844259023666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09140300750732422,
      "backward_entropy": 0.01677458094699042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.72386932373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03882993012666702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09131181240081787,
      "backward_entropy": 0.008344628981181554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.065982818603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03888573870062828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0912202000617981,
      "backward_entropy": 0.01672300696372986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.88874816894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03894089534878731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09112835675477982,
      "backward_entropy": 0.008283215441874095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.374412536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038998059928417206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09103356301784515,
      "backward_entropy": 0.016680885638509477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.69090461730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03905313089489937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09094077348709106,
      "backward_entropy": 0.016661174595355988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.09665298461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03910764679312706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09084813296794891,
      "backward_entropy": 0.016642441706998006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.4995002746582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03916679322719574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09074899554252625,
      "backward_entropy": 0.016628542116710117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.62435531616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039228640496730804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09064561873674393,
      "backward_entropy": 0.01661390279020582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.885007858276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0392904169857502,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09054191410541534,
      "backward_entropy": 0.016597931938511983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.28325653076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03934963420033455,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0904402881860733,
      "backward_entropy": 0.09811303445271083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.33418273925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03940911218523979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0903375893831253,
      "backward_entropy": 0.008080985929284776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.77184295654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03947009891271591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09023261070251465,
      "backward_entropy": 0.008059308997222356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.37696075439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03952980414032936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09012869000434875,
      "backward_entropy": 0.016536513609545573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.485198974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0395948551595211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09001775085926056,
      "backward_entropy": 0.008018129638263158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.590782165527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03965834900736809,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08990754187107086,
      "backward_entropy": 0.016518376767635345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.295799255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03972411900758743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08979380130767822,
      "backward_entropy": 0.007983635578836714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.08143997192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03979063779115677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0896783247590065,
      "backward_entropy": 0.007966489664145879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.880611419677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0398590974509716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08955933153629303,
      "backward_entropy": 0.007949881255626678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.62501525878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03992674872279167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08944043517112732,
      "backward_entropy": 0.007932591651167189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.08047866821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03999494016170502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08931995928287506,
      "backward_entropy": 0.00791537921343531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.30305480957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0400674045085907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08919268846511841,
      "backward_entropy": 0.007900726582322801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.926387786865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04013868421316147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08906712383031845,
      "backward_entropy": 0.007885332086256571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.136043548583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040210094302892685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08893956243991852,
      "backward_entropy": 0.007869424564497811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.46406936645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04027911648154259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08881516754627228,
      "backward_entropy": 0.007852525583335332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.831478118896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04034844785928726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08868932723999023,
      "backward_entropy": 0.007835786257471358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.35162353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041556268930435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08856597542762756,
      "backward_entropy": 0.007817986820425307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.04860305786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04048185050487518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0884426087141037,
      "backward_entropy": 0.007798621164900916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.195638656616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04055112227797508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08831354975700378,
      "backward_entropy": 0.007781195321253368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.00987243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040615785866975784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08819183707237244,
      "backward_entropy": 0.016347824462822506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.08245849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04068475961685181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08806212246417999,
      "backward_entropy": 0.0077462153775351384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.33160400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04075154662132263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08793499320745468,
      "backward_entropy": 0.01631289507661547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.215450286865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040822409093379974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08780036121606827,
      "backward_entropy": 0.007712814956903458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.82853317260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04089212045073509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0876665934920311,
      "backward_entropy": 0.007696821753467832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.19005584716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04096316173672676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08753038942813873,
      "backward_entropy": 0.016263785106795176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.95360565185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041034188121557236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08739273250102997,
      "backward_entropy": 0.016247005334922245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.15087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04110519215464592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08725463598966599,
      "backward_entropy": 0.01622994669846126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.752296447753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04117373377084732,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08711974322795868,
      "backward_entropy": 0.007636115487132754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.27418518066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04123884439468384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0869901031255722,
      "backward_entropy": 0.007619413414171764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.05491638183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04130445048213005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08685807883739471,
      "backward_entropy": 0.016166762581893375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.69451141357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041370488703250885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08672450482845306,
      "backward_entropy": 0.016143283673695157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.4127254486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143575206398964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08659195899963379,
      "backward_entropy": 0.0075687989592552185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.40121078491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041499096900224686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08646199107170105,
      "backward_entropy": 0.0075520117368016925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.188533782958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041563089936971664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0863298773765564,
      "backward_entropy": 0.016069428196975162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.97111892700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04162761569023132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08619552850723267,
      "backward_entropy": 0.0075195154973438805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.79665184020996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041692622005939484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08605919778347015,
      "backward_entropy": 0.007503058761358261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.61522674560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041756849735975266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08592307567596436,
      "backward_entropy": 0.015988251992634366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.209346771240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04182038456201553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0857871025800705,
      "backward_entropy": 0.007468845163072858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.95238494873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041885606944561005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08564697206020355,
      "backward_entropy": 0.007451958954334259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.69093322753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04195234552025795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08550252765417099,
      "backward_entropy": 0.09853098222187587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.875892639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042020417749881744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0853540226817131,
      "backward_entropy": 0.007419018873146602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.68763542175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042087361216545105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08520722389221191,
      "backward_entropy": 0.007402400353125164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.104162216186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04215328395366669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08506107330322266,
      "backward_entropy": 0.0158145363841738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.998119354248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221595451235771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08492119610309601,
      "backward_entropy": 0.007369515619107655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.41849136352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04227569326758385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08478648960590363,
      "backward_entropy": 0.015751646033355167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.600757122039795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04233739152550697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08464645594358444,
      "backward_entropy": 0.00733545795083046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.132567405700684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042393941432237625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08451738953590393,
      "backward_entropy": 0.007318036896841866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.072062492370605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04244700446724892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08439571410417557,
      "backward_entropy": 0.007300102284976414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.53112030029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0424969308078289,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08428047597408295,
      "backward_entropy": 0.015614541513579232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.910449981689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04254746809601784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08416303247213364,
      "backward_entropy": 0.007264828575508935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.348031997680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04259740933775902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08404634892940521,
      "backward_entropy": 0.007248085524354663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.10675048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04264567792415619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08393248170614243,
      "backward_entropy": 0.007231441459485463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.181482315063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042694706469774246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08381590247154236,
      "backward_entropy": 0.007215311484677451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.466001510620117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04274214059114456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08370252698659897,
      "backward_entropy": 0.007199328392744064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.6807279586792,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04278925806283951,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08358945697546005,
      "backward_entropy": 0.09857548986162458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.50705337524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042833827435970306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08348144590854645,
      "backward_entropy": 0.015365873064313616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.996681213378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288286715745926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08336345851421356,
      "backward_entropy": 0.007154505167688642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.278770446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042934805154800415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08323672413825989,
      "backward_entropy": 0.007141647062131337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.453903198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042987097054719925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08310844749212265,
      "backward_entropy": 0.015269619013581957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.59427261352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0430363267660141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08298727869987488,
      "backward_entropy": 0.01523766347340175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.682106018066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04308392480015755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0828697606921196,
      "backward_entropy": 0.015205535505499159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.715984344482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04313116893172264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08275251090526581,
      "backward_entropy": 0.015173618282590593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.57880973815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04317920655012131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08263242244720459,
      "backward_entropy": 0.0070809173796858105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.525142669677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043227940797805786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08250989764928818,
      "backward_entropy": 0.007070108715976987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.236358642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043278418481349945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0823819562792778,
      "backward_entropy": 0.00705991153206144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.12118911743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04332822188735008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08225519955158234,
      "backward_entropy": 0.00704984154020037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.01018524169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337744042277336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0821293294429779,
      "backward_entropy": 0.007040277123451233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.948713302612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043428342789411545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08199803531169891,
      "backward_entropy": 0.007031625935009548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.727615356445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04347630590200424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08187438547611237,
      "backward_entropy": 0.007022849683250699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.755362510681152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043524909764528275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08174841105937958,
      "backward_entropy": 0.007014240005186626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.23129653930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04357188194990158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08162657916545868,
      "backward_entropy": 0.007005506860358375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.44956398010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04362179711461067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08149568736553192,
      "backward_entropy": 0.014883251062461309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.83290481567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04367104172706604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08136622607707977,
      "backward_entropy": 0.006989713226045881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.822723388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04372298717498779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08122824132442474,
      "backward_entropy": 0.006982702229704175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.779743194580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043776240199804306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08108581602573395,
      "backward_entropy": 0.014802723058632441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.496031761169434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0438251867890358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08095565438270569,
      "backward_entropy": 0.006969184747764042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.59893035888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04387134686112404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08083341270685196,
      "backward_entropy": 0.0069619534271104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.080349922180176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0439181849360466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08070898056030273,
      "backward_entropy": 0.006954021751880646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.001829147338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04396352916955948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0805884450674057,
      "backward_entropy": 0.00694614861692701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.8468017578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04400753602385521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08047133684158325,
      "backward_entropy": 0.006938504853418895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.075603485107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04405350238084793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08034796267747879,
      "backward_entropy": 0.006930939321007047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.93819236755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044100139290094376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08022217452526093,
      "backward_entropy": 0.006923029465334756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.36023712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04414745792746544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08009332418441772,
      "backward_entropy": 0.006915894470044545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.13365936279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0441964752972126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0799587219953537,
      "backward_entropy": 0.01451942218201501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.03260803222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044244781136512756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07982578873634338,
      "backward_entropy": 0.006903817078896931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.37751007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044296734035015106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07968093454837799,
      "backward_entropy": 0.006898333983761924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.23070526123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044348713010549545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07953517138957977,
      "backward_entropy": 0.006892435252666473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.904863357543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0444006472826004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07939043641090393,
      "backward_entropy": 0.006885732923235212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.1607084274292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04445474222302437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07923772931098938,
      "backward_entropy": 0.006879780973706927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.422990798950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0445064976811409,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07909224927425385,
      "backward_entropy": 0.00687318029148238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3374128341674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04455723613500595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07894939184188843,
      "backward_entropy": 0.01428541328225817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.49785804748535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446038693189621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.078820139169693,
      "backward_entropy": 0.0068597181567123956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.82206916809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04465099424123764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07868795096874237,
      "backward_entropy": 0.014209866523742676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.4710693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04469649866223335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07856084406375885,
      "backward_entropy": 0.00684651147042002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.658690452575684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04474375769495964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07842672616243362,
      "backward_entropy": 0.0068417846092156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.580484390258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044789496809244156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07829660177230835,
      "backward_entropy": 0.0068387431757790705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.66419982910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04483386129140854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07817001640796661,
      "backward_entropy": 0.006837242415973118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28662395477295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044884052127599716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07802359014749527,
      "backward_entropy": 0.006836080657584327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.345375061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044931281358003616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07788676023483276,
      "backward_entropy": 0.006834943911858967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.597965240478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04497678950428963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07775557786226273,
      "backward_entropy": 0.0068328699895313805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.127345085144043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502493515610695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07761454582214355,
      "backward_entropy": 0.006831495357411248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.22592544555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045070305466651917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07748273015022278,
      "backward_entropy": 0.006830139883926937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.024303436279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0451182946562767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07734094560146332,
      "backward_entropy": 0.006829384182180677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.876636505126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04516454413533211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07720474898815155,
      "backward_entropy": 0.006828866899013519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.76946258544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04521223530173302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07706287503242493,
      "backward_entropy": 0.013866291514464788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.629920959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04526008665561676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07692035287618637,
      "backward_entropy": 0.0068261463727269855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.597200393676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04530816152691841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07677632570266724,
      "backward_entropy": 0.006823707904134478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.625692367553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045355454087257385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07663437724113464,
      "backward_entropy": 0.006821454635688237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.22751808166504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04540093615651131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07649865746498108,
      "backward_entropy": 0.006818149771009173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.91388702392578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04544689133763313,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07636044174432755,
      "backward_entropy": 0.09873179878507342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.387508392333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04549422115087509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07621651142835617,
      "backward_entropy": 0.006812046148947307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.310016632080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04553976282477379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07607884705066681,
      "backward_entropy": 0.006808916905096599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.231857299804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04558368772268295,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07594679296016693,
      "backward_entropy": 0.09873718023300171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.301666259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04562622681260109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07581912726163864,
      "backward_entropy": 0.01356450148991176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.772774696350098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04567042365670204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0756845772266388,
      "backward_entropy": 0.006801705275263105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.004188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04571417346596718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07555095851421356,
      "backward_entropy": 0.01349776131766183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.934289932250977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04575936868786812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07541152834892273,
      "backward_entropy": 0.0067983620933124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.467108726501465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045802999287843704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07527787983417511,
      "backward_entropy": 0.006796959787607193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.78557300567627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045846324414014816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07514365017414093,
      "backward_entropy": 0.00679797466312136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.4110107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045888278633356094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0750143900513649,
      "backward_entropy": 0.00679954354252134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.259380340576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045931823551654816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0748784989118576,
      "backward_entropy": 0.00680028327873775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.572793006896973,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045976873487234116,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07473602890968323,
      "backward_entropy": 0.09875481469290597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.4764461517334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046020179986953735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0746007114648819,
      "backward_entropy": 0.0068006499537399834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.421390533447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046063877642154694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07446375489234924,
      "backward_entropy": 0.0067984483071735925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.349827766418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04610603675246239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07433256506919861,
      "backward_entropy": 0.006795826767172132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.116044998168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046146806329488754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07420676946640015,
      "backward_entropy": 0.006792808217661721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.998470306396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04618821293115616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07407805323600769,
      "backward_entropy": 0.0067891329526901245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.509011268615723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04623017832636833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07394671440124512,
      "backward_entropy": 0.006784917520625251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.75985336303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04627169668674469,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07381691038608551,
      "backward_entropy": 0.013038326586995806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.674034118652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04631377384066582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07368439435958862,
      "backward_entropy": 0.006775877837623868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.931804656982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04635349661111832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0735611617565155,
      "backward_entropy": 0.006771562354905265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.413164138793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04639196768403053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07344191521406174,
      "backward_entropy": 0.006766100014959063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.3019962310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046431366354227066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07331781089305878,
      "backward_entropy": 0.00676210384283747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025978628545999527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04647155478596687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07318921387195587,
      "backward_entropy": 0.006758964487484523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.298614501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046507809311151505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07307685911655426,
      "backward_entropy": 0.006757577615124839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.212066650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046546004712581635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0729556679725647,
      "backward_entropy": 0.006756227995668139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.70672607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046581488102674484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07284504175186157,
      "backward_entropy": 0.006757679262331554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.92173957824707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04661715403199196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07273295521736145,
      "backward_entropy": 0.006759309342929295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.7979679107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665488004684448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07261116802692413,
      "backward_entropy": 0.006761443402085986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.559877395629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04669434204697609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07248196005821228,
      "backward_entropy": 0.006762586534023285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.36213207244873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04673440381884575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.072348952293396,
      "backward_entropy": 0.00676292713199343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.208889961242676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04677411913871765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07221832126379013,
      "backward_entropy": 0.0067633092403411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149890899658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046812672168016434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07209174335002899,
      "backward_entropy": 0.00676448004586356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.108336448669434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04685002937912941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07197055220603943,
      "backward_entropy": 0.006764488560812814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.021181106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046887099742889404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07185102254152298,
      "backward_entropy": 0.006761349205459867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.982898712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04692234843969345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07173904776573181,
      "backward_entropy": 0.0067596643098763055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.68025779724121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04695591703057289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07163408398628235,
      "backward_entropy": 0.0067587484206472126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.652568817138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0469934456050396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07151065766811371,
      "backward_entropy": 0.00675877502986363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.68860149383545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04703245311975479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07138112187385559,
      "backward_entropy": 0.006755915071283068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.386940002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047071103006601334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07125268876552582,
      "backward_entropy": 0.012248843908309937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.240867614746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711112007498741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07111899554729462,
      "backward_entropy": 0.0067473916070801875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.260247230529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047152575105428696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07097789645195007,
      "backward_entropy": 0.0067438238433429176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.676930904388428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719431698322296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07083520293235779,
      "backward_entropy": 0.006740116115127291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.231084823608398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0472337044775486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07070286571979523,
      "backward_entropy": 0.012080434177603041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.379949569702148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04727271944284439,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07057179510593414,
      "backward_entropy": 0.006735782005957195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.328340530395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04731021448969841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07044874131679535,
      "backward_entropy": 0.006730239306177411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.504319190979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047350071370601654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.070314422249794,
      "backward_entropy": 0.006724671593734196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.59355640411377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047387707978487015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07019011676311493,
      "backward_entropy": 0.006720017109598432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.797384262084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04742605239152908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07006171345710754,
      "backward_entropy": 0.00671716992344175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.042682647705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04746411740779877,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06993398815393448,
      "backward_entropy": 0.011826029845646449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.624709129333496,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04750383272767067,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06979724019765854,
      "backward_entropy": 0.09875788007463727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.797786712646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04754311218857765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06966220587491989,
      "backward_entropy": 0.011768342128821782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.456027030944824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04758348688483238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0695224404335022,
      "backward_entropy": 0.01173487092767443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.51913070678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047623176127672195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06938613951206207,
      "backward_entropy": 0.011699100690228599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.158015727996826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04766416177153587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06924289464950562,
      "backward_entropy": 0.006725731172731945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.183934211730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047702763229608536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06911089271306992,
      "backward_entropy": 0.0067276427788393834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.078152179718018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04774101823568344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.068979911506176,
      "backward_entropy": 0.011604901935373033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.027021884918213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04777706414461136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06885980069637299,
      "backward_entropy": 0.0067329369485378265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.995723724365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047811359167099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06874726712703705,
      "backward_entropy": 0.006737467433725085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.80644416809082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047843948006629944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0686427652835846,
      "backward_entropy": 0.006742434842245919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.685901641845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04787814989686012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06853081285953522,
      "backward_entropy": 0.006743982966457095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.73044490814209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04791394993662834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0684107095003128,
      "backward_entropy": 0.00674505638224738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4355685710906982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04794944450259209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06829238682985306,
      "backward_entropy": 0.006745058510984693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.10509490966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047982435673475266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06818513572216034,
      "backward_entropy": 0.006748650223016739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134493350982666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048018861562013626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06806043535470963,
      "backward_entropy": 0.0067531439874853405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.728344440460205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048054151237010956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06794112920761108,
      "backward_entropy": 0.006757608481815883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.300527572631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048087675124406815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06783001124858856,
      "backward_entropy": 0.006763616310698646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.65596342086792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812617227435112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06769388914108276,
      "backward_entropy": 0.006770149937697819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.906115531921387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816248267889023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06756851822137833,
      "backward_entropy": 0.006776714963572366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.584941387176514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819757491350174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06744933128356934,
      "backward_entropy": 0.0067822933197021484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.809206008911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04823071509599686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06734012812376022,
      "backward_entropy": 0.006786553987434932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745181560516357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048262711614370346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06723786890506744,
      "backward_entropy": 0.0067866455231394085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907808303833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04829389229416847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06713933497667313,
      "backward_entropy": 0.006786503429923739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2543952465057373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04832516983151436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06704004108905792,
      "backward_entropy": 0.011090139193194253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604890823364258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04835397005081177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0669538676738739,
      "backward_entropy": 0.011050598961966378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.546813011169434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048382118344306946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06687137484550476,
      "backward_entropy": 0.0067803508469036645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.8072509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048409901559352875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06678998470306396,
      "backward_entropy": 0.006777593067714146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591861724853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04843892529606819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06670159846544266,
      "backward_entropy": 0.010927931538649968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.892578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048468273133039474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06661117821931839,
      "backward_entropy": 0.010891286390168326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.261599540710449,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04850024729967117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06650687754154205,
      "backward_entropy": 0.006774539926222393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.566229820251465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048530496656894684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06641189008951187,
      "backward_entropy": 0.006772940712315696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.265714168548584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048562563955783844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06630644202232361,
      "backward_entropy": 0.006773368056331362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.377355575561523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048593662679195404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06620588898658752,
      "backward_entropy": 0.00677224514739854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.255483627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04862619563937187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0660976767539978,
      "backward_entropy": 0.006769380399159023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.180395126342773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04866032302379608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06598076224327087,
      "backward_entropy": 0.006769326116357531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.046574115753174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04869631305336952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06585467606782913,
      "backward_entropy": 0.01062889610018049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.985896110534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872952401638031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06574265658855438,
      "backward_entropy": 0.006765411368438176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.90043830871582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04876184090971947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06563416123390198,
      "backward_entropy": 0.006766508732523237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.885797500610352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048794057220220566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06552563607692719,
      "backward_entropy": 0.010524957307747431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.688589096069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882541298866272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06542153656482697,
      "backward_entropy": 0.006772129131214959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06694109737873077,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04885763302445412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06531192362308502,
      "backward_entropy": 0.006778426468372345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.32635498046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04888634756207466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06522221118211746,
      "backward_entropy": 0.006780640355178288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.100361824035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04891760274767876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06511842459440231,
      "backward_entropy": 0.010410024651459284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.495871543884277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04895172640681267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.064999520778656,
      "backward_entropy": 0.0067856524671827045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9093579053878784,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048985593020915985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06488122045993805,
      "backward_entropy": 0.006789455456393105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.546943187713623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049016617238521576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06477941572666168,
      "backward_entropy": 0.006790332496166229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.743782997131348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04904664307832718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06468290835618973,
      "backward_entropy": 0.006789535816226687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4415202140808105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04907888174057007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.064574234187603,
      "backward_entropy": 0.0067892489688737056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.390179634094238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049110133200883865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06447073817253113,
      "backward_entropy": 0.0067894527954714635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3430023193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049140531569719315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06437142938375473,
      "backward_entropy": 0.010184207132884435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.556001901626587,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049170155078172684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06427579373121262,
      "backward_entropy": 0.010154119559696742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.002020835876465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0491982027888298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06418882310390472,
      "backward_entropy": 0.006793617137840816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.220988750457764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04922616854310036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06410245597362518,
      "backward_entropy": 0.006791176540510995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.687555313110352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04925338551402092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06402107328176498,
      "backward_entropy": 0.00678732938000134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.824377536773682,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928388074040413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06392151117324829,
      "backward_entropy": 0.006786691290991647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0794501304626465,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04931402578949928,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0638238862156868,
      "backward_entropy": 0.09877598285675049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3772850036621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0493432842195034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06373102962970734,
      "backward_entropy": 0.006779653685433524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.919597625732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04937098175287247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06364661455154419,
      "backward_entropy": 0.0067760587802955085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.46501350402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04940028116106987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06355301290750504,
      "backward_entropy": 0.0067741333373955315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.743926048278809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049431610852479935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06344838440418243,
      "backward_entropy": 0.006771884858608246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.446981906890869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04946395009756088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06333857774734497,
      "backward_entropy": 0.009781509637832642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.632903814315796,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049495846033096313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0632314532995224,
      "backward_entropy": 0.006763998951230731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1897218227386475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952535778284073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06313647329807281,
      "backward_entropy": 0.006762738206556865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.693362236022949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955330863595009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06305010616779327,
      "backward_entropy": 0.006761989423206874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.824466705322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04958093911409378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06296370923519135,
      "backward_entropy": 0.006767878574984414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.676259517669678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049610648304224014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06286605447530746,
      "backward_entropy": 0.006772625127008983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.084794044494629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049640800803899765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06276599317789078,
      "backward_entropy": 0.006776063037770135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539714813232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049670808017253876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06266660988330841,
      "backward_entropy": 0.006781225757939475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.488736629486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049699846655130386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06257252395153046,
      "backward_entropy": 0.0067857370844909125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5129398107528687,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497281514108181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06248192489147186,
      "backward_entropy": 0.006792007280247552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.414400100708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975450038909912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062401436269283295,
      "backward_entropy": 0.0068013401968138555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.811783313751221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049780260771512985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062324102967977524,
      "backward_entropy": 0.006810168602636882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.907143592834473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049806248396635056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06224505230784416,
      "backward_entropy": 0.0068197037492479596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.29982852935791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983563348650932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06214756518602371,
      "backward_entropy": 0.006825949464525495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.661626815795898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049864042550325394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06205567717552185,
      "backward_entropy": 0.00683110739503588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.589199542999268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04989217221736908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061965908855199814,
      "backward_entropy": 0.0068341270089149475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.165297985076904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04992034286260605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061874840408563614,
      "backward_entropy": 0.006840029997485024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.425269365310669,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0499478355050087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0617867186665535,
      "backward_entropy": 0.009340433137757438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.105091094970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04997309669852257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06171208992600441,
      "backward_entropy": 0.006853622517415455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.061240196228027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049997687339782715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06164153292775154,
      "backward_entropy": 0.006857071604047503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3921018838882446,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05002386122941971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06156138330698013,
      "backward_entropy": 0.009262803409780775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.670362949371338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050047870725393295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061494432389736176,
      "backward_entropy": 0.006863799478326525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6483266353607178,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050070930272340775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.061431653797626495,
      "backward_entropy": 0.009207086903708321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3587620258331299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05009312927722931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06137287616729736,
      "backward_entropy": 0.006875441542693547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.298105239868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05011355131864548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061325110495090485,
      "backward_entropy": 0.0068789539592606684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.108950138092041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013706535100937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06125972419977188,
      "backward_entropy": 0.006881483963557652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.088695049285889,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016117915511131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06118887662887573,
      "backward_entropy": 0.006890191031353814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.552597999572754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018540844321251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061117447912693024,
      "backward_entropy": 0.006897335605961936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0035624504089355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050208427011966705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06105315312743187,
      "backward_entropy": 0.006902848503419331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95377254486084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05023159459233284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06098819151520729,
      "backward_entropy": 0.0069061315485409325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6923129558563232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025499314069748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060921844094991684,
      "backward_entropy": 0.006909273564815521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0740838050842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05027802288532257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060856893658638,
      "backward_entropy": 0.006913429392235619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6300060749053955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050301842391490936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0607876256108284,
      "backward_entropy": 0.0069161222449370795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.59432315826416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503251850605011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06072075292468071,
      "backward_entropy": 0.006919074271406446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2261688709259033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05034814029932022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060655541718006134,
      "backward_entropy": 0.006923243403434753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3746466636657715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05036941170692444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060600198805332184,
      "backward_entropy": 0.006927637117249625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.666640281677246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05038982257246971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06054919213056564,
      "backward_entropy": 0.008862210171563285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.482433319091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050410568714141846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060496509075164795,
      "backward_entropy": 0.006935948772089822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.71452522277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05043105408549309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06044537201523781,
      "backward_entropy": 0.00693844524877412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.408707857131958,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05045260861515999,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060387540608644485,
      "backward_entropy": 0.0069412413452352795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.619670391082764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05047406628727913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06032905727624893,
      "backward_entropy": 0.008763501686709268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.679094314575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504964217543602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060265399515628815,
      "backward_entropy": 0.006954145218644824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3356258869171143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052006617188454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06019468232989311,
      "backward_entropy": 0.006957527782235827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06600290536880493,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05054307356476784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06012808531522751,
      "backward_entropy": 0.006959335080214909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.339712142944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050563570111989975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06007692217826843,
      "backward_entropy": 0.008658015834433692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2348225116729736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050584472715854645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06002289056777954,
      "backward_entropy": 0.006958613970449993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.430476665496826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05060520023107529,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05996895581483841,
      "backward_entropy": 0.0069614191140447345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1500535011291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05062800273299217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059902966022491455,
      "backward_entropy": 0.006963354136262622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.152660369873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05064953863620758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05984519049525261,
      "backward_entropy": 0.006962503705705915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.189807891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05067071318626404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05978836864233017,
      "backward_entropy": 0.0069621843951089045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0876729488372803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069344863295555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05972283333539963,
      "backward_entropy": 0.006963154567139489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.082403659820557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05071496218442917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05966423451900482,
      "backward_entropy": 0.006962300411292485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0302913188934326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073845013976097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05959399789571762,
      "backward_entropy": 0.006962454744747707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0057666301727295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05076140910387039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05952613055706024,
      "backward_entropy": 0.00696439402444022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.964341163635254,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05078378692269325,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05946217477321625,
      "backward_entropy": 0.09880156176430839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9880532026290894,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080583691596985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05939863622188568,
      "backward_entropy": 0.00697140342422894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.828934669494629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05082670971751213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05934266746044159,
      "backward_entropy": 0.0069746630532400945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.734236240386963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05084835737943649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05928202345967293,
      "backward_entropy": 0.006977664572851998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.737784385681152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05087114870548248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059215202927589417,
      "backward_entropy": 0.006978255297456469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9103440046310425,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050894398242235184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059145815670490265,
      "backward_entropy": 0.006976902484893799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7305874824523926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050916336476802826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059084806591272354,
      "backward_entropy": 0.006974072328635624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7647781372070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050938092172145844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05902601778507233,
      "backward_entropy": 0.006967480161360332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.351464748382568,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05095948651432991,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05896816402673721,
      "backward_entropy": 0.09879287651606969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8352152109146118,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05098232626914978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05890309810638428,
      "backward_entropy": 0.006955263870103019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.797432780265808,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051003843545913696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05884629115462303,
      "backward_entropy": 0.00694498632635389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2688069343566895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05102452635765076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05879293754696846,
      "backward_entropy": 0.006940094488007682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6313023567199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051046404987573624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0587327778339386,
      "backward_entropy": 0.0069347407136644635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6137492656707764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051067743450403214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05867546424269676,
      "backward_entropy": 0.006930373076881681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.091822624206543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05108838900923729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05862288922071457,
      "backward_entropy": 0.006923294493130275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7159641981124878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05111045762896538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05856049805879593,
      "backward_entropy": 0.007902366774422782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6958446502685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113143101334572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05850435793399811,
      "backward_entropy": 0.007873978997979845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4901514053344727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05115146562457085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05845380946993828,
      "backward_entropy": 0.006921619709048953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4796314239501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117127299308777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05840359255671501,
      "backward_entropy": 0.006926579134804862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.644054651260376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0511905662715435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058356985449790955,
      "backward_entropy": 0.006928356630461556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.437126874923706,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05120912194252014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05831397324800491,
      "backward_entropy": 0.006932842412165233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4007129669189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05122717469930649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058274999260902405,
      "backward_entropy": 0.006932905742100307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6009576320648193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0512450747191906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05823642760515213,
      "backward_entropy": 0.006934445883546557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3572990894317627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05126231908798218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058201294392347336,
      "backward_entropy": 0.00693786729659353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3406827449798584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05127947777509689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058166150003671646,
      "backward_entropy": 0.006942683564765113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0489911250770092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05129645764827728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05813213810324669,
      "backward_entropy": 0.006946909108332225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.29900860786438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05131174623966217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0581081360578537,
      "backward_entropy": 0.006951778594936643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2782130241394043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05132707953453064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05808350071310997,
      "backward_entropy": 0.006957007838147027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.951478481292725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051342498511075974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05805790424346924,
      "backward_entropy": 0.006963379148926053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5041630268096924,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05136054754257202,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.058015912771224976,
      "backward_entropy": 0.09877254281725202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.67128324508667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137794837355614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057977452874183655,
      "backward_entropy": 0.006977703422307968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.189356565475464,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05139610543847084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0579347088932991,
      "backward_entropy": 0.006983412695782525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8873703479766846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051414184272289276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057891279458999634,
      "backward_entropy": 0.0069928525813988274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7476773858070374,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05143248289823532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05784643068909645,
      "backward_entropy": 0.00700151760663305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.133159875869751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0514494888484478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05780915915966034,
      "backward_entropy": 0.0070103577205113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4227426052093506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051466356962919235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05777227133512497,
      "backward_entropy": 0.007019756627934319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7772085666656494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05148260295391083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05773875489830971,
      "backward_entropy": 0.007029673882893154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0755152702331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05149930343031883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05770194157958031,
      "backward_entropy": 0.007040359612022128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033525995910167694,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05151586979627609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0576656199991703,
      "backward_entropy": 0.00705110707453319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.710452079772949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051530998200178146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05763687938451767,
      "backward_entropy": 0.007065638899803162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.341148614883423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05154651403427124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057606011629104614,
      "backward_entropy": 0.007077460842473167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.655540943145752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051562994718551636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0575689896941185,
      "backward_entropy": 0.007088921964168549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038843318819999695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05157984793186188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05752914771437645,
      "backward_entropy": 0.007100186177662441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2550621032714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159506946802139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05749884247779846,
      "backward_entropy": 0.007407309753554208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.484907150268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05161115154623985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057463373988866806,
      "backward_entropy": 0.0071210722838129315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.826709270477295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05162922292947769,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05741478130221367,
      "backward_entropy": 0.007133470049926213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.769887685775757,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05164822190999985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05736139044165611,
      "backward_entropy": 0.00714111647435597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045379504561424255,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166831985116005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05730061233043671,
      "backward_entropy": 0.007149680384567806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.251234531402588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05168629810214043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05725321173667908,
      "backward_entropy": 0.007155732384749821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.851063847541809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05170353502035141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05720935016870499,
      "backward_entropy": 0.007163471409252712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.604947328567505,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05172036960721016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057167984545230865,
      "backward_entropy": 0.007168566009828022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2150813341140747,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05173854902386665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057117052376270294,
      "backward_entropy": 0.007300364651850292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9586541652679443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05175590142607689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05707103759050369,
      "backward_entropy": 0.007185980677604675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3615736961364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05177377536892891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05702254921197891,
      "backward_entropy": 0.007192025227206094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1863675117492676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051791414618492126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056976642459630966,
      "backward_entropy": 0.007191698466028486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.43231463432312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05180807411670685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056937091052532196,
      "backward_entropy": 0.0071890684110777715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.721045970916748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05182565003633499,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056892409920692444,
      "backward_entropy": 0.0071832048041479924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3381052017211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184265226125717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05685202032327652,
      "backward_entropy": 0.007174768085990634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1222872734069824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05186084657907486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05680320784449577,
      "backward_entropy": 0.007170457925115313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7237539291381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05187823623418808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056758224964141846,
      "backward_entropy": 0.007169035396405629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6312845945358276,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051896266639232635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05670870840549469,
      "backward_entropy": 0.007170115730592183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6646018028259277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191389471292496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05666080117225647,
      "backward_entropy": 0.007172332278319767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5560861825942993,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05193202570080757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05661015957593918,
      "backward_entropy": 0.007174027817589896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0684196949005127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05194881558418274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05656708404421806,
      "backward_entropy": 0.007176335368837629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5748445987701416,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05196473374962807,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.056529708206653595,
      "backward_entropy": 0.09880965948104858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5522630214691162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05198129266500473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056488145142793655,
      "backward_entropy": 0.007178027715001788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.020789623260498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05199733003973961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0564504936337471,
      "backward_entropy": 0.006985185933964593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.020164966583252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05201355367898941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05641135573387146,
      "backward_entropy": 0.007174058684280941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9851080179214478,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052028998732566833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05637693032622337,
      "backward_entropy": 0.007172679794686181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9897550940513611,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05204448848962784,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05634268745779991,
      "backward_entropy": 0.09880243028913226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9361790418624878,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05205945670604706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056310564279556274,
      "backward_entropy": 0.0071689678089959285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4574918746948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05207464471459389,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056277014315128326,
      "backward_entropy": 0.007169508508273533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4936198592185974,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05208933725953102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056247636675834656,
      "backward_entropy": 0.0071651797209467205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.334254264831543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05210316926240921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05622240900993347,
      "backward_entropy": 0.0071654074958392554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7650091648101807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05211777612566948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056192055344581604,
      "backward_entropy": 0.007166262183870588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.82899808883667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05213348567485809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056154727935791016,
      "backward_entropy": 0.00716723022716386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3724594116210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052149448543787,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0561147965490818,
      "backward_entropy": 0.0987967848777771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3530234098434448,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05216500163078308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056078001856803894,
      "backward_entropy": 0.007173202931880951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4663127660751343,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05218026787042618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05604265630245209,
      "backward_entropy": 0.007175654172897339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8935515880584717,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052194517105817795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056013159453868866,
      "backward_entropy": 0.00718012239251818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8826183676719666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05220819637179375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055986784398555756,
      "backward_entropy": 0.007185016359601702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.295543909072876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222140625119209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05596292018890381,
      "backward_entropy": 0.0071913812841687885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44600725173950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05223458260297775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05593889579176903,
      "backward_entropy": 0.007198741393429893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.088731050491333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052246980369091034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05591902881860733,
      "backward_entropy": 0.007208458547081266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.482963800430298,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052260417491197586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055891379714012146,
      "backward_entropy": 0.00722244701215199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43266329169273376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05227503553032875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05585605651140213,
      "backward_entropy": 0.0072371384927204675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6368958950042725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052288707345724106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05582595616579056,
      "backward_entropy": 0.007252918822424752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.004356622695923,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05230255052447319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05579518526792526,
      "backward_entropy": 0.007265802472829819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6021498441696167,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05231718719005585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0557582750916481,
      "backward_entropy": 0.007281127784933362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1985352039337158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052331872284412384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05572184920310974,
      "backward_entropy": 0.007292913539069039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.335569143295288,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052346158772706985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05568818747997284,
      "backward_entropy": 0.007301220936434609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5436201095581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052361223846673965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055650435388088226,
      "backward_entropy": 0.007306071264403207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.152931809425354,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05237634852528572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05561196804046631,
      "backward_entropy": 0.007310618247304644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1456305980682373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05239109694957733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055575743317604065,
      "backward_entropy": 0.007314279675483704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8561064004898071,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05240536481142044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05554281920194626,
      "backward_entropy": 0.006593082632337298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.835340976715088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05242007598280907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055507414042949677,
      "backward_entropy": 0.007313663406031472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7420205473899841,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05243513360619545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05547027289867401,
      "backward_entropy": 0.006554971316031047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0784847736358643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05244943127036095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05543720722198486,
      "backward_entropy": 0.006535339568342481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7600626945495605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05246354267001152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05540456622838974,
      "backward_entropy": 0.007309290979589734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7379263639450073,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052478209137916565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05536790192127228,
      "backward_entropy": 0.0073114436651979175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37408435344696045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05249336361885071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05532746762037277,
      "backward_entropy": 0.0073152439934866765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3663053512573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250724405050278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05529545247554779,
      "backward_entropy": 0.007316260997738157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3515657186508179,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05252118036150932,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05526316165924072,
      "backward_entropy": 0.09882170813424247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3308758735656738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05253512039780617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05523097515106201,
      "backward_entropy": 0.00731552392244339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03685788810253143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05254913866519928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05519796162843704,
      "backward_entropy": 0.00731484591960907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9811893105506897,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052561599761247635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055175382643938065,
      "backward_entropy": 0.007311019514288221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6593585014343262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052573926746845245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055153511464595795,
      "backward_entropy": 0.007308198937347957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5834251642227173,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052585698664188385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055134668946266174,
      "backward_entropy": 0.007304987737110683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.257745623588562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05259805545210838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05511217564344406,
      "backward_entropy": 0.007301575371197292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.633677065372467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05261058732867241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05508854240179062,
      "backward_entropy": 0.007298190678868975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8312979936599731,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05262262746691704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055067628622055054,
      "backward_entropy": 0.007296467998198101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0955419540405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05263550952076912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055041469633579254,
      "backward_entropy": 0.007293650614363807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.906757116317749,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264973267912865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05500602349638939,
      "backward_entropy": 0.007294820887701852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1820054054260254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052663546055555344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05497324466705322,
      "backward_entropy": 0.006254877895116806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8896546959877014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05267736315727234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054940372705459595,
      "backward_entropy": 0.007296151880707059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8669688105583191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05269063264131546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05491197109222412,
      "backward_entropy": 0.007292950259787696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6882638931274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052703700959682465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05488414689898491,
      "backward_entropy": 0.007292305252381733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5738587975502014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05271757021546364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05485056713223457,
      "backward_entropy": 0.007292652236563819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1034576892852783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052730757743120193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.054821450263261795,
      "backward_entropy": 0.006172816668237958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5576493144035339,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052744060754776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05479127913713455,
      "backward_entropy": 0.0072960129805973595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3382433652877808,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05275677144527435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05476422980427742,
      "backward_entropy": 0.007300102284976414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0702966451644897,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05276995152235031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05473387986421585,
      "backward_entropy": 0.007305376763854708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7895340323448181,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052782975137233734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054705239832401276,
      "backward_entropy": 0.007306654538427081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7838085889816284,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05279581993818283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05467696487903595,
      "backward_entropy": 0.007310883275100163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5259230732917786,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05280837416648865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05465042591094971,
      "backward_entropy": 0.0073150694370269775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0091372728347778,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282030627131462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05462784692645073,
      "backward_entropy": 0.007318696273224694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5130960941314697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052832379937171936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054604142904281616,
      "backward_entropy": 0.007323084665196282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.223291039466858,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05284387245774269,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054584093391895294,
      "backward_entropy": 0.0073270212326731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4435492753982544,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05285588279366493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05456027761101723,
      "backward_entropy": 0.007331889654908862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49555179476737976,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05286870151758194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054530754685401917,
      "backward_entropy": 0.0073381683656147546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9510758519172668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05288080871105194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054506152868270874,
      "backward_entropy": 0.007342686078378132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1606426239013672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05289287492632866,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.054482124745845795,
      "backward_entropy": 0.09880639825548444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6924736499786377,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0529053658246994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05445494130253792,
      "backward_entropy": 0.09880685806274414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24424298107624054,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05291770398616791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05442773923277855,
      "backward_entropy": 0.00735546914594514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1227699518203735,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05292918160557747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05440564453601837,
      "backward_entropy": 0.007363167724439076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1022913455963135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05294090881943703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05438263714313507,
      "backward_entropy": 0.00736665991800172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6612246632575989,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05295300856232643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05435682833194733,
      "backward_entropy": 0.007370341569185257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0713684558868408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05296484753489494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05433250963687897,
      "backward_entropy": 0.007374640022005353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6434988975524902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0529770664870739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054305337369441986,
      "backward_entropy": 0.00737974579845156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021627983078360558,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05298900231719017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054279692471027374,
      "backward_entropy": 0.00738526029246194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43247154355049133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05299980938434601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05426052212715149,
      "backward_entropy": 0.007391899824142456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22209031879901886,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05300997197628021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05424651503562927,
      "backward_entropy": 0.007394406412328992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.418261855840683,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05301942676305771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05423644930124283,
      "backward_entropy": 0.007397140243223735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026224564760923386,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05302848666906357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0542290098965168,
      "backward_entropy": 0.0073990704757826665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5987274646759033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05303654819726944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054228127002716064,
      "backward_entropy": 0.007399275366749082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4014139473438263,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053044747561216354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05422571301460266,
      "backward_entropy": 0.007401246577501297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20533156394958496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053052790462970734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05422353744506836,
      "backward_entropy": 0.0074051666472639355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7682101726531982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053060490638017654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0542224645614624,
      "backward_entropy": 0.0074126869440078735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5759598016738892,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05306866765022278,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05421800911426544,
      "backward_entropy": 0.09881714412144252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1217883825302124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053076956421136856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05421227216720581,
      "backward_entropy": 0.007430896162986755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5639580488204956,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05308620259165764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05419982969760895,
      "backward_entropy": 0.007440827254738126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3826488256454468,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053095437586307526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05418711155653,
      "backward_entropy": 0.007451310753822327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3811468780040741,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05310423672199249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0541774146258831,
      "backward_entropy": 0.0074592142232826775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5459492206573486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053112562745809555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05417140573263168,
      "backward_entropy": 0.007462967719350543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3693365454673767,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312095209956169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05416441336274147,
      "backward_entropy": 0.00746759506208556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8878290057182312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312901362776756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054159484803676605,
      "backward_entropy": 0.007471013282026563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7009319067001343,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05313748121261597,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05415261536836624,
      "backward_entropy": 0.09882560798100062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3607288599014282,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314621701836586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05414368212223053,
      "backward_entropy": 0.007469926029443741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5169506669044495,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053154487162828445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054138168692588806,
      "backward_entropy": 0.007466513131346021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.510111927986145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316281318664551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05413154885172844,
      "backward_entropy": 0.0074650804911340985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3441813886165619,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053171224892139435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05412361025810242,
      "backward_entropy": 0.007466270455292293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.501086950302124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317934229969978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05411733314394951,
      "backward_entropy": 0.0074677403484072,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.0489601727016271,
    "avg_log_Z": -0.05261846952140331,
    "success_rate": 1.0,
    "avg_reward": 78.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.08,
      "1": 0.06,
      "2": 0.86
    },
    "avg_forward_entropy": 0.055111505873501304,
    "avg_backward_entropy": 0.014584680875497205,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}