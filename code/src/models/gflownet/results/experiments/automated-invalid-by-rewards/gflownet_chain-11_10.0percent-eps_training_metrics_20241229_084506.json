{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301187385212291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013989882036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.27008056640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138911962509155,
      "backward_entropy": 0.06301013448021629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.9759063720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138522545496623,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.94715881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00020012329332530499,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913810928662618,
      "backward_entropy": 0.06301082264293324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.91778564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0003003800520673394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137673179308574,
      "backward_entropy": 0.06301113692196933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.43795776367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00040071248076856136,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913722813129425,
      "backward_entropy": 0.06301307678222656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.13641357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004994482733309269,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136789043744405,
      "backward_entropy": 0.06301166252656416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.83065795898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005981327849440277,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136354923248291,
      "backward_entropy": 0.06301330436359752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.61019897460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006974528660066426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135918815930684,
      "backward_entropy": 0.06301194429397583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.74595642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007971323793753982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135461846987407,
      "backward_entropy": 0.06301196054978804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.459228515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008954705554060638,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09134999910990398,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.40948486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009950569365173578,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913452406724294,
      "backward_entropy": 0.06301198222420433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.99375915527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001094213454052806,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913403828938802,
      "backward_entropy": 0.06301336938684637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.072509765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011945152655243874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133542577425639,
      "backward_entropy": 0.06301336938684637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.324462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012961768079549074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133023023605347,
      "backward_entropy": 0.06301173296841708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.19737243652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013948146952316165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132497509320577,
      "backward_entropy": 0.06301168961958452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.27005004882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014952316414564848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131962060928345,
      "backward_entropy": 0.06301151622425426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.44113159179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015964072663336992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09131411711374919,
      "backward_entropy": 0.06301132115450772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.8167266845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016967479605227709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130859375,
      "backward_entropy": 0.06301109357313676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.903076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017963059945032,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130300084749858,
      "backward_entropy": 0.06301065466620705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8541717529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018940865993499756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129732847213745,
      "backward_entropy": 0.06301055171272972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.85293579101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00199226220138371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129152695337932,
      "backward_entropy": 0.0630102428522977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.19686889648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002088838955387473,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128564596176147,
      "backward_entropy": 0.06300990148024126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.52291870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00218593399040401,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127963582674663,
      "backward_entropy": 0.06300954927097667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.98423767089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00228039245121181,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127358595530193,
      "backward_entropy": 0.06300885027105158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0279083251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002373454859480262,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126743674278259,
      "backward_entropy": 0.06300841136412187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.05311584472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024666942190378904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126118818918864,
      "backward_entropy": 0.06300795620137994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.70306396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025578567292541265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125492970148723,
      "backward_entropy": 0.06300786408511075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8831329345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026483251713216305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124860167503357,
      "backward_entropy": 0.06300698627125133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.78939819335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002737918868660927,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124225378036499,
      "backward_entropy": 0.06300692124800249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.097412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002825681120157242,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123587608337402,
      "backward_entropy": 0.06301291964270851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.13424682617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029141362756490707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122935930887859,
      "backward_entropy": 0.0630059079690413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.98159790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003004194935783744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122264385223389,
      "backward_entropy": 0.06300542029467496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.55577087402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003093673614785075,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121585885683696,
      "backward_entropy": 0.06301280043341896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.33250427246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003182751825079322,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120903412501018,
      "backward_entropy": 0.06301277875900269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.55011749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003271298250183463,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120211998621623,
      "backward_entropy": 0.0630039085041393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.03273010253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003355223685503006,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119523564974467,
      "backward_entropy": 0.06301271915435791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.36228942871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034378725104033947,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911882718404134,
      "backward_entropy": 0.06301268664273349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.48016357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0035180803388357162,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118129809697469,
      "backward_entropy": 0.06300137259743431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.94068908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036001550033688545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911741554737091,
      "backward_entropy": 0.06300066276030107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.06700134277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003686352400109172,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911668340365092,
      "backward_entropy": 0.0630125945264643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.72128295898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00377488206140697,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115942319234212,
      "backward_entropy": 0.06299943273717706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.6985626220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003861993085592985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115199247996013,
      "backward_entropy": 0.06299877166748047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.5072479248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003947849851101637,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114455183347066,
      "backward_entropy": 0.0630126107822765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.94581604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004033559933304787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113699197769165,
      "backward_entropy": 0.06299726529554887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.77325439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004121784586459398,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091129203637441,
      "backward_entropy": 0.06299649585377086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.14117431640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004214518237859011,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112111727396648,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.24891662597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004311494529247284,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911128322283427,
      "backward_entropy": 0.06301267580552534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.59507751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004409493412822485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110434850056966,
      "backward_entropy": 0.06299534710970792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.19081115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004507250152528286,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109573562939961,
      "backward_entropy": 0.06299391117962924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.73724365234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004606412257999182,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108702341715495,
      "backward_entropy": 0.0630127950148149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.46145629882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004705389495939016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107822179794312,
      "backward_entropy": 0.06299329887736928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.8961639404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004800040274858475,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09106947978337605,
      "backward_entropy": 0.06299135901711204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.02249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004897317849099636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106031060218811,
      "backward_entropy": 0.06299141320315274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.4062957763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004991724621504545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091051052014033,
      "backward_entropy": 0.062989126552235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.97173309326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005083989817649126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104175368944804,
      "backward_entropy": 0.06298902901736173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.94073486328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0051726847887039185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103244543075562,
      "backward_entropy": 0.06298758766867897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.51527404785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005260608159005642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102285901705424,
      "backward_entropy": 0.06301245906136253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.28472900390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005350781138986349,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09101281563440959,
      "backward_entropy": 0.06301235068928111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4660186767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005445829126983881,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100223580996196,
      "backward_entropy": 0.06298300352963535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.9920196533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00553832808509469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099142750104268,
      "backward_entropy": 0.06298142129724676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.80406188964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005633722525089979,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0909801721572876,
      "backward_entropy": 0.06301211227070201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.30435180664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005726411938667297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096874793370564,
      "backward_entropy": 0.06297815929759633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.07974243164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005821892060339451,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09095690647761027,
      "backward_entropy": 0.06297466429797086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.86045837402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005918547976762056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09094471732775371,
      "backward_entropy": 0.06297475099563599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.42681884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006014920771121979,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909322698911031,
      "backward_entropy": 0.0629729140888561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.97940063476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006111149210482836,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09091959396998088,
      "backward_entropy": 0.06296933239156549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.44817352294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0062089888378977776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090669949849446,
      "backward_entropy": 0.06296912648461082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.90369415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0063023874536156654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09089382489522298,
      "backward_entropy": 0.06296696446158669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.99424743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0063890935853123665,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09088119864463806,
      "backward_entropy": 0.06296446106650612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.60731506347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006479319650679827,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09086825450261433,
      "backward_entropy": 0.06301144036379727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.90606689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006571638397872448,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09085532029469807,
      "backward_entropy": 0.06295962767167525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.12474822998047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00666683679446578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09084198872248332,
      "backward_entropy": 0.06301131031729958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.27860260009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006758163683116436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09082876642545064,
      "backward_entropy": 0.06295470757917924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1510009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006845664698630571,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09081556399663289,
      "backward_entropy": 0.06295048106800426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.58505249023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006932785734534264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908022125562032,
      "backward_entropy": 0.06294876878911798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.00942993164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00702207675203681,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09078848361968994,
      "backward_entropy": 0.06294437971982089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.2872772216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007112019695341587,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09077450633049011,
      "backward_entropy": 0.06301054629412564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.11981201171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007203630171716213,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09076013167699178,
      "backward_entropy": 0.06301041624762795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.36758422851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007299514953047037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09074523051579793,
      "backward_entropy": 0.06293658776716753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.63282775878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007398252375423908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073001146316528,
      "backward_entropy": 0.06293386762792413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.61963653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007494313642382622,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0907148818174998,
      "backward_entropy": 0.06293090907010165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9195556640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00758334482088685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0907000998655955,
      "backward_entropy": 0.06292666088451039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.08446502685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007670015562325716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09068518877029419,
      "backward_entropy": 0.06292288953607733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.58929443359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007751993834972382,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09067044655481975,
      "backward_entropy": 0.06300969557328658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.43521118164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007836625911295414,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09065521756807964,
      "backward_entropy": 0.06291459907184947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.43838500976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007922201417386532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063965082168579,
      "backward_entropy": 0.06291075186295943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.75396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008011778816580772,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09062361717224121,
      "backward_entropy": 0.06290662288665771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.22727966308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00809895433485508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060750404993693,
      "backward_entropy": 0.06290223381736061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.73387145996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008191120810806751,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09059077501296997,
      "backward_entropy": 0.06289865753867409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.62522888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008281182497739792,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09057408571243286,
      "backward_entropy": 0.06289386749267578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.74467468261719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008371168747544289,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09055739641189575,
      "backward_entropy": 0.06300848180597479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.75704956054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0084574269130826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905407468477885,
      "backward_entropy": 0.062885582447052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.93753051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008544597774744034,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09052392840385437,
      "backward_entropy": 0.06287995793602684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.81539916992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00863281637430191,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09050685167312622,
      "backward_entropy": 0.06300786408511075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.22286987304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008720513433218002,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09048959612846375,
      "backward_entropy": 0.06300762566653165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.50047302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008808203972876072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09047224124272664,
      "backward_entropy": 0.06286468289115212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.47703552246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008902410045266151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09045408169428508,
      "backward_entropy": 0.0628602071241899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.97472381591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00899523589760065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09043572346369426,
      "backward_entropy": 0.06285530870611017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.42604064941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009084511548280716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09041759371757507,
      "backward_entropy": 0.0628513206135143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.84977722167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009177591651678085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09039894739786784,
      "backward_entropy": 0.06284492124210704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.93063354492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009266507811844349,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09038034081459045,
      "backward_entropy": 0.06300683996894142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.67698669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009354713372886181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903615156809489,
      "backward_entropy": 0.06283323873173106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.85153198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009441128931939602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09034266074498494,
      "backward_entropy": 0.06282687729055231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0630645751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009527112357318401,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09032355745633443,
      "backward_entropy": 0.06282169710506093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.87169647216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009615343995392323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09030383825302124,
      "backward_entropy": 0.06281528689644554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.38414001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009698581881821156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09028437733650208,
      "backward_entropy": 0.06280598857186058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.83154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009783351793885231,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0902645190556844,
      "backward_entropy": 0.06300474296916615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.58606719970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009873730130493641,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09024386604626973,
      "backward_entropy": 0.06300450455058705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.52430725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00996022205799818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09022329250971477,
      "backward_entropy": 0.0627840215509588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.79708862304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010041645728051662,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09020290772120158,
      "backward_entropy": 0.06300352920185436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5258026123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010123410262167454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0901822845141093,
      "backward_entropy": 0.0627703449942849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.06664276123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01020526047796011,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09016138315200806,
      "backward_entropy": 0.06276187029751865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.8144989013672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010284212417900562,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09014054139455159,
      "backward_entropy": 0.0630016868764704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.87713623046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010361895896494389,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09011950095494588,
      "backward_entropy": 0.06274354457855225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.38429260253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010442118160426617,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09009808301925659,
      "backward_entropy": 0.06300031055103648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.16983032226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010528599843382835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09007569154103597,
      "backward_entropy": 0.06272162632508711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.50973510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01061656977981329,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0900529424349467,
      "backward_entropy": 0.06271803379058838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.8411407470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01070271898061037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09003015359242757,
      "backward_entropy": 0.06270939653570001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.65542602539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010790183208882809,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09000675876935323,
      "backward_entropy": 0.06270084597847679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.93743896484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010877660475671291,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08998312552769978,
      "backward_entropy": 0.06269214911894365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.27476501464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010970951057970524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0899585485458374,
      "backward_entropy": 0.06267947500402277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.42724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011067843995988369,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08993333578109741,
      "backward_entropy": 0.06267783858559349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.28873443603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011163177900016308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08990785479545593,
      "backward_entropy": 0.06267023086547852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.36170959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011254386976361275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08988253275553386,
      "backward_entropy": 0.06266144188967618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.44741821289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011348197236657143,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08985660473505656,
      "backward_entropy": 0.06299910762093285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.3473358154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011443992145359516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0898300011952718,
      "backward_entropy": 0.0629990967837247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.41839599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01154300943017006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08980260292689006,
      "backward_entropy": 0.06262990561398593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.28612518310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01164047047495842,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08977497617403667,
      "backward_entropy": 0.0626273209398443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.53244018554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011731027625501156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08974814414978027,
      "backward_entropy": 0.06261661919680508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.28639221191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011825264431536198,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08972035845120747,
      "backward_entropy": 0.06299853324890137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.2135772705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01192108727991581,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08969177802403767,
      "backward_entropy": 0.06259605017575351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.40151977539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012015676125884056,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08966295917828877,
      "backward_entropy": 0.06258510459553111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.0548095703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012112043797969818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08963341514269511,
      "backward_entropy": 0.06256819855083119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.2724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012203188613057137,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08960450688997905,
      "backward_entropy": 0.0625560771335255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.22450256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012291694059967995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08957536021868388,
      "backward_entropy": 0.06254284490238536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.75031280517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012377831153571606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08954598506291707,
      "backward_entropy": 0.06253434311259877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.52064514160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01246075052767992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08951672911643982,
      "backward_entropy": 0.0625192793932828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.30772399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012543910183012486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948707580566406,
      "backward_entropy": 0.062498710372231224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.93312072753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01263150293380022,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0894562304019928,
      "backward_entropy": 0.06248949874531139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.92381286621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012720503844320774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08942486842473348,
      "backward_entropy": 0.06299150531942194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.60365295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012813083827495575,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08939231435457866,
      "backward_entropy": 0.06245622851631858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.46607208251953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012910640798509121,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08935852845509847,
      "backward_entropy": 0.062990741296248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.44703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012999174185097218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893259048461914,
      "backward_entropy": 0.06242847442626953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.62832641601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013085450045764446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08929310242335002,
      "backward_entropy": 0.06241253289309415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.83233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013173255138099194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08925974369049072,
      "backward_entropy": 0.0624024976383556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.25830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0132605554535985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.089225967725118,
      "backward_entropy": 0.06238086115230213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.81900024414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013349060900509357,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08919166525204976,
      "backward_entropy": 0.06298667734319513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.2837677001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013438766822218895,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08915752172470093,
      "backward_entropy": 0.062354239550503815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.94252014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013527904637157917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0891230305035909,
      "backward_entropy": 0.0623375881801952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.38209533691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01361841894686222,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08908805251121521,
      "backward_entropy": 0.062320931391282516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.86007690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01370970718562603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08905243873596191,
      "backward_entropy": 0.06229998848655007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.205322265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013800041750073433,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08901641766230266,
      "backward_entropy": 0.06298320943659003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.36448669433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01389235258102417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08897937337557475,
      "backward_entropy": 0.062269069931723854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.97540283203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013983727432787418,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08894201119740804,
      "backward_entropy": 0.0622509934685447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.50028228759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014067043550312519,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890591065088908,
      "backward_entropy": 0.06298045678572221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.31565856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014147556386888027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08886947234471639,
      "backward_entropy": 0.06220747124065052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.12673950195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014228947460651398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08883244792620341,
      "backward_entropy": 0.06217828663912686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.18707275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014310541562736034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08879462877909343,
      "backward_entropy": 0.06216169487346302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.25889587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014391968958079815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08875599503517151,
      "backward_entropy": 0.06213819980621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.33322143554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014473851770162582,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08871673544247945,
      "backward_entropy": 0.06211433627388694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.3581085205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014556745067238808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08867709835370381,
      "backward_entropy": 0.062081347812305794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.87344360351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014638382010161877,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08863719304402669,
      "backward_entropy": 0.06205591288479892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.14834594726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014723817817866802,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0885960857073466,
      "backward_entropy": 0.06296804818240079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.1851043701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014810762368142605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08855409423510234,
      "backward_entropy": 0.062007801099257034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.37741088867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014896051026880741,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08851197361946106,
      "backward_entropy": 0.06199005517092618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.56236267089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014982759952545166,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08846887946128845,
      "backward_entropy": 0.06196437640623613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.553993225097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015070982277393341,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08842493096987407,
      "backward_entropy": 0.06296348571777344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.72886657714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015149557963013649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0883827805519104,
      "backward_entropy": 0.061900973320007324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.15836334228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015226216055452824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08834083875020345,
      "backward_entropy": 0.06187049909071489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.63430786132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01530066691339016,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08829883734385173,
      "backward_entropy": 0.061844722791151566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.57431030273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01537961233407259,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08825528621673584,
      "backward_entropy": 0.06181337616660378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.66876220703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01545662060379982,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08821193377176921,
      "backward_entropy": 0.06295276230031793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.1112976074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015538948588073254,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08816647529602051,
      "backward_entropy": 0.061749734661795876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.28175354003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01563342846930027,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08811736106872559,
      "backward_entropy": 0.06172503124583851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.28938293457031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015727045014500618,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08806785941123962,
      "backward_entropy": 0.06295161897485907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.76771545410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015815749764442444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0880194107691447,
      "backward_entropy": 0.06167034669355913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.42056274414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01590430736541748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08797043561935425,
      "backward_entropy": 0.06163940646431663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.27734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01599571481347084,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08792006969451904,
      "backward_entropy": 0.0629501234401356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.57957458496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016083547845482826,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08787007133165996,
      "backward_entropy": 0.06294928897510875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.88909912109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016172774136066437,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08781902988751729,
      "backward_entropy": 0.061547447334636345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.64572143554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01626455783843994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08776649832725525,
      "backward_entropy": 0.06151584603569724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.04205322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016354678198695183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08771409591039021,
      "backward_entropy": 0.06148252162066373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.98451232910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016442831605672836,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08766154448191325,
      "backward_entropy": 0.0629462491382252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.91606903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01653636433184147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08760643005371094,
      "backward_entropy": 0.06141391667452725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.22038269042969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01662314683198929,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08755286534627278,
      "backward_entropy": 0.06294426051053134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.0103759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016705216839909554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08750007549921672,
      "backward_entropy": 0.06133136966011741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.12168884277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01678784005343914,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0874465008576711,
      "backward_entropy": 0.061293152245608246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.32392120361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016875503584742546,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08739081025123596,
      "backward_entropy": 0.06293852762742476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.54045104980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01695861667394638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0873360534509023,
      "backward_entropy": 0.06120981953360818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.71662902832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017037881538271904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08728224039077759,
      "backward_entropy": 0.06116337125951594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.43257904052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017111437395215034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08722944060961406,
      "backward_entropy": 0.061113140799782494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0983123779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01718210242688656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08717730641365051,
      "backward_entropy": 0.06105848875912753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.89200592041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01725500449538231,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08712417880694072,
      "backward_entropy": 0.06100864843888716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.20053100585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0173267163336277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08707112073898315,
      "backward_entropy": 0.06095775690945712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.1305389404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017398368567228317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08701721827189128,
      "backward_entropy": 0.060905602845278656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.14672088623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0174699779599905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08696251114209493,
      "backward_entropy": 0.06084257364273071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.24436950683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017536401748657227,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08690852920214336,
      "backward_entropy": 0.06290663372386586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.49422454833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01760825887322426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08685208360354106,
      "backward_entropy": 0.0607368295842951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.4535369873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017676936462521553,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0867965817451477,
      "backward_entropy": 0.06066375428980047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.44625854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01774960570037365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08673961957295735,
      "backward_entropy": 0.06061975522474809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.58428955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017825499176979065,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08668103814125061,
      "backward_entropy": 0.06054675579071045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.25927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01790563017129898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08662042021751404,
      "backward_entropy": 0.06050846251574429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.32865905761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0179850272834301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0865593949953715,
      "backward_entropy": 0.06043337691913952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018062274903059006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08649858832359314,
      "backward_entropy": 0.06039234724911777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.2189483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01813860423862934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08643706639607747,
      "backward_entropy": 0.06032944809306751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.04476165771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018215976655483246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08637496829032898,
      "backward_entropy": 0.060265524820847946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.76546478271484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018291795626282692,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08631334702173869,
      "backward_entropy": 0.06287367777390913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.36244201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018362684175372124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08625322580337524,
      "backward_entropy": 0.06011194532567805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.96331787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0184343159198761,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08619256814320882,
      "backward_entropy": 0.06006260351701216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.67137908935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018509244546294212,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08612978458404541,
      "backward_entropy": 0.059972589666193184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.2044219970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018578961491584778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08606818318367004,
      "backward_entropy": 0.059922131625088776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.20437622070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01865379326045513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08600401878356934,
      "backward_entropy": 0.05982830307700417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.22308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018725719302892685,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08594075838724773,
      "backward_entropy": 0.06284970045089722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.61154174804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018801067024469376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08587552110354106,
      "backward_entropy": 0.05970869822935625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.33407592773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018874363973736763,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08581019441286723,
      "backward_entropy": 0.06284266168420966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.5328369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018949097022414207,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08574344714482625,
      "backward_entropy": 0.05952942371368408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.17430114746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019025376066565514,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08567546804745992,
      "backward_entropy": 0.06283568252216686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.95185089111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0190949197858572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08560962478319804,
      "backward_entropy": 0.05939593098380349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.25534057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019163144752383232,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08554353316624959,
      "backward_entropy": 0.059283083135431465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.58644104003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01923360675573349,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08547585209210713,
      "backward_entropy": 0.06282036954706366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.71712493896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01931079849600792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08540470401446025,
      "backward_entropy": 0.05911682952534069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.34707641601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019385922700166702,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0853336751461029,
      "backward_entropy": 0.05903261358087713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.5325469970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019465576857328415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08525995413462321,
      "backward_entropy": 0.05897656354037198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.43289184570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019544692710042,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0851859450340271,
      "backward_entropy": 0.06280855699018999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3445587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019626455381512642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0851099689801534,
      "backward_entropy": 0.05880907448855313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.89984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01970747672021389,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08503371477127075,
      "backward_entropy": 0.06280390240929344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.8044891357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019787965342402458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08495724201202393,
      "backward_entropy": 0.05863238464702259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.0369873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01986798271536827,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08488047122955322,
      "backward_entropy": 0.05853963440114802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.68540954589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019948842003941536,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08480246861775716,
      "backward_entropy": 0.06279292973605069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.5975341796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020027436316013336,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08472488323847453,
      "backward_entropy": 0.06278845396908847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.78579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020104000344872475,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08464760581652324,
      "backward_entropy": 0.058236019177870316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.50794982910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020173335447907448,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08457271258036296,
      "backward_entropy": 0.05813404646786777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.33647918701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020246392115950584,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08449541529019673,
      "backward_entropy": 0.06277031790126454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.59365844726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020317990332841873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08441829681396484,
      "backward_entropy": 0.057908795096657494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.94049072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020388159900903702,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08434111873308818,
      "backward_entropy": 0.057795134457674896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.34225463867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02046036161482334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0842621922492981,
      "backward_entropy": 0.05768165805123069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.7199249267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020532116293907166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08418227235476176,
      "backward_entropy": 0.05756105618043379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.60684204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02060576342046261,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08410086234410603,
      "backward_entropy": 0.05745187672701749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.37008666992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020681118592619896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08401802182197571,
      "backward_entropy": 0.0573204213922674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.34718322753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020762760192155838,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08393149574597676,
      "backward_entropy": 0.05720684745094993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.77476501464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020845673978328705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08384416500727336,
      "backward_entropy": 0.05712056701833552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.029296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020927470177412033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08375651637713115,
      "backward_entropy": 0.057008309797807175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.42655944824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021005073562264442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08367023865381877,
      "backward_entropy": 0.05684950134970925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.90589141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02107812836766243,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0835866133371989,
      "backward_entropy": 0.05675868554548784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.53973388671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021145140752196312,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08350588877995808,
      "backward_entropy": 0.06270143660632047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.10982513427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021216729655861855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08342194557189941,
      "backward_entropy": 0.05644818869504062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.55300903320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0212870966643095,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08333771427472432,
      "backward_entropy": 0.06268647584048184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.09385681152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021359190344810486,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08325121800104777,
      "backward_entropy": 0.06267962130633267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.47663116455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021432971581816673,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0831629087527593,
      "backward_entropy": 0.05603950673883611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.43997192382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02150546759366989,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08307483792304993,
      "backward_entropy": 0.06266777081923051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.32737731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021578481420874596,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0829860270023346,
      "backward_entropy": 0.05579818378795277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.4273223876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021651970222592354,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08289649089177449,
      "backward_entropy": 0.055656996640292083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.42550659179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021733682602643967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08280175924301147,
      "backward_entropy": 0.05548012798482722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.23660278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021814486011862755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08270654579003651,
      "backward_entropy": 0.05534095113927668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.19039916992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021888935938477516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08261534571647644,
      "backward_entropy": 0.05519405820152976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.07212829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02196487970650196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08252225816249847,
      "backward_entropy": 0.05510370297865434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.61880493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02203923650085926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08242949843406677,
      "backward_entropy": 0.05488736521114002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.59136199951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022113969549536705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08233611782391866,
      "backward_entropy": 0.05472985180941495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.11289978027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022181930020451546,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08224587639172871,
      "backward_entropy": 0.05463658679615368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.88546752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02224731631577015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08215638995170593,
      "backward_entropy": 0.05438410693948919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.43582153320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022312987595796585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0820649911959966,
      "backward_entropy": 0.05429688908837058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.747501373291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022381875663995743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08197175463040669,
      "backward_entropy": 0.0540266903963956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.64389038085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02244393341243267,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08188323179880778,
      "backward_entropy": 0.05394963242790916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.83786010742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022512272000312805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08179021378358205,
      "backward_entropy": 0.05366576801646839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.70487976074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022586490958929062,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08169335126876831,
      "backward_entropy": 0.05349621447649869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.15524291992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022658728063106537,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08159639437993367,
      "backward_entropy": 0.06256435134194115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.17471313476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0227362047880888,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0814957320690155,
      "backward_entropy": 0.05314363674684004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.13209533691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022811902686953545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0813956360022227,
      "backward_entropy": 0.052963787859136406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.12388610839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022892368957400322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08129199345906575,
      "backward_entropy": 0.05278767238963734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.97218322753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022969480603933334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08119043707847595,
      "backward_entropy": 0.052605022083629265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.13975524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02304319478571415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08109041055043538,
      "backward_entropy": 0.05258532003922896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.18496704101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023116955533623695,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0809888889392217,
      "backward_entropy": 0.06253311308947476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.71923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023196974769234657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08088230590025584,
      "backward_entropy": 0.05222368240356445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.10359191894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023283084854483604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08077156047026317,
      "backward_entropy": 0.05205540765415539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.32456970214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0233635064214468,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08066441118717194,
      "backward_entropy": 0.05165160786021839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.15630340576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023444967344403267,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08055583635965984,
      "backward_entropy": 0.05168991197239269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.27115631103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023526225239038467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08044728636741638,
      "backward_entropy": 0.05126029794866389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.86465454101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023605648428201675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08033985396226247,
      "backward_entropy": 0.05106031894683838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.93714904785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023685093969106674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08023235201835632,
      "backward_entropy": 0.050858882340517914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.49272918701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023762524127960205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08012551069259644,
      "backward_entropy": 0.0509261434728449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.31695556640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023838277906179428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0800193299849828,
      "backward_entropy": 0.050434248013929886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.96662902832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02392013743519783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799081822236379,
      "backward_entropy": 0.05022429878061468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.30433654785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02400192990899086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07979731261730194,
      "backward_entropy": 0.050333933396772904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.32508850097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024084562435746193,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07968514164288838,
      "backward_entropy": 0.04979959401217374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.79280853271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024165283888578415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07957425713539124,
      "backward_entropy": 0.049584773453799164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.04070281982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024244040250778198,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0794645647207896,
      "backward_entropy": 0.04971382292834195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.90776062011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024319365620613098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07935657103856404,
      "backward_entropy": 0.04949156804518266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.35215759277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024393543601036072,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07924943665663402,
      "backward_entropy": 0.04926705360412598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.83197021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02446836605668068,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07914196948210399,
      "backward_entropy": 0.049042885953729805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.78457641601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02454645000398159,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07903158664703369,
      "backward_entropy": 0.04844331741333008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.94194030761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024620046839118004,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0789247453212738,
      "backward_entropy": 0.04859192804856734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.34197235107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024692457169294357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07881833116213481,
      "backward_entropy": 0.04796327244151722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.80348205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024760190397500992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07871435085932414,
      "backward_entropy": 0.048112739216197624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.60250091552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024835357442498207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07860492666562398,
      "backward_entropy": 0.04746388305317272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.52413177490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024907279759645462,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07849717140197754,
      "backward_entropy": 0.06237524747848511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.44825744628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024975253269076347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07839253544807434,
      "backward_entropy": 0.04694782062010332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.14097595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025045862421393394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07828575372695923,
      "backward_entropy": 0.04668893055482344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.4693603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025118472054600716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07817673186461131,
      "backward_entropy": 0.046888952905481514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.48702239990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025186972692608833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07807084918022156,
      "backward_entropy": 0.046162410215897995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.35774993896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025256432592868805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07796411216259003,
      "backward_entropy": 0.04637565937909213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.87158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025323938578367233,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07785923779010773,
      "backward_entropy": 0.04611520875583996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.04248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02539266087114811,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07775347431500752,
      "backward_entropy": 0.04535912112756209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.25755310058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025460951030254364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07764774560928345,
      "backward_entropy": 0.04559605771845037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.21472930908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025530537590384483,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07754102349281311,
      "backward_entropy": 0.062278319488872184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.79739379882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025600792840123177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07743328809738159,
      "backward_entropy": 0.04454854130744934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.86710357666016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02566765807569027,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0773290346066157,
      "backward_entropy": 0.06225893714211204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.7577362060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0257286224514246,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07722798983256023,
      "backward_entropy": 0.04452698610045693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.36805725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025794751942157745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0771231750647227,
      "backward_entropy": 0.04368484833023765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.52529907226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025863364338874817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07701580226421356,
      "backward_entropy": 0.043395703489130195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.80000305175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025934984907507896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07690668106079102,
      "backward_entropy": 0.04311465133320202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.43675231933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026007788255810738,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07679732143878937,
      "backward_entropy": 0.04345981641249223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.48069763183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026076391339302063,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07669103642304738,
      "backward_entropy": 0.04318720644170588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.46154022216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02615083009004593,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658046980698903,
      "backward_entropy": 0.04227069833061912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.23287200927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026226582005620003,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07647019624710083,
      "backward_entropy": 0.04266899824142456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.96575927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02629956044256687,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07636209825674693,
      "backward_entropy": 0.04239840128205039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.23443603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026378324255347252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07625013589859009,
      "backward_entropy": 0.04214171387932517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.13325500488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026447810232639313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0761458029349645,
      "backward_entropy": 0.041165861216458405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.58500671386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026517236605286598,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07604211072127025,
      "backward_entropy": 0.0415871414271268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.48307418823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026585083454847336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07594020167986552,
      "backward_entropy": 0.040598305788907135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.85218811035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026648035272955894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07584235072135925,
      "backward_entropy": 0.040304937145926735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.08999633789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02671736106276512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07573923468589783,
      "backward_entropy": 0.040020628408952194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.71066284179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02678810805082321,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07563544313112895,
      "backward_entropy": 0.040469399907372215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.79617691040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026861922815442085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07553004225095113,
      "backward_entropy": 0.03946616703813726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.26656341552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026929927989840508,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07542874415715535,
      "backward_entropy": 0.03991374102505771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.57202911376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026997487992048264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07532741626103719,
      "backward_entropy": 0.038875780322334984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.15707397460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02706376276910305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07522787153720856,
      "backward_entropy": 0.03932555697181008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.95779418945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027134636417031288,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07512485980987549,
      "backward_entropy": 0.038285943594845856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.65847778320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02720901183784008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07502066095670064,
      "backward_entropy": 0.03800842436877164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.073097229003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02727954462170601,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07491963108380635,
      "backward_entropy": 0.037721904841336334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.93135070800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02734469622373581,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07482238113880157,
      "backward_entropy": 0.037420993501489815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.65234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027404502034187317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0747280369202296,
      "backward_entropy": 0.037103707140142266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.87794494628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027463383972644806,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07463438312212627,
      "backward_entropy": 0.03678316419774836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.63384246826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027522869408130646,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07454005877176921,
      "backward_entropy": 0.062051019885323265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.33683776855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02757866121828556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07444935043652852,
      "backward_entropy": 0.03613723949952559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02763231471180916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0743600328763326,
      "backward_entropy": 0.03580796447667209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.93874740600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02768895775079727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07426842053731282,
      "backward_entropy": 0.03548642180182717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.43695068359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02774135023355484,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07417941093444824,
      "backward_entropy": 0.061972200870513916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.86071014404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02779856137931347,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07408736149470012,
      "backward_entropy": 0.035660185597159645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.01182556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027856674045324326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07399465640385945,
      "backward_entropy": 0.034506461837074974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.27831268310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027917535975575447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07390059034029643,
      "backward_entropy": 0.03419091755693609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.89553833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027979103848338127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0738062063852946,
      "backward_entropy": 0.0338755493814295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.98295593261719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02803991548717022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07371291518211365,
      "backward_entropy": 0.06190568750554865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1139373779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028103521093726158,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07361852129300435,
      "backward_entropy": 0.06189696355299516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.69204711914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028172442689538002,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0735209087530772,
      "backward_entropy": 0.06189454685557972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.14164733886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02824273891746998,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07342241704463959,
      "backward_entropy": 0.03266632556915283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.1423797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028313016518950462,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07332458098729451,
      "backward_entropy": 0.03237277269363403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.32626342773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028386086225509644,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07322489718596141,
      "backward_entropy": 0.033019672740589485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.47308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02845914475619793,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07312644024689992,
      "backward_entropy": 0.06189226020466198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.53660583496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028538241982460022,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07302448650201161,
      "backward_entropy": 0.03151630000634627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.42893981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02861838787794113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07292316854000092,
      "backward_entropy": 0.031246439977125687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.24400329589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028694048523902893,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07282503445943196,
      "backward_entropy": 0.031948495994914665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.79051208496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028767092153429985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07272860904534657,
      "backward_entropy": 0.03166583180427551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.430660247802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028844600543379784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0726296603679657,
      "backward_entropy": 0.03038616884838451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.67812728881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028916282579302788,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07253483931223552,
      "backward_entropy": 0.030089595101096413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.73686981201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028983116149902344,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07244412104288737,
      "backward_entropy": 0.030819833278656006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.19217681884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029046112671494484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07235751549402873,
      "backward_entropy": 0.02948296070098877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.68310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029109884053468704,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07227076093355815,
      "backward_entropy": 0.030232120643962513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.45162200927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029177775606513023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07218180100123088,
      "backward_entropy": 0.02889377149668607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.40089416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02924938127398491,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07209150989850362,
      "backward_entropy": 0.029685673388567837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.02234649658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029322339221835136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07200063268343608,
      "backward_entropy": 0.028341174125671387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.64624786376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029395395889878273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07191047072410583,
      "backward_entropy": 0.028067594224756413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.38536071777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029464270919561386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0718221515417099,
      "backward_entropy": 0.02777615731412714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.26081848144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029530785977840424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07173674305280049,
      "backward_entropy": 0.027486806566065006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.64868927001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029601240530610085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07164976994196574,
      "backward_entropy": 0.028332507068460636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.94301986694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029668845236301422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07156533002853394,
      "backward_entropy": 0.028057743202556263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.78871154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029730599373579025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07148532072703044,
      "backward_entropy": 0.02663742412220348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.7435073852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02979193441569805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07140612602233887,
      "backward_entropy": 0.026346591385928066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.79853820800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029851021245121956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07132814327875774,
      "backward_entropy": 0.02605192498727278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.60697174072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029909364879131317,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07125259439150493,
      "backward_entropy": 0.02691714330153032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.02760314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02997211180627346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07117408514022827,
      "backward_entropy": 0.026648277586156673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.444583892822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030040815472602844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07109248141447704,
      "backward_entropy": 0.025235243818976662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.22679138183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030105365440249443,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07101401686668396,
      "backward_entropy": 0.026136165315454655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.15204620361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03017248772084713,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07093462347984314,
      "backward_entropy": 0.025882254947315563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.87638854980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03024282120168209,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07085286577542622,
      "backward_entropy": 0.02563118663701144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.39485168457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030309034511446953,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07077451050281525,
      "backward_entropy": 0.02537249435078014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.12376403808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030377833172678947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07069551944732666,
      "backward_entropy": 0.02391041950746016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.25392150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0304523054510355,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.070614293217659,
      "backward_entropy": 0.024885001507672398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.05897521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03052743524312973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0705341746409734,
      "backward_entropy": 0.023431374268098312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.200767517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03060724586248398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07045217355092366,
      "backward_entropy": 0.023205429315567017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.52291107177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03068210557103157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07037396728992462,
      "backward_entropy": 0.022972497073086826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.55442810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03076010011136532,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07029447952906291,
      "backward_entropy": 0.02399363030086864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.01029205322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030835233628749847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07021815578142802,
      "backward_entropy": 0.022516134110364048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.75215911865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030910424888134003,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07014186680316925,
      "backward_entropy": 0.022287555716254494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.69664001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030984200537204742,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07006705303986867,
      "backward_entropy": 0.02205765653740276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.240388870239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031055105850100517,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06999433040618896,
      "backward_entropy": 0.023102115501057018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.47284698486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03111918643116951,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06992662946383159,
      "backward_entropy": 0.021584562279961327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.48407745361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03118363581597805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06985986232757568,
      "backward_entropy": 0.02135451544414867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.4365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031247461214661598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06979315479596455,
      "backward_entropy": 0.02112088284709237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.12999725341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031311482191085815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06972727676232655,
      "backward_entropy": 0.02089275826107372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.21641540527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0313749723136425,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06966147820154826,
      "backward_entropy": 0.021962648088281803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.97299194335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03143724799156189,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06959735850493114,
      "backward_entropy": 0.021740394559773533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.40963745117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03150620684027672,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06953072051207225,
      "backward_entropy": 0.02022380855950442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.44635772705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03158273547887802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0694613258043925,
      "backward_entropy": 0.02003304660320282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.75074768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03165839985013008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06939347585042317,
      "backward_entropy": 0.019844051111828197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.24610900878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031731586903333664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06932765245437622,
      "backward_entropy": 0.019649291580373592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.78286743164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03180879354476929,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06926068663597107,
      "backward_entropy": 0.01946406608278101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.25313949584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03188890218734741,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0691921313603719,
      "backward_entropy": 0.019277136434208263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.49132537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031962815672159195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06912730137507121,
      "backward_entropy": 0.019078793850812046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.47865295410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03203743323683739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06906268497308095,
      "backward_entropy": 0.02024355395273729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.34465026855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03210928663611412,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06899950901667277,
      "backward_entropy": 0.018683000044389206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.38639068603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03218499571084976,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06893522540728252,
      "backward_entropy": 0.019866631789640946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.44766998291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03225969895720482,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06887179613113403,
      "backward_entropy": 0.019682599739594894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.65333557128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03233327344059944,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06880908211072286,
      "backward_entropy": 0.019496411085128784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.94689178466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03240644931793213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06874748071034749,
      "backward_entropy": 0.017915831370787186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.04070281982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03247782588005066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06868788599967957,
      "backward_entropy": 0.01773088357665322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.11436462402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03255028277635574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06862837076187134,
      "backward_entropy": 0.01896259053186937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.65142822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03262057155370712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06857022643089294,
      "backward_entropy": 0.017365832220424305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.94712448120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032688215374946594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06851268808046977,
      "backward_entropy": 0.017171718857505104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.17174530029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327521488070488,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06845694780349731,
      "backward_entropy": 0.016969776966355064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.15432739257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03281617909669876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06840114792188008,
      "backward_entropy": 0.016770215197042984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.20033264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03288201242685318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0683445433775584,
      "backward_entropy": 0.016577422618865967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.53879165649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032951053231954575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06828694542249043,
      "backward_entropy": 0.01786518774249337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.27716827392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033015478402376175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06823218365510304,
      "backward_entropy": 0.016207268292253666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.34785461425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308270499110222,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06817612051963806,
      "backward_entropy": 0.01602004332975908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.53229522705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03315148875117302,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06811992327372234,
      "backward_entropy": 0.015837934884158047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.81094360351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03321891278028488,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06806505719820659,
      "backward_entropy": 0.017175398089668968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.03775024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033286355435848236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06801057855288188,
      "backward_entropy": 0.015481482852589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.33302307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033356718719005585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06795523564020793,
      "backward_entropy": 0.015309629115191374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.35818481445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03342863544821739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06790005167325337,
      "backward_entropy": 0.01669685948978771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.64311981201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0335000604391098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06784538924694061,
      "backward_entropy": 0.0149779428135265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.90282440185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03356851637363434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06779307126998901,
      "backward_entropy": 0.016401507637717506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.51395416259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03363853693008423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06774017214775085,
      "backward_entropy": 0.014654441313310103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.57665252685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033710211515426636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06768726309140523,
      "backward_entropy": 0.014502518556334755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.385135650634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033783044666051865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06763400634129842,
      "backward_entropy": 0.01600054990161549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.79436492919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033851053565740585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06758305927117665,
      "backward_entropy": 0.014197126030921936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.15457916259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0339239276945591,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06753089030583699,
      "backward_entropy": 0.01574081453410062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.79891967773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03399622440338135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06747937202453613,
      "backward_entropy": 0.013907120986418291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.43205261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03406824916601181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06742813686529796,
      "backward_entropy": 0.013762853362343529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.42994689941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03414289280772209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06737600266933441,
      "backward_entropy": 0.013621351935646751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.00325775146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034219566732645035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0673230489095052,
      "backward_entropy": 0.01347920840436762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.60301971435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03429710865020752,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06727028886477153,
      "backward_entropy": 0.013340268622745167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.76014709472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034376855939626694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06721719106038411,
      "backward_entropy": 0.013205213980241255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.57754135131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034455765038728714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06716485818227132,
      "backward_entropy": 0.014918365261771462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.13029098510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03452920541167259,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0671146810054779,
      "backward_entropy": 0.014801259745251049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.56165313720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03459928557276726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06706608335177104,
      "backward_entropy": 0.012790212577039545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.265296936035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03466800972819328,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06701842943827312,
      "backward_entropy": 0.01456570489840074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.94704055786133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03473575785756111,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06697179873784383,
      "backward_entropy": 0.01445333795113997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.74183654785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03479956462979317,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06692702571551006,
      "backward_entropy": 0.014340457591143522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.77262878417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03486412391066551,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06688215335210164,
      "backward_entropy": 0.014230943538925865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.2894287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034929051995277405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06683673461278279,
      "backward_entropy": 0.012117479335178028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.62813949584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03499791398644447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06679051617781322,
      "backward_entropy": 0.011994340203025124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.32950973510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035062700510025024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0667461355527242,
      "backward_entropy": 0.011868449774655428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.06275177001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03512711822986603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06670236090819041,
      "backward_entropy": 0.013824695890600031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.06574249267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035191986709833145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06665807962417603,
      "backward_entropy": 0.013726742430166765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.61042785644531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03526192530989647,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06661243736743927,
      "backward_entropy": 0.06209852478720925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.96580123901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035334158688783646,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06656692425409953,
      "backward_entropy": 0.013555415652014992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.16411590576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03540239855647087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06652315457661946,
      "backward_entropy": 0.011298545382239601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.83620071411133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03547108545899391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06647944450378418,
      "backward_entropy": 0.011191796850074421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.47918701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03553605452179909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06643740336100261,
      "backward_entropy": 0.011084266684272072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.44526672363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03560042008757591,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06639549136161804,
      "backward_entropy": 0.013225856152447786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.01301956176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035664044320583344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06635368863741557,
      "backward_entropy": 0.0108706226403063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.21472930908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035725608468055725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06631260613600413,
      "backward_entropy": 0.010762741619890387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.643680572509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03578857332468033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06627136468887329,
      "backward_entropy": 0.0129800560799512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.62995147705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03584795817732811,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06623116632302602,
      "backward_entropy": 0.010559785095128145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.40010070800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03590768948197365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06619130571683247,
      "backward_entropy": 0.010461588474837217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.50963592529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035967953503131866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06615158915519714,
      "backward_entropy": 0.010370315475897356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.56163024902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036028195172548294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06611201167106628,
      "backward_entropy": 0.010279790921644731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.375343322753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036089733242988586,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06607197721799214,
      "backward_entropy": 0.012610023671930487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.91983413696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036150846630334854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06603188812732697,
      "backward_entropy": 0.010096201165155931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.91875457763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03621230274438858,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06599223613739014,
      "backward_entropy": 0.010008144107731905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.68941497802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0362737774848938,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06595270832379659,
      "backward_entropy": 0.009921652349558744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.65620422363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036338478326797485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06591236591339111,
      "backward_entropy": 0.012351366606625643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.721187591552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03640429303050041,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06587198376655579,
      "backward_entropy": 0.009765501049431887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.841719627380371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03646782413125038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0658320685227712,
      "backward_entropy": 0.009682644497264515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.75979232788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03652479127049446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0657937228679657,
      "backward_entropy": 0.009590618989684364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.06581115722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657596558332443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06575682759284973,
      "backward_entropy": 0.009492981162938204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.55818176269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0366295650601387,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06571924686431885,
      "backward_entropy": 0.012013215910304676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.82940673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036689624190330505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06568014621734619,
      "backward_entropy": 0.00931510329246521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.43382263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036751050502061844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06564019123713176,
      "backward_entropy": 0.009231427853757685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.4569320678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03681529685854912,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06559912363688152,
      "backward_entropy": 0.01182884926145727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.741153717041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03688060864806175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06555790205796559,
      "backward_entropy": 0.009070080112327229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.8770980834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03694401681423187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06551734109719594,
      "backward_entropy": 0.008988922292535955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.94039154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037009984254837036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06547599037488301,
      "backward_entropy": 0.008908474309877916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.02513885498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03707687929272652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06543437639872234,
      "backward_entropy": 0.008828105574304407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.10615539550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03714333474636078,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0653930405775706,
      "backward_entropy": 0.011532249775799837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.66404724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037208300083875656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06535268823305766,
      "backward_entropy": 0.008675292134284973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.29725646972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03727727010846138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06531099478403728,
      "backward_entropy": 0.008605780926617708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.65447235107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037346724420785904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06526889403661092,
      "backward_entropy": 0.00853516161441803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.116920471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037418182939291,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06522627174854279,
      "backward_entropy": 0.008465844121846285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.72383117675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03748612478375435,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06518495579560597,
      "backward_entropy": 0.011290819130160591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.95460510253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037554774433374405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06514347592989604,
      "backward_entropy": 0.008329340002753517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.995227813720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03762296959757805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06510189175605774,
      "backward_entropy": 0.01120282235470685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.396867752075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03768746182322502,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06506125132242839,
      "backward_entropy": 0.011154858903451399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.18057250976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03774743154644966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06502207120259602,
      "backward_entropy": 0.01110430739142678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.06979370117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03781358152627945,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06498181819915771,
      "backward_entropy": 0.011063711887056177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.652587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037884753197431564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0649397224187851,
      "backward_entropy": 0.007999835366552526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.8557357788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037956446409225464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06489727894465129,
      "backward_entropy": 0.0109885267236016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.854148864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03802980110049248,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06485427916049957,
      "backward_entropy": 0.007879733361981132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.00433349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038102541118860245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06481170654296875,
      "backward_entropy": 0.007824598388238386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.202016830444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038176003843545914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06476911902427673,
      "backward_entropy": 0.0077735903588208284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.49552536010742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03824542835354805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06472766896088918,
      "backward_entropy": 0.010860722173344006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.28607940673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03831421211361885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06468655665715535,
      "backward_entropy": 0.007662713527679443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.08751678466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03838935121893883,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06464321911334991,
      "backward_entropy": 0.010798152874816547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.679841995239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03846370428800583,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06460026899973552,
      "backward_entropy": 0.010774227705868807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.15044403076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03853455185890198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06455858051776886,
      "backward_entropy": 0.0075153363021937284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.733707427978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0386088490486145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0645159383614858,
      "backward_entropy": 0.010734033855524931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.552734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038683634251356125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06447330117225647,
      "backward_entropy": 0.06246057423678311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.44603729248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038757264614105225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0644310712814331,
      "backward_entropy": 0.01069781251929023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.23856735229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03882961720228195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06438892086346944,
      "backward_entropy": 0.007335752248764038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.129194259643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03889979049563408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06434736649195354,
      "backward_entropy": 0.007289556617086584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.95671081542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038966815918684006,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06430681049823761,
      "backward_entropy": 0.010633003305305134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.114238739013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039033401757478714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06426611542701721,
      "backward_entropy": 0.0072005309841849585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.29090881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03909553214907646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06422643860181172,
      "backward_entropy": 0.0071545290676030245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.69675827026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916175663471222,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06418557465076447,
      "backward_entropy": 0.007108798758550124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.693187713623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03922620788216591,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06414501865704854,
      "backward_entropy": 0.010544709861278534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.05068588256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03928810730576515,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06410524249076843,
      "backward_entropy": 0.007018168541518125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.09498596191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03935137763619423,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06406499445438385,
      "backward_entropy": 0.06253467906605113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.2059440612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039420343935489655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06402278939882915,
      "backward_entropy": 0.006931853565302762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.11176300048828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03948744013905525,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06398119529088338,
      "backward_entropy": 0.06254942308772694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.64908218383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0395527146756649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0639398843050003,
      "backward_entropy": 0.010443180799484253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.53572082519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03961358219385147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06389989455540974,
      "backward_entropy": 0.00680138035254045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.31842041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039674606174230576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06385965645313263,
      "backward_entropy": 0.01039184494452043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.69255447387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03973628580570221,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06381918986638387,
      "backward_entropy": 0.006715575402433222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.53864669799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03979649767279625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06377901633580525,
      "backward_entropy": 0.0066726275465705176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.882427215576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03985568508505821,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06373871862888336,
      "backward_entropy": 0.010326112535866823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.31121063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03991261124610901,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0636990914742152,
      "backward_entropy": 0.006588212468407371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.64401245117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03997195512056351,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06365882853666942,
      "backward_entropy": 0.01028777929869565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.08090591430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040037453174591064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06361652414004008,
      "backward_entropy": 0.006516743790019642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.020782470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040101557970047,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06357462207476298,
      "backward_entropy": 0.010267289524728601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.88010025024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040164001286029816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06353283921877544,
      "backward_entropy": 0.006446887146342884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.16426086425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04022516310214996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0634912649790446,
      "backward_entropy": 0.006409261714328419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.99202346801758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04028644040226936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06344950199127197,
      "backward_entropy": 0.010213443501429125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.53614044189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04034809768199921,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06340751051902771,
      "backward_entropy": 0.006332167170264504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.31908416748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041261970996857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06336421767870586,
      "backward_entropy": 0.006294784220782193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.557861328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04047985002398491,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0633195290962855,
      "backward_entropy": 0.0626219619404186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.37290954589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04054687172174454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06327517330646515,
      "backward_entropy": 0.00622527233578942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.836618423461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04061402752995491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06323079764842987,
      "backward_entropy": 0.006195506588979201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.11564254760742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040678199380636215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06318728129069011,
      "backward_entropy": 0.006165568801489743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.11489486694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074247181415558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06314357121785481,
      "backward_entropy": 0.006136402487754822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.673484802246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040808338671922684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06309910615285237,
      "backward_entropy": 0.006109739569100467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.7816162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04087299481034279,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06305493911107381,
      "backward_entropy": 0.010114342651583931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.54169464111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040939077734947205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06301009654998779,
      "backward_entropy": 0.0060603564435785465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.63047790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04100500047206879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06296532352765401,
      "backward_entropy": 0.006035020405595953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.26923370361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0410773828625679,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06291743119557698,
      "backward_entropy": 0.006009970198978077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.06722640991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041153065860271454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06286834677060445,
      "backward_entropy": 0.010106536475094881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.789955139160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04122534021735191,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.062820499142011,
      "backward_entropy": 0.010109196332367983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.606143951416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041299715638160706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06277174750963847,
      "backward_entropy": 0.00594486499374563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.570804595947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04137551411986351,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06272223591804504,
      "backward_entropy": 0.01011493598872965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.114688873291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04145026579499245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06267278393109639,
      "backward_entropy": 0.005900960076938976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.25876235961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04152672365307808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06262253721555074,
      "backward_entropy": 0.005879851227456873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.705211639404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04160183295607567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06257261832555135,
      "backward_entropy": 0.005856937305493789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.664602279663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04167196899652481,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06252463658650716,
      "backward_entropy": 0.005834444002671676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.79512023925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041737355291843414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06247850259145101,
      "backward_entropy": 0.005809766325083646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.93195343017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04180243983864784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06243215004603068,
      "backward_entropy": 0.0057838193394921045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.84253692626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04186611250042915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06238623460133871,
      "backward_entropy": 0.005758075551553206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.33846664428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041936587542295456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06233699123064677,
      "backward_entropy": 0.005734887990084561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.182125091552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04200635105371475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06228792667388916,
      "backward_entropy": 0.005711120637980374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.848934173583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04207547754049301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.062238991260528564,
      "backward_entropy": 0.010077775879339739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.32749938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04214158281683922,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062191267808278404,
      "backward_entropy": 0.005663462660529397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.8262939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042206067591905594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06214399139086405,
      "backward_entropy": 0.005639172751795162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.094633102416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04227568209171295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062094117204348244,
      "backward_entropy": 0.005615716630762274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.35865783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042340733110904694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06204616526762644,
      "backward_entropy": 0.010049580173058943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.26186752319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04240817949175835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061996777852376304,
      "backward_entropy": 0.005567137829282067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.31082534790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04247539862990379,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06194733579953512,
      "backward_entropy": 0.005544072525067763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.230772018432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04253964498639107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061899026234944664,
      "backward_entropy": 0.005520750853148374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.139347076416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042601075023412704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06185178955396017,
      "backward_entropy": 0.005496033552018079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.024742126464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04266006499528885,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061805516481399536,
      "backward_entropy": 0.00999898531220176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.145057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042720723897218704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0617583692073822,
      "backward_entropy": 0.005446486852385781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.878171920776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04278429597616196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06170952320098877,
      "backward_entropy": 0.0054225596514615145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.795269012451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042845312505960464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06166180968284607,
      "backward_entropy": 0.009963898496194319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.13515853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290398955345154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06161489089330038,
      "backward_entropy": 0.0053765814412723885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.642242431640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0429631732404232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06156724691390991,
      "backward_entropy": 0.005354391918940978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.38842010498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04301994666457176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06152092417081197,
      "backward_entropy": 0.009930683807893232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.480806350708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04307356849312782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06147607167561849,
      "backward_entropy": 0.005307379094037143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.736385345458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04312543198466301,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061431835095087685,
      "backward_entropy": 0.009905038232153112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.412391662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043179601430892944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061386058727900185,
      "backward_entropy": 0.005259282209656455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.31014633178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043233294039964676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06134029726187388,
      "backward_entropy": 0.009873888032002882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.208431243896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04328656196594238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06129459043343862,
      "backward_entropy": 0.009857762943614613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.11796188354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043339453637599945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061248828967412315,
      "backward_entropy": 0.0051863715052604675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.997346878051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04339490830898285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06120175123214722,
      "backward_entropy": 0.00982943990013816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64563751220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04344993084669113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06115443507830302,
      "backward_entropy": 0.009819336235523224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.70750427246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04351235181093216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061102439959843956,
      "backward_entropy": 0.005126930773258209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.861308097839355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04357491061091423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06105032563209534,
      "backward_entropy": 0.005109479481523687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.79637908935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043633557856082916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06100034713745117,
      "backward_entropy": 0.005090653896331787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.11606216430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04369911924004555,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06094608704249064,
      "backward_entropy": 0.005073012276129289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.74496841430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04376578703522682,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06089106698830923,
      "backward_entropy": 0.0050562444058331575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04849155992269516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383469745516777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060834407806396484,
      "backward_entropy": 0.005040043118325147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.82810974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04389657825231552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06078192591667175,
      "backward_entropy": 0.00502305342392488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.10428237915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043963730335235596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060725907484690346,
      "backward_entropy": 0.0050071609968488865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.49746322631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04403304681181908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060668498277664185,
      "backward_entropy": 0.004992115903984417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.357748985290527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04410179704427719,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06061113874117533,
      "backward_entropy": 0.004977806047959762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.561613082885742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04416630044579506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06055614352226257,
      "backward_entropy": 0.004964617165652188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.442665100097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04422929883003235,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060501878460248314,
      "backward_entropy": 0.009763463654301384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.473209381103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04429103434085846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06044815977414449,
      "backward_entropy": 0.004936855963685296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.29779052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0443541556596756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060393258929252625,
      "backward_entropy": 0.004923377524722706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.08976936340332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04441848769783974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06033726533253988,
      "backward_entropy": 0.004909988831390034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.42702102661133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044481415301561356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06028197705745697,
      "backward_entropy": 0.004896700382232666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.851139068603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044546857476234436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06022466719150543,
      "backward_entropy": 0.004883917217904871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.73119354248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04461068660020828,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060168216625849404,
      "backward_entropy": 0.0048705332658507605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.40690612792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044673092663288116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06011248628298441,
      "backward_entropy": 0.004856875674291091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.595027923583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04473669454455376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06005562345186869,
      "backward_entropy": 0.009740962223573164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.37050437927246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044802602380514145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05999687314033508,
      "backward_entropy": 0.009733949195254932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.943220138549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04486687108874321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05993899703025818,
      "backward_entropy": 0.00481376051902771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.40996551513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044928424060344696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05988284945487976,
      "backward_entropy": 0.004799399863589893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.016700744628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04499007761478424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05982646346092224,
      "backward_entropy": 0.004785892976955934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.342105865478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04505050927400589,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059770544370015465,
      "backward_entropy": 0.009707765145735308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.59408187866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045112401247024536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05971324443817139,
      "backward_entropy": 0.004759800366379998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.509796142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04517180845141411,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05965752899646759,
      "backward_entropy": 0.004747381603175943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.83715057373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04522891342639923,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05960330863793691,
      "backward_entropy": 0.009692004458470778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.34305191040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04528765752911568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05954756339391073,
      "backward_entropy": 0.004721242257139899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.343950271606445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045344360172748566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059493074814478554,
      "backward_entropy": 0.004709388722072948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.23747444152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045400429517030716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05943906307220459,
      "backward_entropy": 0.004698455672372471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.161258697509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545588418841362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05938480297724406,
      "backward_entropy": 0.004688140004873276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.03026580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045511968433856964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05932967861493429,
      "backward_entropy": 0.004677957431836562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.91484832763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556993395090103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05927288035551707,
      "backward_entropy": 0.00966984507712451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.85770606994629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562700539827347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05921660860379537,
      "backward_entropy": 0.0046588138423182745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.856423377990723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045682042837142944,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05916166305541992,
      "backward_entropy": 0.009664713659069755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.703636169433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045734062790870667,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059109121561050415,
      "backward_entropy": 0.009662217714569786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.377376556396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0457846075296402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05905753870805105,
      "backward_entropy": 0.004630249670960687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.707571983337402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04583626240491867,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05900473395983378,
      "backward_entropy": 0.009658352217890999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.485637664794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458853505551815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05895378192265829,
      "backward_entropy": 0.0046136030419306326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.218904495239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045933131128549576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05890380839506785,
      "backward_entropy": 0.004605131393129175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.905948638916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045981019735336304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058853467305501304,
      "backward_entropy": 0.004596575417301871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.54307556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04603029787540436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05880181988080343,
      "backward_entropy": 0.0045884556391022424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.931697845458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0460820198059082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05874761939048767,
      "backward_entropy": 0.004580504514954307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.95115280151367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046133510768413544,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05869340399901072,
      "backward_entropy": 0.06290184367786754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.04646873474121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04618843272328377,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05863585074742635,
      "backward_entropy": 0.004565593871203336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.96946144104004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04624153673648834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05857973297437032,
      "backward_entropy": 0.004558290947567333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.89469337463379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04629308357834816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05852479239304861,
      "backward_entropy": 0.004551657221534036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.63849639892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04634319618344307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0584709495306015,
      "backward_entropy": 0.004545396701856093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.906410217285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04639563709497452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05841465791066488,
      "backward_entropy": 0.004539180208336224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004628760274499655,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046448901295661926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05835739771525065,
      "backward_entropy": 0.009648127989335493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.5986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04649690166115761,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058305000265439354,
      "backward_entropy": 0.004526349969885566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.021587371826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046543776988983154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05825350681940714,
      "backward_entropy": 0.004520286213267933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.490882396697998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658839851617813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05820399522781372,
      "backward_entropy": 0.004514131017706611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.806297302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046629779040813446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058157543341318764,
      "backward_entropy": 0.004508041184056889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.6763801574707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04667428880929947,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05810787777105967,
      "backward_entropy": 0.009645224972204729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.847888946533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046721603721380234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05805516242980957,
      "backward_entropy": 0.0044955238699913025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.00570297241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676666110754013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058004538218180336,
      "backward_entropy": 0.0044895322485403585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.51402473449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04681326821446419,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057952130834261574,
      "backward_entropy": 0.004483420063148846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.777599334716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04686005413532257,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05789938569068909,
      "backward_entropy": 0.009636495601047169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99142074584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046908214688301086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05784498651822408,
      "backward_entropy": 0.009633450345559553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.615468978881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0469588041305542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057787915070851646,
      "backward_entropy": 0.004464806480841203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.702091217041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04700672626495361,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05773346622784933,
      "backward_entropy": 0.004458383403041146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.295228958129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04705708101391792,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05767626563707987,
      "backward_entropy": 0.004451881078156558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.16933822631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047108445316553116,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05761780341466268,
      "backward_entropy": 0.004445629702372985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.417037963867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04716068506240845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05755819876988729,
      "backward_entropy": 0.004439363086765463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007931651780381799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04721014201641083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05750131607055664,
      "backward_entropy": 0.004433433440598575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.296329498291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047254692763090134,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05744963884353638,
      "backward_entropy": 0.004427943717349659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.413381576538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730435088276863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05739248792330424,
      "backward_entropy": 0.004422314803708683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.4560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04735265672206879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05733644962310791,
      "backward_entropy": 0.004416870122606104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.54143524169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740092158317566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05728027721246084,
      "backward_entropy": 0.004411427473480051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.326791763305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047451525926589966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05722127358118693,
      "backward_entropy": 0.004405966536565261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.120098114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04750305786728859,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057161072889963783,
      "backward_entropy": 0.009578926996751265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.076984405517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04755304008722305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05710230271021525,
      "backward_entropy": 0.009573944590308449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.951509475708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04760398343205452,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05704235037167867,
      "backward_entropy": 0.009568635712970387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.89433479309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04765578731894493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05698099732398987,
      "backward_entropy": 0.004385765303264965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.699993133544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0477059930562973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05692135294278463,
      "backward_entropy": 0.0043810592456297445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.4033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04775712266564369,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05686041216055552,
      "backward_entropy": 0.004376394843513315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.32781982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047811418771743774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05679556727409363,
      "backward_entropy": 0.004371652887626128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.301799774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04786738008260727,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0567285418510437,
      "backward_entropy": 0.004366916350343011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.497764587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04792366549372673,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05666090051333109,
      "backward_entropy": 0.004362273622642864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.611655235290527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04797789081931114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056595404942830406,
      "backward_entropy": 0.004357858137650924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.341575622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048029083758592606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05653346081574758,
      "backward_entropy": 0.004353727468035438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.02395248413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04807871952652931,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0564731111129125,
      "backward_entropy": 0.009515149349516088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.657686233520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812810197472572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05641280114650726,
      "backward_entropy": 0.004345955835147338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.533042907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04817841947078705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05635112524032593,
      "backward_entropy": 0.0043420899998057975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.72511863708496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04822958633303642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05628808339436849,
      "backward_entropy": 0.004338369450785897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.624515533447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828033968806267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05622528990109762,
      "backward_entropy": 0.0043347908014600926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.524532318115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048330701887607574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056162744760513306,
      "backward_entropy": 0.004331223666667938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.212860107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04838070645928383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056100438038508095,
      "backward_entropy": 0.004327712072567506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.165947914123535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048428088426589966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056041220823923744,
      "backward_entropy": 0.004324552687731656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.681324005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04847307130694389,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.055985053380330406,
      "backward_entropy": 0.009460866451263428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.23040008544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048517074435949326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05592984954516093,
      "backward_entropy": 0.004318624057553031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.54594612121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856365546584129,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05587098995844523,
      "backward_entropy": 0.004315778274427761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.47815704345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048609115183353424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05581330259641012,
      "backward_entropy": 0.0043133459985256195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.471445560455322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04865353927016258,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05575681229432424,
      "backward_entropy": 0.009434404698285189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.799863815307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048694711178541183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05570454398790995,
      "backward_entropy": 0.009428248486735603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.287912368774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04873640835285187,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05565134187539419,
      "backward_entropy": 0.0094217603856867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.226402282714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04877740517258644,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05559890468915304,
      "backward_entropy": 0.06294612451033159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.777738571166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04881777614355087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05554713308811188,
      "backward_entropy": 0.004302879626100714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.739007949829102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04885644093155861,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05549760162830353,
      "backward_entropy": 0.009399800138040022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.10186767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048893578350543976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055449992418289185,
      "backward_entropy": 0.004299253563989292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.320770263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04893387854099274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.055397748947143555,
      "backward_entropy": 0.009384094991467216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.856731414794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048974767327308655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05534449219703674,
      "backward_entropy": 0.004295131022279913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.29930877685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049018461257219315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05528700351715088,
      "backward_entropy": 0.004293035038492896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.053192138671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04906688630580902,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05522283911705017,
      "backward_entropy": 0.004290261729197068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.194364547729492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049115072935819626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055158719420433044,
      "backward_entropy": 0.004287678748369217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.857341766357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04916420578956604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05509295562903086,
      "backward_entropy": 0.009336915883150968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.381449699401855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04921302944421768,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05502742528915405,
      "backward_entropy": 0.009327747605063698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.500685691833496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049259252846241,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05496554573376974,
      "backward_entropy": 0.004281535744667053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.575632095336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04930427670478821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054905205965042114,
      "backward_entropy": 0.00427955151958899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.965782165527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049349360167980194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05484457810719808,
      "backward_entropy": 0.009298562326214531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.479644775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0493989922106266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054777016242345176,
      "backward_entropy": 0.00427573716098612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.213288307189941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494493804872036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05470806360244751,
      "backward_entropy": 0.004274143075401133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.140277862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049498189240694046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054641117652257286,
      "backward_entropy": 0.004273014312440699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.068803787231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04954551160335541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05457628766695658,
      "backward_entropy": 0.004271809011697769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.001058578491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04959150031208992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05451330542564392,
      "backward_entropy": 0.004270625385371121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.933101654052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049635179340839386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05445361137390137,
      "backward_entropy": 0.004269694062796506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.82406997680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04967791587114334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05439509948094686,
      "backward_entropy": 0.004269081083211032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.669830322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049720827490091324,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.054336210091908775,
      "backward_entropy": 0.009222820401191711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.737019538879395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04976504668593407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0542750358581543,
      "backward_entropy": 0.004266621714288538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.671122550964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04980822652578354,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05421526233355204,
      "backward_entropy": 0.009200903502377596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.81131362915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04985050857067108,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05415663123130798,
      "backward_entropy": 0.00919074768369848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.534881591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049898527562618256,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05408884088198344,
      "backward_entropy": 0.00917896560647271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.826308727264404,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994511231780052,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05402308702468872,
      "backward_entropy": 0.004261696541851217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.99480438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049988143146038055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05396300554275513,
      "backward_entropy": 0.004260269755666906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.882549285888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050032373517751694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05390086770057678,
      "backward_entropy": 0.004258374598893252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.263276100158691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050077687948942184,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053836738069852196,
      "backward_entropy": 0.00912688130682165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.655487060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05012180283665657,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05377434194087982,
      "backward_entropy": 0.004254025153138421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.833276748657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050167012959718704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053709954023361206,
      "backward_entropy": 0.004251659255136143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.425188064575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050212159752845764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05364516874154409,
      "backward_entropy": 0.004249741746620698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.647912979125977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025831237435341,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05357853571573893,
      "backward_entropy": 0.00424787165089087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.82727813720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05030426010489464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05351190765698751,
      "backward_entropy": 0.004246071658351205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.456340789794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050352197140455246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053442031145095825,
      "backward_entropy": 0.0042441412806510925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.184292793273926,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0503997728228569,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.053372075160344444,
      "backward_entropy": 0.06295585632324219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5742082595825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504448227584362,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05330605308214823,
      "backward_entropy": 0.004241752353581515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.638751983642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504864864051342,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053245882193247475,
      "backward_entropy": 0.004240990362384103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.577802658081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052737146615982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05318664014339447,
      "backward_entropy": 0.0042411979626525535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.515451431274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05056745931506157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05312860508759817,
      "backward_entropy": 0.004241546107964082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.421550750732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05060691758990288,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05307132005691528,
      "backward_entropy": 0.004242833026430823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.393909454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05064784735441208,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05301119387149811,
      "backward_entropy": 0.0042437132109295235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.656394958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0506879985332489,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05295217037200928,
      "backward_entropy": 0.004244895821267908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.68909454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050730615854263306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05288862685362498,
      "backward_entropy": 0.004245652393861251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.805745124816895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050773221999406815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052824964125951133,
      "backward_entropy": 0.004245499656959014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.648372650146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05081376060843468,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05276485284169515,
      "backward_entropy": 0.008910821242765947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.07491397857666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050857771188020706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0526982049147288,
      "backward_entropy": 0.004245357079939408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676950454711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05090058967471123,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0526337077220281,
      "backward_entropy": 0.004244942218065262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.94577693939209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05094126611948013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05257300535837809,
      "backward_entropy": 0.004244472154162147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.175701141357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050981149077415466,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05251342058181763,
      "backward_entropy": 0.0629590858112682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.823665618896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05102138593792915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05245277285575867,
      "backward_entropy": 0.004244908013127067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.76378059387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05106084421277046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05239337682723999,
      "backward_entropy": 0.004245496947656979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.937360763549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109957233071327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052335143089294434,
      "backward_entropy": 0.004246026954867623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.643526077270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05113857984542847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05227638284365336,
      "backward_entropy": 0.004245404492725025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.35080337524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117695778608322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052218457063039146,
      "backward_entropy": 0.004245418039235202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.352950096130371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051218848675489426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05215389529863993,
      "backward_entropy": 0.004244702783497897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.313997268676758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05125866085290909,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05209314823150635,
      "backward_entropy": 0.008757263422012329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.792570114135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05129650980234146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05203613142172495,
      "backward_entropy": 0.00424224002794786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.44859504699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051336806267499924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05197450518608093,
      "backward_entropy": 0.004239663820375095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.454103469848633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0513773150742054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05191210409005483,
      "backward_entropy": 0.008699341253800825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.149087905883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141900107264519,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05184728900591532,
      "backward_entropy": 0.004234960133379156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.15114974975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05145854502916336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0517866313457489,
      "backward_entropy": 0.004232008687474511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.093817710876465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05149737372994423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05172707140445709,
      "backward_entropy": 0.004230125383897262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.035531997680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05153541639447212,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05166873832543691,
      "backward_entropy": 0.008618865500796925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.962965965270996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05157272517681122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05161177118619283,
      "backward_entropy": 0.004225733266635375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948704719543457,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051610514521598816,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05155360698699951,
      "backward_entropy": 0.06295471841638739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.811591148376465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051646746695041656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0514981746673584,
      "backward_entropy": 0.004223425957289609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.80564022064209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05168350785970688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051441490650177,
      "backward_entropy": 0.004222895272753455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.39533233642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171974003314972,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05138561129570007,
      "backward_entropy": 0.004222634163769809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.68907356262207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05175958573818207,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05132229129473368,
      "backward_entropy": 0.008511134169318459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.854244232177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051798563450574875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051260530948638916,
      "backward_entropy": 0.004221646284515207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.560318946838379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184285342693329,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05118807156880697,
      "backward_entropy": 0.004220359366048466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.493511199951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05188586562871933,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051117916901906334,
      "backward_entropy": 0.004219701344316656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.820594310760498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05192777141928673,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.051049649715423584,
      "backward_entropy": 0.008443314243446697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5875678062438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05196663364768028,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0509873628616333,
      "backward_entropy": 0.004221474582498724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.550458908081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0520036555826664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05092881123224894,
      "backward_entropy": 0.0042227445678277445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.74774932861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05203899368643761,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05087368686993917,
      "backward_entropy": 0.008400930599732832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.923969268798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05207992345094681,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050806899865468345,
      "backward_entropy": 0.008384671400893818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.134477615356445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05212092399597168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050739601254463196,
      "backward_entropy": 0.004224645143205469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7032408714294434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05216098204255104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050673907001813255,
      "backward_entropy": 0.004226390611041676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.01798439025879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0521981380879879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050614118576049805,
      "backward_entropy": 0.0042288574305447664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.251577377319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052237678319215775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05054907997449239,
      "backward_entropy": 0.004231166771867059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.52419376373291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05227833241224289,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05048142373561859,
      "backward_entropy": 0.008320365439761768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.834112167358398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05231890827417374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0504139761130015,
      "backward_entropy": 0.004234523935751481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.77334213256836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05235852301120758,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.050348242123921715,
      "backward_entropy": 0.06295818090438843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.714559555053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052397292107343674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05028394361337026,
      "backward_entropy": 0.00423914837566289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.112565994262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052435290068387985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050221035877863564,
      "backward_entropy": 0.004242440516298468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.243608474731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052471522241830826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.050161788860956825,
      "backward_entropy": 0.008259771222418005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.063554763793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052512094378471375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05009301006793976,
      "backward_entropy": 0.004248256033117121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.448532104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052554626017808914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050019681453704834,
      "backward_entropy": 0.004250755364244635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.804960250854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052597932517528534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049944400787353516,
      "backward_entropy": 0.00425344163721258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.784496307373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05264284089207649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04986545443534851,
      "backward_entropy": 0.008211673660711809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4445927143096924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05268728733062744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04978724320729574,
      "backward_entropy": 0.004258300093087283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.614964485168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05272817239165306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0497171680132548,
      "backward_entropy": 0.00818497281182896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.531925201416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05276888981461525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04964735607306162,
      "backward_entropy": 0.004260613498362628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.444742202758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052809473127126694,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0495775838692983,
      "backward_entropy": 0.008153179829770868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.704137802124023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05285010486841202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04950705170631409,
      "backward_entropy": 0.0042640373788096686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.661955833435059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05289158225059509,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.049434358874956764,
      "backward_entropy": 0.00812768123366616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.908265113830566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05293063446879387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049367696046829224,
      "backward_entropy": 0.004266325723041187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.13017463684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05296878516674042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04930267731348673,
      "backward_entropy": 0.0042670619758692655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.30562400817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05300698056817055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04923740029335022,
      "backward_entropy": 0.0042674250223419885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.497982978820801,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05304630845785141,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04916896422704061,
      "backward_entropy": 0.004268628291108392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.460537433624268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05308367684483528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0491049587726593,
      "backward_entropy": 0.004270186478441412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.026193618774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05311927571892738,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04904480775197347,
      "backward_entropy": 0.004272011532024903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.566031455993652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05315614119172096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04898144801457723,
      "backward_entropy": 0.004273650659756227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.35394811630249,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053192347288131714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048919081687927246,
      "backward_entropy": 0.004276451062072407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.758734703063965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05322681739926338,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04886088271935781,
      "backward_entropy": 0.004278688268228011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.538007736206055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326257273554802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04879950483640035,
      "backward_entropy": 0.00428009879860011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.360578536987305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053298600018024445,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04873730738957723,
      "backward_entropy": 0.007953979074954987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.392634391784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053333770483732224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048677285512288414,
      "backward_entropy": 0.004281749102202329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.322321891784668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05336931720376015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04861592253049215,
      "backward_entropy": 0.00791833075610074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.310797691345215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053405165672302246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04855344692866007,
      "backward_entropy": 0.004284112629565326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.175031661987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053442105650901794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0484883983929952,
      "backward_entropy": 0.0042847161265936766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.10529899597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05347922444343567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04842250049114227,
      "backward_entropy": 0.007868422703309492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.030964851379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053516361862421036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0483564039071401,
      "backward_entropy": 0.004286853088573976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.98774528503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05355255305767059,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04829271137714386,
      "backward_entropy": 0.004287031225182794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.858179092407227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05358712747693062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.048232500751813255,
      "backward_entropy": 0.007815985517068342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869890213012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053622767329216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04816995561122894,
      "backward_entropy": 0.004288157956166701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.61227798461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05365762487053871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048109233379364014,
      "backward_entropy": 0.00428764826872132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.938990354537964,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05369437858462334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0480441947778066,
      "backward_entropy": 0.0042850307442925195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702094078063965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05372840166091919,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047985722621281944,
      "backward_entropy": 0.004282939501784064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.658782958984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05376202240586281,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.047927493850390114,
      "backward_entropy": 0.0629619685086337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61044692993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05379507318139076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047870670755704246,
      "backward_entropy": 0.004283689639785073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.558131217956543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053827572613954544,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.047814831137657166,
      "backward_entropy": 0.007671027020974593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.688808917999268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05385966971516609,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047759672005971275,
      "backward_entropy": 0.0042851828038692474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.279729843139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05389029532670975,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047708491484324135,
      "backward_entropy": 0.004285370423035188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.62456750869751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392152816057205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0476556271314621,
      "backward_entropy": 0.00428549742156809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8132691383361816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053951434791088104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047606090704600014,
      "backward_entropy": 0.004285389388149435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.640094757080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053979214280843735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04756203293800354,
      "backward_entropy": 0.004284928468140689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.533903121948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05400962382555008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04751122494538625,
      "backward_entropy": 0.004283711314201355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244489669799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05403885245323181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04746316373348236,
      "backward_entropy": 0.004283123056996952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.920537948608398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406787618994713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04741554458936056,
      "backward_entropy": 0.0042825541035695506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572529792785645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0540977381169796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047365268071492515,
      "backward_entropy": 0.004283131184903058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.503299713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05412916839122772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04731073975563049,
      "backward_entropy": 0.004283984953706915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.732054710388184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05416172742843628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047253817319869995,
      "backward_entropy": 0.004282250323078849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3524580001831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05419478937983513,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04719501237074534,
      "backward_entropy": 0.004282260821624236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.610004425048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054226286709308624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04714032014211019,
      "backward_entropy": 0.0042817958376624365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.54302978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05425817146897316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047084699074427284,
      "backward_entropy": 0.004280835390090942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.092742919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429049953818321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047027538220087685,
      "backward_entropy": 0.004280527545647187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.603337287902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054324064403772354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046967009703318276,
      "backward_entropy": 0.004280212250622836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.07482147216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435967445373535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04690088828404745,
      "backward_entropy": 0.004280369051478126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027451107278466225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439801514148712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04682726661364237,
      "backward_entropy": 0.004281072454019027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.657425880432129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054432645440101624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04676318168640137,
      "backward_entropy": 0.004283188418908553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5524661540985107,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05446646362543106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04670122762521108,
      "backward_entropy": 0.004285139116373929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.069798469543457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05449791997671127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046645209193229675,
      "backward_entropy": 0.004288451238112016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.503713607788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452980101108551,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04658769071102142,
      "backward_entropy": 0.004292007197033276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.467953681945801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054562874138355255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046527033050855,
      "backward_entropy": 0.007233879105611281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.950230598449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0545952245593071,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046468377113342285,
      "backward_entropy": 0.0042974661019715395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.825875282287598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05462627112865448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046412656704584755,
      "backward_entropy": 0.007205906239422885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.32848596572876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465755984187126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04635655879974365,
      "backward_entropy": 0.00430391864343123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.279637813568115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054688312113285065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04630187153816223,
      "backward_entropy": 0.004305930638855154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.845060348510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054718684405088425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04624787966410319,
      "backward_entropy": 0.0043087405237284574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1879682540893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05475213751196861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04618522028128306,
      "backward_entropy": 0.004311717369339683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.882965087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05478489026427269,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046124289433161415,
      "backward_entropy": 0.007130795581774278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03985101729631424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05481865257024765,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04606057206789652,
      "backward_entropy": 0.0071160915223034945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.713357925415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054848842322826385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0460072656472524,
      "backward_entropy": 0.004318296570669521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.978771209716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05487764626741409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04595780869325002,
      "backward_entropy": 0.0070767666805874214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.58043098449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05490877106785774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04590159157911936,
      "backward_entropy": 0.004318654537200928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.208870887756348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05494106188416481,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04584193229675293,
      "backward_entropy": 0.004319224506616592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0347876213490963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05497352406382561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04578176140785217,
      "backward_entropy": 0.004319767383011905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.562808990478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055002693086862564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04573072989781698,
      "backward_entropy": 0.004320017993450165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.536279678344727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055030591785907745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04568325479825338,
      "backward_entropy": 0.0043199356984008445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.685126304626465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05506076663732529,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0456293523311615,
      "backward_entropy": 0.006960845806381919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.133545875549316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055093806236982346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04556732873121897,
      "backward_entropy": 0.006940889087590304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.642065048217773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05512772500514984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04550272226333618,
      "backward_entropy": 0.004319204186851328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.404824256896973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05516082048416138,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04544017215569814,
      "backward_entropy": 0.004319469359788028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.068082809448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05519238859415054,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.045381699999173485,
      "backward_entropy": 0.004320963201197711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.185781240463257,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522580072283745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0453175405661265,
      "backward_entropy": 0.004322433336214585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.320418357849121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055256832391023636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04525992274284363,
      "backward_entropy": 0.0043252340771935205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.41765022277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055286332964897156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04520690441131592,
      "backward_entropy": 0.00432704897089438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.826323509216309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05531533807516098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04515509804089864,
      "backward_entropy": 0.0043285810811953115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.231671333312988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05534730479121208,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04509460926055908,
      "backward_entropy": 0.004331030290235172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.45993423461914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05537771061062813,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04503851135571798,
      "backward_entropy": 0.06295459920709784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241477012634277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055409036576747894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044980098803838096,
      "backward_entropy": 0.004333768039941788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.145623207092285,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05543969199061394,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04492346942424774,
      "backward_entropy": 0.06295406276529486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1607279777526855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05546886473894119,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04487112661202749,
      "backward_entropy": 0.0043346702375195246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.093626976013184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05549745261669159,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04482061664263407,
      "backward_entropy": 0.006711456586014141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.064638137817383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05552467703819275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044774328668912254,
      "backward_entropy": 0.004332041537219828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0387725830078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055550750344991684,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04473115007082621,
      "backward_entropy": 0.0629509687423706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.979287147521973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05557495728135109,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04469349980354309,
      "backward_entropy": 0.004327848553657532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0075020790100098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055601466447114944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044649372498194374,
      "backward_entropy": 0.004324694587425752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9620161056518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05562626197934151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04460972547531128,
      "backward_entropy": 0.004323522814295508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9405758380889893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05565030500292778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04457157850265503,
      "backward_entropy": 0.004323962398550727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9211556911468506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567362532019615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044535234570503235,
      "backward_entropy": 0.004325405101884495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.970106601715088,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055696215480566025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04450095693270365,
      "backward_entropy": 0.004326985640959306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.801114559173584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05571725219488144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04447139302889506,
      "backward_entropy": 0.004327699880708347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.767326354980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05573863908648491,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04444047808647156,
      "backward_entropy": 0.004329237070950595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.839336633682251,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055760450661182404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04440767069657644,
      "backward_entropy": 0.004332715814763849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.604723930358887,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05578167364001274,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04437653720378876,
      "backward_entropy": 0.0629462491382252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9188424348831177,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05580398812890053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044341916839281716,
      "backward_entropy": 0.004339870404113422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.396160125732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05582477152347565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04431203007698059,
      "backward_entropy": 0.004342469979416241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.617874622344971,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05584752559661865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044275919596354164,
      "backward_entropy": 0.004345991056073795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5934062004089355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05587046593427658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04423883557319641,
      "backward_entropy": 0.004350381480021911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39654016494751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055893342941999435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044202263156572975,
      "backward_entropy": 0.004353141242807562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.695986032485962,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05591714754700661,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.044162631034851074,
      "backward_entropy": 0.06294809146360918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.315007209777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055940065532922745,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044125775496164955,
      "backward_entropy": 0.006374837999994104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6489949226379395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05596374347805977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04408652583758036,
      "backward_entropy": 0.006358486007560383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.627734899520874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05598665028810501,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044049556056658425,
      "backward_entropy": 0.006342816081914035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.181617736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05600886046886444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04401437441507975,
      "backward_entropy": 0.004365619271993637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.4766845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05603206902742386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04397573073705038,
      "backward_entropy": 0.004369248720732602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.325587749481201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0560583621263504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04392780860265096,
      "backward_entropy": 0.004372392188418995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291066646575928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056084439158439636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0438802440961202,
      "backward_entropy": 0.004376393488862298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.485061645507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05611027404665947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043833146492640175,
      "backward_entropy": 0.0043807483532212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2215728759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05613809823989868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04378014802932739,
      "backward_entropy": 0.004384274848482825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184286117553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05616537481546402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043728927771250405,
      "backward_entropy": 0.004386902871457013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.260859489440918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056192152202129364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04367921749750773,
      "backward_entropy": 0.004388670352372256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.871977806091309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056220781058073044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.043624043464660645,
      "backward_entropy": 0.006220048124139959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.060773849487305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056251879781484604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043561319510142006,
      "backward_entropy": 0.00439129194075411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.353450775146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05628222972154617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043500468134880066,
      "backward_entropy": 0.004393587735566226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.929244041442871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05631321296095848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04343793292840322,
      "backward_entropy": 0.004394520074129105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.567639350891113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05634560436010361,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04337109128634135,
      "backward_entropy": 0.004395176063884388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757022857666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05637785792350769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043304274479548134,
      "backward_entropy": 0.004396972331133756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.062487602233887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05641128122806549,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04323409994443258,
      "backward_entropy": 0.004397667267105796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986761093139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05644497275352478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043163428703943886,
      "backward_entropy": 0.0043971480971032924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.180385112762451,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05647888779640198,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.043092320362726845,
      "backward_entropy": 0.06295080618424849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841712951660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05651095137000084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04302669564882914,
      "backward_entropy": 0.00439476492730054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.669196605682373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056543294340372086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04296044508616129,
      "backward_entropy": 0.004392232745885849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0979881286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657464638352394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04289701581001282,
      "backward_entropy": 0.004390609196641229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.108078479766846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05660431087017059,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04283878207206726,
      "backward_entropy": 0.004389176314527338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.549694061279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056633904576301575,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04278069237867991,
      "backward_entropy": 0.00438793579285795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4915771484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056662723422050476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04272485772768656,
      "backward_entropy": 0.06294696981256659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9909396171569824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05669240280985832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04266575972239176,
      "backward_entropy": 0.004388009282675656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.302430152893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05672062188386917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.042610938350359596,
      "backward_entropy": 0.0059363672679120846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.758084297180176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056751053780317307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04254929224650065,
      "backward_entropy": 0.004391725767742504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.233397483825684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05678267776966095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04248391588528951,
      "backward_entropy": 0.004393071952191266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.314034938812256,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056814707815647125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.042417253057161965,
      "backward_entropy": 0.06294739788228815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.682154178619385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05684562772512436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04235409696896871,
      "backward_entropy": 0.004395547238263217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.84081768989563,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056876346468925476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04229125380516052,
      "backward_entropy": 0.004397362809289585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.741864204406738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056905217468738556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04223489761352539,
      "backward_entropy": 0.004397061738100919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.899413108825684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05693607032299042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04217216372489929,
      "backward_entropy": 0.004396886310794137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4766082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696737766265869,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04210779070854187,
      "backward_entropy": 0.004397414286028255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.415572166442871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056998275220394135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04204473396142324,
      "backward_entropy": 0.004397411915388974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.702146291732788,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05702900514006615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04198173681894938,
      "backward_entropy": 0.004399250176819888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.998913049697876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05705806240439415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041923925280570984,
      "backward_entropy": 0.0044012692841616545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.576972007751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570862703025341,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041868776082992554,
      "backward_entropy": 0.00440326603976163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2255096435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057115163654088974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04181108375390371,
      "backward_entropy": 0.00440619784322652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.453883647918701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05714382976293564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04175422588984171,
      "backward_entropy": 0.0044082369316707955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5774683952331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057173147797584534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041694859663645424,
      "backward_entropy": 0.004411683163859628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5595664978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05720098316669464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04163992404937744,
      "backward_entropy": 0.004416073587807742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7808432579040527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057227347046136856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041589791576067604,
      "backward_entropy": 0.0044194155118682165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.999104976654053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05725320056080818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041540876030921936,
      "backward_entropy": 0.00442404029044238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.859025001525879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05727897956967354,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04149269312620163,
      "backward_entropy": 0.005643380636518652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6903436183929443,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057307567447423935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041435236732165016,
      "backward_entropy": 0.004429680379954251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.848689556121826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057335179299116135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041381143033504486,
      "backward_entropy": 0.004431462762030688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6127560138702393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05736285075545311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04132625957330068,
      "backward_entropy": 0.004435314373536544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5816125869750977,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05738983675837517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04127322882413864,
      "backward_entropy": 0.06295244802128185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.066878318786621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057416148483753204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04122216502825419,
      "backward_entropy": 0.004445405507629568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3626902103424072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05744374915957451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04116685688495636,
      "backward_entropy": 0.004450098357417367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7774152755737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05746978521347046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04111689329147339,
      "backward_entropy": 0.004453200508247723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4579126834869385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05749664455652237,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04106361667315165,
      "backward_entropy": 0.0055465003983540965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.42441987991333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057522669434547424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04101330538590749,
      "backward_entropy": 0.004462005401199514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1598650217056274,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057547979056835175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04096537580092748,
      "backward_entropy": 0.0044649981639601965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3655591011047363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057571299374103546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04092417160669962,
      "backward_entropy": 0.004466758194294843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3295023441314697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05759415403008461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.040884457528591156,
      "backward_entropy": 0.005489372732964429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3127238750457764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05761675909161568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04084502160549164,
      "backward_entropy": 0.004470607096498663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1125314235687256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05763891339302063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0408072496453921,
      "backward_entropy": 0.004472129724242471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.257047414779663,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05765959993004799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04077367732922236,
      "backward_entropy": 0.004475018517537551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.367095470428467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768010392785072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04074067374070486,
      "backward_entropy": 0.004477642137895931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1490399837493896,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057701610028743744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04070452352364858,
      "backward_entropy": 0.004479153589768844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.223433494567871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05772222951054573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040671092768510185,
      "backward_entropy": 0.004480891945687207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.200218677520752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057743433862924576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040635074178377785,
      "backward_entropy": 0.0044844435019926595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03732280433177948,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.057764939963817596,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04059825837612152,
      "backward_entropy": 0.06295599720694801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1336774826049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057784248143434525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040568724274635315,
      "backward_entropy": 0.004488988356156783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.096314430236816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780407413840294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04053739209969839,
      "backward_entropy": 0.004490516741167416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.070364475250244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05782448872923851,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04050365090370178,
      "backward_entropy": 0.004493301903659647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.041086673736572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05784529447555542,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04046862324078878,
      "backward_entropy": 0.00531921230933883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.987337112426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05786699429154396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04043093075354894,
      "backward_entropy": 0.004496833140199835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007941246032715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05789016932249069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0403880774974823,
      "backward_entropy": 0.004497832195325332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.904154300689697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057912081480026245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04035003980000814,
      "backward_entropy": 0.004496939141641964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.891413450241089,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057934876531362534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040308584769566856,
      "backward_entropy": 0.004496910016645084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.902305841445923,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05795791745185852,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040265883008639015,
      "backward_entropy": 0.004498345269398255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8820912837982178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0579804964363575,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04022457698980967,
      "backward_entropy": 0.004500318657268177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7927286624908447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0580025240778923,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040185285111268364,
      "backward_entropy": 0.004501206631010229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.682265758514404,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05802471190690994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040145426988601685,
      "backward_entropy": 0.004501813514666123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.644092559814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058047786355018616,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04010206460952759,
      "backward_entropy": 0.005183764818039807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.685166597366333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05807152017951012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04005644222100576,
      "backward_entropy": 0.004505990242416208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.452611923217773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058095261454582214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04001071055730184,
      "backward_entropy": 0.004508136009628122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.720280170440674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05812026560306549,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039960332214832306,
      "backward_entropy": 0.004511497914791107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.459176540374756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058144472539424896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0399127850929896,
      "backward_entropy": 0.004514024338938973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5441765785217285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05816921219229698,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039863343040148415,
      "backward_entropy": 0.004516884684562683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.368864059448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05819367989897728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03981503347555796,
      "backward_entropy": 0.004518060182983225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6056478023529053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0582185797393322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039765497048695884,
      "backward_entropy": 0.004519268870353699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.440596342086792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05824274197220802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03971820076306661,
      "backward_entropy": 0.004520963538776745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.236792087554932,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058266524225473404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03967298070589701,
      "backward_entropy": 0.004519734192978252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1893534660339355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05829068273305893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03962647418181101,
      "backward_entropy": 0.004517796364697543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.151763916015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058315210044384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0395787904659907,
      "backward_entropy": 0.004515813494270498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.473633050918579,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058339886367321014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03953161338965098,
      "backward_entropy": 0.004511480981653387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.442861795425415,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05836372822523117,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03948719302813212,
      "backward_entropy": 0.004507196897810156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8265174031257629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0583869032561779,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039444478849569954,
      "backward_entropy": 0.004504115744070573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03704407438635826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05840839818120003,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03940702726443609,
      "backward_entropy": 0.004502410238439386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716712474822998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058427710086107254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03937690953413645,
      "backward_entropy": 0.00450066477060318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5783765316009521,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05844830721616745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03934270143508911,
      "backward_entropy": 0.004498396407474171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0877368450164795,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05846797302365303,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.039311145742734276,
      "backward_entropy": 0.0629408901387995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.798291802406311,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05848802998661995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03927764296531677,
      "backward_entropy": 0.004497836259278384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.042942523956299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058506499975919724,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.039250088234742485,
      "backward_entropy": 0.004867992956529964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.260171413421631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0585252046585083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03922189772129059,
      "backward_entropy": 0.004495857114141638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2436776161193848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0585438534617424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03919317573308945,
      "backward_entropy": 0.004497022114016793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.957577705383301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05856236070394516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03916452328364054,
      "backward_entropy": 0.004499607465483926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4873757362365723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05858120694756508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03913452476263046,
      "backward_entropy": 0.004502735354683616,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.703420373313129,
    "avg_log_Z": -0.05740333005785942,
    "success_rate": 1.0,
    "avg_reward": 78.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.08,
      "2": 0.86
    },
    "avg_forward_entropy": 0.041307037323713304,
    "avg_backward_entropy": 0.008045520948415453,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}