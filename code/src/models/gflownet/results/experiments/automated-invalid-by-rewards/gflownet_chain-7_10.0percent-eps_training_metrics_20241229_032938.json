{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09902094943182808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.50453186035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370888650417328,
      "backward_entropy": 0.09901532105037145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.4806365966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708698749542236,
      "backward_entropy": 0.0990197913987296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.58740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019999995129182935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708503544330597,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.62051391601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029931735480204225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370829939842224,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.60076904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003970417892560363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708090782165527,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.58070373535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004939321661368012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707861304283142,
      "backward_entropy": 0.09902092388698033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.56060791015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005903468700125813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707619905471802,
      "backward_entropy": 0.0990203789302281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.08001708984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006864788010716438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137073814868927,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.98377990722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007825446082279086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707131147384644,
      "backward_entropy": 0.09902051516941615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.57974243164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008783827652223408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370687633752823,
      "backward_entropy": 0.09902022566114153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.0218505859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009743748232722282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137066051363945,
      "backward_entropy": 0.09902005536215645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.92575073242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010704087326303124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706323504447937,
      "backward_entropy": 0.09902079616274152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.44451904296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001166289090178907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706035912036896,
      "backward_entropy": 0.09902077913284302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.1144256591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012621660716831684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705739378929138,
      "backward_entropy": 0.09902088982718331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.4053955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001356971450150013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705432415008545,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.77493286132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014519918477162719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705116510391235,
      "backward_entropy": 0.09902095794677734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.28579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015426448080688715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704811036586761,
      "backward_entropy": 0.09901787553514753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.96800231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016354420222342014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704484701156616,
      "backward_entropy": 0.09901743275778634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.147216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017273800913244486,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13704153895378113,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.22088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001823444152250886,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13703806698322296,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.7056884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001920701819472015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703438639640808,
      "backward_entropy": 0.0990159341267177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.48692321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0020133014768362045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703081011772156,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.123291015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020980513654649258,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13702747225761414,
      "backward_entropy": 0.0990208557673863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0406951904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002181506250053644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13702400028705597,
      "backward_entropy": 0.09902080467769078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.38278198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022692792117595673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702017068862915,
      "backward_entropy": 0.09901366063526698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.01734924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023566943127661943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370161473751068,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.06034088134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024463857989758253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701198995113373,
      "backward_entropy": 0.09901246002742223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9461669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002534204861149192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370077133178711,
      "backward_entropy": 0.0990118214062282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.23622131347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002625837456434965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370030790567398,
      "backward_entropy": 0.09902093240192958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.39239501953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002716385992243886,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699842989444733,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.44439697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028087389655411243,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369936615228653,
      "backward_entropy": 0.09902054071426392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.34716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002902899170294404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698868453502655,
      "backward_entropy": 0.09900922434670585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.16189575195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029984121210873127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698384165763855,
      "backward_entropy": 0.0990085346358163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.72079467773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003092380939051509,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697916269302368,
      "backward_entropy": 0.09902049813951765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.62208557128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031830838415771723,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697472214698792,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.98365783691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032769537065178156,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697011768817902,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.37356567382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003371091093868017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13696540892124176,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.47586059570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003469079965725541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696043193340302,
      "backward_entropy": 0.09902068546840123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.38812255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003566932864487171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695548474788666,
      "backward_entropy": 0.0990035959652492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.62054443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036683331709355116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695022463798523,
      "backward_entropy": 0.09902060883385795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.460205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003776429919525981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369445025920868,
      "backward_entropy": 0.09900188446044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.63363647460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038811645936220884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693879544734955,
      "backward_entropy": 0.09900099890572685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.95217895507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003985813818871975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693279027938843,
      "backward_entropy": 0.09900013038090297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.01654052734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040875687263906,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13692672550678253,
      "backward_entropy": 0.09902055774416242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8073272705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004193143919110298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369202584028244,
      "backward_entropy": 0.09902036190032959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.84307861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004301242530345917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691332936286926,
      "backward_entropy": 0.09899730341775077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.3465118408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004410007037222385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690617680549622,
      "backward_entropy": 0.09899633271353585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.5401153564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004517600871622562,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689902424812317,
      "backward_entropy": 0.09902058328901019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.7623748779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004622881766408682,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368919163942337,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.47903442382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004731242079287767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688445091247559,
      "backward_entropy": 0.0990199191229684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.38156127929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004834573715925217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368771195411682,
      "backward_entropy": 0.09902051516941615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.35137939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004939997103065252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686949014663696,
      "backward_entropy": 0.09899032115936279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.41476440429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005042542703449726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686178624629974,
      "backward_entropy": 0.09898886510304042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.76866149902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005140593275427818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685448467731476,
      "backward_entropy": 0.09901925495692662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.65626525878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0052364058792591095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684706389904022,
      "backward_entropy": 0.09898553575788226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.77737426757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005332523956894875,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683950901031494,
      "backward_entropy": 0.09902029378073555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.72352600097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005429413635283709,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683155179023743,
      "backward_entropy": 0.09901842900684901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6473846435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005529351066797972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368231326341629,
      "backward_entropy": 0.09901811395372663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.90565490722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0056293620727956295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681446015834808,
      "backward_entropy": 0.09897794042314802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.23057556152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005730822682380676,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13680541515350342,
      "backward_entropy": 0.09902003833225795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.25028228759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005830477457493544,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679635524749756,
      "backward_entropy": 0.09901995318276542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.43450927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00592584814876318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678736984729767,
      "backward_entropy": 0.09901647056852068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.99810791015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006018664687871933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13677841424942017,
      "backward_entropy": 0.0990159000669207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0700225830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006117439828813076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676878809928894,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.70608520507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006213934160768986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367589831352234,
      "backward_entropy": 0.09896322659083776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0203094482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006309505086392164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13674898445606232,
      "backward_entropy": 0.09901405232293266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.9173126220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0064031342044472694,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673880696296692,
      "backward_entropy": 0.09901930604662214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.5299835205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006497649010270834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13672828674316406,
      "backward_entropy": 0.09895447322300502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.96881103515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006596659775823355,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13671723008155823,
      "backward_entropy": 0.09901906762804304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.5655517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006696863565593958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367059350013733,
      "backward_entropy": 0.09901091030665807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.40194702148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006795722525566816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366945505142212,
      "backward_entropy": 0.09900992257254464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.76861572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006895239930599928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668307662010193,
      "backward_entropy": 0.09900890077863421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.43902587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0070003848522901535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667082786560059,
      "backward_entropy": 0.0990079300744193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.57530212402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00710633909329772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665826618671417,
      "backward_entropy": 0.09901867594037737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.07203674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007214124780148268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366453468799591,
      "backward_entropy": 0.09893146583012172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.86459350585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007323625963181257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663199543952942,
      "backward_entropy": 0.0990046603339059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.66293334960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00743350712582469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13661831617355347,
      "backward_entropy": 0.09892429624285017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.25189208984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007542564999312162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13660433888435364,
      "backward_entropy": 0.09900213990892683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.05633544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007651907857507467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13658997416496277,
      "backward_entropy": 0.09900075197219849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.2574005126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007760338019579649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365753412246704,
      "backward_entropy": 0.0989124093736921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.22512817382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007869989611208439,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656041026115417,
      "backward_entropy": 0.09901835237230573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.78457641601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00797710008919239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654544949531555,
      "backward_entropy": 0.09899588142122541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.9608612060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008085918612778187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13653001189231873,
      "backward_entropy": 0.09889813831874303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.41549682617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008197554387152195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13651400804519653,
      "backward_entropy": 0.09899218593324934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.37904357910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008308064192533493,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13649772107601166,
      "backward_entropy": 0.09901794365474156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.25340270996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008417559787631035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364811658859253,
      "backward_entropy": 0.09898805618286133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.96258544921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008521856740117073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13646535575389862,
      "backward_entropy": 0.09887666361672538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.81241607666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008618888445198536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645006716251373,
      "backward_entropy": 0.09898290463856288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.24139404296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008712371811270714,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13643471896648407,
      "backward_entropy": 0.0990170921598162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.47528076171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008806669153273106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641898334026337,
      "backward_entropy": 0.09901671750204903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.48924255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008900079876184464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640308380126953,
      "backward_entropy": 0.09884929656982422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.18785095214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008996950462460518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638651371002197,
      "backward_entropy": 0.0988421014377049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.65960693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009086541831493378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13637053966522217,
      "backward_entropy": 0.09883403778076172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.9069061279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009174056351184845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13635458052158356,
      "backward_entropy": 0.0989624091557094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.24949645996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009265829809010029,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13633780181407928,
      "backward_entropy": 0.0990145036152431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.21763610839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009356701746582985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632091879844666,
      "backward_entropy": 0.09901398420333862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0828857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009451082907617092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13630333542823792,
      "backward_entropy": 0.09895011356898717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.17938232421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009543029591441154,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628579676151276,
      "backward_entropy": 0.09901298795427595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.164794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009637696668505669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13626745343208313,
      "backward_entropy": 0.09878137281962804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.21498107910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009735705330967903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136248379945755,
      "backward_entropy": 0.09893688133784703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.63784790039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009837817400693893,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362285017967224,
      "backward_entropy": 0.09901186398097447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.6275177001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009933559224009514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362091600894928,
      "backward_entropy": 0.09875435488564628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.2857208251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010028351098299026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13618957996368408,
      "backward_entropy": 0.09892259325299944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.86246490478516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01012392621487379,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361694484949112,
      "backward_entropy": 0.09901051861899239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.68023681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010215908288955688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361493617296219,
      "backward_entropy": 0.0987238883972168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.95391845703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010309808887541294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361282616853714,
      "backward_entropy": 0.09900956494467598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6715850830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010401840321719646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361069679260254,
      "backward_entropy": 0.09870214121682304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.98069763183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010496057569980621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13608501851558685,
      "backward_entropy": 0.09889428956168038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.38800048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010595345869660378,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136061891913414,
      "backward_entropy": 0.09888878038951329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6844482421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010693307965993881,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13603858649730682,
      "backward_entropy": 0.09900806631360735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.0454559326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010788421146571636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360153704881668,
      "backward_entropy": 0.09865864685603551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6573944091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010880562476813793,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13599234819412231,
      "backward_entropy": 0.09900706154959542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.7816619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010972708463668823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359691321849823,
      "backward_entropy": 0.098861677306039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.65054321289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01106442604213953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13594551384449005,
      "backward_entropy": 0.09900571618761335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1739044189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0111564751714468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13592155277729034,
      "backward_entropy": 0.0986018351146153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.37950134277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01124798133969307,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1358972191810608,
      "backward_entropy": 0.0990042005266462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.5692596435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011335737071931362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13587315380573273,
      "backward_entropy": 0.09856847354343959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.56130981445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011430555023252964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13584741950035095,
      "backward_entropy": 0.09900271892547607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.99615478515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011525639332830906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13582126796245575,
      "backward_entropy": 0.09853529930114746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.69703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01161858718842268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357949674129486,
      "backward_entropy": 0.09851772444588798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.15602111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011716179549694061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13576744496822357,
      "backward_entropy": 0.09850028582981654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.40890502929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011816824786365032,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13573893904685974,
      "backward_entropy": 0.09900071791240148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.96641540527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0119183249771595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13571012020111084,
      "backward_entropy": 0.09900031770978655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.98898315429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012020980007946491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13568206131458282,
      "backward_entropy": 0.09876564570835658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.9398956298828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012124922126531601,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13565325736999512,
      "backward_entropy": 0.0989996109689985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.28880310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01223000418394804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356237232685089,
      "backward_entropy": 0.09840986558369227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.77052307128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0123380646109581,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13559328019618988,
      "backward_entropy": 0.09873713765825544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.71157836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012445331551134586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355624496936798,
      "backward_entropy": 0.09872703892844063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.55479431152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012554269284009933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13553084433078766,
      "backward_entropy": 0.09835113797869001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.13534545898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012659307569265366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13549943268299103,
      "backward_entropy": 0.0989980867930821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 271.2166442871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012766372412443161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13546714186668396,
      "backward_entropy": 0.0986941031047276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.01824951171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012880478985607624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13543297350406647,
      "backward_entropy": 0.0989976440157209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.01614379882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012991731986403465,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353987604379654,
      "backward_entropy": 0.09899757589612689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.20455169677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013101892545819283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13536414504051208,
      "backward_entropy": 0.09866182293210711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.91458129882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013204613700509071,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13533061742782593,
      "backward_entropy": 0.09899701390947614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.7154541015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013312321156263351,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13529548048973083,
      "backward_entropy": 0.09899680955069405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.68101501464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013421371579170227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13525956869125366,
      "backward_entropy": 0.09862191336495536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.1791229248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013533012010157108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13522253930568695,
      "backward_entropy": 0.09860782963888985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.14324951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013644496910274029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13518491387367249,
      "backward_entropy": 0.09811946323939733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.51779174804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013751698657870293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13514763116836548,
      "backward_entropy": 0.09809113400323051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.02334594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013857620768249035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13511008024215698,
      "backward_entropy": 0.09855999265398298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.9558563232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013966817408800125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13507112860679626,
      "backward_entropy": 0.09854333741324288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.2821807861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014078902080655098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350308358669281,
      "backward_entropy": 0.0985269376209804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.82998657226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014191758818924427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349899172782898,
      "backward_entropy": 0.09797426632472447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.9112548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014304257929325104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13494841754436493,
      "backward_entropy": 0.09794349329812187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.84590911865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014416941441595554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349060982465744,
      "backward_entropy": 0.09847520078931536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.53114318847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014523660764098167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13486462831497192,
      "backward_entropy": 0.0984551991735186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.88764953613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014633218757808208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13482177257537842,
      "backward_entropy": 0.09784185886383057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.12289428710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014734331518411636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13478043675422668,
      "backward_entropy": 0.09899000610624041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.28375244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014833484776318073,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347389668226242,
      "backward_entropy": 0.09898831163133893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.32984924316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014937672764062881,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13469547033309937,
      "backward_entropy": 0.09898694923945836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.90142822265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015042086131870747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346512883901596,
      "backward_entropy": 0.09834262302943639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.27484130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015148766338825226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13460566103458405,
      "backward_entropy": 0.09764158725738525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.32260131835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015255652368068695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345592737197876,
      "backward_entropy": 0.09829600368227277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.40185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015359815210103989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13451293110847473,
      "backward_entropy": 0.0975571700504848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.07949829101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015465222299098969,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13446560502052307,
      "backward_entropy": 0.09898053748267037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.93960571289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015570956282317638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13441741466522217,
      "backward_entropy": 0.09746487651552473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.02630615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015676716342568398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13436849415302277,
      "backward_entropy": 0.09741646902901786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.96096801757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015779584646224976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343197375535965,
      "backward_entropy": 0.09816232749394008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.53700256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01588159054517746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13427047431468964,
      "backward_entropy": 0.0973116329738072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.3000946044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015979735180735588,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342216581106186,
      "backward_entropy": 0.09810090916497367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.85008239746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016077376902103424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.134172260761261,
      "backward_entropy": 0.09896957874298096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.47836303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01617497019469738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13412204384803772,
      "backward_entropy": 0.09713988644736153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.0081558227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016276825219392776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13406957685947418,
      "backward_entropy": 0.09800301279340472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.81405639648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016371658071875572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13401880860328674,
      "backward_entropy": 0.09796810150146484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.6432342529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01646347902715206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1339683085680008,
      "backward_entropy": 0.09793135098048619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.41424560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016554096713662148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13391746580600739,
      "backward_entropy": 0.09789348500115531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.14312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016646858304739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13386502861976624,
      "backward_entropy": 0.09785611288888114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.79652404785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016738733276724815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1338120698928833,
      "backward_entropy": 0.09676774059023176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.84597778320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01683075912296772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337582767009735,
      "backward_entropy": 0.09670121329171318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.81385803222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016919109970331192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1337050050497055,
      "backward_entropy": 0.09773680141993932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.6678466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017006490379571915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13365134596824646,
      "backward_entropy": 0.09769399677004133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.15969848632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017088284716010094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335991472005844,
      "backward_entropy": 0.09648006302969796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.85646057128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01717170514166355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13354550302028656,
      "backward_entropy": 0.09760306562696185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.1182098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017257802188396454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13349002599716187,
      "backward_entropy": 0.09632079941885811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 266.3170166015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017343316227197647,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.133433997631073,
      "backward_entropy": 0.09892439842224121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.81646728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017438340932130814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13337348401546478,
      "backward_entropy": 0.09747156075068883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.28656005859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017533332109451294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1333121359348297,
      "backward_entropy": 0.09892026015690394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.756103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01762843132019043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13324987888336182,
      "backward_entropy": 0.09738763741084508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.47586059570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01772627979516983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13318566977977753,
      "backward_entropy": 0.09734605039869036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.69186401367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01782800629734993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13311901688575745,
      "backward_entropy": 0.0973059790475028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.03326416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01792953349649906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13305141031742096,
      "backward_entropy": 0.09577962330409459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.2389907836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018027929589152336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13298417627811432,
      "backward_entropy": 0.09722157887050084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.08636474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018119383603334427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.132919043302536,
      "backward_entropy": 0.09717321395874023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.6913299560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018212633207440376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1328524798154831,
      "backward_entropy": 0.09552993944713048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.70127868652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018305886536836624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13278517127037048,
      "backward_entropy": 0.0989060742514474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.62652587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018399419263005257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13271674513816833,
      "backward_entropy": 0.0953501548085894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.62554931640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018493205308914185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13264721632003784,
      "backward_entropy": 0.09525844880512782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.77127838134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018585186451673508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13257767260074615,
      "backward_entropy": 0.09516029698508126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.97103881835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01867322437465191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325090527534485,
      "backward_entropy": 0.0950563635144915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.30755615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01876303181052208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13243898749351501,
      "backward_entropy": 0.09679474149431501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.4136962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018850358203053474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13236917555332184,
      "backward_entropy": 0.09673213958740234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 266.25701904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018932824954390526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13230085372924805,
      "backward_entropy": 0.09472058500562396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 248.59664916992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01902463287115097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1322271078824997,
      "backward_entropy": 0.0966047729764666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.54462432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019123811274766922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13214875757694244,
      "backward_entropy": 0.09450546332768031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.72605895996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019215410575270653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13207335770130157,
      "backward_entropy": 0.09648661954062325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.14824676513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01930917799472809,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13199582695960999,
      "backward_entropy": 0.09886772292000907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.24077606201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0193974319845438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319202035665512,
      "backward_entropy": 0.09416421822139195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.45938110351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01948210597038269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13184556365013123,
      "backward_entropy": 0.09628570079803467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.00833129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019566304981708527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1317702680826187,
      "backward_entropy": 0.0962098411151341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.82229614257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019655710086226463,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13168948888778687,
      "backward_entropy": 0.09885036945343018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.4406280517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019743219017982483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13160842657089233,
      "backward_entropy": 0.09884614603860038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4896697998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019831601530313492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13152523338794708,
      "backward_entropy": 0.09352490731648036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.02001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01991763897240162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13144199550151825,
      "backward_entropy": 0.09338673523494176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.0771026611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020007522776722908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13135525584220886,
      "backward_entropy": 0.0932516370500837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.15989685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020098837092518806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13126643002033234,
      "backward_entropy": 0.09311079978942871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.98724365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020193034783005714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1311747133731842,
      "backward_entropy": 0.09565309967313494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.67752075195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020287426188588142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13108162581920624,
      "backward_entropy": 0.09556945732661656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.91864013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020377930253744125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1309896856546402,
      "backward_entropy": 0.09267113889966692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.0487518310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020465608686208725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13089829683303833,
      "backward_entropy": 0.095387978213174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.30569458007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020553752779960632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13080544769763947,
      "backward_entropy": 0.09234612328665597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.16383361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020639458671212196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13071298599243164,
      "backward_entropy": 0.09217374665396554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.96331787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020726677030324936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1306183636188507,
      "backward_entropy": 0.09509176867348808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.31216430664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020814981311559677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13052186369895935,
      "backward_entropy": 0.09499156475067139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.5658416748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02090412564575672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1304236650466919,
      "backward_entropy": 0.09489047527313232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.98650360107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02099495567381382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13032318651676178,
      "backward_entropy": 0.09478844915117536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.00888061523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02108200453221798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1302241086959839,
      "backward_entropy": 0.09131343024117607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.99290466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021170036867260933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13012318313121796,
      "backward_entropy": 0.09457271439688546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.80853271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021261904388666153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13001853227615356,
      "backward_entropy": 0.09095256669180733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.00154876708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021361099556088448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12990784645080566,
      "backward_entropy": 0.09436871324266706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.91860961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021455252543091774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12980076670646667,
      "backward_entropy": 0.09060289178575788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.06430053710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021544869989156723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12969332933425903,
      "backward_entropy": 0.0941483463559832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.25482177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021630974486470222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295885592699051,
      "backward_entropy": 0.09403106144496373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.8885498046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021717876195907593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1294819712638855,
      "backward_entropy": 0.09873347623007638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.30682373046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0218045637011528,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12937431037425995,
      "backward_entropy": 0.09872726031712123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.1331329345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021889561787247658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12926672399044037,
      "backward_entropy": 0.09872065271650042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.5945587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021974412724375725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12915802001953125,
      "backward_entropy": 0.08940034253256661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.99773406982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022059280425310135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.129048153758049,
      "backward_entropy": 0.09341468129839216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.72511291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022139325737953186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1289408653974533,
      "backward_entropy": 0.09327903815678187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.84808349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022221112623810768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12883102893829346,
      "backward_entropy": 0.09314254352024623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.21019744873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02229839377105236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12872415781021118,
      "backward_entropy": 0.08851417473384313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.83686828613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022371476516127586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12861871719360352,
      "backward_entropy": 0.08826965945107597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.71864318847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02243952266871929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12851683795452118,
      "backward_entropy": 0.09269063813345772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.83650207519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022512085735797882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12841007113456726,
      "backward_entropy": 0.09253606625965663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.1448974609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022579966112971306,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12830623984336853,
      "backward_entropy": 0.09863589491162982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.3793182373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02264687605202198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1282021701335907,
      "backward_entropy": 0.08724309716905866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.14510345458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022718455642461777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280933916568756,
      "backward_entropy": 0.0869878785950797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.38819885253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022787990048527718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12798473238945007,
      "backward_entropy": 0.08672485181263515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.5143280029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02286316454410553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1278705596923828,
      "backward_entropy": 0.09859005042484828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.22931671142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022940387949347496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12775349617004395,
      "backward_entropy": 0.09153798648289271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.72176361083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02301391400396824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12763869762420654,
      "backward_entropy": 0.09135878937585014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.33038330078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023084262385964394,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12752574682235718,
      "backward_entropy": 0.09855641637529645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.107666015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023153839632868767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12741239368915558,
      "backward_entropy": 0.09097705568586077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.84730529785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023228025063872337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12729384005069733,
      "backward_entropy": 0.09853180817195348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.55496215820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0233015026897192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12717583775520325,
      "backward_entropy": 0.09059349128178187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.04356384277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02337213046848774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12705790996551514,
      "backward_entropy": 0.09039496523993355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.2664031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023448795080184937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12693408131599426,
      "backward_entropy": 0.08420957837785993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.02188110351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023525914177298546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12680897116661072,
      "backward_entropy": 0.08392695018223353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.35704040527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023605113849043846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12668083608150482,
      "backward_entropy": 0.08982104063034058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.34884643554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023682178929448128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1265537440776825,
      "backward_entropy": 0.08334425517490932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.01080322265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02376149222254753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12642350792884827,
      "backward_entropy": 0.09846164499010358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.06697845458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02384541556239128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12628789246082306,
      "backward_entropy": 0.08921689646584648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.44851684570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0239267498254776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12615381181240082,
      "backward_entropy": 0.08900859526225499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.93524169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024012912064790726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1260140985250473,
      "backward_entropy": 0.08880123070308141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.04598999023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024097517132759094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12587490677833557,
      "backward_entropy": 0.08186563423701695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.7648468017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02418225258588791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257345974445343,
      "backward_entropy": 0.08836696829114642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.977783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024269985035061836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12559033930301666,
      "backward_entropy": 0.08815074818474906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.07591247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024351397529244423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12545152008533478,
      "backward_entropy": 0.08093202114105225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.7685089111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024437513202428818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1253070831298828,
      "backward_entropy": 0.08061540978295463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.24253845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0245219599455595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12516482174396515,
      "backward_entropy": 0.08029026644570487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.6590118408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024603813886642456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12502437829971313,
      "backward_entropy": 0.08721406970705305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.57403564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02468842640519142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12488009035587311,
      "backward_entropy": 0.08697066988263812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.88333129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024765796959400177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12474389374256134,
      "backward_entropy": 0.08670898846217565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.42642211914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024842552840709686,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12460640072822571,
      "backward_entropy": 0.08644533157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024926308542490005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12445926666259766,
      "backward_entropy": 0.07856513772691999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.87104797363281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02500990778207779,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12431234121322632,
      "backward_entropy": 0.09831685679299491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.60345458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025090081617236137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12416835874319077,
      "backward_entropy": 0.07787666150501796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.57656860351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025166163221001625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12402869760990143,
      "backward_entropy": 0.07751137018203735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.59720611572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025242894887924194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12388753890991211,
      "backward_entropy": 0.08513786111559186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.5060577392578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025316188111901283,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12374958395957947,
      "backward_entropy": 0.09825893810817174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.3966064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02539072558283806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12360931932926178,
      "backward_entropy": 0.08455801861626762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.16110610961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025462063029408455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12347199022769928,
      "backward_entropy": 0.08425512484141759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.94387817382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02552657201886177,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12334203720092773,
      "backward_entropy": 0.09819964851651873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.94908142089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025594497099518776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12320715934038162,
      "backward_entropy": 0.08362213202885219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.41118621826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025662720203399658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12307105213403702,
      "backward_entropy": 0.07471808365413121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.11537170410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025729823857545853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12293541431427002,
      "backward_entropy": 0.07429406472614833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.22871398925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02580026537179947,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12279496341943741,
      "backward_entropy": 0.08266225031444005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.4571533203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02586701139807701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12265867739915848,
      "backward_entropy": 0.08233351366860527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.30416870117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02593267895281315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12252198159694672,
      "backward_entropy": 0.07302163328443255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.36544799804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026000484824180603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12238222360610962,
      "backward_entropy": 0.07259258202144078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.1763153076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026072045788168907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12223716080188751,
      "backward_entropy": 0.0980372599193028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.36092376708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026144737377762794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1220899224281311,
      "backward_entropy": 0.0810144373348781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.29022216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02621566131711006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12194409966468811,
      "backward_entropy": 0.0806763768196106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.87185668945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026289917528629303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12179387360811234,
      "backward_entropy": 0.08034593718392509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.17257690429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026359301060438156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12164860963821411,
      "backward_entropy": 0.07999822923115321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.53929138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02642645873129368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12150535732507706,
      "backward_entropy": 0.0699925252369472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.519065856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026495983824133873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12135868519544601,
      "backward_entropy": 0.07928918940680367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.23202514648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026558881625533104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12122007459402084,
      "backward_entropy": 0.06909402353422982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2244415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02662121318280697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12108145654201508,
      "backward_entropy": 0.06862695728029523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.37675476074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02668711729347706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12093751132488251,
      "backward_entropy": 0.07816175052097865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.9344482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026750916615128517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12079566717147827,
      "backward_entropy": 0.07777879919324603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.89312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026817064732313156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12065013498067856,
      "backward_entropy": 0.077400769506182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.06314849853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026887167245149612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12049882858991623,
      "backward_entropy": 0.06674605182238988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.54490661621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02695775404572487,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1203463077545166,
      "backward_entropy": 0.09776863881519862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.16230010986328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027022983878850937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12020045518875122,
      "backward_entropy": 0.09774429457528251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.96322631835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02708839438855648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12005384266376495,
      "backward_entropy": 0.06534616010529655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.21009826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027152130380272865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11990891396999359,
      "backward_entropy": 0.07548709426607404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.74066162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027214229106903076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11976565420627594,
      "backward_entropy": 0.09767310108457293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.68251037597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02727501466870308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11962392926216125,
      "backward_entropy": 0.07468199729919434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.41161346435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02732975222170353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11949054896831512,
      "backward_entropy": 0.06343827503068107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.01272583007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027382517233490944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11935876309871674,
      "backward_entropy": 0.07382830551692418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.38931274414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027443408966064453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11921452730894089,
      "backward_entropy": 0.06247238601957049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.25479125976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027504589408636093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11907028406858444,
      "backward_entropy": 0.07302618026733398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.16938018798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02757137268781662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11891783773899078,
      "backward_entropy": 0.06154619795935495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.09231567382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02763744443655014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11876600980758667,
      "backward_entropy": 0.07223543950489589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.92877197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027706146240234375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11861026287078857,
      "backward_entropy": 0.0718399030821664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.8345184326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02777722477912903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11845098435878754,
      "backward_entropy": 0.07144874334335327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.95417785644531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027855977416038513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11828131228685379,
      "backward_entropy": 0.09746670722961426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.3704071044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027932289987802505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11811457574367523,
      "backward_entropy": 0.07069143227168492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.25566864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028014371171593666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.117939792573452,
      "backward_entropy": 0.07031921829496111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.80211639404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028096113353967667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11776557564735413,
      "backward_entropy": 0.05834054946899414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.92337036132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028175877407193184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11759528517723083,
      "backward_entropy": 0.06955836500440325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.67034912109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028255563229322433,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1174253448843956,
      "backward_entropy": 0.0974312424659729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.83824157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02833615057170391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11725299060344696,
      "backward_entropy": 0.06877849783216204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.2167510986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028418276458978653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11707828938961029,
      "backward_entropy": 0.0683960999761309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.86090087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028503315523266792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11690053343772888,
      "backward_entropy": 0.05608155471937997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.53938293457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02859191596508026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11671794950962067,
      "backward_entropy": 0.05565867679459708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.86542510986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02867806702852249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11653879284858704,
      "backward_entropy": 0.05522599390574864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.08189392089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028760485351085663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11636503040790558,
      "backward_entropy": 0.06688495193208967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.19793701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028842922300100327,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1161913126707077,
      "backward_entropy": 0.06648948362895421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.73979949951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028928285464644432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11601369082927704,
      "backward_entropy": 0.0661071240901947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.45587921142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029013389721512794,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11583654582500458,
      "backward_entropy": 0.09743119989122663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.89776611328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029097413644194603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11566120386123657,
      "backward_entropy": 0.09743166821343559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.53358459472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029179377481341362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1154886931180954,
      "backward_entropy": 0.05262906210763114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.66835021972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02926132269203663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1153152734041214,
      "backward_entropy": 0.06451594403811864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.87612915039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029343118891119957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11514241248369217,
      "backward_entropy": 0.06410673686436244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.8197021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029425084590911865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11496991664171219,
      "backward_entropy": 0.06369985852922712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.1689453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029511744156479836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11479105055332184,
      "backward_entropy": 0.0633178608758109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.89724731445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02959657646715641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11461469531059265,
      "backward_entropy": 0.0629290086882455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.02964782714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02968224510550499,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11443664133548737,
      "backward_entropy": 0.05010366439819336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.49920654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029763955622911453,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11426416039466858,
      "backward_entropy": 0.062111888613019674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.34803771972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0298484954982996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408768594264984,
      "backward_entropy": 0.061699586255209785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0648956298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029928695410490036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11391830444335938,
      "backward_entropy": 0.06127245085580008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.94051361083984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030011901631951332,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11374415457248688,
      "backward_entropy": 0.09740076746259417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.31654357910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030092177912592888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11357413232326508,
      "backward_entropy": 0.06043833919933864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.43001556396484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0301667507737875,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1134132668375969,
      "backward_entropy": 0.09737568242209298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.14366149902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030237749218940735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11325840651988983,
      "backward_entropy": 0.05953626547540937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.62105560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030311666429042816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11309964954853058,
      "backward_entropy": 0.059094744069235663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.7584228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030386272817850113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11293935775756836,
      "backward_entropy": 0.04609590768814087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.44696044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030456479638814926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11278600990772247,
      "backward_entropy": 0.05819376025881086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.35855865478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030531467869877815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11262550950050354,
      "backward_entropy": 0.057746478489467075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.289424896240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030606940388679504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11246459186077118,
      "backward_entropy": 0.04466708217348371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.71294403076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030676359310746193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11231356859207153,
      "backward_entropy": 0.05683330127171108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.5545654296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030747003853321075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11216023564338684,
      "backward_entropy": 0.04371948327336993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.44558715820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030821366235613823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11200179904699326,
      "backward_entropy": 0.055932887962886264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.62095642089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030893296003341675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11184737086296082,
      "backward_entropy": 0.04277908802032471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.33165740966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030966538935899734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11169156432151794,
      "backward_entropy": 0.04231722014290946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.71182250976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031037935987114906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11153917014598846,
      "backward_entropy": 0.05456309233392988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.55342864990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031107403337955475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11139003187417984,
      "backward_entropy": 0.04138284921646118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.44627380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031178778037428856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11123868077993393,
      "backward_entropy": 0.05365029403141567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2339630126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031247686594724655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11109133064746857,
      "backward_entropy": 0.053185062749045234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.7255401611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031321972608566284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11093689501285553,
      "backward_entropy": 0.05273890921047756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.66060638427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03140123561024666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11077521741390228,
      "backward_entropy": 0.0523177513054439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.88639831542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03147859498858452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11061758548021317,
      "backward_entropy": 0.03913771254675729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.11915588378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031551070511341095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11046802997589111,
      "backward_entropy": 0.05146312713623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.49274826049805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03162575140595436,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11031574010848999,
      "backward_entropy": 0.09699766976492745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.58056640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03169388324022293,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11017438769340515,
      "backward_entropy": 0.09697199719292778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.12271118164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03176390379667282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11003033071756363,
      "backward_entropy": 0.050138303211757114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.83697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03183521330356598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1098853126168251,
      "backward_entropy": 0.049708732536860874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.86642456054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031909991055727005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10973557084798813,
      "backward_entropy": 0.04928429637636457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.52951049804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031983308494091034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10958915948867798,
      "backward_entropy": 0.03607623066220965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.69313049316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032057635486125946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1094416081905365,
      "backward_entropy": 0.048447183200291226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.43965911865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03212849795818329,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10930022597312927,
      "backward_entropy": 0.04801491328648159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.4765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03220108151435852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1091572716832161,
      "backward_entropy": 0.03481713788849967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.73348999023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03227509185671806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10901328921318054,
      "backward_entropy": 0.04718996797289167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.97914123535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032350119203329086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10886788368225098,
      "backward_entropy": 0.0467937844140189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.45977020263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03242579102516174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10872255265712738,
      "backward_entropy": 0.09683226687567574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.25399398803711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03249962627887726,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10858097672462463,
      "backward_entropy": 0.09682060991014753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.35879516601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03256922960281372,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10844659805297852,
      "backward_entropy": 0.045566090515681675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.9700164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032637499272823334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10831494629383087,
      "backward_entropy": 0.03241497703960964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.61217498779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032711148262023926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10817645490169525,
      "backward_entropy": 0.04475483298301697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.27587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327833853662014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10804088413715363,
      "backward_entropy": 0.03167669900826046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.87174987792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03286377340555191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10789494216442108,
      "backward_entropy": 0.0440068074635097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.59336853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03294238820672035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10775287449359894,
      "backward_entropy": 0.030981604542051042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.84635543823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03301448002457619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1076214388012886,
      "backward_entropy": 0.043265193700790405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.2728042602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033082373440265656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10749687254428864,
      "backward_entropy": 0.042868388550622125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.812191009521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03314801678061485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10737656056880951,
      "backward_entropy": 0.04246697681290763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.89588928222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033210720866918564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10726344585418701,
      "backward_entropy": 0.042067004101617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.44949340820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03326994180679321,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10715638846158981,
      "backward_entropy": 0.09670512165342059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.52877807617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033333417028188705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10704284906387329,
      "backward_entropy": 0.041266679763793945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.93434143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03340235352516174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1069212481379509,
      "backward_entropy": 0.040911278554371426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.48690795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03346661105751991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1068076342344284,
      "backward_entropy": 0.040549205882208686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.39470672607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03352911397814751,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10669735074043274,
      "backward_entropy": 0.0966738292149135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.48858642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033592917025089264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10658593475818634,
      "backward_entropy": 0.039829679897853305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.86875915527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03366410359740257,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10646377503871918,
      "backward_entropy": 0.09668331486838204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.79141998291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033735889941453934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1063418909907341,
      "backward_entropy": 0.039218757833753316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.2822036743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03381090611219406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10621625930070877,
      "backward_entropy": 0.038923067705971856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.12501525878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03388361632823944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10609504580497742,
      "backward_entropy": 0.026265140090669905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.03179168701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03395603969693184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10597515106201172,
      "backward_entropy": 0.09674343041011266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.5107650756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034027379006147385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10585802048444748,
      "backward_entropy": 0.03804144263267517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.35588455200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03409896045923233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10574133694171906,
      "backward_entropy": 0.0377437812941415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.4681854248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034166451543569565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10563181340694427,
      "backward_entropy": 0.025154852441379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.35580444335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03424103930592537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1055130809545517,
      "backward_entropy": 0.03715190717152187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.56674194335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034317757934331894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10539233684539795,
      "backward_entropy": 0.024643978902271817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.9097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03439931571483612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1052660197019577,
      "backward_entropy": 0.03666829211371286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.93330383300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03447910025715828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10514354705810547,
      "backward_entropy": 0.03643780095236642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.00143432617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03455638885498047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1050257608294487,
      "backward_entropy": 0.03620960031236921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.53781127929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03463675081729889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10490459203720093,
      "backward_entropy": 0.03599599003791809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.3555145263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03471696749329567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10478486120700836,
      "backward_entropy": 0.03578085558755057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.38007354736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034802310168743134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10466007143259048,
      "backward_entropy": 0.03558194211551121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.55850219726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03488833084702492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10453605651855469,
      "backward_entropy": 0.035381591745785305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7852554321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03497101366519928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10441778600215912,
      "backward_entropy": 0.035172854151044576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.434566497802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03505479916930199,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10429921001195908,
      "backward_entropy": 0.034969953554017205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.637725830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035132408142089844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1041899025440216,
      "backward_entropy": 0.03474859041827066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.61683654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035202208906412125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10409203916788101,
      "backward_entropy": 0.022267299039023265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.09346008300781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03527402877807617,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10399220883846283,
      "backward_entropy": 0.09716456277029854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.01387023925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03534238412976265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10389808565378189,
      "backward_entropy": 0.03403487162930625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.05524444580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03541175648570061,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.103803351521492,
      "backward_entropy": 0.03379601665905544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.52706909179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03548455238342285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10370538383722305,
      "backward_entropy": 0.03356457608086722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.34050750732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03555939719080925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10360588133335114,
      "backward_entropy": 0.021087835941995894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.4244384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03563347086310387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10350814461708069,
      "backward_entropy": 0.020862643207822527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.23985290527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035707905888557434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1034107357263565,
      "backward_entropy": 0.03291335489068713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.95785522460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03578740730881691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10330721735954285,
      "backward_entropy": 0.02043790476662772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.97732543945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035868048667907715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10320344567298889,
      "backward_entropy": 0.032547405787876675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.449127197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03594828397035599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10310155153274536,
      "backward_entropy": 0.03235451238495963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.00638580322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036022767424583435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10300882905721664,
      "backward_entropy": 0.019797993557793752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.68894958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0361003652215004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10291251540184021,
      "backward_entropy": 0.03193663273538862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.48068237304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03617974370718002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10281484574079514,
      "backward_entropy": 0.03174634916441781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.89573669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03625641390681267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10272195190191269,
      "backward_entropy": 0.019158037645476206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.5436782836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03633641079068184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1026257574558258,
      "backward_entropy": 0.031374384249959676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.75463104248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03641640767455101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10253077745437622,
      "backward_entropy": 0.031200004475457326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.14968872070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03649497777223587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10243862867355347,
      "backward_entropy": 0.031023538538387845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.427490234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03657371550798416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10234713554382324,
      "backward_entropy": 0.03085079789161682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.60002136230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03665207326412201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10225721448659897,
      "backward_entropy": 0.03066830975668771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.29570770263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0367279089987278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1021714136004448,
      "backward_entropy": 0.01794406771659851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.8397445678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03680252283811569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208821296691895,
      "backward_entropy": 0.0177317847098623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.38910675048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03687917813658714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200497508049011,
      "backward_entropy": 0.0301149274621691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.82695770263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03695522993803024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019224226474762,
      "backward_entropy": 0.029946237802505493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.30117797851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037034615874290466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10183484107255936,
      "backward_entropy": 0.029791959694453647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.90290069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03711801394820213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10174322873353958,
      "backward_entropy": 0.01697248433317457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.69236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03720514476299286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10164940357208252,
      "backward_entropy": 0.016802161931991577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.444904327392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037290651351213455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10155875980854034,
      "backward_entropy": 0.02938112829412733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.43282318115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03736872598528862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1014784723520279,
      "backward_entropy": 0.029231888907296315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.17451477050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03744778409600258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10139752924442291,
      "backward_entropy": 0.016291324581418718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.65010070800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037526052445173264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10131825506687164,
      "backward_entropy": 0.02898764823164259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.95919799804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03760451078414917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10123960673809052,
      "backward_entropy": 0.02886670614991869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.47511291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03768380358815193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10116060823202133,
      "backward_entropy": 0.028763587985719954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.03596496582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0377592109143734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10108734667301178,
      "backward_entropy": 0.028649602617536272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.67152404785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03783678635954857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10101236402988434,
      "backward_entropy": 0.028546848467418125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.82108306884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03791491314768791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10093753039836884,
      "backward_entropy": 0.028449673737798418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.8414306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0379914864897728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10086561739444733,
      "backward_entropy": 0.01520962906735284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.11796569824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03807404264807701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10078781098127365,
      "backward_entropy": 0.02823203376361302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.91267395019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038153596222400665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10071448236703873,
      "backward_entropy": 0.014905355870723724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.40269470214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03823491930961609,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10064050555229187,
      "backward_entropy": 0.02801991786275591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.4941291809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03831682726740837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10056591778993607,
      "backward_entropy": 0.027936090316091265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.43196868896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03839467465877533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10049684345722198,
      "backward_entropy": 0.027840243918555125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.95773315429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03847283124923706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10042784363031387,
      "backward_entropy": 0.027742419924054827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.61299133300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038555555045604706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10035471618175507,
      "backward_entropy": 0.027662151626178196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.8713493347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038637470453977585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10028344392776489,
      "backward_entropy": 0.014078765043190547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.57645797729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038714341819286346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1002185270190239,
      "backward_entropy": 0.027524164744785855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.58636474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038789357990026474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10015630722045898,
      "backward_entropy": 0.027456513472965786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.9545669555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03886359930038452,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10009566694498062,
      "backward_entropy": 0.0273813328572682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.57726287841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038940053433179855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10003327578306198,
      "backward_entropy": 0.01357072698218482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.1767692565918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03901875019073486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09996908903121948,
      "backward_entropy": 0.013453123824937003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.20767211914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039094164967536926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09990955889225006,
      "backward_entropy": 0.027196496725082397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.35311889648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03917180746793747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0998474508523941,
      "backward_entropy": 0.027142714176859175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.26829528808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03924906253814697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09978656470775604,
      "backward_entropy": 0.013109479631696428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.128971099853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03932750225067139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0997256487607956,
      "backward_entropy": 0.01298552325793675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.017539978027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03940119966864586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09967061877250671,
      "backward_entropy": 0.026946387120655606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.42898559570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03947141021490097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09962031245231628,
      "backward_entropy": 0.026853278279304504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.01637268066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039543136954307556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956826269626617,
      "backward_entropy": 0.012600255864007133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.53945922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03961360082030296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09951832890510559,
      "backward_entropy": 0.012478463351726532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.420406341552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03968706354498863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09946571290493011,
      "backward_entropy": 0.02665559095995767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.87200164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03975681960582733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09941715747117996,
      "backward_entropy": 0.012261156524930681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.11734390258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039827797561883926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09936794638633728,
      "backward_entropy": 0.01215401611157826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.9517593383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03989598900079727,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09932228922843933,
      "backward_entropy": 0.02651913676943098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.46067810058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03996694087982178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09927432239055634,
      "backward_entropy": 0.011931345931121282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.53274536132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040033742785453796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09923213720321655,
      "backward_entropy": 0.011813124375683921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.49401092529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040101077407598495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09918913245201111,
      "backward_entropy": 0.02633498396192278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.79026794433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04016866162419319,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09914564341306686,
      "backward_entropy": 0.026268886668341502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.45364379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040233369916677475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09910615533590317,
      "backward_entropy": 0.026182185326303755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.85323333740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040300097316503525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0990653857588768,
      "backward_entropy": 0.011341336582388197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.707481384277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037337750196457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09901881217956543,
      "backward_entropy": 0.011225866419928414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.82373046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0404428206384182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09897688031196594,
      "backward_entropy": 0.02596344692366464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.33768463134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04051753133535385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0989297479391098,
      "backward_entropy": 0.011009888989584786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.83824157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04059214144945145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0988832414150238,
      "backward_entropy": 0.02586119089807783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.29508209228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040668800473213196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09883558750152588,
      "backward_entropy": 0.01080972169126783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.9056396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040747981518507004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09878581017255783,
      "backward_entropy": 0.010719117309365953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.74789428710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04082639142870903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09873732924461365,
      "backward_entropy": 0.010629230311938695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.40323257446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04090568795800209,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09868839383125305,
      "backward_entropy": 0.02572993508407048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.36565399169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04097979515790939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09864526987075806,
      "backward_entropy": 0.01044822484254837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.057220458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0410536527633667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09860280156135559,
      "backward_entropy": 0.01035267859697342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.00183868408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04112616181373596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09856191277503967,
      "backward_entropy": 0.025599415813173567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.721038818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0412013866007328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09851881861686707,
      "backward_entropy": 0.025571397372654507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.673095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04127524793148041,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09847719967365265,
      "backward_entropy": 0.025551314864839827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.17866516113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04135012626647949,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09843503683805466,
      "backward_entropy": 0.025531198297228132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.29600524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04143013432621956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09838852286338806,
      "backward_entropy": 0.02552762201854161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.53005981445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04151042550802231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09834237396717072,
      "backward_entropy": 0.02551869409424918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.78005981445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04159438610076904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09829296171665192,
      "backward_entropy": 0.025536860738481795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.15498161315918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04167933389544487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09824341535568237,
      "backward_entropy": 0.009733366114752633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.33106994628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0417584665119648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0981992781162262,
      "backward_entropy": 0.025555308376039778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.91069793701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04183816909790039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09815506637096405,
      "backward_entropy": 0.009608060121536255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.003551483154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04191960021853447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09810962527990341,
      "backward_entropy": 0.00954467590366091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.22447204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04199545830488205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09806940704584122,
      "backward_entropy": 0.02559772559574672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.33399963378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04206976667046547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09803084284067154,
      "backward_entropy": 0.02561433826174055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.25961303710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04214156046509743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09799467027187347,
      "backward_entropy": 0.02563399715082986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.06118774414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221475496888161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09795744717121124,
      "backward_entropy": 0.00930556867803846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.10679626464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04228920862078667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09791931509971619,
      "backward_entropy": 0.025673523545265198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.05372619628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236720874905586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09787839651107788,
      "backward_entropy": 0.009190241140978677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.344085693359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042444758117198944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09783808887004852,
      "backward_entropy": 0.025710870112691606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.19525146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04252057895064354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09779953211545944,
      "backward_entropy": 0.02572934329509735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.5147705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04259747639298439,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09776009619235992,
      "backward_entropy": 0.009023440735680717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.77767181396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042674023658037186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09772121906280518,
      "backward_entropy": 0.00897035002708435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.98191261291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04275156557559967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09768152236938477,
      "backward_entropy": 0.008919618491615568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.4329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04282452538609505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09764649718999863,
      "backward_entropy": 0.02581816485949925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.86957550048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04289862886071205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09761066734790802,
      "backward_entropy": 0.025823984827314104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.62586975097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042972445487976074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09757537394762039,
      "backward_entropy": 0.025821930595806668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.18174362182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04304388165473938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09754303097724915,
      "backward_entropy": 0.02578563562461308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.5533676147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04311409592628479,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09751200675964355,
      "backward_entropy": 0.0257498494216374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.41154479980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318593069911003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09747923165559769,
      "backward_entropy": 0.008523061339344298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.54877853393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043259020894765854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09744555503129959,
      "backward_entropy": 0.008455356849091393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.12002944946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04332932457327843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09741458296775818,
      "backward_entropy": 0.025675009403909956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.77885437011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04339621216058731,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09738662838935852,
      "backward_entropy": 0.025652457560811723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.41984558105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04346495494246483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09735696017742157,
      "backward_entropy": 0.025634116360119412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.38581848144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043532371520996094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09732884913682938,
      "backward_entropy": 0.02560079949242728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.23969268798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04360159486532211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09729911386966705,
      "backward_entropy": 0.008115145244768687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.8437385559082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04367224499583244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0972682312130928,
      "backward_entropy": 0.025551084961209978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.79922103881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04374188184738159,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09723823517560959,
      "backward_entropy": 0.025529693279947554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.603872299194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04380882531404495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09721097350120544,
      "backward_entropy": 0.007914812437125615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.39491081237793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04387233778834343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09718701243400574,
      "backward_entropy": 0.025448758687291826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.26475524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04393325373530388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09716516733169556,
      "backward_entropy": 0.025418258139065335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.08829116821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0439942441880703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09714306145906448,
      "backward_entropy": 0.007711945367710931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.344995498657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04405549541115761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09712044894695282,
      "backward_entropy": 0.007655005902051926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.7503662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044112712144851685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09710169583559036,
      "backward_entropy": 0.00759491537298475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.255613327026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0441724956035614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09708091616630554,
      "backward_entropy": 0.02535362115928105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.84347152709961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044228311628103256,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09706392884254456,
      "backward_entropy": 0.09861396040235247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.91558074951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04428325220942497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09704743325710297,
      "backward_entropy": 0.007407653544630323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.803035736083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04433621093630791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09703263640403748,
      "backward_entropy": 0.025273631725992476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.10919952392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0443875752389431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09701934456825256,
      "backward_entropy": 0.025259205273219516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.26201248168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04444102197885513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09700413048267365,
      "backward_entropy": 0.025246649980545044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.80836868286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0444948747754097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09698871523141861,
      "backward_entropy": 0.007174093276262283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.2363052368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044550660997629166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09697144478559494,
      "backward_entropy": 0.02521501055785588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.81459426879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04460985213518143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09695155918598175,
      "backward_entropy": 0.025179809757641385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.001365661621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446692556142807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09693139791488647,
      "backward_entropy": 0.00699722341128758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.603050231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04472775012254715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09691181778907776,
      "backward_entropy": 0.006943506853921073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.640657424926758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04478627070784569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09689216315746307,
      "backward_entropy": 0.025126699890409197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.92601013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04484114050865173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09687590599060059,
      "backward_entropy": 0.02510817987578256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.65870666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044897690415382385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09685815125703812,
      "backward_entropy": 0.006779364177158901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.49241256713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044956453144550323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09683804214000702,
      "backward_entropy": 0.0067339422447340825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.459877014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045014388859272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09681876748800278,
      "backward_entropy": 0.025111771055630276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.75911712646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04507115110754967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09680013358592987,
      "backward_entropy": 0.006647518702915737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.756113052368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04513094201683998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09677869826555252,
      "backward_entropy": 0.00660580609525953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.87367248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045188359916210175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09675949811935425,
      "backward_entropy": 0.025146931409835815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.38186264038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04524974897503853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09673671424388885,
      "backward_entropy": 0.025161066225596836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.701316833496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045311324298381805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09671356528997421,
      "backward_entropy": 0.025185802153178623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.124046325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045373834669589996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09668970108032227,
      "backward_entropy": 0.00644781014748982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.672569274902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04543633386492729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09666571021080017,
      "backward_entropy": 0.0064114486532551905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.4908676147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04549747332930565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09664304554462433,
      "backward_entropy": 0.025257785405431474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.32003784179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045561011880636215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09661789238452911,
      "backward_entropy": 0.00634145417383739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.0760269165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04562653973698616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09659113734960556,
      "backward_entropy": 0.025314571602003916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.32801818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04569418355822563,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09656237065792084,
      "backward_entropy": 0.006272435188293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.11343002319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04576605558395386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09652982652187347,
      "backward_entropy": 0.025379732251167297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.31681442260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0458354614675045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0964994803071022,
      "backward_entropy": 0.02540836589676993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.98566436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04590507224202156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09646894037723541,
      "backward_entropy": 0.02543229503290994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.9631233215332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045973774045705795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09643910825252533,
      "backward_entropy": 0.025457618491990224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.83091354370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04604266956448555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09640909731388092,
      "backward_entropy": 0.025476611086300442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.536746978759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046113137155771255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09637746214866638,
      "backward_entropy": 0.025497696229389737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.309473037719727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04618252441287041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09634670615196228,
      "backward_entropy": 0.006027639976569584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.17500305175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04624757915735245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09631963819265366,
      "backward_entropy": 0.025547664080347334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.99587631225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04631480947136879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09629030525684357,
      "backward_entropy": 0.005964968353509903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.9642219543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04638376086950302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09625934809446335,
      "backward_entropy": 0.025624664766447886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.87129211425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04645099118351936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09622934460639954,
      "backward_entropy": 0.005909747843231473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.62168884277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046516433358192444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0962008684873581,
      "backward_entropy": 0.025730203304971968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.681907653808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658150672912598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0961725115776062,
      "backward_entropy": 0.005860867777041027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.19849395751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04664461687207222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09614600241184235,
      "backward_entropy": 0.025828495621681213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.181026458740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0467083640396595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09611877799034119,
      "backward_entropy": 0.02585766783782414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.06315231323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04677204787731171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09609130024909973,
      "backward_entropy": 0.025898309690611705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.481101989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04683544486761093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09606382250785828,
      "backward_entropy": 0.02594017130987985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.19713592529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04689595848321915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09603901952505112,
      "backward_entropy": 0.02597371595246451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.304384231567383,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04695888236165047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0960116982460022,
      "backward_entropy": 0.098824143409729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.50303268432617,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04701904207468033,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09598687291145325,
      "backward_entropy": 0.09882816246577672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.103904724121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04707932844758034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09596164524555206,
      "backward_entropy": 0.026080548763275146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.43596649169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04713748022913933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09593813866376877,
      "backward_entropy": 0.026131059442247664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.538246154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471983328461647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09591179341077805,
      "backward_entropy": 0.005583091505936214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.344099044799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0472579263150692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09588640928268433,
      "backward_entropy": 0.005559852080685752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.86674499511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04731392115354538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09586447477340698,
      "backward_entropy": 0.005535277404955455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.22594451904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047370150685310364,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09584219753742218,
      "backward_entropy": 0.02631638731275286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.594276428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047427885234355927,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09581820666790009,
      "backward_entropy": 0.026348320501191274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.26750183105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748581722378731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09579384326934814,
      "backward_entropy": 0.005452352442911693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.17085266113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04754837974905968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09576505422592163,
      "backward_entropy": 0.02639253650392805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.790950775146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047612808644771576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0957341343164444,
      "backward_entropy": 0.02639910578727722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.02100372314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047675471752882004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09570486098527908,
      "backward_entropy": 0.026405100311551775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.558597564697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04773790389299393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.095675528049469,
      "backward_entropy": 0.026417666247912815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.95345306396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047798771411180496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09564755856990814,
      "backward_entropy": 0.02642812899180821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.68905639648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04786427691578865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09561482071876526,
      "backward_entropy": 0.005264478070395333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.19505310058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047933876514434814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09557788074016571,
      "backward_entropy": 0.0264562155519213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.48643493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04800119251012802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0955430269241333,
      "backward_entropy": 0.0052053555846214294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.735153198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048068929463624954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09550745040178299,
      "backward_entropy": 0.026482111641338894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.66204071044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04813383147120476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09547428786754608,
      "backward_entropy": 0.005152098302330289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.96713638305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819590598344803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0954437255859375,
      "backward_entropy": 0.005128134042024612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.503311157226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048258647322654724,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09541232883930206,
      "backward_entropy": 0.09888088703155518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.54829406738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04831851273775101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09538371115922928,
      "backward_entropy": 0.026581674814224243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.40902328491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04837825894355774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09535498172044754,
      "backward_entropy": 0.026594630309513638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.21923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048437897115945816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0953260138630867,
      "backward_entropy": 0.0266071047101702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.09492492675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04849409684538841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09530039131641388,
      "backward_entropy": 0.0049895984785897395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.84931945800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04855511337518692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09526963531970978,
      "backward_entropy": 0.004962522004331861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.90310287475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04862026125192642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09523455798625946,
      "backward_entropy": 0.02664474504334586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.59712600708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04868381470441818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09520068764686584,
      "backward_entropy": 0.004905967307942254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.414634704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048747990280389786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0951659232378006,
      "backward_entropy": 0.026667322431291853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.54768943786621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04881278797984123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09513020515441895,
      "backward_entropy": 0.026678281170981272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.0650634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04887589439749718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09509594738483429,
      "backward_entropy": 0.026694442544664656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.311279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04893947020173073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09506097435951233,
      "backward_entropy": 0.026701009699276516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.94725036621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049001410603523254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09502741694450378,
      "backward_entropy": 0.02671052728380476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.25484848022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0490630604326725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09499390423297882,
      "backward_entropy": 0.02672317624092102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.560518264770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049126677215099335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09495779871940613,
      "backward_entropy": 0.026736457433019365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.84870719909668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04918653890490532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09492554515600204,
      "backward_entropy": 0.00469839945435524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.73328399658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049244947731494904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09489457309246063,
      "backward_entropy": 0.026778989604541233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.62447166442871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04930223152041435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09486453235149384,
      "backward_entropy": 0.026799323303358897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.69340133666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935849830508232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09483534097671509,
      "backward_entropy": 0.0046279387814658025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.40880584716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049416135996580124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09480419754981995,
      "backward_entropy": 0.00460570039493697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.43825149536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049472663551568985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09477405250072479,
      "backward_entropy": 0.0045835817498820165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.68876266479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04953279718756676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09473958611488342,
      "backward_entropy": 0.004561642983130046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.506996154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049592968076467514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09470465779304504,
      "backward_entropy": 0.004542154393025807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.29969787597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04965514317154884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0946672111749649,
      "backward_entropy": 0.026953054325921193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.830841064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049719229340553284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09462728351354599,
      "backward_entropy": 0.026981628366879055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.1015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04978160187602043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09458893537521362,
      "backward_entropy": 0.0044824475688593724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.03511047363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04984359070658684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0945507138967514,
      "backward_entropy": 0.02704396205289023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.80228042602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049908749759197235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09450840950012207,
      "backward_entropy": 0.004445611632296017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04997294768691063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09446693956851959,
      "backward_entropy": 0.02710591895239694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.956954956054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05003529042005539,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09442728012800217,
      "backward_entropy": 0.09891865934644427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.628496170043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050095148384571075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09439007192850113,
      "backward_entropy": 0.02716457630906786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.79117774963379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050151724368333817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09435638785362244,
      "backward_entropy": 0.027215402041162764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.52242660522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020604282617569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09432508051395416,
      "backward_entropy": 0.00435790978372097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.80413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025728419423103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0942971259355545,
      "backward_entropy": 0.004342023017151015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.99114227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05030817165970802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09426919370889664,
      "backward_entropy": 0.02735352941921779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.60592269897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050360918045043945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09423863887786865,
      "backward_entropy": 0.027403056621551514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.0621566772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050413038581609726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09420847147703171,
      "backward_entropy": 0.004298382305673191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.198718547821045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05047111213207245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09417091310024261,
      "backward_entropy": 0.004281728661486081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.37035369873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05052480101585388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09413839876651764,
      "backward_entropy": 0.027534831847463335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.144235610961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050580091774463654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09410351514816284,
      "backward_entropy": 0.027585268020629883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.06560134887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05063126981258392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09407337754964828,
      "backward_entropy": 0.027644082903862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.87836456298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050684232264757156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09404069185256958,
      "backward_entropy": 0.027700577463422502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.69236373901367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050739821046590805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09400437772274017,
      "backward_entropy": 0.0042172327105488095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.40852355957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05079781264066696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09396476298570633,
      "backward_entropy": 0.027798337595803396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.29243469238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05085919052362442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09392064809799194,
      "backward_entropy": 0.027847581676074436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.67622184753418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05092231556773186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0938740149140358,
      "backward_entropy": 0.02789111222539629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.41103172302246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05098280310630798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09383025765419006,
      "backward_entropy": 0.02794376654284341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.297378540039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05104188248515129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09378780424594879,
      "backward_entropy": 0.027997225522994995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.652530670166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051099635660648346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09374667704105377,
      "backward_entropy": 0.028048813343048096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.340503692626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05115398392081261,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09370952844619751,
      "backward_entropy": 0.028100633195468357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.980138778686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05120644345879555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.093674436211586,
      "backward_entropy": 0.028155580163002014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.497536659240723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05125816911458969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09363988041877747,
      "backward_entropy": 0.028205941830362593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.453147888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0513070784509182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09360863268375397,
      "backward_entropy": 0.028256488697869436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.33334732055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051356617361307144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09357622265815735,
      "backward_entropy": 0.02829756268433162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.97100067138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051406972110271454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09354230761528015,
      "backward_entropy": 0.02834243859563555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.093040466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05145576596260071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09351008385419846,
      "backward_entropy": 0.028387344309261868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.544776916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05150553584098816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09347616136074066,
      "backward_entropy": 0.02844118433339255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.751483917236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05155714601278305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09343941509723663,
      "backward_entropy": 0.02849498816898891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.249263763427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05160725489258766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09340423345565796,
      "backward_entropy": 0.0040235261299780434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.59962463378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051659002900123596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09336652606725693,
      "backward_entropy": 0.004013108887842723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.47295379638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171110853552818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09332790970802307,
      "backward_entropy": 0.004001359854425702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.896242141723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05176372453570366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09328816086053848,
      "backward_entropy": 0.02870997999395643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.37137794494629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051815684884786606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09324906766414642,
      "backward_entropy": 0.003979536039488656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.297399520874023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05186593532562256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09321169555187225,
      "backward_entropy": 0.003969114007694381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.226062774658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05191464349627495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09317618608474731,
      "backward_entropy": 0.02886960336140224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.565773010253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05196215212345123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09314197301864624,
      "backward_entropy": 0.0039510032428162435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.73753547668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05201255902647972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09310348331928253,
      "backward_entropy": 0.02898767590522766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.612308502197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052063554525375366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09306387603282928,
      "backward_entropy": 0.029038591044289724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.651561737060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052114974707365036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09302330762147903,
      "backward_entropy": 0.003919446042605809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.62069320678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052163656800985336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09298619627952576,
      "backward_entropy": 0.0039091237953730994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.323101997375488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05221426859498024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09294598549604416,
      "backward_entropy": 0.029188075235911777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.333553314208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05226120352745056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0929107815027237,
      "backward_entropy": 0.02925088788781847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.18962097167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230999365448952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09287252277135849,
      "backward_entropy": 0.029303382549967085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.039947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05236053466796875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0928313359618187,
      "backward_entropy": 0.029351059879575456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.48757553100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052412550896406174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09278762340545654,
      "backward_entropy": 0.029390009386198863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.520185470581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05246293172240257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09274610877037048,
      "backward_entropy": 0.029438180582863942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.337949752807617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052512701600790024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0927046537399292,
      "backward_entropy": 0.02948154721941267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.2659912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256091430783272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09266530722379684,
      "backward_entropy": 0.003828746665801321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.269269943237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052607808262109756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09262754023075104,
      "backward_entropy": 0.029576997671808516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.12406349182129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052655596286058426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09258799254894257,
      "backward_entropy": 0.029627378497804915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.064373970031738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05270170047879219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09255065768957138,
      "backward_entropy": 0.003797808662056923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.957551956176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052745331078767776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09251676499843597,
      "backward_entropy": 0.02969044234071459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.923110961914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05278899148106575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09248240292072296,
      "backward_entropy": 0.02971639803477696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.70956039428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052831728011369705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0924491137266159,
      "backward_entropy": 0.0037583152630499433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.792322158813477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05287570506334305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09241349250078201,
      "backward_entropy": 0.029780128172465732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.727052688598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291880667209625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09237882494926453,
      "backward_entropy": 0.029821412903921946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.525047302246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0529610738158226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09234504401683807,
      "backward_entropy": 0.029869203056607927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.43854522705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0530037060379982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0923103392124176,
      "backward_entropy": 0.02992458002907889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.534278869628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05304640531539917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09227514266967773,
      "backward_entropy": 0.029972495777266368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.66490173339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05308821052312851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09224100410938263,
      "backward_entropy": 0.0036999514060361044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.95456886291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05313350260257721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09220093488693237,
      "backward_entropy": 0.030068646584238325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.34257507324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053179822862148285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09215886145830154,
      "backward_entropy": 0.030118480324745178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.258628845214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05322890728712082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0921119898557663,
      "backward_entropy": 0.030153274536132812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.59331512451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05327656865119934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09206704795360565,
      "backward_entropy": 0.0036624127200671603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.793598175048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05332475155591965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09202085435390472,
      "backward_entropy": 0.030229396053722928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.351903915405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05337274447083473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09197446703910828,
      "backward_entropy": 0.030274889298847744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.965591430664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05342145636677742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0919264703989029,
      "backward_entropy": 0.030322547469820296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.32536315917969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053468599915504456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0918806791305542,
      "backward_entropy": 0.09899391446794782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.148502349853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053518444299697876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0918300524353981,
      "backward_entropy": 0.03040508713041033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.963741302490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05357062816619873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09177515655755997,
      "backward_entropy": 0.030428158385413035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.24032211303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05362506955862045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09171619266271591,
      "backward_entropy": 0.03044834520135607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.570526123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053680356591939926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09165525436401367,
      "backward_entropy": 0.030457635010991777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.9581298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053735386580228806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09159431606531143,
      "backward_entropy": 0.03046223521232605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.292232513427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05378924682736397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09153473377227783,
      "backward_entropy": 0.003547340099300657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.57179641723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05384301766753197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09147486090660095,
      "backward_entropy": 0.030475092785699025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.234167098999023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053897708654403687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09141289442777634,
      "backward_entropy": 0.003518191565360342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.430081844329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05395008623600006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09135440737009048,
      "backward_entropy": 0.003503040277532169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.08089828491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05399848520755768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09130242466926575,
      "backward_entropy": 0.030487418174743652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.26255798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05404534935951233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09125261008739471,
      "backward_entropy": 0.0034768017274992807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.50873565673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05409475415945053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09119784086942673,
      "backward_entropy": 0.030513058815683638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.594257354736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0541444793343544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09114204347133636,
      "backward_entropy": 0.030522157038961138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.542774200439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05419161170721054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09109041839838028,
      "backward_entropy": 0.030545198491641452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.499886512756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05423625186085701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09104278683662415,
      "backward_entropy": 0.03057195246219635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.65158748626709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05427879840135574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09099853038787842,
      "backward_entropy": 0.030610552855900357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.10713768005371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05432049557566643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09095551073551178,
      "backward_entropy": 0.030658372810908725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06496796011924744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054364319890737534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09090791642665863,
      "backward_entropy": 0.030704004423958913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.45860481262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05440409481525421,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09086757898330688,
      "backward_entropy": 0.003398259569491659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.173916816711426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054443199187517166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0908280685544014,
      "backward_entropy": 0.003393239474722317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.437501907348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054479632526636124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09079320728778839,
      "backward_entropy": 0.030888310500553677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.663455963134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05451670661568642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09075693786144257,
      "backward_entropy": 0.030953175255230496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.43987274169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054558295756578445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09071126580238342,
      "backward_entropy": 0.0033778000090803418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.122961044311523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054602913558483124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09065978229045868,
      "backward_entropy": 0.031049370765686035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.09292221069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05464532598853111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09061197936534882,
      "backward_entropy": 0.003363214433193207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.026402473449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054686956107616425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09056533128023148,
      "backward_entropy": 0.031159324305398122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.900270462036133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05472768843173981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09051987528800964,
      "backward_entropy": 0.031223671776907786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.47783660888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476949363946915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09047199785709381,
      "backward_entropy": 0.03128047926085336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.977642059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05481807887554169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0904109925031662,
      "backward_entropy": 0.003339742709483419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.656003952026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05486290901899338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09035678207874298,
      "backward_entropy": 0.031344792672566006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.563411712646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05490751191973686,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09030251204967499,
      "backward_entropy": 0.0313809939793178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.033721923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054951831698417664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09024830907583237,
      "backward_entropy": 0.031417016472135274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05511529743671417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054998729377985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09018868207931519,
      "backward_entropy": 0.003303723143679755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.095624923706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05504117161035538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09013744443655014,
      "backward_entropy": 0.0032949205487966537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.41419506072998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05508442595601082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09008415043354034,
      "backward_entropy": 0.03150053322315216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.11247444152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0551266074180603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09003250300884247,
      "backward_entropy": 0.0032766610383987427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.513925552368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05516871437430382,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08998055756092072,
      "backward_entropy": 0.0032682205949510846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.21584415435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055212825536727905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0899241715669632,
      "backward_entropy": 0.031608011041368754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.245067596435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055255766957998276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08986963331699371,
      "backward_entropy": 0.03165246333394732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.756120681762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05530053377151489,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08981095254421234,
      "backward_entropy": 0.03169499124799456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.663793563842773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05534501373767853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08975233137607574,
      "backward_entropy": 0.031740884695734294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.57607650756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0553891584277153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08969391882419586,
      "backward_entropy": 0.003233129158616066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.089962005615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055433206260204315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0896352231502533,
      "backward_entropy": 0.031840620296342034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.22128963470459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05547782778739929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08957479894161224,
      "backward_entropy": 0.031886471169335504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.866323471069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05552016198635101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08951874077320099,
      "backward_entropy": 0.03193542148385729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.674560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055563151836395264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08946076780557632,
      "backward_entropy": 0.03197161214692252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.131454467773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0556049607694149,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08940481394529343,
      "backward_entropy": 0.03200914178575788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.03822326660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05564679205417633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08934825658798218,
      "backward_entropy": 0.0320539048739842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.949304580688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05569232255220413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08928348124027252,
      "backward_entropy": 0.032088522400174825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.502280235290527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055737316608428955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08921928703784943,
      "backward_entropy": 0.003178305391754423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.923744201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055779118090867996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08916155993938446,
      "backward_entropy": 0.003172126997794424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.673828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05582552030682564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08909355103969574,
      "backward_entropy": 0.03219891658851078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.96385955810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055871203541755676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.089026540517807,
      "backward_entropy": 0.0031556950083800723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.84213638305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05591731145977974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08895814418792725,
      "backward_entropy": 0.03225098763193403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.0602970123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05596358701586723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0888887345790863,
      "backward_entropy": 0.032263998474393575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.91105079650879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05601121485233307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0888158529996872,
      "backward_entropy": 0.032279608505112786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.331648826599121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056059982627630234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08873984962701797,
      "backward_entropy": 0.032293617725372314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569965362548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05610496550798416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08867189288139343,
      "backward_entropy": 0.032310494354793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.246166229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05614747107028961,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08860905468463898,
      "backward_entropy": 0.003096404086266245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.136741638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056190598756074905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08854418992996216,
      "backward_entropy": 0.003086312540939876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.629459381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0562344491481781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08847713470458984,
      "backward_entropy": 0.03236713792596545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.56551456451416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056276820600032806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08841297030448914,
      "backward_entropy": 0.032385564276150296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.502013206481934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05631799250841141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08835108578205109,
      "backward_entropy": 0.0030588292117629734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.568866729736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05635811388492584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08829102665185928,
      "backward_entropy": 0.0030507338898522513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266706466674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05639810487627983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08823084086179733,
      "backward_entropy": 0.03246306947299412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.228882789611816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0564361996948719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08817466348409653,
      "backward_entropy": 0.03249478553022657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.40421485900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05647268518805504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08812181651592255,
      "backward_entropy": 0.03253883123397827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.256816864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05651029944419861,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08806585520505905,
      "backward_entropy": 0.03257550724915096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.177112579345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056548140943050385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08800867199897766,
      "backward_entropy": 0.032616178904260905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.057182788848877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05658607929944992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08795087039470673,
      "backward_entropy": 0.03265430246080671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.037167072296143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05662132799625397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08789919316768646,
      "backward_entropy": 0.003001866862177849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.916954040527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05665405094623566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08785330504179001,
      "backward_entropy": 0.03273250162601471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964941024780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05668921396136284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08780089020729065,
      "backward_entropy": 0.03276440714086805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.816811561584473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05672293156385422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08775165677070618,
      "backward_entropy": 0.0029808953404426575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.59927749633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056757163256406784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08770067244768143,
      "backward_entropy": 0.0029742135001080377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.949878692626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056793760508298874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08764365315437317,
      "backward_entropy": 0.002967666568500655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.707592964172363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056827887892723083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08759237080812454,
      "backward_entropy": 0.00296227474297796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.656553268432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05686136707663536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08754149079322815,
      "backward_entropy": 0.002955314570239612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.46298599243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05689432471990585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08749200403690338,
      "backward_entropy": 0.002947618652667318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.231882095336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0569278746843338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08744054287672043,
      "backward_entropy": 0.033018559217453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679963111877441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696288123726845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0873849019408226,
      "backward_entropy": 0.002933243289589882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.052453994750977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05699640139937401,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08733270317316055,
      "backward_entropy": 0.03308786877564022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.96247100830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057031240314245224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08727669715881348,
      "backward_entropy": 0.033117179359708517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.103771209716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05706729367375374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08721700310707092,
      "backward_entropy": 0.033142185636929104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7861263751983643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05710360035300255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08715621381998062,
      "backward_entropy": 0.03317024878093174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7694172859191895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0571373887360096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08710163086652756,
      "backward_entropy": 0.03320462788854327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.468265056610107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05716896802186966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08705250918865204,
      "backward_entropy": 0.033248684235981533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.228599548339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057199571281671524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08700570464134216,
      "backward_entropy": 0.03330673703125545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.076885223388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05723288282752037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08695125579833984,
      "backward_entropy": 0.033369986074311395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.03076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05726548284292221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08689825981855392,
      "backward_entropy": 0.0028797837772539686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.21993637084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057297755032777786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08684563636779785,
      "backward_entropy": 0.03346788031714303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.55367374420166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057334210723638535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08678153902292252,
      "backward_entropy": 0.03351520214762006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.476255416870117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05737088620662689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08671638369560242,
      "backward_entropy": 0.03356770319598062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.40130615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057407625019550323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08665059506893158,
      "backward_entropy": 0.002858616943870272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.32529067993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057444509118795395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08658386766910553,
      "backward_entropy": 0.03366759845188686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.694437026977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057481542229652405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08651629090309143,
      "backward_entropy": 0.00284842135650771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.637141227722168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057517703622579575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08645057678222656,
      "backward_entropy": 0.0028433573565312792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.099432945251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057552944868803024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08638695627450943,
      "backward_entropy": 0.03381936890738351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5312561988830566,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05758832395076752,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08632249385118484,
      "backward_entropy": 0.0989988020488194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.439308166503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057621102780103683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08626486361026764,
      "backward_entropy": 0.0028228150414569037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.886163711547852,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05765518173575401,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08620307594537735,
      "backward_entropy": 0.09899841036115374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.370590209960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768943205475807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08614037930965424,
      "backward_entropy": 0.002806477514760835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.461024284362793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057723116129636765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08607877045869827,
      "backward_entropy": 0.033980020454951694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.2685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057754456996917725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08602343499660492,
      "backward_entropy": 0.03401334583759308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.220131874084473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057785481214523315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08596856892108917,
      "backward_entropy": 0.0027837521795715603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.552661895751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057816214859485626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08591411262750626,
      "backward_entropy": 0.002776813560298511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.123620986938477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057847604155540466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08585717529058456,
      "backward_entropy": 0.002770155668258667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.423831939697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05787868797779083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08580071479082108,
      "backward_entropy": 0.03416938654014042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.025135040283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05791044235229492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0857418105006218,
      "backward_entropy": 0.03421806863376072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.29146671295166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057941753417253494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08568376302719116,
      "backward_entropy": 0.03426331281661987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.525243759155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05797349289059639,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08562395721673965,
      "backward_entropy": 0.034300923347473145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.157092094421387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05800655484199524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08555980026721954,
      "backward_entropy": 0.0027390127735478537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5608696937561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05803988501429558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08549439907073975,
      "backward_entropy": 0.03436263544218881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.021846771240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05807194858789444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08543228358030319,
      "backward_entropy": 0.034405912671770365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.185447692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05810442566871643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08536843210458755,
      "backward_entropy": 0.0027194789477757047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.671009063720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05813808739185333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08530063927173615,
      "backward_entropy": 0.0027128144034317563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.816397666931152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058171141892671585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08523408323526382,
      "backward_entropy": 0.03451966600758689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.746431350708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058204516768455505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0851660966873169,
      "backward_entropy": 0.03455790025847299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.190795660018921,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058238089084625244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08509703725576401,
      "backward_entropy": 0.03459066152572632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.320568561553955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05826929956674576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0850348174571991,
      "backward_entropy": 0.03462642431259155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029580052942037582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05829925090074539,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08497601747512817,
      "backward_entropy": 0.0346642541033881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.262149333953857,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058326490223407745,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0849253386259079,
      "backward_entropy": 0.09899772916521345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.648290634155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058352939784526825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0848766416311264,
      "backward_entropy": 0.03477387343134199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.381368637084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05838209390640259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08481903374195099,
      "backward_entropy": 0.034830221108027866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.173192024230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05841187760233879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08475925028324127,
      "backward_entropy": 0.03488228150776455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.202193260192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0584404394030571,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0847025141119957,
      "backward_entropy": 0.0026588503803525653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.202777862548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05846869945526123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08464647829532623,
      "backward_entropy": 0.03496187499591282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.114399909973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05849757790565491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08458804339170456,
      "backward_entropy": 0.03498832242829459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.098856925964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058526284992694855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08452968299388885,
      "backward_entropy": 0.03501770751816886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.021143913269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058556556701660156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08446592092514038,
      "backward_entropy": 0.0026318486779928207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.92427635192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05858728289604187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08440016955137253,
      "backward_entropy": 0.03507670760154724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.889435768127441,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058620236814022064,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08432680368423462,
      "backward_entropy": 0.09899846145084926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.82063102722168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058653395622968674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08425234258174896,
      "backward_entropy": 0.03513715522629874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.751800537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05868670344352722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0841769203543663,
      "backward_entropy": 0.0026053528168371747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.511573791503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058720167726278305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08410046994686127,
      "backward_entropy": 0.0025985025401626316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.297138214111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05875551328063011,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08401742577552795,
      "backward_entropy": 0.0989974822316851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.284019470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05879325419664383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08392611891031265,
      "backward_entropy": 0.002584457663553102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.87409019470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05883234366774559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08382999897003174,
      "backward_entropy": 0.03525197080203465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.362796783447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05887417867779732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08372433483600616,
      "backward_entropy": 0.03525462746620178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.903099060058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05891522392630577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08362072706222534,
      "backward_entropy": 0.03525504469871521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399694442749023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058957114815711975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08351375162601471,
      "backward_entropy": 0.035244924681527276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.108743667602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058997441083192825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08341153711080551,
      "backward_entropy": 0.03524096097264971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.773881912231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05903732404112816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08331015706062317,
      "backward_entropy": 0.0025301256350108554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.391199111938477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059080690145492554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08319675177335739,
      "backward_entropy": 0.035256915858813694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.845251083374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05912480503320694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08308017253875732,
      "backward_entropy": 0.035266871963228495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02757706120610237,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059167906641960144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08296623080968857,
      "backward_entropy": 0.035278411848204475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.00262451171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05920696258544922,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08286583423614502,
      "backward_entropy": 0.03530551280294146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.239081382751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05924703925848007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08276140689849854,
      "backward_entropy": 0.03532522065298898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.135549545288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05928734317421913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08265542984008789,
      "backward_entropy": 0.03534969687461853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.431830406188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05932769924402237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08254866302013397,
      "backward_entropy": 0.035368425505501885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.934067726135254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059367306530475616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08244384825229645,
      "backward_entropy": 0.035384561334337504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71057653427124,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059407178312540054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08233751356601715,
      "backward_entropy": 0.035408041306904385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.568373441696167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059445638209581375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08223562687635422,
      "backward_entropy": 0.0354368303503309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.12186336517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059481147676706314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08214378356933594,
      "backward_entropy": 0.035467135054724555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5464043617248535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05951635167002678,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08205246925354004,
      "backward_entropy": 0.03549384432179587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.005762577056885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05955066531896591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08196374773979187,
      "backward_entropy": 0.0024407867874417987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.919307708740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05958337336778641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08188046514987946,
      "backward_entropy": 0.03557887673377991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.851996421813965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05961630865931511,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08179566264152527,
      "backward_entropy": 0.035640710166522434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347823143005371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05964909493923187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0817108079791069,
      "backward_entropy": 0.03568983503750393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.875350475311279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05968116968870163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08162814378738403,
      "backward_entropy": 0.03574548023087638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664287567138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059711720794439316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08155060559511185,
      "backward_entropy": 0.03580059323992048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4206056594848633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05974261090159416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08147117495536804,
      "backward_entropy": 0.035863254751477926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.306998252868652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0597713477909565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0813995972275734,
      "backward_entropy": 0.035926410130092075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.121387958526611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05980195477604866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08132023364305496,
      "backward_entropy": 0.03598142947469439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.726643085479736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05983193963766098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08124278485774994,
      "backward_entropy": 0.03603391136441912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.371221542358398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05986068397760391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08116993308067322,
      "backward_entropy": 0.03609239203589303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31424331665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059889696538448334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08109482377767563,
      "backward_entropy": 0.03614192349570138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.487205505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05991891399025917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0810188353061676,
      "backward_entropy": 0.036181092262268066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.483623504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05995141342282295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0809297040104866,
      "backward_entropy": 0.036211490631103516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.676250457763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05998452752828598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08083779364824295,
      "backward_entropy": 0.03623455762863159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.573043823242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060018982738256454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08074000477790833,
      "backward_entropy": 0.036251762083598545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.22634506225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0600547231733799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08063668012619019,
      "backward_entropy": 0.03627074616295951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.470210075378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06009083241224289,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08053132891654968,
      "backward_entropy": 0.036291846207209995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.847058296203613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060124967247247696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08043329417705536,
      "backward_entropy": 0.03631561994552612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.969047546386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060158874839544296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08033561706542969,
      "backward_entropy": 0.0023527637656245914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.369362831115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060193270444869995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08023540675640106,
      "backward_entropy": 0.03637035403932844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025557592511177063,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06022581830620766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08014219254255295,
      "backward_entropy": 0.002340400591492653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.449563026428223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06025529280304909,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08006101846694946,
      "backward_entropy": 0.036432823964527676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.407866477966309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06028423830866814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07998144626617432,
      "backward_entropy": 0.0023301366184438977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.70720100402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06031258776783943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07990389317274094,
      "backward_entropy": 0.03650892632348197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.519848823547363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06034261733293533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0798189789056778,
      "backward_entropy": 0.036538047449929376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360908508300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060373514890670776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07972988486289978,
      "backward_entropy": 0.03657025098800659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.301471710205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06040440499782562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07964037358760834,
      "backward_entropy": 0.036602556705474854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1326446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060435160994529724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07955095171928406,
      "backward_entropy": 0.036626343216214864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.14445686340332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06046450510621071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07946697622537613,
      "backward_entropy": 0.03665796773774283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.153865814208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06049320101737976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07938516139984131,
      "backward_entropy": 0.03668805531093052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.083663940429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060522839426994324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07929884642362595,
      "backward_entropy": 0.0022838679807526724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01245403289795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060553088784217834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07920964062213898,
      "backward_entropy": 0.036735709224428446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953161239624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06058328598737717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07912029325962067,
      "backward_entropy": 0.03674947363989694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9923958778381348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060613516718149185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07903013378381729,
      "backward_entropy": 0.002262524462171963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840889930725098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0606415718793869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07894900441169739,
      "backward_entropy": 0.0022561438381671906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9055655002593994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06066976860165596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07886683195829391,
      "backward_entropy": 0.036811343261173794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.73490047454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060696687549352646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07878974080085754,
      "backward_entropy": 0.036834078175680976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.596658706665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060723789036273956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07871143519878387,
      "backward_entropy": 0.03685009479522705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.529216766357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06075180321931839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07862883061170578,
      "backward_entropy": 0.03686256919588361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.45917797088623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06078057363629341,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0785425454378128,
      "backward_entropy": 0.03686757172857012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.387256622314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06081007048487663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07845266163349152,
      "backward_entropy": 0.002211987706167357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.172147750854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06084033101797104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07835870236158371,
      "backward_entropy": 0.036879884345190864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39570951461792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06087198480963707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07825814187526703,
      "backward_entropy": 0.03689604997634888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.818862915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060903362929821014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07815837860107422,
      "backward_entropy": 0.0021907885425857137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.271778583526611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06093647703528404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0780506357550621,
      "backward_entropy": 0.03691258600779942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4129319190979,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06096912547945976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07794447243213654,
      "backward_entropy": 0.00217445327767304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92917537689209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06100067123770714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07784290611743927,
      "backward_entropy": 0.0369140590940203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.556039571762085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061032652854919434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07773880660533905,
      "backward_entropy": 0.03691890835762024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.029608249664307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06106294319033623,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07764194160699844,
      "backward_entropy": 0.036928998572485786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.235358715057373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06109301745891571,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07754558324813843,
      "backward_entropy": 0.0369374794619424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02471351809799671,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06112236902117729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07745203375816345,
      "backward_entropy": 0.0021370952682835715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.577880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06114909052848816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07736995816230774,
      "backward_entropy": 0.036996424198150635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.815849304199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06117653101682663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07728444784879684,
      "backward_entropy": 0.0021265300789049695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.44920825958252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0612039752304554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07719840109348297,
      "backward_entropy": 0.03704463584082467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.039797782897949,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.061232101172208786,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07710880041122437,
      "backward_entropy": 0.09898168700081962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.001204490661621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06125948950648308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0770222619175911,
      "backward_entropy": 0.03707212209701538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.963547706604004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061286211013793945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07693846523761749,
      "backward_entropy": 0.03708342143467495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.560937881469727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06131235137581825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07685691118240356,
      "backward_entropy": 0.03709547860281808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.755406379699707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06133856251835823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07677476108074188,
      "backward_entropy": 0.037101179361343384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.286540985107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06136615574359894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07668566703796387,
      "backward_entropy": 0.037099863801683695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.809286117553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06139577180147171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07658660411834717,
      "backward_entropy": 0.03710177115031651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1874935626983643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06142447516322136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07649142295122147,
      "backward_entropy": 0.03710430434771946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.162017345428467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061451736837625504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07640275359153748,
      "backward_entropy": 0.03711186136518206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252049446105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0614776685833931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07632002234458923,
      "backward_entropy": 0.0020446069538593292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.658510684967041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06150384992361069,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07623561471700668,
      "backward_entropy": 0.03714108467102051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.623575210571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06152944266796112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0761536955833435,
      "backward_entropy": 0.03715868932860238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.588737487792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06155464053153992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07607311755418777,
      "backward_entropy": 0.03718574983733041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.575798988342285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0615793913602829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07599435746669769,
      "backward_entropy": 0.03721490502357483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.016020774841309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06160510703921318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07591050118207932,
      "backward_entropy": 0.03725069761276245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4829182624816895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06163227930665016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07581895589828491,
      "backward_entropy": 0.037286852087293355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.818957328796387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061658814549446106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07573013007640839,
      "backward_entropy": 0.03732602511133466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.407350063323975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06168791651725769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0756283700466156,
      "backward_entropy": 0.037361357893262594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4722957611083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06171608343720436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07553085684776306,
      "backward_entropy": 0.03739244597298758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.897221565246582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06174233555793762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07544243335723877,
      "backward_entropy": 0.03743813293320792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.300533771514893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06176736205816269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07535973936319351,
      "backward_entropy": 0.03748574001448495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.097610950469971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061791978776454926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.075278639793396,
      "backward_entropy": 0.037539230925696235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0411858558654785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06181733310222626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07519345730543137,
      "backward_entropy": 0.001981080509722233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.983377456665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061843421310186386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07510416209697723,
      "backward_entropy": 0.03762618984494891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304154396057129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06187013164162636,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07501140236854553,
      "backward_entropy": 0.037665869508470805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.127218723297119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06189805269241333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07491204142570496,
      "backward_entropy": 0.0377055151121957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.802939414978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0619250051677227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07481749355792999,
      "backward_entropy": 0.03773296730858939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.772258758544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06195230782032013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07472094893455505,
      "backward_entropy": 0.03774725113596235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.675182819366455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0619819201529026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07461224496364594,
      "backward_entropy": 0.03775977236883981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291929721832275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062011800706386566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0745016410946846,
      "backward_entropy": 0.03777735999652317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543898582458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062041252851486206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0743928849697113,
      "backward_entropy": 0.037797016756875176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.187046051025391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06207093223929405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07428251951932907,
      "backward_entropy": 0.03781813383102417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.858734607696533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06210029870271683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0741732120513916,
      "backward_entropy": 0.03784992865153721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.288612961769104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062128521502017975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07406962662935257,
      "backward_entropy": 0.03787208029202053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.53184175491333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062154799699783325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07397570461034775,
      "backward_entropy": 0.03791074241910662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.998237609863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06217987462878227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07388754189014435,
      "backward_entropy": 0.001912614463695458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1881937980651855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06220496445894241,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07379892468452454,
      "backward_entropy": 0.038007148674556186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.468292236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062230661511421204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07370658963918686,
      "backward_entropy": 0.0019052752426692418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.293915748596191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06225498765707016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07362134754657745,
      "backward_entropy": 0.03809357966695513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6250462532043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06228046119213104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07352978736162186,
      "backward_entropy": 0.038124182394572666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5929722785949707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06230532005429268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07344098389148712,
      "backward_entropy": 0.038159693990434916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.383126735687256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062329649925231934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07335443049669266,
      "backward_entropy": 0.03820234111377171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.043294429779053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06235280632972717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07327385246753693,
      "backward_entropy": 0.03824404307774135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1816085577011108,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062377315014600754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07318560779094696,
      "backward_entropy": 0.038288308041436334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4739913940429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.062400173395872116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07310567796230316,
      "backward_entropy": 0.0018755182889955385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.728113174438477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062422577291727066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07302788645029068,
      "backward_entropy": 0.03839496203831264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.416670560836792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06244571506977081,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07294579595327377,
      "backward_entropy": 0.038442211491721015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.390390157699585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062468383461236954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07286585867404938,
      "backward_entropy": 0.03848882232393537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2472329139709473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062490470707416534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07278896868228912,
      "backward_entropy": 0.038522141320364814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.752003192901611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06251165270805359,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0727166086435318,
      "backward_entropy": 0.03856081621987479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.30627703666687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06253471970558167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07263366878032684,
      "backward_entropy": 0.03859006081308637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.363062381744385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06255723536014557,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07255348563194275,
      "backward_entropy": 0.03861568655286517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.327533721923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06257983297109604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07247263193130493,
      "backward_entropy": 0.0018390004656144551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.487478256225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06260234117507935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07239219546318054,
      "backward_entropy": 0.038648128509521484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.358047008514404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06262654811143875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07230211049318314,
      "backward_entropy": 0.038650576557431905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2037739753723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06265188008546829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07220520824193954,
      "backward_entropy": 0.03866123301642282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1628570556640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0626770630478859,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07210870087146759,
      "backward_entropy": 0.038678135190691264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.198254108428955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06270204484462738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07201284170150757,
      "backward_entropy": 0.03869619539805821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0638620853424072,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06272836029529572,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07190960645675659,
      "backward_entropy": 0.09898509298052106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.041140556335449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06275381147861481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07181064784526825,
      "backward_entropy": 0.0387114371572222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9940457344055176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06277945637702942,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07171058654785156,
      "backward_entropy": 0.038714545113699775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.954301118850708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06280481815338135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07161170244216919,
      "backward_entropy": 0.038720543895448954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9410719871520996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06282977014780045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07151515781879425,
      "backward_entropy": 0.03871728266988482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.909776210784912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06285379827022552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07142357528209686,
      "backward_entropy": 0.0387044974735805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8343992233276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0628771260380745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07133566588163376,
      "backward_entropy": 0.0386969404561179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9661614894866943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0629003494977951,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07124804705381393,
      "backward_entropy": 0.038692619119371684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.697943210601807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06292182952165604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07117021828889847,
      "backward_entropy": 0.0017418522121650831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.800250768661499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06294377148151398,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0710894986987114,
      "backward_entropy": 0.03867924639156887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.527125835418701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06296518445014954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07101138681173325,
      "backward_entropy": 0.038672498294285367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.747018575668335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06298761814832687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07092730700969696,
      "backward_entropy": 0.03866113083703177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8216171264648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06300947070121765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.070846326649189,
      "backward_entropy": 0.03865402936935425,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.681332333106548,
    "avg_log_Z": -0.06175531860440969,
    "success_rate": 1.0,
    "avg_reward": 21.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.83,
      "2": 0.15
    },
    "avg_forward_entropy": 0.07527869574725628,
    "avg_backward_entropy": 0.03355701937074108,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}