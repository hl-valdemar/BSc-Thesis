{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09901210239955358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.09897781269890922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.84075927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368524581193924,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.8120880126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686323165893555,
      "backward_entropy": 0.09901309013366699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.76087951660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00020000000949949026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687381148338318,
      "backward_entropy": 0.09902088982718331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.15745544433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00029910868033766747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688421249389648,
      "backward_entropy": 0.09901486124311175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.1312713623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039776487392373383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13689438998699188,
      "backward_entropy": 0.09901562758854457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.51197814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004961997037753463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690438866615295,
      "backward_entropy": 0.09901632581438337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.0924530029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005930534680373967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691410422325134,
      "backward_entropy": 0.09901693889072963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.46446228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006911021191626787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692373037338257,
      "backward_entropy": 0.0990205066544669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.4493865966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007877431344240904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369331181049347,
      "backward_entropy": 0.09901802880423409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.9895782470703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008846365381032228,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369423270225525,
      "backward_entropy": 0.09900937761579241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.39791870117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000978961936198175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369512975215912,
      "backward_entropy": 0.0990191102027893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.79022216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010740322759374976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696013391017914,
      "backward_entropy": 0.09901845455169678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.76852416992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001166650326922536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369686871767044,
      "backward_entropy": 0.0990195529801505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.73956298828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001258897827938199,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697703182697296,
      "backward_entropy": 0.09901609591075353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.87574768066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013533197343349457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698530197143555,
      "backward_entropy": 0.09901724542890276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.41522216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014486222062259912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699348270893097,
      "backward_entropy": 0.09901517629623413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.40475463867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001546617248095572,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370016634464264,
      "backward_entropy": 0.09901901653834752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.66329956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001644916832447052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700972497463226,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.31150817871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017403160454705358,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701751828193665,
      "backward_entropy": 0.0990201575415475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.73202514648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018391874618828297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13702532649040222,
      "backward_entropy": 0.09901082515716553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.4081268310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0019391271052882075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703304529190063,
      "backward_entropy": 0.09900964157921928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.25657653808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020418744534254074,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13704079389572144,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.11370849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002145075239241123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704843819141388,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.33709716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022460613399744034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705581426620483,
      "backward_entropy": 0.09902101755142212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.69747924804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023489068262279034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706320524215698,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.36920166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002454089466482401,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707053661346436,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.4681396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025600320659577847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370777040719986,
      "backward_entropy": 0.09900213139397758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.7617645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002667668741196394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708476722240448,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.0959014892578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002776991343125701,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709183037281036,
      "backward_entropy": 0.09902065140860421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.952392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028844615444540977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709869980812073,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.91461181640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029962228145450354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710564374923706,
      "backward_entropy": 0.09902090685708183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.38795471191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031086201779544353,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711245357990265,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.42840576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032194978557527065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711902499198914,
      "backward_entropy": 0.09899594102587018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.21337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00333116902038455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712550699710846,
      "backward_entropy": 0.09902082170758929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.76910400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034400098957121372,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713166117668152,
      "backward_entropy": 0.09899428912571498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.96337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035464242100715637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371375471353531,
      "backward_entropy": 0.09902077061789376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.24745178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003649634076282382,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714322447776794,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.26112365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0037482951302081347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13714852929115295,
      "backward_entropy": 0.09902053219931466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.1424102783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038493850734084845,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715383410453796,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.88677978515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003947460558265448,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715887069702148,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.12925720214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004043940920382738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716359436511993,
      "backward_entropy": 0.09902046407972064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.86387634277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004140688572078943,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716821372509003,
      "backward_entropy": 0.09902068546840123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.3914337158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004238675814121962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717268407344818,
      "backward_entropy": 0.09902029378073555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.91818237304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004335175268352032,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13717693090438843,
      "backward_entropy": 0.09902077061789376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.60015869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004436557646840811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718122243881226,
      "backward_entropy": 0.09902007239205497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.07765197753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004537674598395824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718542456626892,
      "backward_entropy": 0.09898555278778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.2913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004639835562556982,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371895968914032,
      "backward_entropy": 0.0990208557673863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.7611541748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004742619581520557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719360530376434,
      "backward_entropy": 0.09901959555489677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.3118133544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004847176373004913,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719752430915833,
      "backward_entropy": 0.09902089834213257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.94090270996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0049533601850271225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720136880874634,
      "backward_entropy": 0.09902090685708183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.43508911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005058041773736477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720491528511047,
      "backward_entropy": 0.09901891435895648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.80926513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005159229971468449,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372082382440567,
      "backward_entropy": 0.09898059708731514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.36585998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005259980913251638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721142709255219,
      "backward_entropy": 0.09901826722281319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.67642211914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005360445939004421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372145265340805,
      "backward_entropy": 0.09897861310413905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.03375244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0054590580984950066,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372174173593521,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.62472534179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005558665841817856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722024857997894,
      "backward_entropy": 0.09897629703794207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.7002410888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00566302752122283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722316920757294,
      "backward_entropy": 0.09901630878448486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.6323699951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005763729102909565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722585141658783,
      "backward_entropy": 0.0990156616483416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.82452392578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005863983649760485,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722838461399078,
      "backward_entropy": 0.09902090685708183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.5333709716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005961215123534203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372307538986206,
      "backward_entropy": 0.09901405232293266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.48670959472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0060630664229393005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723304867744446,
      "backward_entropy": 0.09896885497229439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.68922424316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0061669363640248775,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723528385162354,
      "backward_entropy": 0.09902083873748779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.48313903808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006272279657423496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723741471767426,
      "backward_entropy": 0.0990109954561506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.27757263183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006376583129167557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723939657211304,
      "backward_entropy": 0.09902077061789376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.3465576171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006479747127741575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372411698102951,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.85169982910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006584750022739172,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372428834438324,
      "backward_entropy": 0.09902066843850273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.44747924804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0066900658421218395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724447786808014,
      "backward_entropy": 0.09902060883385795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.33108520507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006791478022933006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724581897258759,
      "backward_entropy": 0.0990034852709089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.164306640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0068922401405870914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372470259666443,
      "backward_entropy": 0.09895329816000802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.5806121826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006993686780333519,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724808394908905,
      "backward_entropy": 0.09895082882472447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.55758666992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007097062189131975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724903762340546,
      "backward_entropy": 0.09899721826825823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.9741973876953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007198472041636705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372498720884323,
      "backward_entropy": 0.09902013199669975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.20802307128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007299528457224369,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372506320476532,
      "backward_entropy": 0.09902000427246094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.32376098632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007401428651064634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725128769874573,
      "backward_entropy": 0.09893971681594849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.5439224243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0075028082355856895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725179433822632,
      "backward_entropy": 0.0989365918295724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.88128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007597825489938259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372520476579666,
      "backward_entropy": 0.09898335593087333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.12814331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007691068109124899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725203275680542,
      "backward_entropy": 0.09897980519703456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.9837188720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007785498630255461,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725179433822632,
      "backward_entropy": 0.09901915277753558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.54733276367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00787684042006731,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725130259990692,
      "backward_entropy": 0.09901893138885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.7967071533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007965526543557644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372506022453308,
      "backward_entropy": 0.09896748406546456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.91787719726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008056260645389557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724975287914276,
      "backward_entropy": 0.09896290302276611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.55963134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008145913481712341,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724873960018158,
      "backward_entropy": 0.09895844118935722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.4583282470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008238829672336578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724759221076965,
      "backward_entropy": 0.09890646593911308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.30320739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008332131430506706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724632561206818,
      "backward_entropy": 0.09890237024852208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.50306701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008418724872171879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724496960639954,
      "backward_entropy": 0.0988976103918893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.72438049316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008511372841894627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724341988563538,
      "backward_entropy": 0.0988932762827192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.74085998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008600026369094849,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724170625209808,
      "backward_entropy": 0.09893367971692767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.30215454101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008690958842635155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723981380462646,
      "backward_entropy": 0.0988837480545044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.64736938476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008782480843365192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723790645599365,
      "backward_entropy": 0.09892263582774571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.43814086914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008871778845787048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723589479923248,
      "backward_entropy": 0.09901620660509382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.79820251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008958850987255573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723373413085938,
      "backward_entropy": 0.0989102806363787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.3729248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009047071449458599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372314691543579,
      "backward_entropy": 0.09890375818525042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.97982788085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009139002300798893,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722902536392212,
      "backward_entropy": 0.0990153465952192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.7041778564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009225189685821533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722635805606842,
      "backward_entropy": 0.09888999802725655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.8679962158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00931521039456129,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137223482131958,
      "backward_entropy": 0.09901471648897443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.8400115966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009409822523593903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372203230857849,
      "backward_entropy": 0.09887559924806867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.60768127441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009503398090600967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721662759780884,
      "backward_entropy": 0.09901438440595355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.59576416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009598434902727604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721254467964172,
      "backward_entropy": 0.09886091096060616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.6822052001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009693199768662453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372079998254776,
      "backward_entropy": 0.09901409489767891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.9231719970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009792031720280647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720306754112244,
      "backward_entropy": 0.09884583950042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.51869201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009889036417007446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137197807431221,
      "backward_entropy": 0.09881108147757393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.99160766601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009982889518141747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371922492980957,
      "backward_entropy": 0.09882904802049909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.03892517089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010078288614749908,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718636333942413,
      "backward_entropy": 0.09901352439607893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010179275646805763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718010485172272,
      "backward_entropy": 0.09879381316048759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.74188232421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01028637494891882,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137173593044281,
      "backward_entropy": 0.09901364360536848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.3881378173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01039072871208191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716687262058258,
      "backward_entropy": 0.09879534585135323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.72157287597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010496494360268116,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715973496437073,
      "backward_entropy": 0.09901372875486102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.98500061035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010598033666610718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715232908725739,
      "backward_entropy": 0.09877244063786098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.96473693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010704033076763153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714447617530823,
      "backward_entropy": 0.09876765523638044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.3809051513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010813013650476933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371362805366516,
      "backward_entropy": 0.09901376281465803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.1392059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010923043824732304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712774217128754,
      "backward_entropy": 0.09874863283974784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.58979034423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011033781804144382,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711878657341003,
      "backward_entropy": 0.09901394162859235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.70753479003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011138688772916794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711020350456238,
      "backward_entropy": 0.0987269537789481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.98814392089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01124343741685152,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371014565229416,
      "backward_entropy": 0.09901361806052071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.89871978759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011349448934197426,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709230720996857,
      "backward_entropy": 0.09901337112699236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.18731689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011449969373643398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708308339118958,
      "backward_entropy": 0.09868809155055455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.25962829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011547056026756763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707375526428223,
      "backward_entropy": 0.09867319890430995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.401123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01164289377629757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706432282924652,
      "backward_entropy": 0.09865784645080566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.6253204345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011734371073544025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705480098724365,
      "backward_entropy": 0.09868511131831578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.2095031738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011827345006167889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704486191272736,
      "backward_entropy": 0.09867324999400548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.44158935546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011927152052521706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370343118906021,
      "backward_entropy": 0.09900924137660436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.18089294433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01203171256929636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370232105255127,
      "backward_entropy": 0.09900884117398943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.32760620117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012132049538195133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701188564300537,
      "backward_entropy": 0.09864180428641182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.49465942382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012229390442371368,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700053095817566,
      "backward_entropy": 0.09900751284190587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.62554931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012325982563197613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698872923851013,
      "backward_entropy": 0.09861752816608974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6000213623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012424902059137821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369764506816864,
      "backward_entropy": 0.09852392332894462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.04669189453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012523128651082516,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13696379959583282,
      "backward_entropy": 0.09900520529065814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.95074462890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012628852389752865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695038855075836,
      "backward_entropy": 0.09849056175776891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9109649658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012730199843645096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136936753988266,
      "backward_entropy": 0.0990042771611895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.14175415039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012827611528337002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369229257106781,
      "backward_entropy": 0.09845345360892159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.8980255126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012922978028655052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690878450870514,
      "backward_entropy": 0.09843291555132185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.05470275878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013020866550505161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368941068649292,
      "backward_entropy": 0.09852954319545201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.8693084716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013116658665239811,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13687916100025177,
      "backward_entropy": 0.09900038582938057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.67657470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013212159276008606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368638277053833,
      "backward_entropy": 0.09850062642778669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013308963738381863,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368480920791626,
      "backward_entropy": 0.0989981974874224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.52569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013403787277638912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683202862739563,
      "backward_entropy": 0.09899701390947614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.9626007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013498764485120773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681566715240479,
      "backward_entropy": 0.09830033779144287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.2237243652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013596217148005962,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367986649274826,
      "backward_entropy": 0.09899498735155378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4114532470703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013700135052204132,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13678078353405,
      "backward_entropy": 0.09899477447782244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.35580444335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01380443386733532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676254451274872,
      "backward_entropy": 0.0984135355268206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.90142822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013909068889915943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674411177635193,
      "backward_entropy": 0.09821440492357526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2113800048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01401410810649395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672524690628052,
      "backward_entropy": 0.09838637283870152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.38385009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014117073267698288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670581579208374,
      "backward_entropy": 0.09837162494659424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.5409393310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014220177195966244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668586313724518,
      "backward_entropy": 0.09814435243606567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.63882446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014324822463095188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666526973247528,
      "backward_entropy": 0.09834139687674386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.81317138671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014425041154026985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13664452731609344,
      "backward_entropy": 0.09809110845838274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.9600067138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014525789767503738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662323355674744,
      "backward_entropy": 0.09830684321267265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.6891632080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014627229422330856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13660146296024323,
      "backward_entropy": 0.09803385393960136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.65057373046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014730270020663738,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365789920091629,
      "backward_entropy": 0.09899008274078369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.21949768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014832314103841782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655616343021393,
      "backward_entropy": 0.09797447919845581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.47479248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014930527657270432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365332454442978,
      "backward_entropy": 0.09823209898812431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 289.7259521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015031878836452961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650935888290405,
      "backward_entropy": 0.09821216549192156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.0142822265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01514152716845274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364840269088745,
      "backward_entropy": 0.09819599560328893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8992919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015248995274305344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645827770233154,
      "backward_entropy": 0.09817823341914586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3120880126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015357451513409615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13643184304237366,
      "backward_entropy": 0.09781764234815325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.98053741455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015464280731976032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364051103591919,
      "backward_entropy": 0.09814086130687169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.04034423828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015565493144094944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637861609458923,
      "backward_entropy": 0.09811784539903913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.2323760986328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015664376318454742,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13635188341140747,
      "backward_entropy": 0.09898296424320766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.93441772460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01576526090502739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13632434606552124,
      "backward_entropy": 0.09806832245418004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.77056884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015863846987485886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362965703010559,
      "backward_entropy": 0.09762954711914062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.4231414794922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015963371843099594,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13626821339130402,
      "backward_entropy": 0.0989783661706107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.16693115234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0160647202283144,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362389475107193,
      "backward_entropy": 0.09897708892822266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5358123779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016163604333996773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362094134092331,
      "backward_entropy": 0.09750636986323766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.09141540527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016260728240013123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617971539497375,
      "backward_entropy": 0.09897361482892718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.17605590820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016358505934476852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614922761917114,
      "backward_entropy": 0.09741793360028948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6195526123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016458837315440178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13611790537834167,
      "backward_entropy": 0.09787658282688685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.31744384765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01655510812997818,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13608644902706146,
      "backward_entropy": 0.09896860803876605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0417938232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0166498851031065,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13605476915836334,
      "backward_entropy": 0.09896641969680786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.44981384277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016745783388614655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13602226972579956,
      "backward_entropy": 0.09723050253731864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.60801696777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01684659533202648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135988250374794,
      "backward_entropy": 0.09896326065063477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.8370361328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016949407756328583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13595327734947205,
      "backward_entropy": 0.09896257945469447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.11538696289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01705247536301613,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359175741672516,
      "backward_entropy": 0.0989619152886527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.69595336914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01715478114783764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13588149845600128,
      "backward_entropy": 0.09704719270978655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.1613311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017257394269108772,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13584473729133606,
      "backward_entropy": 0.09762406349182129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.67513275146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017362983897328377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358065903186798,
      "backward_entropy": 0.09759346076420375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.54161071777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01746259443461895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13576854765415192,
      "backward_entropy": 0.09689947537013463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 271.2511901855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01756419613957405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13572943210601807,
      "backward_entropy": 0.09684652941567558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.88931274414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01767263561487198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568812608718872,
      "backward_entropy": 0.09679852213178362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.90867614746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01777937449514866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13564661145210266,
      "backward_entropy": 0.09745862654277257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.7482147216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017887407913804054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13560423254966736,
      "backward_entropy": 0.097426210130964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.62249755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017993774265050888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13556143641471863,
      "backward_entropy": 0.09739140101841517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.13568115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01810535043478012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551674783229828,
      "backward_entropy": 0.09659615584782191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.5416717529297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018212998285889626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354718804359436,
      "backward_entropy": 0.09895731721605573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 269.7145690917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018322644755244255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354255974292755,
      "backward_entropy": 0.09648140839168004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.76019287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018438300117850304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353771686553955,
      "backward_entropy": 0.09642913511821202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.9126739501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018549907952547073,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353287547826767,
      "backward_entropy": 0.09895723206656319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.99044799804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018658095970749855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13528040051460266,
      "backward_entropy": 0.09895623581750053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.39474487304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01876983605325222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13523034751415253,
      "backward_entropy": 0.09624663421085902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.26670837402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018876809626817703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13518071174621582,
      "backward_entropy": 0.0970919132232666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.09324645996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01898513361811638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13513003289699554,
      "backward_entropy": 0.09611505270004272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.12774658203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019095497205853462,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1350778192281723,
      "backward_entropy": 0.09895301716668266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.45797729492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01920870505273342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13502375781536102,
      "backward_entropy": 0.09696190697806222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.68263244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019316306337714195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349700540304184,
      "backward_entropy": 0.09590559346335274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.84019470214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01941964216530323,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13491681218147278,
      "backward_entropy": 0.0989478315625872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8845977783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019521333277225494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348629891872406,
      "backward_entropy": 0.09573624815259661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.17529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019620677456259727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348094344139099,
      "backward_entropy": 0.09564609186989921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.83148193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019721707329154015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347547024488449,
      "backward_entropy": 0.09555607182638985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.3672332763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019821546971797943,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13469941914081573,
      "backward_entropy": 0.09893265792301723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.2880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019920429214835167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346435695886612,
      "backward_entropy": 0.09536681856427874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.50755310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020018456503748894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345871239900589,
      "backward_entropy": 0.09526837723595756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.94473266601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02011701837182045,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13452959060668945,
      "backward_entropy": 0.09891899994441442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.81361389160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020217565819621086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134470596909523,
      "backward_entropy": 0.0950718777520316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.56683349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02031686343252659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13441097736358643,
      "backward_entropy": 0.09497009856360299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.99102783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020418912172317505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13434934616088867,
      "backward_entropy": 0.09486814907618932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.29629516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020518355071544647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13428764045238495,
      "backward_entropy": 0.09476082665579659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.97010803222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0206153467297554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13422581553459167,
      "backward_entropy": 0.0988973719733102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.75872802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020712977275252342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341630220413208,
      "backward_entropy": 0.0959636994770595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.0315399169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02080845646560192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341000497341156,
      "backward_entropy": 0.09441513674599784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.93150329589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020906027406454086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1340354084968567,
      "backward_entropy": 0.09888190882546562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 266.98675537109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02100547030568123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1339690089225769,
      "backward_entropy": 0.09887782164982387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.7229461669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02111181616783142,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13389915227890015,
      "backward_entropy": 0.09887657846723284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.23526000976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021219078451395035,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13382789492607117,
      "backward_entropy": 0.09887565885271345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.74681091308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02132726088166237,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13375532627105713,
      "backward_entropy": 0.09887519904545375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.7569122314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02143636718392372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13368146121501923,
      "backward_entropy": 0.09376876694815499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.2830047607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021543307229876518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13360726833343506,
      "backward_entropy": 0.09365762983049665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.80987548828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021648412570357323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13353271782398224,
      "backward_entropy": 0.09527054854801723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.09323120117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021751977503299713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13345776498317719,
      "backward_entropy": 0.09341762747083392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.5315704345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02185405232012272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13338187336921692,
      "backward_entropy": 0.09509250095912389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.77853393554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021960195153951645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333029568195343,
      "backward_entropy": 0.0931657041822161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2717742919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022069847211241722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13322120904922485,
      "backward_entropy": 0.09304782322474889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.1670379638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02217618003487587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1331397294998169,
      "backward_entropy": 0.09483616692679268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.24029541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022277899086475372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13305896520614624,
      "backward_entropy": 0.09278122867856707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.1222686767578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02238074503839016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13297629356384277,
      "backward_entropy": 0.0988518340247018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.2726593017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022480633109807968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328936219215393,
      "backward_entropy": 0.09452942439488002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.53363037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02257971093058586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13281038403511047,
      "backward_entropy": 0.09441932610103063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.93963623046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022679563611745834,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13272589445114136,
      "backward_entropy": 0.09883585997990199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.01882934570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022778064012527466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13264063000679016,
      "backward_entropy": 0.09419656651360649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.23419189453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022877922281622887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13255324959754944,
      "backward_entropy": 0.09408158915383476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.95220947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022980472072958946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324632316827774,
      "backward_entropy": 0.0916887606893267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.01052856445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02308289147913456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13237202167510986,
      "backward_entropy": 0.09881704194205147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.09133911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023181205615401268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13228172063827515,
      "backward_entropy": 0.09134760924748012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.56776428222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023282580077648163,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13218869268894196,
      "backward_entropy": 0.09880641528538295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.78359985351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02337973192334175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13209651410579681,
      "backward_entropy": 0.09348329475947789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.27484130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02347879856824875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13200221955776215,
      "backward_entropy": 0.0908081020627703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.6344451904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023574210703372955,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13190878927707672,
      "backward_entropy": 0.09878718852996826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02367139607667923,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13181301951408386,
      "backward_entropy": 0.09878098113196236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.3668975830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02376900240778923,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.131715789437294,
      "backward_entropy": 0.09877496106284005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.15509033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02386559545993805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13161784410476685,
      "backward_entropy": 0.09002351760864258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.63002014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023961609229445457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13151921331882477,
      "backward_entropy": 0.0926499537059239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.02081298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024061033502221107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13141754269599915,
      "backward_entropy": 0.08962229319981166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.266845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024159260094165802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1313154697418213,
      "backward_entropy": 0.08941732134137835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.55453491210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024256303906440735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13121287524700165,
      "backward_entropy": 0.08920274462018694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.66868591308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024348603561520576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13111212849617004,
      "backward_entropy": 0.0920373797416687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.97952270507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024440443143248558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13101038336753845,
      "backward_entropy": 0.09186726808547974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.57598876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02453487366437912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13090601563453674,
      "backward_entropy": 0.091704147202628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.03109741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024632353335618973,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13079823553562164,
      "backward_entropy": 0.09154639073780604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.82713317871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02472766488790512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13069070875644684,
      "backward_entropy": 0.09138083457946777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.29283142089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024822324514389038,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13058239221572876,
      "backward_entropy": 0.09870128120694842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.83067321777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024912720546126366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13047607243061066,
      "backward_entropy": 0.08757775170462472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.82514190673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025004155933856964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1303676962852478,
      "backward_entropy": 0.09084226403917585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.07318115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02509143576025963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1302611231803894,
      "backward_entropy": 0.09064527920314244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.56576538085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025180846452713013,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13015246391296387,
      "backward_entropy": 0.0986640453338623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.10601806640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02526729553937912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13004440069198608,
      "backward_entropy": 0.09025500501905169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.32933044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02535119839012623,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1299367994070053,
      "backward_entropy": 0.09004139048712594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.6676483154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025435542687773705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12982678413391113,
      "backward_entropy": 0.09862491062709264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.61041259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02551920898258686,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1297169029712677,
      "backward_entropy": 0.08960639578955513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92349243164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0256019439548254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12960617244243622,
      "backward_entropy": 0.08938070705958776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.7216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02568087913095951,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12949658930301666,
      "backward_entropy": 0.09857746532985143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.27349853515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0257570743560791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12938809394836426,
      "backward_entropy": 0.0847342950957162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.14065551757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025841407477855682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12927260994911194,
      "backward_entropy": 0.08443708079201835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.10989379882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025924762710928917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12915641069412231,
      "backward_entropy": 0.08413026162556239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.0984649658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026012416929006577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12903526425361633,
      "backward_entropy": 0.08383073125566755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.54834747314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026103291660547256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1289108693599701,
      "backward_entropy": 0.08802294731140137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.5133819580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026188265532255173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12878957390785217,
      "backward_entropy": 0.08779239654541016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.81912231445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026276202872395515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12866462767124176,
      "backward_entropy": 0.08756750822067261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.13070678710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026363039389252663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12853950262069702,
      "backward_entropy": 0.08260633264269147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.65451049804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026453306898474693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12841102480888367,
      "backward_entropy": 0.08711516005652291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.84132385253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026546429842710495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12827947735786438,
      "backward_entropy": 0.08690316336495536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.00579833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026640189811587334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12814602255821228,
      "backward_entropy": 0.08668860367366246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.13499450683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026739172637462616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12800753116607666,
      "backward_entropy": 0.08145448139735631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.9892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026838937774300575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12786749005317688,
      "backward_entropy": 0.08119002410343715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.49838256835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02693908102810383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12772534787654877,
      "backward_entropy": 0.08091955525534493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.58016967773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02703934907913208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12758147716522217,
      "backward_entropy": 0.08588249342782157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.77166748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027142567560076714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12743383646011353,
      "backward_entropy": 0.0803628819329398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.23757934570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027246849611401558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12728393077850342,
      "backward_entropy": 0.08008129256112236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.38729858398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027352506294846535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12713183462619781,
      "backward_entropy": 0.07980374779020037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.52267456054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02745896391570568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1269775629043579,
      "backward_entropy": 0.07951887164797102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.3015899658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027566347271203995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12682129442691803,
      "backward_entropy": 0.09851717097418648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.26190185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027670880779623985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12666666507720947,
      "backward_entropy": 0.0789350015776498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.73822021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027771031484007835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12651455402374268,
      "backward_entropy": 0.08438433919634138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.83731079101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027871716767549515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12636101245880127,
      "backward_entropy": 0.07828620501926967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.48624420166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027969911694526672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12620848417282104,
      "backward_entropy": 0.07794606685638428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.53573608398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028061892837285995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12606064975261688,
      "backward_entropy": 0.08359333447047643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.5303497314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028155148029327393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12591060996055603,
      "backward_entropy": 0.08330827099936348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.83099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02825123630464077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12575732171535492,
      "backward_entropy": 0.09848518030984062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.607177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028347963467240334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125602126121521,
      "backward_entropy": 0.07651354585375104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.92959594726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02844133973121643,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12544897198677063,
      "backward_entropy": 0.09847004924501691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.88996124267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028537221252918243,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12529250979423523,
      "backward_entropy": 0.09846373966761998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.09100341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028628559783101082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1251395046710968,
      "backward_entropy": 0.08187569890703474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.58308410644531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02872103825211525,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12498410046100616,
      "backward_entropy": 0.09844084296907697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.1903839111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02880825288593769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12483329325914383,
      "backward_entropy": 0.08123649869646345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.42869567871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02889373153448105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12468230724334717,
      "backward_entropy": 0.0741675581250872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.80194091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02897820435464382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12453123182058334,
      "backward_entropy": 0.08053370884486608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.5084228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029067499563097954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1243746280670166,
      "backward_entropy": 0.07330489158630371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.19956970214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029159432277083397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12421426177024841,
      "backward_entropy": 0.0728934918131147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.515380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029245426878333092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12405882775783539,
      "backward_entropy": 0.07952622856412615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 264.5316162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029332205653190613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12390206754207611,
      "backward_entropy": 0.0791776009968349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.7333526611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029428698122501373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12373504042625427,
      "backward_entropy": 0.0788785559790475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.55113220214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029527390375733376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12356514483690262,
      "backward_entropy": 0.07858714035579137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.03925323486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02962670288980007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12339402735233307,
      "backward_entropy": 0.07829606533050537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.72653198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971852384507656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12323035299777985,
      "backward_entropy": 0.07048502564430237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.49200439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02980778180062771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12306886166334152,
      "backward_entropy": 0.07006557924406868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0176239013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029896119609475136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.122907854616642,
      "backward_entropy": 0.06964240329606193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.04818725585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029983747750520706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12274719774723053,
      "backward_entropy": 0.06921924863542829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.35101318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030072009190917015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12258537113666534,
      "backward_entropy": 0.07656819479806083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.90480041503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030161995440721512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1224210113286972,
      "backward_entropy": 0.06839210646493095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.48674774169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030251342803239822,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12225720286369324,
      "backward_entropy": 0.07587799855640956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.53057098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030338533222675323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12209530174732208,
      "backward_entropy": 0.06757793256214686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0164031982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0304233580827713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12193509936332703,
      "backward_entropy": 0.07514875275748116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.50367736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030508816242218018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12177320569753647,
      "backward_entropy": 0.06671192816325597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.04399871826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030591044574975967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12161435931921005,
      "backward_entropy": 0.06626161507197789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.1923065185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030671434476971626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12145667523145676,
      "backward_entropy": 0.06579350573675972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.02069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030755238607525826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12129396200180054,
      "backward_entropy": 0.06532973051071167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.88409423828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030841181054711342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12112822383642197,
      "backward_entropy": 0.07322170053209577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.11819458007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030928120017051697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12096132338047028,
      "backward_entropy": 0.0644369125366211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.07815551757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031009390950202942,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12080121785402298,
      "backward_entropy": 0.07245296239852905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.30709838867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031091934069991112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12063917517662048,
      "backward_entropy": 0.07206003155027117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.57992553710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031175844371318817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12047544121742249,
      "backward_entropy": 0.0716767566544669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.09278869628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03125792369246483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12031327188014984,
      "backward_entropy": 0.09807617323739189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.19505310058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031339745968580246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12015098333358765,
      "backward_entropy": 0.07087439298629761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.15341186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03142532333731651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1199837327003479,
      "backward_entropy": 0.07049002817698888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.0041046142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03151260316371918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1198137179017067,
      "backward_entropy": 0.07010580812181745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.86602020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031600162386894226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11964279413223267,
      "backward_entropy": 0.06079631618091038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.34307861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03168589994311333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11947418004274368,
      "backward_entropy": 0.060329292501722066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.34369659423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03177377209067345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11930292099714279,
      "backward_entropy": 0.0689254914011274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.90365600585938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03185948729515076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11913403123617172,
      "backward_entropy": 0.09800968851361956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.797119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03195279836654663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11895652115345001,
      "backward_entropy": 0.06817082847867693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.74783325195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03205356001853943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11877021193504333,
      "backward_entropy": 0.05860396793910435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.90998077392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03215591609477997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11858202517032623,
      "backward_entropy": 0.05821676765169416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.84334564208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032252587378025055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11840145289897919,
      "backward_entropy": 0.06720370905739921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.4400634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032346442341804504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11822434514760971,
      "backward_entropy": 0.05739046846117292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.2670669555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032436300069093704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11805209517478943,
      "backward_entropy": 0.056940904685429165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.8811798095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03252142295241356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11788584291934967,
      "backward_entropy": 0.06603606258119855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.84796142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032609984278678894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1177152469754219,
      "backward_entropy": 0.056015461683273315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.4287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270263969898224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11753946542739868,
      "backward_entropy": 0.05557557940483093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.15447998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03279270604252815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11736688017845154,
      "backward_entropy": 0.05512031487056187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.03762817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032881587743759155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11719556897878647,
      "backward_entropy": 0.054650306701660156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.54936981201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03296827897429466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11702698469161987,
      "backward_entropy": 0.06404155492782593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.82725524902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033053550869226456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11686082184314728,
      "backward_entropy": 0.06361981374876839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.70966339111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03313992917537689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11669372022151947,
      "backward_entropy": 0.05322561093739101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.80060577392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03322429582476616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11652912199497223,
      "backward_entropy": 0.06277443255696978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.00180053710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03330354392528534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11637161672115326,
      "backward_entropy": 0.05224867377962385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.46185302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03338710591197014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11620894819498062,
      "backward_entropy": 0.05178586074284145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.19219970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03347321227192879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11604345589876175,
      "backward_entropy": 0.061500217233385356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.49060821533203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033559150993824005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11587868630886078,
      "backward_entropy": 0.09794001919882638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.00390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033640358597040176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11571960896253586,
      "backward_entropy": 0.0606755827154432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.03121948242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033721379935741425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11556071043014526,
      "backward_entropy": 0.04994922876358032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.15415573120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03380214050412178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11540195345878601,
      "backward_entropy": 0.059795992715018134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.83872985839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033876653760671616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11525174975395203,
      "backward_entropy": 0.059322621141161234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.79348754882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033949967473745346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11510396748781204,
      "backward_entropy": 0.05885346446718488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.12569427490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034023139625787735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1149568185210228,
      "backward_entropy": 0.09782033307211739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.2509002685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03409168869256973,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11481541395187378,
      "backward_entropy": 0.057893642357417514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.32398986816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034166768193244934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11466599255800247,
      "backward_entropy": 0.05744467888559614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.6017608642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03424616530537605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11451123654842377,
      "backward_entropy": 0.04647261755807059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.45951843261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034325987100601196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435668915510178,
      "backward_entropy": 0.046011005129132955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.5043716430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03440340980887413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11420559883117676,
      "backward_entropy": 0.045533635786601474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.76795959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03447858244180679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11405762284994125,
      "backward_entropy": 0.045038930007389615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.30552673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03455609083175659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11390742659568787,
      "backward_entropy": 0.044571514640535624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.26657104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034640662372112274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11374932527542114,
      "backward_entropy": 0.04414830037525722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.29443359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03472128137946129,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11359691619873047,
      "backward_entropy": 0.09770382302148002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.56108856201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0348009392619133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11344651877880096,
      "backward_entropy": 0.04326363120760236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.56851196289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034878186881542206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11329960823059082,
      "backward_entropy": 0.053649536200932095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.76051330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034957606345415115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11315092444419861,
      "backward_entropy": 0.04235785773822239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.02923583984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035035692155361176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11300402879714966,
      "backward_entropy": 0.04189785463469369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.37293243408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035114139318466187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11285713315010071,
      "backward_entropy": 0.041439324617385864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.78086853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035187993198633194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1127166748046875,
      "backward_entropy": 0.04096586789403643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.93462371826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03526255860924721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11257578432559967,
      "backward_entropy": 0.05152917334011623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.70443725585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035334303975105286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11243925988674164,
      "backward_entropy": 0.05108165740966797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.5079345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03540732339024544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11230181157588959,
      "backward_entropy": 0.050647735595703125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6519317626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035482726991176605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11216209083795547,
      "backward_entropy": 0.03909594672066825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.83468627929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03556060045957565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11202047765254974,
      "backward_entropy": 0.0386729325566973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.86090087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03563805669546127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11188043653964996,
      "backward_entropy": 0.04943503226552691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.140869140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03571382537484169,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11174342036247253,
      "backward_entropy": 0.09756523370742798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6566619873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03578125685453415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11161743849515915,
      "backward_entropy": 0.03737511805125645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.31246185302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03585149347782135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1114884689450264,
      "backward_entropy": 0.04814596687044416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.36453247070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03592080995440483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11136142909526825,
      "backward_entropy": 0.04771427171570914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.66399383544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03599831461906433,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11122576892375946,
      "backward_entropy": 0.09751377786908831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.149658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036076635122299194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1110900342464447,
      "backward_entropy": 0.04697677067347935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.6394805908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03615416958928108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11095597594976425,
      "backward_entropy": 0.035323504890714376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.1096954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03623505309224129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11081909388303757,
      "backward_entropy": 0.03495384965624128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.19595336914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03631743788719177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1106814444065094,
      "backward_entropy": 0.03458361114774432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.69721984863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036403678357601166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1105402261018753,
      "backward_entropy": 0.045563267810004096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.92466735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036488693207502365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11040188372135162,
      "backward_entropy": 0.03386393189430237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.18844604492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036571308970451355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11026760190725327,
      "backward_entropy": 0.04486598713057382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.69525146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0366520918905735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11013688147068024,
      "backward_entropy": 0.044510875429425924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.2240753173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03673604130744934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1100037544965744,
      "backward_entropy": 0.0441784816128867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.84146881103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03682294115424156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10986873507499695,
      "backward_entropy": 0.03246176029954638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.2403335571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036910008639097214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.109734907746315,
      "backward_entropy": 0.0321459025144577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.75981903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036994319409132004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10960518568754196,
      "backward_entropy": 0.031810758369309564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.65469360351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0370778851211071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10947759449481964,
      "backward_entropy": 0.03148144483566284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.03187942504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03715917468070984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10935357213020325,
      "backward_entropy": 0.042572349309921265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.58248901367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03723469376564026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10923713445663452,
      "backward_entropy": 0.0422030644757407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.50926208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03730767220258713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10912440717220306,
      "backward_entropy": 0.03040423563548497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.95985794067383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037383075803518295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10900957882404327,
      "backward_entropy": 0.0300459052835192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.31204223632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03745314106345177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10890138149261475,
      "backward_entropy": 0.04108389360564096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.9001693725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037524085491895676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10879328846931458,
      "backward_entropy": 0.029310049755232676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.67963409423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037593014538288116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10868827998638153,
      "backward_entropy": 0.02894986527306693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.59709167480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03766245022416115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10858333110809326,
      "backward_entropy": 0.028592669538089206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.76637268066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037726324051618576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10848545283079147,
      "backward_entropy": 0.039601560149874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.6345977783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03779234364628792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10838583111763,
      "backward_entropy": 0.02786154406411307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.37681579589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03786448389291763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10828068852424622,
      "backward_entropy": 0.0388893187046051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.4698715209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037935782223939896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10817751288414001,
      "backward_entropy": 0.027205043605395725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.1082992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03800753131508827,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1080748438835144,
      "backward_entropy": 0.03822276847703116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.32760620117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03807980567216873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10797268897294998,
      "backward_entropy": 0.037897544247763496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.45093536376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03815632686018944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10786731541156769,
      "backward_entropy": 0.02626171495233263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.35787963867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038231730461120605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10776422917842865,
      "backward_entropy": 0.037301761763436456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.69036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03830872103571892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10766077786684036,
      "backward_entropy": 0.02568540402821132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.57553100585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838801756501198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10755601525306702,
      "backward_entropy": 0.025410971471241543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.95753479003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038466162979602814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10745378583669662,
      "backward_entropy": 0.03648139749254499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.6610107421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03854915872216225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10734808444976807,
      "backward_entropy": 0.03623811687741961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.35187530517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038635239005088806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10724067687988281,
      "backward_entropy": 0.02465281529085977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.24395751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03871920704841614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10713660717010498,
      "backward_entropy": 0.0357672529561179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.8155975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0388047993183136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1070321649312973,
      "backward_entropy": 0.0241588865007673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.72101593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03889195993542671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1069275289773941,
      "backward_entropy": 0.023917411054883684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.58035278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03897574916481972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10682746767997742,
      "backward_entropy": 0.023666960852486745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.02870178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03905533626675606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10673268139362335,
      "backward_entropy": 0.023406716329710826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.8257827758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039133716374635696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10664021968841553,
      "backward_entropy": 0.02314988204411098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.98863220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03921102359890938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10654989629983902,
      "backward_entropy": 0.022896990180015564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.36507415771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03928707540035248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10646166652441025,
      "backward_entropy": 0.022639908960887363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.22212219238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03936444967985153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10637301951646805,
      "backward_entropy": 0.033758695636476786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.75070190429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03944089263677597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10628636926412582,
      "backward_entropy": 0.03350531203406198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.04734802246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039521560072898865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1061970591545105,
      "backward_entropy": 0.03328166689191546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.86940002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03960174694657326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10610906779766083,
      "backward_entropy": 0.03305003046989441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.91695785522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039683274924755096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10602109134197235,
      "backward_entropy": 0.03283278431211199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.75032806396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039759375154972076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10593894869089127,
      "backward_entropy": 0.03258664267403739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.99030303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039834216237068176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10585860908031464,
      "backward_entropy": 0.03233177747045245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.18385314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03990930691361427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10577885806560516,
      "backward_entropy": 0.020728847810200283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.58882141113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03998599573969841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10569872707128525,
      "backward_entropy": 0.03184141431535993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.11121368408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040061913430690765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1056203544139862,
      "backward_entropy": 0.031607559749058316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.28941345214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040135689079761505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1055447980761528,
      "backward_entropy": 0.03136721892016275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.52544403076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04020891338586807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10547058284282684,
      "backward_entropy": 0.03113103551524026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.19966125488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04028291255235672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10539660602807999,
      "backward_entropy": 0.030904467616762434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.65742492675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04035772383213043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10532291233539581,
      "backward_entropy": 0.030689490692956106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.56513214111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.040434226393699646,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10524871945381165,
      "backward_entropy": 0.09803005627223424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.1868133544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04051370173692703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10517311096191406,
      "backward_entropy": 0.030295423098972867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.7431869506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04059649631381035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10509571433067322,
      "backward_entropy": 0.03011470607348851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.7112274169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04067664593458176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10502151399850845,
      "backward_entropy": 0.01857819301741464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.32748413085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040762897580862045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10494370758533478,
      "backward_entropy": 0.02976666816643306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.11627960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04084816947579384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10486768186092377,
      "backward_entropy": 0.02959385301385607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.43867492675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04093211516737938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10479394346475601,
      "backward_entropy": 0.01804740939821516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6939468383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041014283895492554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10472255945205688,
      "backward_entropy": 0.017863546098981584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.14085388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041094012558460236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10465405881404877,
      "backward_entropy": 0.029073736497334073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.69548034667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04117364436388016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10458646714687347,
      "backward_entropy": 0.017492026090621948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.22649383544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04125206172466278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10452061891555786,
      "backward_entropy": 0.017303543431418284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.72344970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04132968932390213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10445624589920044,
      "backward_entropy": 0.01712040603160858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.05032348632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04140840098261833,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10439173877239227,
      "backward_entropy": 0.028357265251023427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.76984405517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041486017405986786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10432890057563782,
      "backward_entropy": 0.028176650404930115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.51781463623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04156522452831268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1042657196521759,
      "backward_entropy": 0.016572079488209317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.383155822753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041644636541604996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1042032316327095,
      "backward_entropy": 0.01639955597264426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.023677825927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04171939939260483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10414495319128036,
      "backward_entropy": 0.01621651543038232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.79134368896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04179028421640396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10409031808376312,
      "backward_entropy": 0.027497770530836924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.7067642211914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041863370686769485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10403472185134888,
      "backward_entropy": 0.027330539056233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.50943374633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04193608835339546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10398011654615402,
      "backward_entropy": 0.02716544270515442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3754653930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04200641065835953,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10392796993255615,
      "backward_entropy": 0.027003760848726546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.57228088378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04207656905055046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10387647151947021,
      "backward_entropy": 0.026841495718274797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.97923278808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042144130915403366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10382735729217529,
      "backward_entropy": 0.015162844743047441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.96199035644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042211830615997314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10377869009971619,
      "backward_entropy": 0.014986731112003326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.32353210449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04227853938937187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10373126715421677,
      "backward_entropy": 0.01481166694845472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.0610122680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042345885187387466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10368399322032928,
      "backward_entropy": 0.0261703793491636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.89466094970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04241549223661423,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10363562405109406,
      "backward_entropy": 0.0982276541846139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.58660888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042482536286115646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10358958691358566,
      "backward_entropy": 0.014312829290117537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.31394958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042551152408123016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10354304313659668,
      "backward_entropy": 0.02570070539202009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.58261108398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04262473061680794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10349378734827042,
      "backward_entropy": 0.014005392789840698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.8905029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042697928845882416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10344544798135757,
      "backward_entropy": 0.01385978183576039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.65233612060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04277210310101509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10339707136154175,
      "backward_entropy": 0.02533164620399475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.19979095458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0428471602499485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10334870964288712,
      "backward_entropy": 0.025223519120897566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.73674774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042920876294374466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10330188274383545,
      "backward_entropy": 0.013458694730486189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.4724349975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04299423098564148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10325582325458527,
      "backward_entropy": 0.025022168244634355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.2105712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043067362159490585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10321037471294403,
      "backward_entropy": 0.024924680590629578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.87056350708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04314039275050163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10316559672355652,
      "backward_entropy": 0.024833998509815762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8909454345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043209515511989594,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10312385857105255,
      "backward_entropy": 0.024726833615984236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.94420623779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04328467324376106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1030789315700531,
      "backward_entropy": 0.012829768870558058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.71757507324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04335889220237732,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1030350923538208,
      "backward_entropy": 0.0127011239528656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.61346435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04343051463365555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10299334675073624,
      "backward_entropy": 0.012572056480816432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.949928283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043499719351530075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10295359790325165,
      "backward_entropy": 0.012441086981977736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.86996459960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043566010892391205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1029161661863327,
      "backward_entropy": 0.012315168976783752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.72160339355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04363275319337845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287882387638092,
      "backward_entropy": 0.01219216627734048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.53729248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043696850538253784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284356027841568,
      "backward_entropy": 0.012073515781334468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.45291137695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04376751184463501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10280467569828033,
      "backward_entropy": 0.023967457669121877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.92250061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383940249681473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10276544094085693,
      "backward_entropy": 0.011867231556347438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.66019439697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391001537442207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10272739827632904,
      "backward_entropy": 0.011762459363256181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.350830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04397966340184212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10269030928611755,
      "backward_entropy": 0.01165894525391715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.34091186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04404734447598457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10265479236841202,
      "backward_entropy": 0.023708867175238475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.13979721069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04411565512418747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10261917114257812,
      "backward_entropy": 0.023652874997683933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.06836700439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04418068006634712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10258584469556808,
      "backward_entropy": 0.011353529989719391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.829132080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04424634203314781,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10255248099565506,
      "backward_entropy": 0.011249771075589316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.5738754272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044309183955192566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10252116620540619,
      "backward_entropy": 0.023438428129468645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.58967590332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04437316581606865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10248951613903046,
      "backward_entropy": 0.011043278234345573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.29730987548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044436633586883545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10245845466852188,
      "backward_entropy": 0.010941015822546822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.97100830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0444989912211895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10242828726768494,
      "backward_entropy": 0.010844005005700248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.19387435913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044563569128513336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10239696502685547,
      "backward_entropy": 0.023199566773005893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.53941345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044626496732234955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1023668646812439,
      "backward_entropy": 0.010658153465815954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.261474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044691599905490875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10233573615550995,
      "backward_entropy": 0.02309427091053554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.41725158691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044759489595890045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10230322182178497,
      "backward_entropy": 0.02304710234914507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.48481750488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044832661747932434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10226798057556152,
      "backward_entropy": 0.010404684713908605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.44436264038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044908974319696426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1022312343120575,
      "backward_entropy": 0.01033001925264086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.71066284179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04498249664902687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10219642519950867,
      "backward_entropy": 0.022962955491883413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.49311065673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04505578428506851,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10216185450553894,
      "backward_entropy": 0.022923454642295837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.71583557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512885957956314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212770104408264,
      "backward_entropy": 0.010085540158408028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.2718276977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045206744223833084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209136456251144,
      "backward_entropy": 0.010016492434910365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.61475372314453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04528329521417618,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1020561009645462,
      "backward_entropy": 0.09860880034310478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.45735168457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535713791847229,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202248394489288,
      "backward_entropy": 0.02284027636051178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.758907318115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04542854428291321,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10199044644832611,
      "backward_entropy": 0.09863414083208356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.65384674072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04549667239189148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019604504108429,
      "backward_entropy": 0.022785697664533342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.46710205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045566365122795105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10192978382110596,
      "backward_entropy": 0.02275734714099339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.34595489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563521593809128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10189973562955856,
      "backward_entropy": 0.02272882844720568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.390708923339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04570123180747032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10187147557735443,
      "backward_entropy": 0.022701644471713474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.6223258972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04576243460178375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10184620320796967,
      "backward_entropy": 0.022671612245695933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.51006317138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04582232981920242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10182175785303116,
      "backward_entropy": 0.02263118965285165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.97543334960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04588096961379051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10179808735847473,
      "backward_entropy": 0.022578250084604536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.45114135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0459410697221756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10177361965179443,
      "backward_entropy": 0.02253174568925585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.98348999023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04600464180111885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10174736380577087,
      "backward_entropy": 0.022492649299757823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.65011978149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04606993868947029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10172010213136673,
      "backward_entropy": 0.00904355411018644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.1418228149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04613247513771057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016945093870163,
      "backward_entropy": 0.022397186074938093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.14923858642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0461963452398777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10166819393634796,
      "backward_entropy": 0.008889898657798767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.9585952758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04626256600022316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10164058208465576,
      "backward_entropy": 0.008825712970324926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.381591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04633074253797531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10161187499761581,
      "backward_entropy": 0.022339759128434316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.92997169494629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04640492424368858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10157989710569382,
      "backward_entropy": 0.02234321619783129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.02288818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046474337577819824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10155080258846283,
      "backward_entropy": 0.008653262896197183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.15925598144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04654323682188988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1015220582485199,
      "backward_entropy": 0.022326954773494175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.75370025634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466158501803875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10149116814136505,
      "backward_entropy": 0.008543203983988081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.4915542602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04669097065925598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10145899653434753,
      "backward_entropy": 0.022344636065619334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.24720764160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04676598682999611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1014268547296524,
      "backward_entropy": 0.022364039506231035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.68495178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04684196040034294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10139411687850952,
      "backward_entropy": 0.008406915834971837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.0328369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046923454850912094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10135844349861145,
      "backward_entropy": 0.022426324231284007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.96714401245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04700175300240517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10132459551095963,
      "backward_entropy": 0.008332356810569763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.53714370727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047076188027858734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10129299759864807,
      "backward_entropy": 0.008288529834577016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.48215866088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714926332235336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.101262167096138,
      "backward_entropy": 0.008241570953811918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.297794342041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04722028598189354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10123252868652344,
      "backward_entropy": 0.022498654467718943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.242854118347168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047289617359638214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1012038141489029,
      "backward_entropy": 0.0225214489868709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.72705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04735247418284416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10117903351783752,
      "backward_entropy": 0.022524327039718628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.00027465820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047415584325790405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10115408152341843,
      "backward_entropy": 0.022539534739085605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.06832885742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047480881214141846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1011277511715889,
      "backward_entropy": 0.022559153182165965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.66496276855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04754723608493805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011006236076355,
      "backward_entropy": 0.007974963103021895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.33047485351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04761190339922905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10107439756393433,
      "backward_entropy": 0.007931394236428397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.49227905273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04767851158976555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10104689002037048,
      "backward_entropy": 0.022615826555660794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.76150131225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04774589091539383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10101877152919769,
      "backward_entropy": 0.022632884127753123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.0429916381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04781268164515495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.100990891456604,
      "backward_entropy": 0.022644509162221636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.4154052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04788044095039368,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1009623184800148,
      "backward_entropy": 0.02267026049750192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.821678161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047949668020009995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10093267261981964,
      "backward_entropy": 0.007724681070872715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.90557861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048014815896749496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10090543329715729,
      "backward_entropy": 0.022694651569638933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.24002075195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048081908375024796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10087692737579346,
      "backward_entropy": 0.007638557148831231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.47566986083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048149775713682175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10084788501262665,
      "backward_entropy": 0.02272603554385049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.168704986572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04821901023387909,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10081769526004791,
      "backward_entropy": 0.022737098591668264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.2574234008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04828627035021782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1007886528968811,
      "backward_entropy": 0.022738971880504062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.67648315429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048359375447034836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10075576603412628,
      "backward_entropy": 0.00747182805623327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.65568542480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04843366891145706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10072192549705505,
      "backward_entropy": 0.0074328599231583735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.746978759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048505693674087524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10068941116333008,
      "backward_entropy": 0.022770470806530545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.4055061340332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04857657104730606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10065744817256927,
      "backward_entropy": 0.022775032690593174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8601303100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04864501953125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1006268709897995,
      "backward_entropy": 0.022758385964802334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.29640197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04871591925621033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10059453547000885,
      "backward_entropy": 0.007253935826676232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4049072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0487869568169117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10056190192699432,
      "backward_entropy": 0.022728496364184787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.02997589111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048852115869522095,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10053311288356781,
      "backward_entropy": 0.0989067554473877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.46166229248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04891996830701828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10050234198570251,
      "backward_entropy": 0.02272850913660867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.41598129272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04898412898182869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10047391057014465,
      "backward_entropy": 0.007080239909035819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.2089614868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04904578626155853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10044705867767334,
      "backward_entropy": 0.022724677409444536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.181312561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049110762774944305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1004176139831543,
      "backward_entropy": 0.02272909028189523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.82218551635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04917316138744354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10038980841636658,
      "backward_entropy": 0.02272701050554003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.32820129394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04923674464225769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10036087036132812,
      "backward_entropy": 0.02273596610341753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.544578552246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049304522573947906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003287136554718,
      "backward_entropy": 0.022755192858832225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.86782836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04937177523970604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10029665380716324,
      "backward_entropy": 0.022776810186249868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.33798599243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04944188520312309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10026224702596664,
      "backward_entropy": 0.02281190667833601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.74846649169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049510408192873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10022873431444168,
      "backward_entropy": 0.00679789377110345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.81224822998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04957953840494156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10019443929195404,
      "backward_entropy": 0.022910173450197493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.50502014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049647849053144455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10016047954559326,
      "backward_entropy": 0.0067536218890122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.405738830566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049719538539648056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10012367367744446,
      "backward_entropy": 0.006728995059217725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.254484176635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049790408462285995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10008717328310013,
      "backward_entropy": 0.023041495255061557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.05670928955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04985734447836876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10005339980125427,
      "backward_entropy": 0.023089502538953508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.862422943115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04992365092039108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10001976788043976,
      "backward_entropy": 0.023130678704806736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.95431900024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049989521503448486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09998615086078644,
      "backward_entropy": 0.023171024663107737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.48537826538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0500522181391716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.099954754114151,
      "backward_entropy": 0.023226150444575717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80272102355957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05011509358882904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09992288053035736,
      "backward_entropy": 0.006597841424601418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.72706604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05017257481813431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09989519417285919,
      "backward_entropy": 0.023347961051123484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.552494049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05022913217544556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09986799955368042,
      "backward_entropy": 0.023385980299540927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.14496612548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05028532072901726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09984076023101807,
      "backward_entropy": 0.006528713341270175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.2977523803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05034533888101578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09981001913547516,
      "backward_entropy": 0.02348027910505022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.92027282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05040986090898514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09977523237466812,
      "backward_entropy": 0.023540096623556956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.38128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05047488585114479,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.099739670753479,
      "backward_entropy": 0.023585979427610124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.0949935913086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050542622804641724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09970147162675858,
      "backward_entropy": 0.02362928433077676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.52625274658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05061284825205803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09966081380844116,
      "backward_entropy": 0.023673325777053833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.2691650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05068423971533775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09961877018213272,
      "backward_entropy": 0.006406504128660474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.4271469116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05075659975409508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09957541525363922,
      "backward_entropy": 0.00638450203197343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.71862030029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050831932574510574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995291993021965,
      "backward_entropy": 0.02379017855439867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.85453796386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05090788006782532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09948195517063141,
      "backward_entropy": 0.023827158979007175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.41854095458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05098026245832443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09943738579750061,
      "backward_entropy": 0.023861112339156016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.73033905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051055312156677246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09939001500606537,
      "backward_entropy": 0.023883031947272166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.43138122558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051128990948200226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09934336692094803,
      "backward_entropy": 0.006267185189894268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.31056213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05119944363832474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09929916262626648,
      "backward_entropy": 0.02393764683178493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.18394088745117,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051266860216856,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09925727546215057,
      "backward_entropy": 0.09899091720581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.035491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513315387070179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09921753406524658,
      "backward_entropy": 0.006192752293178013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.85528564453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05139448121190071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0991789773106575,
      "backward_entropy": 0.006162450781890324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.28579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05145624652504921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09914106130599976,
      "backward_entropy": 0.02401344052382878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.57511901855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051520880311727524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09909990429878235,
      "backward_entropy": 0.024028064949171885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.24015426635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0515839047729969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0990598201751709,
      "backward_entropy": 0.0240357837506703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.05647277832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05164671689271927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09901945292949677,
      "backward_entropy": 0.006047448409455163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.42759704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05170939490199089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09897871315479279,
      "backward_entropy": 0.006021110607045037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.23092269897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051773905754089355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09893561899662018,
      "backward_entropy": 0.024092682770320346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.5211181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051835764199495316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09889476001262665,
      "backward_entropy": 0.024106796298708235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.34408187866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189750716090202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09885350614786148,
      "backward_entropy": 0.005942666104861668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.86202049255371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05195913836359978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09881185740232468,
      "backward_entropy": 0.02414825345788683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.732093811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05201858654618263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09877204895019531,
      "backward_entropy": 0.024170275245394026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.837825775146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0520763173699379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09873360395431519,
      "backward_entropy": 0.0058703140488692695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.108585357666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0521342009305954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09869450330734253,
      "backward_entropy": 0.024234116077423096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.59425354003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052191056311130524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09865601360797882,
      "backward_entropy": 0.02425355783530644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.270402908325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05225014686584473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09861460328102112,
      "backward_entropy": 0.024271930967058455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.197683334350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230522155761719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09857726097106934,
      "backward_entropy": 0.02428759208747319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.481929779052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052358631044626236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09854118525981903,
      "backward_entropy": 0.005741474883896964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.16512298583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05241357535123825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09850305318832397,
      "backward_entropy": 0.024306967854499817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.453018188476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05247195065021515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09846066683530807,
      "backward_entropy": 0.02431942309652056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.04607391357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05252748355269432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09842107445001602,
      "backward_entropy": 0.024335720709392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.623321533203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052587393671274185,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09837590157985687,
      "backward_entropy": 0.09898151670183454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.157222747802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264557898044586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09833230078220367,
      "backward_entropy": 0.005617850060973849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.005340576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052704256027936935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09828761219978333,
      "backward_entropy": 0.005603072366544178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.63347625732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052762940526008606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09824240207672119,
      "backward_entropy": 0.02449992299079895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.65227508544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05282473936676979,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09819293022155762,
      "backward_entropy": 0.024556181260517666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.52511596679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05288627743721008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09814319014549255,
      "backward_entropy": 0.024609912719045366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.27787780761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05295233801007271,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09808752685785294,
      "backward_entropy": 0.024655246308871677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.23933029174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0530177541077137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09803203493356705,
      "backward_entropy": 0.024702480861118863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.675994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05308340862393379,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09797558933496475,
      "backward_entropy": 0.024743331330163137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.88731384277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314629524946213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09792199730873108,
      "backward_entropy": 0.005489290292773928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.466224670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532105416059494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09786607325077057,
      "backward_entropy": 0.005468113081795829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.346649169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05327340215444565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09781128168106079,
      "backward_entropy": 0.02483219121183668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.146663665771484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05333713814616203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09775470942258835,
      "backward_entropy": 0.09899616241455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.96461868286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05340123176574707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09769698977470398,
      "backward_entropy": 0.024929250989641463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.777767181396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05346475541591644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0976393073797226,
      "backward_entropy": 0.024973575557981218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.79558753967285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05352775380015373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0975816622376442,
      "backward_entropy": 0.00538587463753564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.54471969604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0535883866250515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09752655029296875,
      "backward_entropy": 0.005369507308517184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.40810012817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05364782735705376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0974724143743515,
      "backward_entropy": 0.02510277501174382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.68423843383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05370594933629036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09741942584514618,
      "backward_entropy": 0.005332714744976589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.338098526000977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05376598611474037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09736306965351105,
      "backward_entropy": 0.02515860753399985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.208620071411133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05382357910275459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09730955958366394,
      "backward_entropy": 0.005290055913584573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.819698333740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05387932062149048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.097258061170578,
      "backward_entropy": 0.005267671708549772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.385982513427734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05393439158797264,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09720687568187714,
      "backward_entropy": 0.09899965354374476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.533288955688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05398961156606674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09715484082698822,
      "backward_entropy": 0.025232581155640737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.48076057434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05404139682650566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0971074029803276,
      "backward_entropy": 0.005205414124897548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.440879821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05409008637070656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09706418961286545,
      "backward_entropy": 0.025301788534436907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.585298538208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05413569509983063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09702517092227936,
      "backward_entropy": 0.025332005960600718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.766817569732666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418051406741142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09698682278394699,
      "backward_entropy": 0.005147291613476617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.0756721496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054221875965595245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09695351123809814,
      "backward_entropy": 0.025387870413916453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.84538650512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05426560342311859,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09691573679447174,
      "backward_entropy": 0.02540679063115801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.24836730957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054309945553541183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09687668085098267,
      "backward_entropy": 0.005086423030921391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.60482406616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054355595260858536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0968351736664772,
      "backward_entropy": 0.025473171046801975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.43376159667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05440305545926094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0967901200056076,
      "backward_entropy": 0.025489253657204763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.81230163574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05445219948887825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0967417061328888,
      "backward_entropy": 0.005022374647004264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.65898132324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0545022152364254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09669136255979538,
      "backward_entropy": 0.005000438008989606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.8963508605957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054553013294935226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09663920104503632,
      "backward_entropy": 0.004979949976716723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.26689338684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0546051487326622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.096584253013134,
      "backward_entropy": 0.0255341146673475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.856468200683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054654739797115326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09653290361166,
      "backward_entropy": 0.02553401674543108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.349246978759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05470411106944084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09648135304450989,
      "backward_entropy": 0.025537893176078796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.87947463989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05475511774420738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09642649441957474,
      "backward_entropy": 0.004886249346392495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.979496002197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054806843400001526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09636986255645752,
      "backward_entropy": 0.0048660774316106525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.097614288330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0548599548637867,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09631022065877914,
      "backward_entropy": 0.02557506092957088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.60081481933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05491156876087189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09625256061553955,
      "backward_entropy": 0.0048259784068380085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.88074493408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05496484786272049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09619151055812836,
      "backward_entropy": 0.004809891006776265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.92491340637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05501677095890045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09613221883773804,
      "backward_entropy": 0.02567813651902335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.79287338256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055068377405405045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09607286751270294,
      "backward_entropy": 0.004784741571971348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.5642032623291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055119749158620834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0960133969783783,
      "backward_entropy": 0.025803233895983015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.90128707885742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05516993626952171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09595543146133423,
      "backward_entropy": 0.02587926813534328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.401817321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05522442236542702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0958891436457634,
      "backward_entropy": 0.025949893253190175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.227754592895508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055277857929468155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0958239734172821,
      "backward_entropy": 0.02599936936582838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.13632583618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05532858148217201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09576310962438583,
      "backward_entropy": 0.026036177362714494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.068506240844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05537820979952812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09570372849702835,
      "backward_entropy": 0.0047193047191415516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.8255729675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542583391070366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09564754366874695,
      "backward_entropy": 0.004708111818347659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.007452964782715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05547424033284187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09558917582035065,
      "backward_entropy": 0.026199234383446828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.430015563964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055519405752420425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09553642570972443,
      "backward_entropy": 0.026235637920243398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.390018463134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05556664988398552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09547904133796692,
      "backward_entropy": 0.026277644293648855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.702007293701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05561475083231926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09541936218738556,
      "backward_entropy": 0.004652060568332672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.629436492919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0556609220802784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09536291658878326,
      "backward_entropy": 0.0046385712921619415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.96161651611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570540577173233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09530921280384064,
      "backward_entropy": 0.004626372562987464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.488525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05575094372034073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09525281935930252,
      "backward_entropy": 0.02646688691207341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.17429542541504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579490587115288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09519906342029572,
      "backward_entropy": 0.004602663218975067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.087726593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05583833530545235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0951458215713501,
      "backward_entropy": 0.004593229187386376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.99612045288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055881064385175705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09509341418743134,
      "backward_entropy": 0.02665042451449803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.90945816040039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05592337250709534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09504133462905884,
      "backward_entropy": 0.02671527862548828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.15867233276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05596524104475975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0949895977973938,
      "backward_entropy": 0.02678291712488447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.730714797973633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05601120740175247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09492874145507812,
      "backward_entropy": 0.004554911383560726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.639423370361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056056197732686996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09486936032772064,
      "backward_entropy": 0.026905826159885952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.53261947631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05610019341111183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09481140971183777,
      "backward_entropy": 0.026950274194989885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.44796371459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0561479851603508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09474482387304306,
      "backward_entropy": 0.026989425931658064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.99089050292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0561944954097271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0946803092956543,
      "backward_entropy": 0.00450138162289347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.816307067871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05624287202954292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09461116790771484,
      "backward_entropy": 0.004486867359706334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.143108367919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0562928132712841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09453795850276947,
      "backward_entropy": 0.027085674660546438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.45939636230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056341350078582764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09446713328361511,
      "backward_entropy": 0.027116328477859497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.72623062133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05639125779271126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09439253807067871,
      "backward_entropy": 0.004441109352878162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.665733337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056443050503730774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09431299567222595,
      "backward_entropy": 0.004420573690107891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.32158851623535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05649499595165253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09423233568668365,
      "backward_entropy": 0.027130288737160817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.881569862365723,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056544769555330276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0941559225320816,
      "backward_entropy": 0.09901153189795357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.830010414123535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05659133568406105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09408614039421082,
      "backward_entropy": 0.02716153221470969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.37594985961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05663522705435753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09402216970920563,
      "backward_entropy": 0.0271883202450616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.324295043945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056681063026189804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09395290911197662,
      "backward_entropy": 0.004333902150392532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1469002664089203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056726034730672836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09388502687215805,
      "backward_entropy": 0.027251894984926497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.396936416625977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056766580790281296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09382721781730652,
      "backward_entropy": 0.027291016919272288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.76039123535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056803908199071884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0937766283750534,
      "backward_entropy": 0.027324521115847995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.6131477355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05684354156255722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0937197357416153,
      "backward_entropy": 0.027342617511749268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.26902198791504,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05688535049557686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09365686774253845,
      "backward_entropy": 0.0990091221673148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.804710388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05692851170897484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0935901552438736,
      "backward_entropy": 0.0273803642817906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.284716606140137,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05697058513760567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09352534264326096,
      "backward_entropy": 0.09900777680533272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.87512969970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05700945109128952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09346798062324524,
      "backward_entropy": 0.02739611268043518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.74679183959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05704984441399574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09340628236532211,
      "backward_entropy": 0.027415871620178223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.455921173095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057091452181339264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09334079176187515,
      "backward_entropy": 0.027432273541178023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.598270416259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057132378220558167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09327641874551773,
      "backward_entropy": 0.004154135340026447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.240988731384277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057176221162080765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09320397675037384,
      "backward_entropy": 0.027457620416368757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.17363452911377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05721840262413025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09313520044088364,
      "backward_entropy": 0.0274749185357775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.09959602355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05725913867354393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09306960552930832,
      "backward_entropy": 0.02750069328716823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.95159149169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05729958042502403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0930042564868927,
      "backward_entropy": 0.004093351640871593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.872282028198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057341352105140686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09293477982282639,
      "backward_entropy": 0.00408206826874188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.835514068603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0573834665119648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0928637906908989,
      "backward_entropy": 0.004071908603821482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.65242576599121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0574248768389225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09279398620128632,
      "backward_entropy": 0.027686781116894314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896714210510254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05746674910187721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09272235631942749,
      "backward_entropy": 0.027747654489108493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.60342025756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05750618129968643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09265667200088501,
      "backward_entropy": 0.027803746717316762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.31926727294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05755132436752319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0925753191113472,
      "backward_entropy": 0.004034156778029033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.82771682739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05759648233652115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0924931988120079,
      "backward_entropy": 0.027925736137798855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.499506950378418,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05764312297105789,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0924062579870224,
      "backward_entropy": 0.09901098694120135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.49162292480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05768762156367302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09232437610626221,
      "backward_entropy": 0.028023030076708113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.096923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057733699679374695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0922374352812767,
      "backward_entropy": 0.02806131754602705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.00159454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057778824120759964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09215252846479416,
      "backward_entropy": 0.003984175356371062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51982593536377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05782308429479599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09206926822662354,
      "backward_entropy": 0.028169551065989902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.493690490722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05786462873220444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.091993048787117,
      "backward_entropy": 0.028222722666604177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.732872009277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05790633335709572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09191565215587616,
      "backward_entropy": 0.02827118762901851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.90435028076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05794734135270119,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09183952212333679,
      "backward_entropy": 0.028319128922053745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.951703071594238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05798948183655739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09175936877727509,
      "backward_entropy": 0.028369524649211338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.22753143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05802958086133003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09168438613414764,
      "backward_entropy": 0.003920571346368108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.381393432617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05807201564311981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09160196036100388,
      "backward_entropy": 0.0039095572595085415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.45846176147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05811366066336632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09152111411094666,
      "backward_entropy": 0.003898399748972484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.71673583984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058157987892627716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09143166244029999,
      "backward_entropy": 0.028514457600457326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.57740783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05820224806666374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09134161472320557,
      "backward_entropy": 0.02855883538722992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.944561004638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058249928057193756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.091240793466568,
      "backward_entropy": 0.028612913829939707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.348209381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05829780548810959,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09113845229148865,
      "backward_entropy": 0.0286523699760437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.223268508911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05834508314728737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09103700518608093,
      "backward_entropy": 0.02868449262210301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.492372512817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0583917573094368,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0909365713596344,
      "backward_entropy": 0.028706635747637068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.973417282104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058438949286937714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09083366394042969,
      "backward_entropy": 0.028736465743609836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.53790283203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05848568305373192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09073132276535034,
      "backward_entropy": 0.028768075363976613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.403648376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05853382125496864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09062376618385315,
      "backward_entropy": 0.028811701706477573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.48158264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05858052521944046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09051987528800964,
      "backward_entropy": 0.028854278581483022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.7391414642334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05862946808338165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0904080718755722,
      "backward_entropy": 0.0037786002670015606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.339487075805664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05867859348654747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0902947336435318,
      "backward_entropy": 0.02896047064236232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.779146194458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05872726812958717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09018199890851974,
      "backward_entropy": 0.0037642092044864383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.90146255493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05877366289496422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09007583558559418,
      "backward_entropy": 0.003758103719779423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.313377380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058818645775318146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08997337520122528,
      "backward_entropy": 0.02915577377591814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.5611572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05886499956250191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08986544609069824,
      "backward_entropy": 0.02921242586203984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.104373931884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05890938267111778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08976327627897263,
      "backward_entropy": 0.003734699583479336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.8114013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05895586311817169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08965310454368591,
      "backward_entropy": 0.0293320289679936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.48971939086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05900342017412186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08953835070133209,
      "backward_entropy": 0.029378237468855723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.465396881103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05905039981007576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08942466229200363,
      "backward_entropy": 0.029424326760428294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.28411102294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059098273515701294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0893067941069603,
      "backward_entropy": 0.029455672417368208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.11031723022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059147197753190994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08918439596891403,
      "backward_entropy": 0.0036846274243933813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.015857696533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05919605866074562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0890611857175827,
      "backward_entropy": 0.029523281114442006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.91614818572998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05924312397837639,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08894334733486176,
      "backward_entropy": 0.029538520744868686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.972330570220947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05928856506943703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08883019536733627,
      "backward_entropy": 0.02954185221876417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.723002433776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059331126511096954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08872649818658829,
      "backward_entropy": 0.02955056301185063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.26665496826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05937286466360092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08862496167421341,
      "backward_entropy": 0.02957522017615182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.689348220825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05941624194383621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08851667493581772,
      "backward_entropy": 0.02961108088493347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.29120635986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059457872062921524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0884140208363533,
      "backward_entropy": 0.0035926963069609235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.37095832824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05949936807155609,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08831086754798889,
      "backward_entropy": 0.029698088765144348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.286394119262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05953996255993843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08821015059947968,
      "backward_entropy": 0.0035712947802884237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.19918441772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05957968533039093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08811184018850327,
      "backward_entropy": 0.029775329998561313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.36521339416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05961882695555687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08801496773958206,
      "backward_entropy": 0.029824112142835344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.760055541992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05965958535671234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08791095018386841,
      "backward_entropy": 0.02986547350883484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.947209358215332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05970030650496483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08780628442764282,
      "backward_entropy": 0.029908780540738786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.18132209777832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05974021553993225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08770385384559631,
      "backward_entropy": 0.029955778803144182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.11884880065918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059778470546007156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08760710805654526,
      "backward_entropy": 0.02999566069671086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.060508728027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05981532856822014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08751506358385086,
      "backward_entropy": 0.003497412694352014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.629998207092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05985092744231224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08742727339267731,
      "backward_entropy": 0.003486800938844681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.776609420776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05988619849085808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08734001219272614,
      "backward_entropy": 0.03012837895325252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.889575004577637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0599224828183651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08724784106016159,
      "backward_entropy": 0.030157985431807383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.836688995361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0599576011300087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08715973794460297,
      "backward_entropy": 0.030194701892989024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.09606170654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059991512447595596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08707571029663086,
      "backward_entropy": 0.030225172638893127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.25135326385498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06002911925315857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08697613328695297,
      "backward_entropy": 0.030256607702800205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.22510528564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06006627157330513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08687758445739746,
      "backward_entropy": 0.03030391037464142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.58214569091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06010616943240166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08676721900701523,
      "backward_entropy": 0.030365828956876482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.540031433105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06014612317085266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08665578067302704,
      "backward_entropy": 0.030435813324792043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.027805805206299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0601843036711216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08655094355344772,
      "backward_entropy": 0.030493063586098806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.42324161529541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0602201372385025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08645521104335785,
      "backward_entropy": 0.0033824704587459564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.19675636291504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060254596173763275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08636461198329926,
      "backward_entropy": 0.0033702238329819272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.307291984558105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0602894090116024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08627165108919144,
      "backward_entropy": 0.0033572537026235034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.391462326049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06032319739460945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08618246018886566,
      "backward_entropy": 0.03064702664102827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8359479904174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06035828962922096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0860869437456131,
      "backward_entropy": 0.030691027641296387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.491150856018066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0603916309773922,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0859983041882515,
      "backward_entropy": 0.03075080897126879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.06974220275879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060424719005823135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08591003715991974,
      "backward_entropy": 0.030808218887874057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.355411529541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06045925244688988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0858147144317627,
      "backward_entropy": 0.030874546085085188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.406977891921997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060493141412734985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08572126924991608,
      "backward_entropy": 0.030915845717702593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.667795658111572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06052444130182266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0856386125087738,
      "backward_entropy": 0.030958667397499084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.442636489868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06055399402976036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0855630561709404,
      "backward_entropy": 0.030988403729030063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.355405807495117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06058730185031891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08547011017799377,
      "backward_entropy": 0.031007417610713413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.460010528564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0606180801987648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08538810908794403,
      "backward_entropy": 0.03103049738066537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.563339233398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060650382190942764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08529847115278244,
      "backward_entropy": 0.03105793467589787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.0648136138916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06068487837910652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08519841730594635,
      "backward_entropy": 0.03109575169427054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.796256065368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06071948632597923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08509714901447296,
      "backward_entropy": 0.031115101916449412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.414767265319824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0607537105679512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08499687910079956,
      "backward_entropy": 0.031140137995992388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.064634323120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06078623607754707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08490394055843353,
      "backward_entropy": 0.0031811680112566266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.231151819229126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060820743441581726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08480125665664673,
      "backward_entropy": 0.0031700924571071354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.717100143432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060852497816085815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08471076190471649,
      "backward_entropy": 0.0031581188419035505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1971216201782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06088566780090332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08461307734251022,
      "backward_entropy": 0.0312958551304681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.521099090576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06091616302728653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08452733606100082,
      "backward_entropy": 0.03132686231817518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.417524337768555,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06094793975353241,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0844348669052124,
      "backward_entropy": 0.09901462282453265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20961856842041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060981009155511856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08433564752340317,
      "backward_entropy": 0.031367680856159756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162140846252441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06101309135556221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08424055576324463,
      "backward_entropy": 0.03139738951410566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.112884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06104408577084541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08415000140666962,
      "backward_entropy": 0.031418131930487495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.04473876953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06107566878199577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08405588567256927,
      "backward_entropy": 0.031438889248030524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.816743850708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06110706552863121,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08396212756633759,
      "backward_entropy": 0.03146338888577053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.804086685180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061142027378082275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08385074883699417,
      "backward_entropy": 0.031496603574071615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.687519073486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06117791682481766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0837341845035553,
      "backward_entropy": 0.0315316596201488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.664703369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0612148754298687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08361197263002396,
      "backward_entropy": 0.003026757389307022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.569560050964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06125178933143616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0834893137216568,
      "backward_entropy": 0.03164037210600717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.472028732299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06128860265016556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0833662748336792,
      "backward_entropy": 0.031684930835451396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.378058433532715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06132541224360466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08324258774518967,
      "backward_entropy": 0.0029987849827323642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.94890785217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06136211007833481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0831187292933464,
      "backward_entropy": 0.031766301819256375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.18166732788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06140033155679703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08298663794994354,
      "backward_entropy": 0.031813898256846836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.286300659179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06143837794661522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08285467326641083,
      "backward_entropy": 0.031862701688494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.435751914978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061475612223148346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08272603154182434,
      "backward_entropy": 0.03191847460610526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.136771202087402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061511263251304626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08260475099086761,
      "backward_entropy": 0.03197037747928074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.543041229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06154626980423927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08248597383499146,
      "backward_entropy": 0.0029449651816061567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.269983291625977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061582159250974655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08236201107501984,
      "backward_entropy": 0.0029372434530939373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.51138973236084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06161662936210632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08224456012248993,
      "backward_entropy": 0.0029292210404361996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.856926918029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061649177223443985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08213646709918976,
      "backward_entropy": 0.03220239068780627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.448507308959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06168120354413986,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08203036338090897,
      "backward_entropy": 0.03225216056619372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.069164276123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0617113895714283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08193321526050568,
      "backward_entropy": 0.002902290118592126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.665853500366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06174074113368988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08183976262807846,
      "backward_entropy": 0.03234108430998666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.48601531982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06176996976137161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08174630999565125,
      "backward_entropy": 0.03238533011504582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3226704597473145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0618010088801384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08164255321025848,
      "backward_entropy": 0.03241183076586042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.479251861572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061830341815948486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08154723793268204,
      "backward_entropy": 0.03243801210607801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.997406005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06185958534479141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08145181089639664,
      "backward_entropy": 0.03246784210205078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.920454025268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06188946217298508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08135229349136353,
      "backward_entropy": 0.032502985426357815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.294461250305176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06191990524530411,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08124911785125732,
      "backward_entropy": 0.03254342079162598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.763500213623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06195012852549553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08114653080701828,
      "backward_entropy": 0.03258510785443442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.2409725189209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06198091432452202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08104021102190018,
      "backward_entropy": 0.032634686146463664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.103889465332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06201409548521042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08092036098241806,
      "backward_entropy": 0.032676139048167636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.459714889526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06204666197299957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08080315589904785,
      "backward_entropy": 0.0027889148997409003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.032181262969971,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06208193302154541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08067060261964798,
      "backward_entropy": 0.002776362800172397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.2432804107666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06211504712700844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08054929971694946,
      "backward_entropy": 0.032732286623546054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.55129623413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06214951351284981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0804198682308197,
      "backward_entropy": 0.0027504597923585345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.749988555908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06218578666448593,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08027991652488708,
      "backward_entropy": 0.032720987285886495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4922261238098145,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06222110986709595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08014451712369919,
      "backward_entropy": 0.09901142120361328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.36087703704834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062253713607788086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08002392202615738,
      "backward_entropy": 0.032713709133011956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09593692421913147,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06228721886873245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07989750057458878,
      "backward_entropy": 0.03272971298013415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.81891918182373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062317632138729095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07978837192058563,
      "backward_entropy": 0.0327700674533844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.060319900512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06234859675168991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07967551052570343,
      "backward_entropy": 0.0328286417893001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.971368789672852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062382571399211884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07954511791467667,
      "backward_entropy": 0.03288892763001578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9851531982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06241721287369728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07941024750471115,
      "backward_entropy": 0.0329484577689852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.04511833190918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06245036795735359,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07928329706192017,
      "backward_entropy": 0.033001058867999485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.619861125946045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06248493120074272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07914760708808899,
      "backward_entropy": 0.03305723624570029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.588706970214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06251746416091919,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0790230929851532,
      "backward_entropy": 0.033118362937654765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.78950309753418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06254810839891434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07890891283750534,
      "backward_entropy": 0.03317880630493164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53130578994751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06257762759923935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07880063354969025,
      "backward_entropy": 0.03323242919785636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906598091125488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06260544806718826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07870172709226608,
      "backward_entropy": 0.03327531899724688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.664731979370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06263299286365509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07860378921031952,
      "backward_entropy": 0.03330570672239576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.964107513427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0626596137881279,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07851071655750275,
      "backward_entropy": 0.033323155982153754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.056748390197754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0626869946718216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0784125030040741,
      "backward_entropy": 0.03335613012313843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53461217880249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06271567940711975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07830598950386047,
      "backward_entropy": 0.03340106776782444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.022791862487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06274350732564926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07820399105548859,
      "backward_entropy": 0.03345000105244773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.688591957092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06277314573526382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07809068262577057,
      "backward_entropy": 0.03350122060094561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.405667304992676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06280297040939331,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07797566056251526,
      "backward_entropy": 0.033540351050240655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.79762077331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06283175200223923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07786627858877182,
      "backward_entropy": 0.0025399838175092426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.608613967895508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06286312639713287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0777408629655838,
      "backward_entropy": 0.03364449313708714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329458236694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06289590895175934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07760649919509888,
      "backward_entropy": 0.0025269966572523117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.305964469909668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06292784959077835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07747659832239151,
      "backward_entropy": 0.0025190460894789013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.224335670471191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06295973062515259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07734645903110504,
      "backward_entropy": 0.03380088082381657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.142658233642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06299164891242981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07721550017595291,
      "backward_entropy": 0.03384249550955636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.039602279663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06302368640899658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07708320021629333,
      "backward_entropy": 0.03389417699405125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.958065032958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06305935978889465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07692840695381165,
      "backward_entropy": 0.0024854588721479687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.890795707702637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06309526413679123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07677175104618073,
      "backward_entropy": 0.033968567848205566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.57208251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06313080340623856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07661671191453934,
      "backward_entropy": 0.034012245280402045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.875159740447998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0631684958934784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07644793391227722,
      "backward_entropy": 0.03406100400856563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.003525733947754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06320412456989288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07629144936800003,
      "backward_entropy": 0.03409133851528168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.447909355163574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06323684006929398,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07615265995264053,
      "backward_entropy": 0.03412259689399174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.720285415649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06326980143785477,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0760117620229721,
      "backward_entropy": 0.034132806318146844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538031578063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06330133974552155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07587917149066925,
      "backward_entropy": 0.034146936876433234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4762701988220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06333208829164505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07575096189975739,
      "backward_entropy": 0.03415343591145107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.244328498840332,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06336216628551483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07562647014856339,
      "backward_entropy": 0.09901412895747594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.545329570770264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06339231878519058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07550086081027985,
      "backward_entropy": 0.03416759627205985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.915335655212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06342121213674545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07538275420665741,
      "backward_entropy": 0.03417233484131949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.03126335144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06345051527023315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07526151835918427,
      "backward_entropy": 0.03414696880749294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.729388236999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06347990036010742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0751391351222992,
      "backward_entropy": 0.03412632431302752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.611119508743286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06351003050804138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07501136511564255,
      "backward_entropy": 0.034117860453469415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.328334331512451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06353842467069626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07489441335201263,
      "backward_entropy": 0.0023189732538802283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.760676383972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06356582790613174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07478347420692444,
      "backward_entropy": 0.0023074115493467878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.964445114135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06359317153692245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07467231154441833,
      "backward_entropy": 0.03411048012120383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7973496913909912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06362029165029526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07456204295158386,
      "backward_entropy": 0.034108951687812805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.870503902435303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06364545226097107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0744643360376358,
      "backward_entropy": 0.03412592623914991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.868633270263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06367035210132599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07436780631542206,
      "backward_entropy": 0.03413290211132595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.781977653503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06369665265083313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07426146417856216,
      "backward_entropy": 0.0022455863654613495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.058993339538574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0637241080403328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07414687424898148,
      "backward_entropy": 0.03408724921090262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.015758037567139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06375064700841904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07403799891471863,
      "backward_entropy": 0.034065306186676025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.613013744354248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06377661228179932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07393255084753036,
      "backward_entropy": 0.03408005620752062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.417980194091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06380242109298706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0738278403878212,
      "backward_entropy": 0.002195863053202629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6980929374694824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06382983922958374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07371197640895844,
      "backward_entropy": 0.034146983708654134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873781204223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0638551265001297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07360990345478058,
      "backward_entropy": 0.002178760511534555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.420883655548096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0638796016573906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0735129714012146,
      "backward_entropy": 0.03422515307153974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.381467819213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06390393525362015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07341638207435608,
      "backward_entropy": 0.034262044089181085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2104876041412354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0639277920126915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07332240790128708,
      "backward_entropy": 0.03426616532461984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1840384006500244,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06395041942596436,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07323635369539261,
      "backward_entropy": 0.09899330139160156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.246217727661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06397222727537155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0731554925441742,
      "backward_entropy": 0.03431578619139535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.380162239074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0639941468834877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07307350635528564,
      "backward_entropy": 0.0021209770015307833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.636501789093018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06401956081390381,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07296744734048843,
      "backward_entropy": 0.03440113578523908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.614182472229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06404440850019455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07286497950553894,
      "backward_entropy": 0.03446881685938154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562245845794678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06406986713409424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07275793701410294,
      "backward_entropy": 0.03455837709563119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502115726470947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06409552693367004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0726490169763565,
      "backward_entropy": 0.03463458589145115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.913954734802246,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06412144750356674,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07253780961036682,
      "backward_entropy": 0.09900297437395368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9196295738220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0641481801867485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07242066413164139,
      "backward_entropy": 0.03477981686592102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.875111103057861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06417465209960938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07230488210916519,
      "backward_entropy": 0.034864336252212524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9496452808380127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0642007365822792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07219135016202927,
      "backward_entropy": 0.0020770288205572535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.904593467712402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06422563642263412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0720856636762619,
      "backward_entropy": 0.0350518524646759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9148330688476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06425311416387558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07196173071861267,
      "backward_entropy": 0.03515997741903577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.091020584106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06427881866693497,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0718497559428215,
      "backward_entropy": 0.03524591667311532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.64319372177124,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06430467963218689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07173610478639603,
      "backward_entropy": 0.03532327924455915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.115219116210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06433015316724777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07162480801343918,
      "backward_entropy": 0.0020562305248209406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.817213773727417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06435729563236237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07150137424468994,
      "backward_entropy": 0.03544507494994572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.505190372467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06438281387090683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07138893753290176,
      "backward_entropy": 0.035490917307989936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.114255905151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06440789252519608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0712791159749031,
      "backward_entropy": 0.0020339241517441614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7533905506134033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06443209946155548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07117507606744766,
      "backward_entropy": 0.03556644703660693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.376089096069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06445486098527908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07108067721128464,
      "backward_entropy": 0.03559123831135886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.708665609359741,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06447743624448776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07098712027072906,
      "backward_entropy": 0.03560986263411386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.301922798156738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06449881941080093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07090161740779877,
      "backward_entropy": 0.035629336323056905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.556179046630859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06452000141143799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07081710547208786,
      "backward_entropy": 0.035629217113767354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.220735549926758,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06454156339168549,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07072953134775162,
      "backward_entropy": 0.09901469094412667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.628382444381714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06456299871206284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07064244151115417,
      "backward_entropy": 0.035593745963914056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145715713500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06458340585231781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07056225091218948,
      "backward_entropy": 0.035584253924233575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8441781997680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06460375338792801,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07048207521438599,
      "backward_entropy": 0.035565235785075595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.316944599151611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06462382525205612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07040347158908844,
      "backward_entropy": 0.035569188850266595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.746707916259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06464450806379318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07032007724046707,
      "backward_entropy": 0.0355740487575531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7618954181671143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06466683000326157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07022446393966675,
      "backward_entropy": 0.03558515650885446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.173489570617676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06468858569860458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07013271003961563,
      "backward_entropy": 0.03560713359287807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4905688762664795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06471076607704163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07003745436668396,
      "backward_entropy": 0.0018926499677555902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.683673858642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06473203003406525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06994855403900146,
      "backward_entropy": 0.0018860105691211565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.601278305053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0647551417350769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06984598934650421,
      "backward_entropy": 0.035708955356052945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.516764640808105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06477999687194824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06973052024841309,
      "backward_entropy": 0.035729791436876567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.742239952087402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06480631232261658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06960421800613403,
      "backward_entropy": 0.035735487937927246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.384415626525879,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06483234465122223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06947969645261765,
      "backward_entropy": 0.0990082962172372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.955354690551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06485705822706223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06936456263065338,
      "backward_entropy": 0.03583897863115583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.615077972412109,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0648823231458664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06924509257078171,
      "backward_entropy": 0.0018428739692483629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.824494361877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06490723788738251,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06912786513566971,
      "backward_entropy": 0.03596725634166172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.294496536254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06493279337882996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06900563836097717,
      "backward_entropy": 0.036043030875069756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3938722610473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06495717912912369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0688917487859726,
      "backward_entropy": 0.03615143895149231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.268122911453247,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06498046219348907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06878548860549927,
      "backward_entropy": 0.03623231393950326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.418335914611816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06500232219696045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06868938356637955,
      "backward_entropy": 0.03629416227340698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3001222610473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06502397358417511,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06859436631202698,
      "backward_entropy": 0.03634914755821228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.757749557495117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06504509598016739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06850282847881317,
      "backward_entropy": 0.03641638585499355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2470703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06506898254156113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06839081645011902,
      "backward_entropy": 0.03647343601499285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.322603702545166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06509200483560562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06828469038009644,
      "backward_entropy": 0.03653344086238316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1963634490966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06511504203081131,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06817808747291565,
      "backward_entropy": 0.036576258284705024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1570653915405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0651371031999588,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06807855516672134,
      "backward_entropy": 0.03660331879343305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.133645534515381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06515860557556152,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06798261404037476,
      "backward_entropy": 0.0366501339844295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1332926750183105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0651795044541359,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06789080053567886,
      "backward_entropy": 0.036702322108404975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.098264694213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06519998610019684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06780174374580383,
      "backward_entropy": 0.03672346898487636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03358268737793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06522192806005478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0677015408873558,
      "backward_entropy": 0.03675735422543117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.024832248687744,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06524521112442017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06759091466665268,
      "backward_entropy": 0.099018394947052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0026488304138184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06526773422956467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06748558580875397,
      "backward_entropy": 0.03686601775033133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.916360378265381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06528942286968231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06738622486591339,
      "backward_entropy": 0.03691926172801426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.827244281768799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06531121581792831,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06728579103946686,
      "backward_entropy": 0.03695663809776306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8738250732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06533367186784744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06718001514673233,
      "backward_entropy": 0.03699206028665815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8435885906219482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06535573303699493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06707693636417389,
      "backward_entropy": 0.037021172898156304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8640525341033936,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06537728756666183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0669773742556572,
      "backward_entropy": 0.0370299688407353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.388982772827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0653982162475586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06688215583562851,
      "backward_entropy": 0.037053849015917094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8983385562896729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06542127579450607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06677073240280151,
      "backward_entropy": 0.03708202924047198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6994142532348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0654430091381073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06666899472475052,
      "backward_entropy": 0.03711627210889544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.558977127075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0654643326997757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06657007336616516,
      "backward_entropy": 0.0016851489033017839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6274490356445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06548585742712021,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06646936386823654,
      "backward_entropy": 0.037164117608751567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.593745231628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06550706923007965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06637062877416611,
      "backward_entropy": 0.037187431539808004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.697204351425171,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06552799791097641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06627382338047028,
      "backward_entropy": 0.037208999906267436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.253790855407715,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06554795801639557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0661841481924057,
      "backward_entropy": 0.09901717730930873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.067381858825684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06556878238916397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06608754396438599,
      "backward_entropy": 0.03721444947378976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8496785163879395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06559067219495773,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06598265469074249,
      "backward_entropy": 0.037226974964141846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.268049716949463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06561411917209625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06586567312479019,
      "backward_entropy": 0.03725806304386684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.876280784606934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06563735753297806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06575015932321548,
      "backward_entropy": 0.037278175354003906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.989177703857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0656614676117897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0656278133392334,
      "backward_entropy": 0.0016192884317466191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.311735153198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0656859278678894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06550256162881851,
      "backward_entropy": 0.001613456489784377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4811105728149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06570976227521896,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06538192927837372,
      "backward_entropy": 0.037385480744498115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6606773138046265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06573237478733063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06527049839496613,
      "backward_entropy": 0.037406163556235175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.209813117980957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06575347483158112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06517047435045242,
      "backward_entropy": 0.03741028479167393,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.556712516546249,
    "avg_log_Z": -0.06461972624063492,
    "success_rate": 1.0,
    "avg_reward": 21.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.79,
      "2": 0.15
    },
    "avg_forward_entropy": 0.07030840262770653,
    "avg_backward_entropy": 0.03446580152559493,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}