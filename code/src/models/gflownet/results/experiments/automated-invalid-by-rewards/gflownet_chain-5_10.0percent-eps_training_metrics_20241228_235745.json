{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13859477043151855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13855125904083251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.32919311523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266451358795166,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3047332763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826575001080831,
      "backward_entropy": 0.13862936496734618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.28077697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019999995129182935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826504667599996,
      "backward_entropy": 0.13854197263717652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.80662536621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0002999998105224222,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826434334119161,
      "backward_entropy": 0.13862898349761962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4809112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004000535700470209,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263618151346842,
      "backward_entropy": 0.13862864971160888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.76124572753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004992175963707268,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18262892961502075,
      "backward_entropy": 0.13860372304916382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5370330810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005987370386719704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18262147903442383,
      "backward_entropy": 0.13862770795822144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006977623561397195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261377016703287,
      "backward_entropy": 0.1385151267051697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3978729248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007971232407726347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260598182678223,
      "backward_entropy": 0.1386263847351074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.37705993652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008958557154983282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18259815375010172,
      "backward_entropy": 0.13862555027008056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.06494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009941115276888013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825902263323466,
      "backward_entropy": 0.13862453699111937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.85491180419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010907425312325358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258229891459146,
      "backward_entropy": 0.13862338066101074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00118480424862355,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257439136505127,
      "backward_entropy": 0.13861439228057862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.5787811279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012816539965569973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256614605585733,
      "backward_entropy": 0.13862065076828003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9197998046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001379354391247034,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825577219327291,
      "backward_entropy": 0.13861722946166993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.09474182128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014769963454455137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254899978637695,
      "backward_entropy": 0.1386173963546753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.60704040527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001576933078467846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825399398803711,
      "backward_entropy": 0.13861558437347413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.57843017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016772935632616282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18253064155578613,
      "backward_entropy": 0.1386136531829834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.00965881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017758741741999984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252122402191162,
      "backward_entropy": 0.13861160278320311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.71726989746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018728111172094941,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18251178661982217,
      "backward_entropy": 0.13843462467193604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.24203491210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001966924872249365,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250242869059244,
      "backward_entropy": 0.13862388134002684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.05093383789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020612794905900955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249295155207315,
      "backward_entropy": 0.1386247158050537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.8352508544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002154797548428178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248337507247925,
      "backward_entropy": 0.13841121196746825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.0945281982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022471295669674873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18247385819753012,
      "backward_entropy": 0.13859920501708983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3250732421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023414785973727703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246376514434814,
      "backward_entropy": 0.13839502334594728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.42849731445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002437082352116704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18245355288187662,
      "backward_entropy": 0.13838682174682618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.24957275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025315838865935802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244320154190063,
      "backward_entropy": 0.13859038352966307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.619873046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026239375583827496,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824327309926351,
      "backward_entropy": 0.13862817287445067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.68629455566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00271085137501359,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242251873016357,
      "backward_entropy": 0.13858377933502197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.25619506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002799971029162407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824121673901876,
      "backward_entropy": 0.13858019113540648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.5344696044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028885300271213055,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240177631378174,
      "backward_entropy": 0.13862905502319336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9191131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029773591086268425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239088853200278,
      "backward_entropy": 0.13857251405715942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.69996643066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0030670117121189833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18237982193628946,
      "backward_entropy": 0.13856832981109618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.01547241210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031552196014672518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18236841758092245,
      "backward_entropy": 0.13862941265106202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.64694213867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003247310873121023,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823564370473226,
      "backward_entropy": 0.13862943649291992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.4800567626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033413064666092396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823440988858541,
      "backward_entropy": 0.1382967233657837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.28614807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034358741249889135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233150243759155,
      "backward_entropy": 0.1385514736175537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.25743103027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035331989638507366,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823181708653768,
      "backward_entropy": 0.13862924575805663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.54318237304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036329086869955063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823043425877889,
      "backward_entropy": 0.13854217529296875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.9785919189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037335536908358335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229003747304282,
      "backward_entropy": 0.1382591962814331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.84561157226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038373894058167934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822750767072042,
      "backward_entropy": 0.13853235244750978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.9099884033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003943759016692638,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822595993677775,
      "backward_entropy": 0.1385273218154907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.95609283447266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004052478354424238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18224356571833292,
      "backward_entropy": 0.1386281967163086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.62632751464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004154076799750328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222794930140176,
      "backward_entropy": 0.13862788677215576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.38035583496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004254735540598631,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18221229314804077,
      "backward_entropy": 0.1385110139846802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.5543670654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004353140015155077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18219677607218424,
      "backward_entropy": 0.13850488662719726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.4071502685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004450034350156784,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18218096097310385,
      "backward_entropy": 0.13862671852111816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0663299560547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004548253025859594,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18216454982757568,
      "backward_entropy": 0.1386262893676758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.24659729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004646037705242634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18214799960454306,
      "backward_entropy": 0.13816280364990235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.45401000976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004744821228086948,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18213109175364176,
      "backward_entropy": 0.13848007917404176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.1433563232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004842035938054323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821139653523763,
      "backward_entropy": 0.1381393313407898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.85211181640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004943805281072855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18209614356358847,
      "backward_entropy": 0.138624370098114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.33098602294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005043505225330591,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207822243372598,
      "backward_entropy": 0.13846012353897094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.5992889404297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005138009786605835,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820606787999471,
      "backward_entropy": 0.13862326145172119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.03168487548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005230698734521866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182043194770813,
      "backward_entropy": 0.1384448528289795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.581787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005320616532117128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18202577034632364,
      "backward_entropy": 0.13807228803634644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.1795654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005417235195636749,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820073127746582,
      "backward_entropy": 0.1384284257888794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.40914916992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005516276229172945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18198819955190024,
      "backward_entropy": 0.1384202718734741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.95581817626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005615972448140383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18196868896484375,
      "backward_entropy": 0.13841192722320556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.2481231689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005711073987185955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18194925785064697,
      "backward_entropy": 0.13801175355911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.6833038330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005810102913528681,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819289525349935,
      "backward_entropy": 0.1383946418762207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.58157348632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005908465012907982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819084088007609,
      "backward_entropy": 0.13838574886322022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.83332061767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0060050152242183685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18188772598902384,
      "backward_entropy": 0.1379650354385376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.62728881835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0060982792638242245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18186714251836142,
      "backward_entropy": 0.13861627578735353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.84393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006190540734678507,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18184620141983032,
      "backward_entropy": 0.13861548900604248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.20645904541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006281251087784767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18182524045308432,
      "backward_entropy": 0.1383462905883789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.65354919433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006369140464812517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818044384320577,
      "backward_entropy": 0.13789390325546264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.45005798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006459123454988003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18178359667460123,
      "backward_entropy": 0.13787492513656616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.98692321777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006544589996337891,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18176349004109701,
      "backward_entropy": 0.13785436153411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.65737915039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006631066091358662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18174286683400473,
      "backward_entropy": 0.13829991817474366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.22769165039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006720093544572592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18172144889831543,
      "backward_entropy": 0.13828788995742797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.56834411621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006808077450841665,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18169931570688883,
      "backward_entropy": 0.13860890865325928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.55564880371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006892314180731773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181676983833313,
      "backward_entropy": 0.13777059316635132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.76490020751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006979402620345354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18165361881256104,
      "backward_entropy": 0.13824899196624757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.2472686767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007064760196954012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18162983655929565,
      "backward_entropy": 0.1382354974746704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.02959442138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0071510751731693745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18160547812779745,
      "backward_entropy": 0.13770561218261718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.05422973632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007233961019665003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158111969629923,
      "backward_entropy": 0.13768248558044432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.191162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0073164994828403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18155638376871744,
      "backward_entropy": 0.13860281705856323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.74976348876953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007402912247925997,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1815307935078939,
      "backward_entropy": 0.13860151767730713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.42538452148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007485308218747377,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18150552113850912,
      "backward_entropy": 0.1376076579093933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.05990600585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007568627595901489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181479811668396,
      "backward_entropy": 0.13814349174499513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0288848876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007654507178813219,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814532478650411,
      "backward_entropy": 0.13755205869674683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.53538513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0077439467422664165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18142573038736978,
      "backward_entropy": 0.1381094217300415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.2829132080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007835417054593563,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18139741818110147,
      "backward_entropy": 0.13859459161758422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.59712219238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007925540208816528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181368887424469,
      "backward_entropy": 0.13807443380355836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.67046356201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008011278696358204,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18134077390034994,
      "backward_entropy": 0.1380551815032959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.13316345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008094762451946735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813126802444458,
      "backward_entropy": 0.13740044832229614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.88912963867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008182940073311329,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18128315607706705,
      "backward_entropy": 0.13858858346939087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.31224060058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008273469284176826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18125269810358682,
      "backward_entropy": 0.13799641132354737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.65584564208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008364660665392876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18122090895970663,
      "backward_entropy": 0.1373067855834961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.23463439941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008453335613012314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18118908007939658,
      "backward_entropy": 0.13727455139160155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4235382080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008542891591787338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18115639686584473,
      "backward_entropy": 0.13793601989746093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.04624938964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008632544428110123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811231772104899,
      "backward_entropy": 0.13791444301605224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.52174377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008722713217139244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810892422993978,
      "backward_entropy": 0.13717253208160402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.35877990722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00881480984389782,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18105431397755942,
      "backward_entropy": 0.13857920169830323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.39684295654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008900897577404976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18102012077967325,
      "backward_entropy": 0.1378456473350525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.38670349121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00898329820483923,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18098602692286173,
      "backward_entropy": 0.13857526779174806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.11802673339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009068497456610203,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18095068136850992,
      "backward_entropy": 0.1385733366012573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.41918182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009152626618742943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809150775273641,
      "backward_entropy": 0.1377673864364624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.10374450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009233575314283371,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808794935544332,
      "backward_entropy": 0.13773925304412843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4503631591797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009312497451901436,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18084381024042764,
      "backward_entropy": 0.1385660409927368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.240478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00939220655709505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18080719312032065,
      "backward_entropy": 0.1376797914505005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.88442993164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009478297084569931,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807684302330017,
      "backward_entropy": 0.13765134811401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.84384155273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009566293098032475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18072869380315146,
      "backward_entropy": 0.13762209415435792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.59410858154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009657260030508041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18068742752075195,
      "backward_entropy": 0.1367098093032837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.82162475585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009745640680193901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806461215019226,
      "backward_entropy": 0.1375639796257019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.46682739257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009834341704845428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806041399637858,
      "backward_entropy": 0.1375328779220581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.49740600585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00992540456354618,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18056084712346396,
      "backward_entropy": 0.1375017762184143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4665985107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010015574283897877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1805170178413391,
      "backward_entropy": 0.13746967315673828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.37357711791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010106613859534264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18047221501668295,
      "backward_entropy": 0.13743735551834108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.82559204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010187996551394463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18042941888173422,
      "backward_entropy": 0.1374006986618042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.08981323242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010275895707309246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18038413921991983,
      "backward_entropy": 0.1363785982131958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.03128051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010369140654802322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803365151087443,
      "backward_entropy": 0.13633215427398682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.54928588867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010465544648468494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18028736114501953,
      "backward_entropy": 0.1385389447212219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.497314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010561683215200901,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18023749192555746,
      "backward_entropy": 0.13853724002838136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.708251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01065758801996708,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18018690745035806,
      "backward_entropy": 0.13723044395446776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.55870056152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010757655836641788,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18013431628545126,
      "backward_entropy": 0.137196683883667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.8128662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010854034684598446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18008198340733847,
      "backward_entropy": 0.13853254318237304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.16494750976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01094425655901432,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18003066380818686,
      "backward_entropy": 0.13853001594543457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.313232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011034567840397358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799785296122233,
      "backward_entropy": 0.13708181381225587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.2880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011127179488539696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799247662226359,
      "backward_entropy": 0.13704168796539307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.8294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011225280351936817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17986828088760376,
      "backward_entropy": 0.13585455417633058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.2229766845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011318022385239601,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17981270949045816,
      "backward_entropy": 0.13852126598358155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.80779266357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0114152692258358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17975481351216635,
      "backward_entropy": 0.13692374229431153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.5804901123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011505498550832272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17969838778177896,
      "backward_entropy": 0.1356729745864868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.8849334716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011594554409384727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1796414852142334,
      "backward_entropy": 0.1368318557739258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.2384033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01168762892484665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17958219846089682,
      "backward_entropy": 0.13678650856018065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.5175323486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01177799329161644,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1795229117075602,
      "backward_entropy": 0.13850734233856202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.87132263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011871051974594593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17946165800094604,
      "backward_entropy": 0.13669252395629883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.88368225097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011966999620199203,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17939837773640951,
      "backward_entropy": 0.13850271701812744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.73484802246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012061333283782005,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1793347398440043,
      "backward_entropy": 0.13850016593933107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.66735076904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012155882082879543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17926998933156332,
      "backward_entropy": 0.13521220684051513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.59561157226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012246016412973404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17920595407485962,
      "backward_entropy": 0.13649454116821289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.68553161621094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012334851548075676,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1791414419809977,
      "backward_entropy": 0.13849050998687745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.84874725341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012424786575138569,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17907540003458658,
      "backward_entropy": 0.13638589382171631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.19520568847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012510322034358978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1790101925532023,
      "backward_entropy": 0.1349121332168579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.06941223144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012600316666066647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1789421041806539,
      "backward_entropy": 0.13627176284790038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.40950775146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012687481939792633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1788741946220398,
      "backward_entropy": 0.13475435972213745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.22286987304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012773008085787296,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17880562941233316,
      "backward_entropy": 0.13615019321441652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.1800308227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012858770787715912,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17873581250508627,
      "backward_entropy": 0.13608843088150024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.57249450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012937645427882671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17866796255111694,
      "backward_entropy": 0.13602046966552733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.79100036621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013018264435231686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17859816551208496,
      "backward_entropy": 0.1359518885612488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.31666564941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013101990334689617,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17852536837259927,
      "backward_entropy": 0.13844989538192748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.05012512207031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013186674565076828,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1784499684969584,
      "backward_entropy": 0.1384446620941162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.80043029785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013264581561088562,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17837637662887573,
      "backward_entropy": 0.13843789100646972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.8406219482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013341219164431095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1783019701639811,
      "backward_entropy": 0.135658860206604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.5805206298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01341906376183033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17822559674580893,
      "backward_entropy": 0.13396036624908447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.99526977539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013500657863914967,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17814608414967856,
      "backward_entropy": 0.1384180188179016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.61940002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013583475723862648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17806456486384073,
      "backward_entropy": 0.13542711734771729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.01943969726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013676891103386879,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1779766082763672,
      "backward_entropy": 0.13535873889923095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.19166564941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01377370860427618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17788555224736533,
      "backward_entropy": 0.1384063720703125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.19691467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013870999217033386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1777928868929545,
      "backward_entropy": 0.1352250337600708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92218017578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013963484205305576,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17770147323608398,
      "backward_entropy": 0.13840093612670898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.69712829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01405337080359459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17761015892028809,
      "backward_entropy": 0.13507776260375975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.9010238647461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014143881388008595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17751709620157877,
      "backward_entropy": 0.13500053882598878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.92494201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014229964464902878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17742518583933511,
      "backward_entropy": 0.13312849998474122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.93521118164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014320122078061104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17732956012090048,
      "backward_entropy": 0.1348343849182129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.1973419189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014412990771234035,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17723101377487183,
      "backward_entropy": 0.13475477695465088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.3175506591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014511240646243095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17712803681691489,
      "backward_entropy": 0.1346798062324524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6659698486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014609236270189285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17702374855677286,
      "backward_entropy": 0.13460195064544678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.99903106689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014706859365105629,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17691818873087564,
      "backward_entropy": 0.13452060222625734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.93309020996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014801517128944397,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.176813006401062,
      "backward_entropy": 0.1383639693260193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.53904724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014894766733050346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17670722802480063,
      "backward_entropy": 0.13241982460021973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.24877166748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014993074350059032,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17659680048624674,
      "backward_entropy": 0.13425710201263427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.352783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015086933970451355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17648784319559732,
      "backward_entropy": 0.13220343589782715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.31553649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015184584073722363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17637497186660767,
      "backward_entropy": 0.13407527208328246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.92601776123047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01528218388557434,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1762605905532837,
      "backward_entropy": 0.13834223747253419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.86618041992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015375102870166302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1761478583017985,
      "backward_entropy": 0.13388431072235107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.486328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01547380443662405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1760298808415731,
      "backward_entropy": 0.13833367824554443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.97213745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01557218749076128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1759104530016581,
      "backward_entropy": 0.133698570728302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.45774841308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015670431777834892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17578951517740884,
      "backward_entropy": 0.13154850006103516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.8839569091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01576870121061802,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17566696802775064,
      "backward_entropy": 0.13832249641418456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.92840576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015865620225667953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17554384469985962,
      "backward_entropy": 0.13339976072311402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.02452087402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015956193208694458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17542386054992676,
      "backward_entropy": 0.1311877965927124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.15691375732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016041357070207596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1753065586090088,
      "backward_entropy": 0.1331632375717163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.69642639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016123546287417412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17519001166025797,
      "backward_entropy": 0.13091094493865968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.34628295898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01620529592037201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17507209380467734,
      "backward_entropy": 0.13076357841491698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.26841735839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01628711260855198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17495246728261313,
      "backward_entropy": 0.13276821374893188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.3506317138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01636900007724762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17483119169871011,
      "backward_entropy": 0.1304603099822998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.3756561279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016458846628665924,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17470196882883707,
      "backward_entropy": 0.13825435638427735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.55075073242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016547484323382378,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1745701233545939,
      "backward_entropy": 0.13237210512161254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.41029357910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01664021424949169,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17443289359410605,
      "backward_entropy": 0.13002192974090576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.47239685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016738073900341988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17428942521413168,
      "backward_entropy": 0.1298823118209839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.6859359741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01683930680155754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17414126793543497,
      "backward_entropy": 0.1320065975189209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.19225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016935205087065697,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17399583260218301,
      "backward_entropy": 0.13187766075134277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.95518493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01702645607292652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17385262250900269,
      "backward_entropy": 0.1317345380783081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.45946502685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017121491953730583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1737042268117269,
      "backward_entropy": 0.1315905809402466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.04348754882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01720833033323288,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17356147368748984,
      "backward_entropy": 0.13142788410186768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.06783294677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01728902943432331,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17342297236124674,
      "backward_entropy": 0.13125407695770264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.9519500732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017366914078593254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17328540484110513,
      "backward_entropy": 0.12874319553375244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.34980010986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01744650863111019,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17314438025156656,
      "backward_entropy": 0.12855355739593505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.56330108642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017523257061839104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17300434907277426,
      "backward_entropy": 0.12835454940795898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.66423797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0175961721688509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17286654313405356,
      "backward_entropy": 0.12814829349517823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8922576904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017668666318058968,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1727274258931478,
      "backward_entropy": 0.1302942156791687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.90785217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01774408482015133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17258361975351968,
      "backward_entropy": 0.13009216785430908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.8454818725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01781679317355156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17244080702463785,
      "backward_entropy": 0.12988063097000122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.34754180908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017888976261019707,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17229672273000082,
      "backward_entropy": 0.1380681037902832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.50328063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017957022413611412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17215317487716675,
      "backward_entropy": 0.12943847179412843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.65133666992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01802850514650345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17200374603271484,
      "backward_entropy": 0.12685298919677734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.15695190429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0181026179343462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1718492309252421,
      "backward_entropy": 0.12662850618362426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.8566436767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018177373334765434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17169211308161417,
      "backward_entropy": 0.12640023231506348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.1896743774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018254289403557777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17153066396713257,
      "backward_entropy": 0.12616946697235107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.8456802368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018326954916119576,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17137245337168375,
      "backward_entropy": 0.12831528186798097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.75921630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018399326130747795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17121277252833048,
      "backward_entropy": 0.12568130493164062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.66871643066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01847144216299057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17105168104171753,
      "backward_entropy": 0.1254345417022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.98179626464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018544459715485573,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17088772853215536,
      "backward_entropy": 0.1379163980484009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.05409240722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01861814223229885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17072123289108276,
      "backward_entropy": 0.12492247819900512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.8125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018692746758461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17055187622706094,
      "backward_entropy": 0.12707022428512574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.16148376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018771182745695114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17037612199783325,
      "backward_entropy": 0.1243996262550354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.33708190917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01885506510734558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17019220193227133,
      "backward_entropy": 0.12657963037490844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.72775268554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0189322829246521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17001527547836304,
      "backward_entropy": 0.12388501167297364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.38770294189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01901150494813919,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1698339581489563,
      "backward_entropy": 0.12605760097503663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.73653411865234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019087446853518486,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16965510447820029,
      "backward_entropy": 0.13780510425567627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.45465087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019162531942129135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16947559515635172,
      "backward_entropy": 0.12304352521896363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.89051818847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01923653669655323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1692957878112793,
      "backward_entropy": 0.13776392936706544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.9689178466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019308293238282204,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1691174109776815,
      "backward_entropy": 0.12489756345748901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.029808044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019385967403650284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1689295768737793,
      "backward_entropy": 0.12460391521453858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.83805847167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019456489011645317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1687502066294352,
      "backward_entropy": 0.12181906700134278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.32508850097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019524643197655678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.168572465578715,
      "backward_entropy": 0.12148811817169189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.81680297851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019595973193645477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16838862498601279,
      "backward_entropy": 0.12363933324813843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.91583251953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019669529050588608,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16819997628529867,
      "backward_entropy": 0.13761833906173707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.8982391357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019742542877793312,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16801047325134277,
      "backward_entropy": 0.12298860549926757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.8908462524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01981968805193901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16781353950500488,
      "backward_entropy": 0.12009274959564209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.64534759521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01989627070724964,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1676159699757894,
      "backward_entropy": 0.13755393028259277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0935516357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019970588386058807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16742020845413208,
      "backward_entropy": 0.12201056480407715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.57688903808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02005220390856266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1672127644220988,
      "backward_entropy": 0.12169351577758789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.42518615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020135989412665367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16700086990992227,
      "backward_entropy": 0.11871225833892822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.16213989257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020224831998348236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16678057114283243,
      "backward_entropy": 0.12108027935028076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.25570678710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02031649649143219,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16655497749646506,
      "backward_entropy": 0.1207850694656372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.85945892333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020411914214491844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16632267832756042,
      "backward_entropy": 0.11777091026306152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.2076416015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020504631102085114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16609304149945578,
      "backward_entropy": 0.12018792629241944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.3633041381836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020598219707608223,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1658608317375183,
      "backward_entropy": 0.13747528791427613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.48809814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020686276257038116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1656357745329539,
      "backward_entropy": 0.11954586505889893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.3182830810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020771443843841553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1654139757156372,
      "backward_entropy": 0.11642521619796753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.02667236328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020855911076068878,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16519159078598022,
      "backward_entropy": 0.13743590116500853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.1276626586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02093673311173916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16497336824735007,
      "backward_entropy": 0.11565825939178467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.88673400878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021014606580138206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16475836435953775,
      "backward_entropy": 0.11805378198623658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.1742401123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021101413294672966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16452866792678833,
      "backward_entropy": 0.1148719310760498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.78343200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021188009530305862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16429800788561502,
      "backward_entropy": 0.11448975801467895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.26040649414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0212816521525383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16405516862869263,
      "backward_entropy": 0.11696338653564453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.92330169677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021374227479100227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16381288568178812,
      "backward_entropy": 0.11372966766357422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.78673553466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021462537348270416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16357629497845969,
      "backward_entropy": 0.11620949506759644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.54156494140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02155081368982792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16333880027135214,
      "backward_entropy": 0.11289716958999634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.18336486816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02163701504468918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16310352087020874,
      "backward_entropy": 0.11540577411651612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.82157897949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021726831793785095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16286172469456991,
      "backward_entropy": 0.11501064300537109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.16920471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02181125618517399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1626278559366862,
      "backward_entropy": 0.11161675453186035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5391845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02190055139362812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16238517562548319,
      "backward_entropy": 0.11417601108551026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.61931610107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021992357447743416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16213738918304443,
      "backward_entropy": 0.11076630353927612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.9132843017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022083483636379242,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618898113568624,
      "backward_entropy": 0.13720839023590087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.77220153808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022178620100021362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16163488229115805,
      "backward_entropy": 0.11295120716094971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.47837829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02227134443819523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16138331095377603,
      "backward_entropy": 0.10947192907333374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.93193054199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02236516959965229,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1611293156941732,
      "backward_entropy": 0.10904127359390259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.40953063964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02245166152715683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16088728109995523,
      "backward_entropy": 0.10857455730438233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.36223602294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022538194432854652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16064439217249551,
      "backward_entropy": 0.11120195388793945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.115478515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02261829562485218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16041211287180582,
      "backward_entropy": 0.1076101541519165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.23946380615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022695470601320267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16018394629160562,
      "backward_entropy": 0.11019805669784546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.08058166503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02277035266160965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1599589983622233,
      "backward_entropy": 0.10656152963638306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.73973083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022839989513158798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15974279244740805,
      "backward_entropy": 0.10912318229675293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.11614227294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022912522777915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15952032804489136,
      "backward_entropy": 0.10858041048049927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.40325164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022979069501161575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1593076984087626,
      "backward_entropy": 0.10486665964126587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.8579864501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023043006658554077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15909935037295023,
      "backward_entropy": 0.10741512775421143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.65462493896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023110629990696907,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15888354182243347,
      "backward_entropy": 0.10683761835098267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.54112243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02317490242421627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15867316722869873,
      "backward_entropy": 0.10623799562454224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.8855209350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023236172273755074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15846763054529825,
      "backward_entropy": 0.10561908483505249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.02204132080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0232970230281353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15826251109441122,
      "backward_entropy": 0.1017874836921692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.08248138427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023358944803476334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15805490811665854,
      "backward_entropy": 0.10438406467437744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.4599838256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023419754579663277,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15784873565038046,
      "backward_entropy": 0.10050978660583496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.7824249267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023481348529458046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15764065583546957,
      "backward_entropy": 0.10312949419021607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.9947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02355232834815979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15741562843322754,
      "backward_entropy": 0.10256032943725586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.29457092285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02362467162311077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15718793869018555,
      "backward_entropy": 0.10199273824691772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.38563537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023697005584836006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15696038802464804,
      "backward_entropy": 0.09807870388031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.89651489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023772653192281723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15672703584035239,
      "backward_entropy": 0.09749643802642823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.17015075683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02385096065700054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15648899475733438,
      "backward_entropy": 0.10032455921173096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.9353485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023928530514240265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1562525232632955,
      "backward_entropy": 0.09977089166641236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.66289520263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024012159556150436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15600583950678507,
      "backward_entropy": 0.09925333261489869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.33760833740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02408977970480919,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15577077865600586,
      "backward_entropy": 0.09869775176048279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.13452911376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024168821051716805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1555304229259491,
      "backward_entropy": 0.09815045595169067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.68194580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02424199879169464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1552985111872355,
      "backward_entropy": 0.09400751590728759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.5397834777832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024314846843481064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15506654977798462,
      "backward_entropy": 0.09338313341140747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.0876693725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024383146315813065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1548430323600769,
      "backward_entropy": 0.09634812474250794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.1399917602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024448459967970848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1546246608098348,
      "backward_entropy": 0.09570891857147217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.96497344970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024515697732567787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1544020672639211,
      "backward_entropy": 0.09507184028625489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.884178161621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024577219039201736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1541909376780192,
      "backward_entropy": 0.0944057822227478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.49380493164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024633096531033516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15399078528086343,
      "backward_entropy": 0.09370557069778443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.45323181152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024693816900253296,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15378105640411377,
      "backward_entropy": 0.09303277730941772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.84556579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02475239709019661,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15357547998428345,
      "backward_entropy": 0.08860981464385986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.56046295166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02481016330420971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15337111552556357,
      "backward_entropy": 0.08788257241249084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.883731842041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024869650602340698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15316375096638998,
      "backward_entropy": 0.08716967105865478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.46393585205078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024924898520112038,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15296469132105509,
      "backward_entropy": 0.1353916883468628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.864234924316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024977026507258415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15277224779129028,
      "backward_entropy": 0.08566130399703979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.28223419189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025024237111210823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15258977810541788,
      "backward_entropy": 0.08487269878387452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.56749725341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02506968192756176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15241150061289468,
      "backward_entropy": 0.08800470232963561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.98359298706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02511466108262539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15223434567451477,
      "backward_entropy": 0.08331626653671265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.7780990600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02515711821615696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15206227699915567,
      "backward_entropy": 0.08647001981735229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.56797409057617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025201579555869102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15188682079315186,
      "backward_entropy": 0.08174738883972169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.76050567626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02524482272565365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1517147421836853,
      "backward_entropy": 0.08496638536453247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.0462646484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025289364159107208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1515402595202128,
      "backward_entropy": 0.08023172616958618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.0005874633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02533721923828125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1513598362604777,
      "backward_entropy": 0.07949985265731811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.73209381103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025390353053808212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15117037296295166,
      "backward_entropy": 0.08283782005310059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.16798400878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025445982813835144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15097695589065552,
      "backward_entropy": 0.07816797494888306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.95748901367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02550705149769783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15077418088912964,
      "backward_entropy": 0.08157740831375122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.21917724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025573017075657845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15056334932645163,
      "backward_entropy": 0.07694702744483947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.96642303466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02564023807644844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15035156408945718,
      "backward_entropy": 0.08042951822280883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.45603942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025705767795443535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15014506379763284,
      "backward_entropy": 0.07985698580741882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.17572784423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025772295892238617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14993723233540854,
      "backward_entropy": 0.07518870234489441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.74097442626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025836385786533356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14973551034927368,
      "backward_entropy": 0.078699791431427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.88275909423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025898469612002373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14953887462615967,
      "backward_entropy": 0.07809344530105591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.15349578857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025960881263017654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14934309323628744,
      "backward_entropy": 0.0733264446258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.6112060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02602502517402172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14914536476135254,
      "backward_entropy": 0.07272296547889709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.283233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026087049394845963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14895284175872803,
      "backward_entropy": 0.07630582451820374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.47874450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026143968105316162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14877137541770935,
      "backward_entropy": 0.07566862106323242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.07587432861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02620004676282406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14859280983606973,
      "backward_entropy": 0.070793616771698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.26580810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026259828358888626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14840821425120035,
      "backward_entropy": 0.07440332174301148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.34345626831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026314621791243553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14823432763417563,
      "backward_entropy": 0.07374217510223388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.22271728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026367077603936195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14806614319483438,
      "backward_entropy": 0.07306986451148986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.09356689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02642066217958927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14789687593777975,
      "backward_entropy": 0.06813767552375793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.83516693115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02647368609905243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14772983392079672,
      "backward_entropy": 0.0717458724975586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.88603973388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02653101645410061,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14755584796269736,
      "backward_entropy": 0.0711164653301239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.98841857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026585860177874565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14738794167836508,
      "backward_entropy": 0.07047720551490784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.18739700317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026643630117177963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14721600214640299,
      "backward_entropy": 0.06986758708953858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.39833068847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02669857069849968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14705055952072144,
      "backward_entropy": 0.06492827534675598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.91978454589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026759633794426918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14687544107437134,
      "backward_entropy": 0.06865812540054321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.27146911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026820611208677292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14670167366663614,
      "backward_entropy": 0.0637308418750763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.8838005065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02688118815422058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14652969439824423,
      "backward_entropy": 0.06310414671897888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.572021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02693997137248516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14636320869127908,
      "backward_entropy": 0.0624997079372406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.2872543334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02699594385921955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14620324969291687,
      "backward_entropy": 0.06625920534133911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.30867767333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027058042585849762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14603402217229208,
      "backward_entropy": 0.06569321751594544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.1966552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027122685685753822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14586222171783447,
      "backward_entropy": 0.06074697971343994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.23515319824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027184704318642616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14569705724716187,
      "backward_entropy": 0.0601970374584198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.38699340820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027247043326497078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14553276697794595,
      "backward_entropy": 0.064067804813385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.97452545166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027308102697134018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14537223180135092,
      "backward_entropy": 0.06351689100265503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.48848724365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027372954413294792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14520668983459473,
      "backward_entropy": 0.05853895545005798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.9377670288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027440711855888367,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1450376013914744,
      "backward_entropy": 0.062469756603240965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.30493927001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027514025568962097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1448614994684855,
      "backward_entropy": 0.0575069785118103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.59667205810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02758539281785488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14469085137049356,
      "backward_entropy": 0.061539101600646975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.82373046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027659904211759567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1445171038309733,
      "backward_entropy": 0.06109822392463684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.102874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02773447521030903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1443456013997396,
      "backward_entropy": 0.05611780881881714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.88023376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027805618941783905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1441819965839386,
      "backward_entropy": 0.05566763281822205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.62761688232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027876155450940132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14402101437250772,
      "backward_entropy": 0.05519979000091553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.0585708618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027945466339588165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1438633600870768,
      "backward_entropy": 0.059295809268951415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.46697235107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028014738112688065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14370753367741904,
      "backward_entropy": 0.05418672561645508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.99574279785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02808728814125061,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1435482700665792,
      "backward_entropy": 0.05836406350135803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.79964065551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028165875002741814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14338160554567972,
      "backward_entropy": 0.05795364379882813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.41950225830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028240401297807693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1432236929734548,
      "backward_entropy": 0.05752263069152832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.090118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02831718511879444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14306414127349854,
      "backward_entropy": 0.0570967435836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.16587829589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02839047461748123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14291241765022278,
      "backward_entropy": 0.05188554525375366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.924312591552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028463242575526237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14276334643363953,
      "backward_entropy": 0.05622320771217346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.01427459716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028532078489661217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14262219270070395,
      "backward_entropy": 0.05092089176177979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.99348449707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028600703924894333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1424830158551534,
      "backward_entropy": 0.0504184365272522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7996826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028668120503425598,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14234755436579385,
      "backward_entropy": 0.054802966117858884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.83500671386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028736207634210587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14221288760503134,
      "backward_entropy": 0.054349422454833984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.94219207763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02880474179983139,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1420793135960897,
      "backward_entropy": 0.05390713810920715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.20371627807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028875941410660744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14194377263387045,
      "backward_entropy": 0.048550212383270265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.51045227050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02894262596964836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14181693394978842,
      "backward_entropy": 0.05308468341827392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.51348114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029009779915213585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1416909098625183,
      "backward_entropy": 0.05266954898834229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.3771743774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029074767604470253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14156941572825113,
      "backward_entropy": 0.04720715880393982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.200653076171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029141809791326523,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1414464215437571,
      "backward_entropy": 0.13385026454925536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.05996322631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029206054285168648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1413292090098063,
      "backward_entropy": 0.051333606243133545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.965576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029266923666000366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1412182648976644,
      "backward_entropy": 0.04572895169258118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.21672058105469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02933015301823616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14110549290974936,
      "backward_entropy": 0.05037603974342346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.498680114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029396913945674896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14098928372065225,
      "backward_entropy": 0.04996117949485779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.99455261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029461178928613663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1408785581588745,
      "backward_entropy": 0.04430060088634491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.82128143310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029524074867367744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14077121019363403,
      "backward_entropy": 0.04910191893577576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.81373596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029592279344797134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14065857728322348,
      "backward_entropy": 0.0433556854724884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.91850280761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02966594509780407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14053971568743387,
      "backward_entropy": 0.048310840129852296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.60459899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029739251360297203,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14042367537816366,
      "backward_entropy": 0.0425106942653656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.61109161376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029811061918735504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.140311598777771,
      "backward_entropy": 0.04755460917949676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.11542510986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029879124835133553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14020625750223795,
      "backward_entropy": 0.0471465140581131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.60614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02994418703019619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14010653893152872,
      "backward_entropy": 0.0411499947309494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.375247955322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030002251267433167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14001786708831787,
      "backward_entropy": 0.040660953521728514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.27177047729492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030056629329919815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13993537425994873,
      "backward_entropy": 0.04015533030033112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.94424819946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030107716098427773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.139858345190684,
      "backward_entropy": 0.04535465240478516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.07337188720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03015724942088127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13978471358617148,
      "backward_entropy": 0.03911205232143402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.49369812011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03020731545984745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13971134026845297,
      "backward_entropy": 0.044406333565711976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.603172302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03025943972170353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13963566223780313,
      "backward_entropy": 0.03809595704078674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.00904846191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03031105175614357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13956220944722494,
      "backward_entropy": 0.043533536791801455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.83618927001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0303637757897377,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13948875665664673,
      "backward_entropy": 0.043139272928237916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.98514556884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030418548732995987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13941391309102377,
      "backward_entropy": 0.04275946319103241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.08187103271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030476896092295647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13933595021565756,
      "backward_entropy": 0.036317956447601316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.16127014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03054017201066017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13925390442212424,
      "backward_entropy": 0.04208593666553497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.14906120300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03060467354953289,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13917145133018494,
      "backward_entropy": 0.03556168079376221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.14214324951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030663272365927696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1390975018342336,
      "backward_entropy": 0.03515536487102509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.46710968017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030718475580215454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13902873794237772,
      "backward_entropy": 0.03473473787307739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.98087692260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030778657644987106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13895565271377563,
      "backward_entropy": 0.03434117436408997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.97409439086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030838429927825928,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13888461391131082,
      "backward_entropy": 0.03398436903953552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.71883010864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03089459240436554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13881897926330566,
      "backward_entropy": 0.04012739062309265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.87798309326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03095146268606186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13875373204549155,
      "backward_entropy": 0.039828824996948245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.870147705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031006773933768272,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13869139552116394,
      "backward_entropy": 0.03952229022979736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.08735656738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031060026958584785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13863259553909302,
      "backward_entropy": 0.03923084139823914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.64216232299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03111688792705536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1385707954565684,
      "backward_entropy": 0.032152265310287476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.11725997924805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031172091141343117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13851189613342285,
      "backward_entropy": 0.03866567611694336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.00606536865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031224630773067474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13845711946487427,
      "backward_entropy": 0.031425073742866516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.54095458984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03128159046173096,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13839844862620035,
      "backward_entropy": 0.13294632434844972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.460941314697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03134455159306526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13833482066790262,
      "backward_entropy": 0.03081417977809906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.86070251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031404655426740646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13827607035636902,
      "backward_entropy": 0.030536061525344847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.54729461669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03146626427769661,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13821633656819662,
      "backward_entropy": 0.037527349591255185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.83045196533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03152789548039436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.138157327969869,
      "backward_entropy": 0.037328985333442685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.9489860534668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03158735856413841,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13810171683629355,
      "backward_entropy": 0.03714968264102936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.87754440307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03164608031511307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13804811239242554,
      "backward_entropy": 0.029423150420188903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.62120819091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03170549497008324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13799484570821127,
      "backward_entropy": 0.029147011041641236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.14114379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03176572173833847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13794185717900595,
      "backward_entropy": 0.0365715891122818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.72727584838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031828537583351135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13788741827011108,
      "backward_entropy": 0.03642880618572235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.529014587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03188864141702652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13783669471740723,
      "backward_entropy": 0.03628686368465424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.9708480834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03194648399949074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1377891500790914,
      "backward_entropy": 0.036151379346847534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.31930160522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03200668841600418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377404530843099,
      "backward_entropy": 0.02797689139842987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.35466003417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032061949372291565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1376973589261373,
      "backward_entropy": 0.02772524356842041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.88261413574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03212633728981018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13764619827270508,
      "backward_entropy": 0.035756295919418334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.195533752441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032191794365644455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13759544491767883,
      "backward_entropy": 0.02730606198310852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.2278823852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032255370169878006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13754743337631226,
      "backward_entropy": 0.027084487676620483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.178585052490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03232508525252342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13749508062998453,
      "backward_entropy": 0.026878562569618226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.75757598876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03239466995000839,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13744393984476724,
      "backward_entropy": 0.03530480563640594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.66648483276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032468780875205994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13739011685053507,
      "backward_entropy": 0.026510703563690185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.33812713623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032540179789066315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13733975092569986,
      "backward_entropy": 0.035150077939033506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.80792236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032609470188617706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1372925043106079,
      "backward_entropy": 0.035061851143836975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.9763069152832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032684311270713806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13724136352539062,
      "backward_entropy": 0.0349832147359848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.74957275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032756876200437546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13719322284062704,
      "backward_entropy": 0.03490445017814636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.65927124023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032827556133270264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13714773456255594,
      "backward_entropy": 0.03483190834522247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.8862190246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03289920836687088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13710244496663412,
      "backward_entropy": 0.025431087613105773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.175125122070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032970573753118515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13705829779307047,
      "backward_entropy": 0.03469696640968323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.35993194580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03303622454404831,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13701972365379333,
      "backward_entropy": 0.03460173606872559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.852428436279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033102888613939285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13698118925094604,
      "backward_entropy": 0.03450096845626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.44884490966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033164650201797485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13694727420806885,
      "backward_entropy": 0.024665763974189757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.041481018066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033226825296878815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13691375652949014,
      "backward_entropy": 0.03427010178565979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.3502197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03328985720872879,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13688024878501892,
      "backward_entropy": 0.03417559266090393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.00197219848633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033350907266139984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13684892654418945,
      "backward_entropy": 0.034054124355316163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.930908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033412471413612366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1368178923924764,
      "backward_entropy": 0.03393924832344055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.54330062866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03347254917025566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13678866624832153,
      "backward_entropy": 0.03381249904632568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.01634216308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033533576875925064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13675947984059653,
      "backward_entropy": 0.03370461165904999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.08182144165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0336010567843914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13672612110773721,
      "backward_entropy": 0.03361448049545288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.19114685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033669065684080124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366931994756063,
      "backward_entropy": 0.02310307025909424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.11982727050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03374019265174866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13665889700253805,
      "backward_entropy": 0.022952941060066224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.863527297973633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03381380811333656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13662375013033548,
      "backward_entropy": 0.02280625104904175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.86090087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03388094902038574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13659397761027017,
      "backward_entropy": 0.022655177116394042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.87689971923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033946409821510315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1365658938884735,
      "backward_entropy": 0.02249765694141388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.781532287597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034008730202913284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13654053211212158,
      "backward_entropy": 0.03327431082725525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.51559829711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034068234264850616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13651758432388306,
      "backward_entropy": 0.03318822085857391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.23854446411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03412801772356033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13649510343869528,
      "backward_entropy": 0.03309130966663361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.86811828613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03418602794408798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364742120107015,
      "backward_entropy": 0.02179824411869049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.955140113830566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03424743562936783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13645175099372864,
      "backward_entropy": 0.021623507142066956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.58582305908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034302882850170135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13643373052279154,
      "backward_entropy": 0.021433253586292268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.00065612792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03435982018709183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364151338736216,
      "backward_entropy": 0.021257269382476806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.38067626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034420888870954514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13639443119366965,
      "backward_entropy": 0.021093432605266572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.4682502746582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03448742628097534,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13637090722719827,
      "backward_entropy": 0.03260096311569214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.96195220947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03455360606312752,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363482673962911,
      "backward_entropy": 0.03253657221794128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.38734436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03462093695998192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1363255480925242,
      "backward_entropy": 0.032461506128311154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.66273880004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034690193831920624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13630219300587973,
      "backward_entropy": 0.032408219575881955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.37222671508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03475620970129967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13628140091896057,
      "backward_entropy": 0.03234963417053223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.1632194519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03482018783688545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13626235723495483,
      "backward_entropy": 0.03227024972438812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.805631637573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034882206469774246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13624469439188638,
      "backward_entropy": 0.0322148323059082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.119659423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494040295481682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13622967402140299,
      "backward_entropy": 0.019887349009513854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.5245475769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03499971702694893,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13621437549591064,
      "backward_entropy": 0.03211228251457214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.63657760620117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035058580338954926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619967301686606,
      "backward_entropy": 0.032072237133979796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.143367767333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03511646017432213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13618598381678262,
      "backward_entropy": 0.019469942152500152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.17435073852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517681732773781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13617132107416788,
      "backward_entropy": 0.019332171976566316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.16521453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03523663431406021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13615729411443075,
      "backward_entropy": 0.019200250506401062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.67350387573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03529568761587143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13614406188329062,
      "backward_entropy": 0.019066256284713746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.20869827270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035356972366571426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613003492355347,
      "backward_entropy": 0.018932813405990602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.30778503417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035418812185525894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13611612717310587,
      "backward_entropy": 0.0318010151386261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.516239166259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035484764724969864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13610039154688516,
      "backward_entropy": 0.03178483545780182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.144376754760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03554978594183922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360854705174764,
      "backward_entropy": 0.03177831172943115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.43648147583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03561265766620636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13607192039489746,
      "backward_entropy": 0.031783998012542725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.62144088745117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03567636013031006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360584000746409,
      "backward_entropy": 0.03179762065410614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.75523376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035741690546274185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13604430357615152,
      "backward_entropy": 0.01828806698322296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.98282241821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03581278771162033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360280712445577,
      "backward_entropy": 0.018185585737228394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.035152435302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03588216006755829,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136013130346934,
      "backward_entropy": 0.01808275729417801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.75647735595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03595100715756416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13599889477094015,
      "backward_entropy": 0.03176721930503845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.362003326416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03602408990263939,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359831690788269,
      "backward_entropy": 0.017865392565727233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.17911911010742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03609723597764969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13596771160761514,
      "backward_entropy": 0.031760001182556154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.28923416137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03617172688245773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13595197598139444,
      "backward_entropy": 0.031780725717544554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.28607177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03624415025115013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359375516573588,
      "backward_entropy": 0.03180116713047028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.17055892944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03631430119276047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13592464725176492,
      "backward_entropy": 0.017503920197486877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.158960342407227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03638137876987457,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359134316444397,
      "backward_entropy": 0.03180570602416992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.79498291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03644541651010513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590391476949057,
      "backward_entropy": 0.017300108075141908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.000181198120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03651440143585205,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589251041412354,
      "backward_entropy": 0.031794479489326476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.08134078979492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036580029875040054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358829935391744,
      "backward_entropy": 0.03177917003631592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.79796028137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03664630278944969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358733077843984,
      "backward_entropy": 0.03177961111068726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.67229461669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0367094948887825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586528102556863,
      "backward_entropy": 0.016893406212329865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.73015594482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03677420690655708,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13585700591405234,
      "backward_entropy": 0.1360556364059448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.93291091918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036839257925748825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358487606048584,
      "backward_entropy": 0.016670316457748413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.200407028198242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03690332546830177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358410914738973,
      "backward_entropy": 0.03168804943561554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.40476989746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03696521371603012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358344554901123,
      "backward_entropy": 0.016467341780662538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.1124496459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037030305713415146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358268658320109,
      "backward_entropy": 0.0163665771484375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.957462310791016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03710133954882622,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13581724961598715,
      "backward_entropy": 0.1361733317375183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.96915435791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037171948701143265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580814997355142,
      "backward_entropy": 0.03164925873279571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.59405517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03724917396903038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579684495925903,
      "backward_entropy": 0.03163506686687469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.95572662353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03732534870505333,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578631480534872,
      "backward_entropy": 0.031617474555969236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.853057861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037404004484415054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577502965927124,
      "backward_entropy": 0.03162218630313873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.342073440551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037480175495147705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13576493660608926,
      "backward_entropy": 0.031625750660896304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.81807327270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037552960216999054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135756254196167,
      "backward_entropy": 0.015722496807575224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.28170394897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03762524574995041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574798901875815,
      "backward_entropy": 0.015640799701213837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.31391525268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03769618272781372,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357402503490448,
      "backward_entropy": 0.031678876280784606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.33392333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037765271961688995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573343555132547,
      "backward_entropy": 0.015494415163993835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.31273651123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03783409669995308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572694857915243,
      "backward_entropy": 0.0317114919424057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.92341995239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03790583088994026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571967681248984,
      "backward_entropy": 0.03173266649246216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.7167854309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037977274507284164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571250438690186,
      "backward_entropy": 0.015268552303314208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.59738540649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03804857283830643,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357054909070333,
      "backward_entropy": 0.015199802815914154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.43075942993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038120996206998825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569827874501547,
      "backward_entropy": 0.015133409202098847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.33286666870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03819291666150093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356914540131887,
      "backward_entropy": 0.01506493091583252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.16272735595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03826287016272545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135685533285141,
      "backward_entropy": 0.03185850977897644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.88296890258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03833117336034775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568034768104553,
      "backward_entropy": 0.03187525272369385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.71937942504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03839949145913124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567525148391724,
      "backward_entropy": 0.03189440965652466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.110204696655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038468603044748306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567020495732626,
      "backward_entropy": 0.03189239799976349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.042085647583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03853336349129677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566675782203674,
      "backward_entropy": 0.0318889319896698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.938602447509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038594212383031845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566472133000693,
      "backward_entropy": 0.014596761763095855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.701379776000977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03865208849310875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356640656789144,
      "backward_entropy": 0.014495554566383361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.79751968383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03870789706707001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135664165019989,
      "backward_entropy": 0.03180176019668579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.524539947509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03876093402504921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566515843073526,
      "backward_entropy": 0.03177100121974945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4624321758747101,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03881239891052246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566678762435913,
      "backward_entropy": 0.014195495843887329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.363325119018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03885840252041817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567030429840088,
      "backward_entropy": 0.03169538676738739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.52099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03890354931354523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567409912745157,
      "backward_entropy": 0.01399252712726593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.628032684326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03895058110356331,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567725817362467,
      "backward_entropy": 0.031599438190460204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.502941131591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03899528831243515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568125168482462,
      "backward_entropy": 0.031545281410217285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.52360916137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03903825953602791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568572203318277,
      "backward_entropy": 0.031503498554229736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.9808292388916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03908553719520569,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356886625289917,
      "backward_entropy": 0.031488281488418576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.36883544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039131879806518555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356919507185618,
      "backward_entropy": 0.03146779835224152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.47532653808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03917887806892395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569511969884238,
      "backward_entropy": 0.013421878218650818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.43706130981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03923387825489044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356956958770752,
      "backward_entropy": 0.031446582078933714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.96661376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03929082676768303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569557666778564,
      "backward_entropy": 0.031475219130516055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.63620376586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03935473784804344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569345076878866,
      "backward_entropy": 0.013241446018218994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.501251220703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03942038118839264,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13569092750549316,
      "backward_entropy": 0.1368046522140503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.863800048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03948724642395973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356882651646932,
      "backward_entropy": 0.013137805461883544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.73576736450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039554499089717865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568549354871115,
      "backward_entropy": 0.03164645135402679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.607722282409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962187469005585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568276166915894,
      "backward_entropy": 0.013039498031139374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.767473220825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03968380019068718,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568164904912314,
      "backward_entropy": 0.03173089027404785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.4863166809082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03974228352308273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568158944447836,
      "backward_entropy": 0.03177289962768555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.79740333557129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03980288654565811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568095366160074,
      "backward_entropy": 0.012884093821048737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.58860969543457,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039861541241407394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1356809139251709,
      "backward_entropy": 0.13696846961975098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.933616638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03991496190428734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356825828552246,
      "backward_entropy": 0.012765100598335266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.625484466552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039969224482774734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568419218063354,
      "backward_entropy": 0.03183537423610687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.537208557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04002342000603676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568582137425741,
      "backward_entropy": 0.012618716061115264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.38722229003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040079012513160706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568701346715292,
      "backward_entropy": 0.012551917135715485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.28759002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04014020040631294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568662603696188,
      "backward_entropy": 0.012495646625757218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.28260612487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040201764553785324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356862187385559,
      "backward_entropy": 0.012436667084693908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.850929260253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04025951772928238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568694392840067,
      "backward_entropy": 0.01237252652645111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.965105056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031963646411896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568717241287231,
      "backward_entropy": 0.031880241632461545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.349552154541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037795215845108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568776845932007,
      "backward_entropy": 0.012256572395563126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.007213592529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040439896285533905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568725188573202,
      "backward_entropy": 0.012203633040189742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.277706146240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040498100221157074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135687788327535,
      "backward_entropy": 0.03193922638893128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.382003784179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040557462722063065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135688046614329,
      "backward_entropy": 0.03196619749069214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.546085357666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04061632603406906,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568844397862753,
      "backward_entropy": 0.03199688494205475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.09636116027832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04067320004105568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13568936785062155,
      "backward_entropy": 0.011995574831962586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.08516311645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04073011130094528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569019238154092,
      "backward_entropy": 0.03206443786621094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.913410186767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079074412584305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356900930404663,
      "backward_entropy": 0.011910727620124817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.17755699157715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04085063189268112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569019238154092,
      "backward_entropy": 0.03214941620826721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.489184379577637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04090841859579086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569088776906332,
      "backward_entropy": 0.0321844220161438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.263431549072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04096297174692154,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569241762161255,
      "backward_entropy": 0.032213646173477176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.49875259399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041021350771188736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569298386573792,
      "backward_entropy": 0.03223985433578491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.75165557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04108193516731262,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356930136680603,
      "backward_entropy": 0.03226845562458038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.120023727416992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041146282106637955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356920301914215,
      "backward_entropy": 0.011643847823143006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.140995979309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0412098653614521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569114605585733,
      "backward_entropy": 0.032383760809898375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.064626693725586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04126982018351555,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13569114605585733,
      "backward_entropy": 0.1373325228691101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.936073303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04132659733295441,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569189111391702,
      "backward_entropy": 0.03251686990261078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.378456115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04138708487153053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569173216819763,
      "backward_entropy": 0.03258615732192993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.187788009643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041449494659900665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569112618764242,
      "backward_entropy": 0.011499515175819397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.428030014038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041509874165058136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569095730781555,
      "backward_entropy": 0.03272416591644287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.486626148223877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04156944900751114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569100697835287,
      "backward_entropy": 0.03278907537460327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.4155158996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041624534875154495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356921394666036,
      "backward_entropy": 0.032856062054634094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.27121353149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04168073087930679,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569289445877075,
      "backward_entropy": 0.03291852474212646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.432404041290283,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041737914085388184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356934905052185,
      "backward_entropy": 0.011358758807182312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.93744659423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04179055988788605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569517930348715,
      "backward_entropy": 0.033026695251464844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.64798355102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041844893246889114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356963316599528,
      "backward_entropy": 0.011296521127223968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.50252914428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041897404938936234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356980005900065,
      "backward_entropy": 0.03313579261302948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.433874130249023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041948724538087845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356999079386393,
      "backward_entropy": 0.03318505585193634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.415189743041992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04199887439608574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570203383763632,
      "backward_entropy": 0.03323299586772919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.266846656799316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04204752296209335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570462663968405,
      "backward_entropy": 0.033260238170623777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.281719207763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04209386557340622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13570775588353476,
      "backward_entropy": 0.011109723150730133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.21033763885498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04214021563529968,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571099440256754,
      "backward_entropy": 0.0332832932472229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.75278091430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042184144258499146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571481903394064,
      "backward_entropy": 0.010998190939426422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.661109924316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223540797829628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571698466936746,
      "backward_entropy": 0.010942722856998443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.678260803222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04229068011045456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571823636690775,
      "backward_entropy": 0.01088976263999939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.53832244873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04234688729047775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571926951408386,
      "backward_entropy": 0.03323984146118164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.706663131713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042403846979141235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572015364964804,
      "backward_entropy": 0.010783915221691132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.821592330932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04245898500084877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572140534718832,
      "backward_entropy": 0.010731396824121475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.8745231628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04251110926270485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572330276171365,
      "backward_entropy": 0.010678057372570039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.670257568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04256566986441612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572468360265097,
      "backward_entropy": 0.03319811224937439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.732357025146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04262266680598259,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572547833124796,
      "backward_entropy": 0.033193758130073546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.586146354675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042680900543928146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357258359591166,
      "backward_entropy": 0.01053495928645134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.505271911621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042735736817121506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572696844736734,
      "backward_entropy": 0.01049216166138649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.708322525024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04279135540127754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572796185811362,
      "backward_entropy": 0.010446497797966003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.97129249572754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04284656047821045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572903474171957,
      "backward_entropy": 0.01040133237838745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.604644775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290027916431427,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573034604390463,
      "backward_entropy": 0.010359764099121094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.810894012451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04295646771788597,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573106129964194,
      "backward_entropy": 0.033262899518013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.231788635253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043010905385017395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357321540514628,
      "backward_entropy": 0.03328239321708679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.62406921386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0430622473359108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573394219080606,
      "backward_entropy": 0.010240934789180756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.55411720275879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04311477392911911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13573548197746277,
      "backward_entropy": 0.01019739955663681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.37540054321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0431659072637558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573727011680603,
      "backward_entropy": 0.033303046226501466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.21181869506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04321792721748352,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357389489809672,
      "backward_entropy": 0.03329236209392548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.55723237991333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04327097535133362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357404092947642,
      "backward_entropy": 0.033278551697731015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.203907012939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04331989213824272,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574273387591043,
      "backward_entropy": 0.03326382040977478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.796899795532227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04336792975664139,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574514786402384,
      "backward_entropy": 0.009962157905101776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.35653305053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043417468667030334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574724396069845,
      "backward_entropy": 0.033262237906455994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.060909271240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04346717149019241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574924071629843,
      "backward_entropy": 0.033266282081604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.649507522583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04352085664868355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13575037320454916,
      "backward_entropy": 0.009837235510349273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.768678665161133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043571699410676956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575209180514017,
      "backward_entropy": 0.033287516236305235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.920246124267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043621763586997986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575382033983865,
      "backward_entropy": 0.033322381973266604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.12984848022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043671850115060806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575551907221475,
      "backward_entropy": 0.03335393667221069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.55661964416504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04372459650039673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13575667142868042,
      "backward_entropy": 0.009707418084144593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.703893661499023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04377591237425804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575814167658487,
      "backward_entropy": 0.03342281579971314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.317449569702148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04382828250527382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575934370358786,
      "backward_entropy": 0.03344884514808655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.307443618774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04387786239385605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576104243596396,
      "backward_entropy": 0.009612303972244263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.267024993896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04392631724476814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576296965281168,
      "backward_entropy": 0.009579052031040192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.159111022949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04397652670741081,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13576446970303854,
      "backward_entropy": 0.03353002667427063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.05257797241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04402408376336098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576648632685342,
      "backward_entropy": 0.009521208703517914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.79228973388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044071875512599945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135768453280131,
      "backward_entropy": 0.033584558963775636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.986730575561523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04412378743290901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576956590016684,
      "backward_entropy": 0.009461786597967148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.836444854736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044173017144203186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357711354891459,
      "backward_entropy": 0.009432806074619294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.860941886901855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04422099515795708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13577298323313394,
      "backward_entropy": 0.009402131289243698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.216732025146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0442669577896595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13577510913213095,
      "backward_entropy": 0.009376084059476852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.08230209350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0443158820271492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357766588528951,
      "backward_entropy": 0.009351177513599396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.90311050415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044367123395204544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13577779134114584,
      "backward_entropy": 0.009321323037147522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.45374870300293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04442064091563225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357784867286682,
      "backward_entropy": 0.03379732668399811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.338645935058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04447212815284729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135779599348704,
      "backward_entropy": 0.00925266444683075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.386409759521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04452225938439369,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578091065088907,
      "backward_entropy": 0.03380126357078552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.850582122802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044574953615665436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578168551127115,
      "backward_entropy": 0.03381471633911133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.0499382019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04462745040655136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578244050343832,
      "backward_entropy": 0.033834907412528994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.356518745422363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04468218609690666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578274846076965,
      "backward_entropy": 0.03386008143424988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.521615982055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044734206050634384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357834835847219,
      "backward_entropy": 0.00910298228263855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.971139907836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04478581249713898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578427831331888,
      "backward_entropy": 0.03392918705940247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.75900650024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04483844339847565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578488429387411,
      "backward_entropy": 0.009051796793937684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.641544342041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04488925263285637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578581809997559,
      "backward_entropy": 0.033977237343788144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.53424835205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04493600130081177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578750689824423,
      "backward_entropy": 0.00898781642317772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.5042667388916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04498688876628876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578838109970093,
      "backward_entropy": 0.034003031253814694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.985176086425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04503631219267845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578949371973673,
      "backward_entropy": 0.008930179476737975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.758779525756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04508321359753609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13579106330871582,
      "backward_entropy": 0.008900538831949235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.649974822998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04513024166226387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357925534248352,
      "backward_entropy": 0.03405040502548218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.831502914428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04517750442028046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13579395413398743,
      "backward_entropy": 0.008841288834810257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.10813331604004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04522239789366722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579578200976053,
      "backward_entropy": 0.03408040106296539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.038307189941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04526659846305847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357976794242859,
      "backward_entropy": 0.008783534169197083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.969529151916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04531010985374451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579964637756348,
      "backward_entropy": 0.034126374125480655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.424535751342773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045352935791015625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580169280370077,
      "backward_entropy": 0.03415117561817169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.330382823944092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04539776220917702,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580334186553955,
      "backward_entropy": 0.03418664038181305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.757796287536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04543956369161606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580545783042908,
      "backward_entropy": 0.03423265516757965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.48580265045166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045480839908123016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358075737953186,
      "backward_entropy": 0.034276175498962405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.623372077941895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04552057012915611,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580995798110962,
      "backward_entropy": 0.03432452976703644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.025177001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04556002840399742,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358123222986857,
      "backward_entropy": 0.008636529743671417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.757205963134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045602958649396896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581401109695435,
      "backward_entropy": 0.03442983329296112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.305906295776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04564770683646202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13581534226735434,
      "backward_entropy": 0.00860779732465744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.52976417541504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04569048807024956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581698139508566,
      "backward_entropy": 0.03454437851905823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.282712936401367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045734912157058716,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358183224995931,
      "backward_entropy": 0.03459351360797882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.336740493774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577839747071266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358198126157125,
      "backward_entropy": 0.0085591621696949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.116839408874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458245575428009,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582082589467367,
      "backward_entropy": 0.008537652343511582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.05491065979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04586847871541977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582218686739603,
      "backward_entropy": 0.00851529762148857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.030035972595215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459127277135849,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358234683672587,
      "backward_entropy": 0.008491906523704528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.925387382507324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04595465213060379,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358251670996348,
      "backward_entropy": 0.008463802933692931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.77293586730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045995768159627914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13582696517308554,
      "backward_entropy": 0.03471932113170624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.678781509399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04603753611445427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13582863410313925,
      "backward_entropy": 0.034719806909561154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.832151412963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04607994109392166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583014408747354,
      "backward_entropy": 0.034725725650787354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.497785568237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04612048342823982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583190242449442,
      "backward_entropy": 0.03473198413848877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.90214157104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046161726117134094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358335018157959,
      "backward_entropy": 0.034739619493484496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.879475116729736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046207278966903687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358343263467153,
      "backward_entropy": 0.008298279345035553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.43152904510498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046249546110630035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583566745122275,
      "backward_entropy": 0.008276204019784928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.593069076538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04629106819629669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583709796269736,
      "backward_entropy": 0.008253113180398942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.036909103393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633096605539322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583874702453613,
      "backward_entropy": 0.008232660591602325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.944087982177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04637160524725914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584023714065552,
      "backward_entropy": 0.0082124724984169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.557798385620117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046413056552410126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584154844284058,
      "backward_entropy": 0.008195125311613084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.765579223632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04645618423819542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584254185358682,
      "backward_entropy": 0.00817660391330719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37006664276123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04649966210126877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13584343592325845,
      "backward_entropy": 0.03494336903095245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.951042175292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046541061252355576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584468762079874,
      "backward_entropy": 0.008136409521102905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06571678072214127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046581827104091644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13584595918655396,
      "backward_entropy": 0.03498368859291077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.817648887634277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661843925714493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135847936073939,
      "backward_entropy": 0.03499743640422821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.465585708618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665513336658478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584996263186136,
      "backward_entropy": 0.008072789758443832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.694806098937988,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046695075929164886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13585148255030313,
      "backward_entropy": 0.13801753520965576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.583648204803467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04673461616039276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13585305213928223,
      "backward_entropy": 0.00803437978029251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572064399719238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046771373599767685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13585501909255981,
      "backward_entropy": 0.03509877324104309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.96054458618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046807896345853806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13585700591405234,
      "backward_entropy": 0.035119903087615964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.29425048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046847883611917496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13585842649141947,
      "backward_entropy": 0.007978210598230362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93315315246582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046892061829566956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358591914176941,
      "backward_entropy": 0.03518514931201935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.886886596679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04693417251110077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358602245648702,
      "backward_entropy": 0.035219120979309085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054247550666332245,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04697441682219505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586150606473288,
      "backward_entropy": 0.007932499051094055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.55209732055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0470106303691864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586336374282837,
      "backward_entropy": 0.03528186082839966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.475709915161133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047047898173332214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586502273877463,
      "backward_entropy": 0.03531380295753479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.056025505065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708584398031235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358665625254313,
      "backward_entropy": 0.007881054282188415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67870807647705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047123365104198456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586815198262533,
      "backward_entropy": 0.03534942865371704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.518497467041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04715942218899727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586990038553873,
      "backward_entropy": 0.0078410804271698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.869061470031738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047197822481393814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587124149004617,
      "backward_entropy": 0.007825005799531937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.553074836730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047235872596502304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135872612396876,
      "backward_entropy": 0.007809519022703171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.744824409484863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047272488474845886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587416211764017,
      "backward_entropy": 0.03545159697532654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.902347564697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04730905219912529,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358756422996521,
      "backward_entropy": 0.0354914128780365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.820405960083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04734646528959274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135876993338267,
      "backward_entropy": 0.007768803834915161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.735544204711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047384679317474365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358781854311625,
      "backward_entropy": 0.00775480717420578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3464937210083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04742372781038284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587920864423117,
      "backward_entropy": 0.03559554815292358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.438858985900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047461267560720444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588041067123413,
      "backward_entropy": 0.03563684821128845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.603330612182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047498468309640884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588162263234457,
      "backward_entropy": 0.03567556142807007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.496871948242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04753752425312996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588255643844604,
      "backward_entropy": 0.007706914097070694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.38522720336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04757828265428543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588321208953857,
      "backward_entropy": 0.03573653697967529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.317306518554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04762064293026924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588361938794455,
      "backward_entropy": 0.03576674461364746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.083662033081055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047665491700172424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588364919026694,
      "backward_entropy": 0.03579519093036652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.03076934814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04770811274647713,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588395714759827,
      "backward_entropy": 0.035821616649627686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.984730243682861,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047755420207977295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588360945383707,
      "backward_entropy": 0.007638915628194809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.986276149749756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047800324857234955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358835498491923,
      "backward_entropy": 0.0076261632144451145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.893246173858643,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784196615219116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588387767473856,
      "backward_entropy": 0.007614090293645859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8492279052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04788152873516083,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358844836552938,
      "backward_entropy": 0.035931116342544554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.578328132629395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047919292002916336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588528831799826,
      "backward_entropy": 0.0075823083519935604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9000589847564697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04795771464705467,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588599363962808,
      "backward_entropy": 0.03596090078353882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.110027313232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04799344018101692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358870267868042,
      "backward_entropy": 0.03597643375396729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.157516479492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803206026554108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358876427014669,
      "backward_entropy": 0.007531241327524185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.639182090759277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04807242006063461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358879804611206,
      "backward_entropy": 0.03599602282047272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596915245056152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048111043870449066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588851690292358,
      "backward_entropy": 0.03601386249065399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.31905460357666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04814813658595085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588922222455344,
      "backward_entropy": 0.007486683875322342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.002950668334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04818495735526085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588992754618326,
      "backward_entropy": 0.036069446802139284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7537434101104736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04822252318263054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358905037244161,
      "backward_entropy": 0.036100763082504275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.847603797912598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04825751110911369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589138785998026,
      "backward_entropy": 0.007453656941652298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.086167335510254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0482933409512043,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589213291803995,
      "backward_entropy": 0.03616304993629456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.361668586730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04832872003316879,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589290777842203,
      "backward_entropy": 0.036182057857513425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.62028980255127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04836280271410942,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589381178220114,
      "backward_entropy": 0.036203020811080934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.916250228881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04839790239930153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589455684026083,
      "backward_entropy": 0.007402704656124115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6383533477783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04843268170952797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589531183242798,
      "backward_entropy": 0.03624612390995026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.399703025817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846515879034996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358963350454966,
      "backward_entropy": 0.0073761515319347385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.601801633834839,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04849885776638985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589715957641602,
      "backward_entropy": 0.03629730343818664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.143203258514404,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0485304556787014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358982523282369,
      "backward_entropy": 0.0073566347360610965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.110179424285889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048561181873083115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589940468470255,
      "backward_entropy": 0.036375346779823306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.131197929382324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859114810824394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590063651402792,
      "backward_entropy": 0.007342898845672607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.044784069061279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048622556030750275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590162992477417,
      "backward_entropy": 0.03647225499153137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.012043476104736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04865309223532677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590270280838013,
      "backward_entropy": 0.03652494251728058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.980942726135254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04868290200829506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590383529663086,
      "backward_entropy": 0.036583039164543155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.41340446472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048711925745010376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359050472577413,
      "backward_entropy": 0.007327944040298462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.60561180114746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048741310834884644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359061598777771,
      "backward_entropy": 0.007324359565973282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023084286600351334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048776473850011826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590651750564575,
      "backward_entropy": 0.03675307333469391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.674444198608398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04880812019109726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590731223424277,
      "backward_entropy": 0.03680726587772369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.81334924697876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048840854316949844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590790828069052,
      "backward_entropy": 0.007315767556428909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.159682273864746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048872508108615875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590863347053528,
      "backward_entropy": 0.03690396547317505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745467185974121,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04890413582324982,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13590930898984274,
      "backward_entropy": 0.1382382869720459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.405965805053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048934873193502426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591007391611734,
      "backward_entropy": 0.00729970782995224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.350196123123169,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048966873437166214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359106500943502,
      "backward_entropy": 0.03703520894050598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.648543834686279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04899675399065018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591144482294717,
      "backward_entropy": 0.03707845807075501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.215819358825684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049025729298591614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591232895851135,
      "backward_entropy": 0.03711553812026978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.868003845214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04905591532588005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591304421424866,
      "backward_entropy": 0.0072745256125926975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2856433391571045,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04908624291419983,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13591370979944864,
      "backward_entropy": 0.13825757503509523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.773552894592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049114640802145004,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591458400090536,
      "backward_entropy": 0.03719260692596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.964401245117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049143433570861816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359153687953949,
      "backward_entropy": 0.007247269153594971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.121686935424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04917360097169876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359159549077352,
      "backward_entropy": 0.037249335646629335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2207412719726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0492059662938118,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591625293095908,
      "backward_entropy": 0.03727525472640991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.580615043640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0492362454533577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591675957043967,
      "backward_entropy": 0.03730449974536896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.188523769378662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04926660284399986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591724634170532,
      "backward_entropy": 0.03732910752296448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.642653465270996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929501563310623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359179417292277,
      "backward_entropy": 0.007205944508314133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.580140113830566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0493248850107193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359184185663859,
      "backward_entropy": 0.03738460540771484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.389936447143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04935598000884056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591870665550232,
      "backward_entropy": 0.037416106462478636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.55823040008545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0493871308863163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359189748764038,
      "backward_entropy": 0.007186096161603928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288033485412598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04942024126648903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591899474461874,
      "backward_entropy": 0.007177678495645523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0891873836517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04945319518446922,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591899474461874,
      "backward_entropy": 0.03749303817749024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.244547843933105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04948385804891586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359192430973053,
      "backward_entropy": 0.03751187324523926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.218390464782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04951560124754906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591933250427246,
      "backward_entropy": 0.007151416689157486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.037609577178955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04954928904771805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591917355855307,
      "backward_entropy": 0.03754754066467285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.033028602600098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049580637365579605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591927289962769,
      "backward_entropy": 0.037561720609664916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0038628578186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049612049013376236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591933250427246,
      "backward_entropy": 0.03758222460746765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.836292266845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04964139685034752,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591960072517395,
      "backward_entropy": 0.037603247165679934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.927742004394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049674853682518005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359193722407023,
      "backward_entropy": 0.037617847323417664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.893631935119629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04970698431134224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591928283373514,
      "backward_entropy": 0.037629491090774535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.784876823425293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04973794147372246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591931263605753,
      "backward_entropy": 0.0070858001708984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735701560974121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04976880922913551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591931263605753,
      "backward_entropy": 0.0070745587348937985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7956318855285645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049799662083387375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591929276784262,
      "backward_entropy": 0.037655168771743776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.39136791229248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04982941597700119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591939210891724,
      "backward_entropy": 0.007052391767501831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589296340942383,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049861226230859756,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13591919342676798,
      "backward_entropy": 0.13828139305114745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.696667194366455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049892961978912354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591899474461874,
      "backward_entropy": 0.0070310734212398526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.143969535827637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04992373660206795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591890533765158,
      "backward_entropy": 0.007023870944976807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8210301399230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049956414848566055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591854770978293,
      "backward_entropy": 0.03771204948425293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.185643196105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998680576682091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591844836870828,
      "backward_entropy": 0.007007146626710892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.342890739440918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05001819133758545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591819008191428,
      "backward_entropy": 0.03774063289165497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.815847396850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05004938319325447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359179417292277,
      "backward_entropy": 0.037751543521881106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.242077827453613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05008251219987869,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591742515563965,
      "backward_entropy": 0.03776760995388031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.917512893676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050115350633859634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359169085820516,
      "backward_entropy": 0.006974415481090545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.847708702087402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05014895275235176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591628273328146,
      "backward_entropy": 0.03780611753463745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.468482971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018308386206627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591556747754416,
      "backward_entropy": 0.006960415095090866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.029657363891602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050218790769577026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591463367144266,
      "backward_entropy": 0.006953693926334381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.665189504623413,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05025390535593033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591372966766357,
      "backward_entropy": 0.037858223915100096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.200876235961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05028664693236351,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591311375300089,
      "backward_entropy": 0.03788351714611053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.871461391448975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050321005284786224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591225941975912,
      "backward_entropy": 0.03790683150291443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819014549255371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035494267940521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13591142495473227,
      "backward_entropy": 0.006931631267070771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.353471755981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05038837343454361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591063022613525,
      "backward_entropy": 0.03795478343963623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5779833793640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050422344356775284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590974609057108,
      "backward_entropy": 0.03797451853752136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666401386260986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05045398324728012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590912024180093,
      "backward_entropy": 0.03799729943275452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.763708114624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050485361367464066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590850432713827,
      "backward_entropy": 0.03801797926425934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.082880020141602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0505203977227211,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590741157531738,
      "backward_entropy": 0.006903595477342606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.51106071472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05055577680468559,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13590620954831442,
      "backward_entropy": 0.038061922788619994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.417501449584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05059244856238365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359048088391622,
      "backward_entropy": 0.03808373212814331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.858747482299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05063023418188095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359032392501831,
      "backward_entropy": 0.03810376226902008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.668302536010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05066807568073273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590161999066672,
      "backward_entropy": 0.006882274150848388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4314937591552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050707828253507614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589970270792642,
      "backward_entropy": 0.006876663118600845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4129281044006348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074455216526985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589816292126974,
      "backward_entropy": 0.006870196759700775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008415133692324162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077864229679108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589694102605185,
      "backward_entropy": 0.006864561140537262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.123466968536377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050809476524591446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589617609977722,
      "backward_entropy": 0.03820083141326904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7210235595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05084001272916794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589540123939514,
      "backward_entropy": 0.03822139799594879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3748197555542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05086945742368698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589476545651755,
      "backward_entropy": 0.006850559264421463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.987391948699951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050899751484394073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13589399059613547,
      "backward_entropy": 0.03827000260353088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.253741264343262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05092982202768326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135893185933431,
      "backward_entropy": 0.03829275667667389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.895805358886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05096068233251572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589227199554443,
      "backward_entropy": 0.006838072836399078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849964618682861,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05099128186702728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589135805765787,
      "backward_entropy": 0.006834268569946289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.804272174835205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051021695137023926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13589044411977133,
      "backward_entropy": 0.0068312957882881165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2579703330993652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051051802933216095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588953018188477,
      "backward_entropy": 0.03839576840400696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.427370071411133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051079925149679184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588889439900717,
      "backward_entropy": 0.006823930889368057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.892572402954102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051110751926898956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588784138361612,
      "backward_entropy": 0.006820441037416458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.830041885375977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05114217847585678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358866492907206,
      "backward_entropy": 0.0068165697157382965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.386630058288574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05117415264248848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358853280544281,
      "backward_entropy": 0.038494613766670224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.356199264526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05120475962758064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588420550028482,
      "backward_entropy": 0.03851474225521088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.487107276916504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05123414844274521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588322202364603,
      "backward_entropy": 0.0068031661212444305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.880882263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05126328766345978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588224848111471,
      "backward_entropy": 0.00679733008146286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006446200888603926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05129494145512581,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588085770606995,
      "backward_entropy": 0.038562539219856265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2383832931518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05132344737648964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135879913965861,
      "backward_entropy": 0.006785353273153305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1086370944976807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05135102942585945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135879119237264,
      "backward_entropy": 0.03859395682811737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18564510345459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05137677863240242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587855299313864,
      "backward_entropy": 0.038611996173858645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006099478341639042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05140180140733719,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358780860900879,
      "backward_entropy": 0.006771041452884674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205211639404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05142436921596527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587798674901327,
      "backward_entropy": 0.03865099549293518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.116218090057373,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05144737288355827,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.135877788066864,
      "backward_entropy": 0.13834259510040284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.094167232513428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051469895988702774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587764898935953,
      "backward_entropy": 0.03868833780288696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.139232635498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05149201303720474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587753971417746,
      "backward_entropy": 0.038709455728530885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.093198776245117,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051515497267246246,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13587719202041626,
      "backward_entropy": 0.13834539651870728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.025350093841553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05154012516140938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587665557861328,
      "backward_entropy": 0.03874556124210358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.99993371963501,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05156414210796356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358761489391327,
      "backward_entropy": 0.03876450359821319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.909655570983887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05158843845129013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587559262911478,
      "backward_entropy": 0.006735438853502274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9778374433517456,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05161644518375397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587441047032675,
      "backward_entropy": 0.006730994582176209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.885131359100342,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0516425259411335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587351640065512,
      "backward_entropy": 0.006725849956274033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8468122482299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051668692380189896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587258259455362,
      "backward_entropy": 0.006721378117799759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8741137981414795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05169488117098808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587158918380737,
      "backward_entropy": 0.0067167535424232485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8494045734405518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05172025039792061,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13587073485056558,
      "backward_entropy": 0.03886399269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.735783100128174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051744844764471054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586997985839844,
      "backward_entropy": 0.038880538940429685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.395004272460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05176955834031105,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13586913545926413,
      "backward_entropy": 0.13835128545761108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.430108070373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05179698020219803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586783409118652,
      "backward_entropy": 0.0066973350942134855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.74692964553833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051825955510139465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586624463399252,
      "backward_entropy": 0.006691466271877289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.292830467224121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05185384303331375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586480418841043,
      "backward_entropy": 0.0066865809261798855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.691490888595581,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051883306354284286,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586307565371195,
      "backward_entropy": 0.03894134759902954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324021816253662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051911577582359314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586151599884033,
      "backward_entropy": 0.0066788449883461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.452755928039551,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0519404262304306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358598272005717,
      "backward_entropy": 0.006674505025148392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.818819046020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05196899548172951,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13585813840230307,
      "backward_entropy": 0.03898879885673523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7921582460403442,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051999758929014206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135856032371521,
      "backward_entropy": 0.006665973365306855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100795269012451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0520283579826355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13585427403450012,
      "backward_entropy": 0.006661804020404815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.284852027893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05205751582980156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358523964881897,
      "backward_entropy": 0.03903188407421112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4974663257598877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052086248993873596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13585050900777182,
      "backward_entropy": 0.006653206050395965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4712929725646973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05211383104324341,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584882020950317,
      "backward_entropy": 0.00664864182472229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.609161376953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05214037001132965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358473002910614,
      "backward_entropy": 0.006644376367330551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542810440063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05216844752430916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584545254707336,
      "backward_entropy": 0.006640318036079407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3920576572418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05219786986708641,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358433167139689,
      "backward_entropy": 0.006636030226945877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3653907775878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222611129283905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584138949712118,
      "backward_entropy": 0.006632851064205169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.007996082305908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05225323885679245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583962122599283,
      "backward_entropy": 0.006630007922649383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.280828475952148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05228019133210182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358378529548645,
      "backward_entropy": 0.006627657264471054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6459532976150513,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052308522164821625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358358065287272,
      "backward_entropy": 0.039172643423080446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.634090781211853,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05233483389019966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583407799402872,
      "backward_entropy": 0.006620673090219497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6222585439682007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05235946178436279,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583266735076904,
      "backward_entropy": 0.03920828700065613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.435389518737793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0523824468255043,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583154479662576,
      "backward_entropy": 0.039226993918418884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.794387340545654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05240637809038162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13583020369211832,
      "backward_entropy": 0.006611893326044083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.346657752990723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0524304062128067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582881291707358,
      "backward_entropy": 0.006609074771404266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.300891399383545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052455250173807144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582724332809448,
      "backward_entropy": 0.006605677306652069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003572260495275259,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05248085781931877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13582544525464377,
      "backward_entropy": 0.03929455280303955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037637969944626093,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250394344329834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582415382067362,
      "backward_entropy": 0.006598801165819168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5459346771240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05252483859658241,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582328955332437,
      "backward_entropy": 0.006596504151821137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5369799137115479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052544500678777695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358226736386617,
      "backward_entropy": 0.03935364484786987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.103547096252441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256306007504463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582223653793335,
      "backward_entropy": 0.0065927855670452114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.583393096923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05258294194936752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13582152128219604,
      "backward_entropy": 0.006590621173381805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.02767276763916,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052604783326387405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13582034905751547,
      "backward_entropy": 0.1383723020553589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977360725402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052627645432949066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581892848014832,
      "backward_entropy": 0.03943545818328857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.423973083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052652955055236816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13581699132919312,
      "backward_entropy": 0.006582413613796234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.251487731933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0526796393096447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358146866162618,
      "backward_entropy": 0.03946543335914612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.919083833694458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05271071940660477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581143816312155,
      "backward_entropy": 0.0394787073135376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.781346797943115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052740320563316345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13580846786499023,
      "backward_entropy": 0.006572926044464111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7276153564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05277010425925255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580541809399924,
      "backward_entropy": 0.03950968384742737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.673825740814209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052800025790929794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580225904782614,
      "backward_entropy": 0.039524078369140625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.236727714538574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05283007398247719,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357990304629008,
      "backward_entropy": 0.006564246118068695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.560611248016357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05286325886845589,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357950766881307,
      "backward_entropy": 0.039551916718482974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.501803874969482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05289623141288757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357910931110382,
      "backward_entropy": 0.03956618905067444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.443655490875244,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052928972989320755,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1357871095339457,
      "backward_entropy": 0.13837883472442628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.694469451904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05296149477362633,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578309615453085,
      "backward_entropy": 0.03959242403507233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.331676483154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05299225449562073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577941060066223,
      "backward_entropy": 0.03960093557834625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2774882316589355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053022950887680054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357757051785787,
      "backward_entropy": 0.03960784375667572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.223621368408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05305355414748192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13577192028363547,
      "backward_entropy": 0.006538756936788559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8782589435577393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05308406427502632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357681155204773,
      "backward_entropy": 0.006533274054527282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.67563009262085,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05311373993754387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576442003250122,
      "backward_entropy": 0.00652756467461586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003159186104312539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314487963914871,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576032718022665,
      "backward_entropy": 0.006521876156330109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.015183925628662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05317297950387001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575694958368936,
      "backward_entropy": 0.03962104618549347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.966029644012451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320129916071892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357534925142924,
      "backward_entropy": 0.006513186544179916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6886045932769775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05322974547743797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13574995597203574,
      "backward_entropy": 0.006509755551815033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2196800708770752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05325758084654808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574651877085367,
      "backward_entropy": 0.03965714275836944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.619483232498169,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05328342318534851,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574355840682983,
      "backward_entropy": 0.03967311382293701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1977447271347046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05330883711576462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13574067751566568,
      "backward_entropy": 0.039686340093612674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.557180643081665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053332481533288956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573821385701498,
      "backward_entropy": 0.039700770378112794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.876679420471191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05335598811507225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357357700665792,
      "backward_entropy": 0.00649552270770073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.660408973693848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053380727767944336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573294878005981,
      "backward_entropy": 0.0397361695766449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6177802085876465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05340593308210373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357299784819285,
      "backward_entropy": 0.006491938233375549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2889437675476074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053431473672389984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357268492380778,
      "backward_entropy": 0.039779430627822875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.799420356750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345591530203819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13572396834691366,
      "backward_entropy": 0.03980076313018799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2466964721679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053482066839933395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572055101394653,
      "backward_entropy": 0.006486235558986664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.448557376861572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053507085889577866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571741183598837,
      "backward_entropy": 0.00648421049118042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.204662799835205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05353241413831711,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13571413358052573,
      "backward_entropy": 0.006482011824846268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.366186618804932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053556639701128006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571115334828696,
      "backward_entropy": 0.03986857533454895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405869483947754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05358119308948517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570815324783325,
      "backward_entropy": 0.03988237679004669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1427018642425537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05360671877861023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570485512415567,
      "backward_entropy": 0.0398924708366394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.241946697235107,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05363108217716217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357019046942393,
      "backward_entropy": 0.006469199806451798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.101824998855591,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0536557175219059,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569881518681845,
      "backward_entropy": 0.039907369017601016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1220664978027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053679268807172775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356960336367289,
      "backward_entropy": 0.03991268873214722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.062971830368042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05370254069566727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569331169128418,
      "backward_entropy": 0.039919301867485046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002834545448422432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05372488126158714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356908082962036,
      "backward_entropy": 0.006451170146465302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.040663242340088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053745076060295105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356889804204305,
      "backward_entropy": 0.039940348267555235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0114173889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05376535281538963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568710287412009,
      "backward_entropy": 0.03995725810527802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002690315479412675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053785018622875214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135685404141744,
      "backward_entropy": 0.039977270364761355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9591991901397705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053802791982889175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568426171938577,
      "backward_entropy": 0.039999717473983766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002604427980259061,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053821489214897156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568278153737387,
      "backward_entropy": 0.0400217592716217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9016833305358887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05383838713169098,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568185766537985,
      "backward_entropy": 0.040045836567878725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9376204013824463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05385624244809151,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568061590194702,
      "backward_entropy": 0.04006719291210174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.923625111579895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05387363210320473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567944367726645,
      "backward_entropy": 0.040085673332214355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9100286960601807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05389061197638512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356783906618754,
      "backward_entropy": 0.040102329850196836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8437914848327637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053907252848148346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567741711934408,
      "backward_entropy": 0.00643240362405777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704005241394043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392422899603844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567630449930826,
      "backward_entropy": 0.006430418789386749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9350461363792419,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05394277721643448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567463556925455,
      "backward_entropy": 0.040154671669006346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7801830768585205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053960103541612625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13567334413528442,
      "backward_entropy": 0.006425054371356964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.678075075149536,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05397767201066017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567193349202475,
      "backward_entropy": 0.04018000364303589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.825526237487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053996093571186066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567018508911133,
      "backward_entropy": 0.04019352197647095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6201226711273193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05401403829455376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566861550013223,
      "backward_entropy": 0.006417175382375717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6933295726776123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05403276905417442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566672801971436,
      "backward_entropy": 0.006414978951215744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6710238456726074,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05405156686902046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13566476106643677,
      "backward_entropy": 0.13839976787567138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6485989093780518,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054070428013801575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566274444262186,
      "backward_entropy": 0.006410044431686401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.375744819641113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05408930778503418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566067814826965,
      "backward_entropy": 0.040266367793083194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8687793612480164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054109442979097366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13565812508265176,
      "backward_entropy": 0.006403400003910065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5803167819976807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05412820354104042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13565601905186972,
      "backward_entropy": 0.040281403064727786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8541144728660583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054146986454725266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13565383354822794,
      "backward_entropy": 0.006395392119884491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6924960613250732,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054164569824934006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13565202554066977,
      "backward_entropy": 0.04029548764228821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5177536010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054181698709726334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13565033674240112,
      "backward_entropy": 0.040306076407432556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6656211614608765,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054199036210775375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356485684712728,
      "backward_entropy": 0.0063860006630420685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.303333282470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054215896874666214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135646919409434,
      "backward_entropy": 0.040330222249031066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8203549385070801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054233551025390625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356449325879415,
      "backward_entropy": 0.04034022092819214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.438410997390747,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054250068962574005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13564329346021017,
      "backward_entropy": 0.0063767209649086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.419325113296509,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054266780614852905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13564157485961914,
      "backward_entropy": 0.006373108178377151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6004613637924194,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05428372323513031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356397271156311,
      "backward_entropy": 0.04036678373813629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3808701038360596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054300229996442795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13563799858093262,
      "backward_entropy": 0.04037797152996063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.935148000717163,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543169341981411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13563618063926697,
      "backward_entropy": 0.006364618986845016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5614129304885864,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054335009306669235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13563382625579834,
      "backward_entropy": 0.006361613422632218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3214173316955566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543525256216526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13563165068626404,
      "backward_entropy": 0.006358779966831207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3014988899230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054370149970054626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13562939564387003,
      "backward_entropy": 0.006356458365917206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.041346788406372,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05438786745071411,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13562708099683127,
      "backward_entropy": 0.040435421466827395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7547537088394165,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054406218230724335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135624498128891,
      "backward_entropy": 0.006352605670690537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.734891653060913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05442337319254875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13562230269114176,
      "backward_entropy": 0.04046264886856079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4813573360443115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05444176867604256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13561962048212686,
      "backward_entropy": 0.04047332406044006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9344635009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05445956438779831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135617067416509,
      "backward_entropy": 0.006346058845520019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4545656442642212,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05447795242071152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13561431566874185,
      "backward_entropy": 0.04049752950668335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.161309003829956,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05449574068188667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356117526690165,
      "backward_entropy": 0.006341936439275742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.141741991043091,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054513558745384216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13560913999875387,
      "backward_entropy": 0.00634051114320755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.415311574935913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05453140661120415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13560650746027628,
      "backward_entropy": 0.040545514225959776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1032772064208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05454867705702782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13560402393341064,
      "backward_entropy": 0.006338679790496826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4730067253112793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054565977305173874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13560152053833008,
      "backward_entropy": 0.04058120548725128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3768373727798462,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05458441749215126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13559848070144653,
      "backward_entropy": 0.04059382677078247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.088805198669434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054602205753326416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13559565941492716,
      "backward_entropy": 0.006333783268928528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6759217977523804,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05462166294455528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13559220234553018,
      "backward_entropy": 0.006331884860992431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0046517848968506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054639849811792374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558918237686157,
      "backward_entropy": 0.040638139843940733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.985406517982483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054657939821481705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558617234230042,
      "backward_entropy": 0.04065483808517456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3112773895263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05467597395181656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558314243952432,
      "backward_entropy": 0.04067312180995941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6503050923347473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469335988163948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13558033108711243,
      "backward_entropy": 0.006328384578227997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.573603868484497,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05470963194966316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13557795683542886,
      "backward_entropy": 0.0063278920948505405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2757331132888794,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05472652241587639,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13557525475819907,
      "backward_entropy": 0.006326952576637268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.89557945728302,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05474288389086723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13557273149490356,
      "backward_entropy": 0.006326211988925934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6271628141403198,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054759249091148376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13557018836339316,
      "backward_entropy": 0.04076142311096191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.103200674057007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05477457866072655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355680227279663,
      "backward_entropy": 0.04077686667442322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2307003736495972,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054791130125522614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13556532065073648,
      "backward_entropy": 0.006321446597576141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0467212200164795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480719357728958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13556277751922607,
      "backward_entropy": 0.0063204824924469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001400657114572823,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05482441559433937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355597178141276,
      "backward_entropy": 0.006319526582956314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1969496011734009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05483994632959366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13555733362833658,
      "backward_entropy": 0.040842413902282715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5940260291099548,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05485500395298004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13555510838826498,
      "backward_entropy": 0.006316667050123214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.76486074924469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05486913025379181,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13555325071016947,
      "backward_entropy": 0.04087046980857849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.584332287311554,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05488349497318268,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13555127382278442,
      "backward_entropy": 0.040885090827941895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8932058811187744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05489702895283699,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554959495862326,
      "backward_entropy": 0.040902674198150635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8680644035339355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05491188168525696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1355473299821218,
      "backward_entropy": 0.040917468070983884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.569232165813446,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.054927896708250046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13554449876149496,
      "backward_entropy": 0.13842668533325195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8157238960266113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054942864924669266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135542094707489,
      "backward_entropy": 0.006306569278240204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7885589599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05495898053050041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13553913434346518,
      "backward_entropy": 0.006303955614566803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5529417991638184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05497610941529274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13553574681282043,
      "backward_entropy": 0.0063009396195411686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2793257236480713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05499204993247986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13553277651468912,
      "backward_entropy": 0.040958178043365476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6227586269378662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055009521543979645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13552910089492798,
      "backward_entropy": 0.006293633580207824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0707570314407349,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0550268329679966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13552545507748923,
      "backward_entropy": 0.04096309244632721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5888534784317017,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05504351109266281,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13552210728327432,
      "backward_entropy": 0.04096929132938385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5724514722824097,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05506007745862007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13551870981852213,
      "backward_entropy": 0.00628393366932869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0745015144348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055076539516448975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13551531235376993,
      "backward_entropy": 0.040979743003845215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.05238676071167,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055093392729759216,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1355117162068685,
      "backward_entropy": 0.13842439651489258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5227206945419312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05511059612035751,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13550790150960287,
      "backward_entropy": 0.13842384815216063,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.328649176933104,
    "avg_log_Z": -0.05425409596413374,
    "success_rate": 1.0,
    "avg_reward": 43.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.54,
      "2": 0.42
    },
    "avg_forward_entropy": 0.1356326962510745,
    "avg_backward_entropy": 0.029974921219050887,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}