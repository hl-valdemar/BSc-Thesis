{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09886412961142403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09891528742653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.2205047607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721096515655518,
      "backward_entropy": 0.09893980196544103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.19444274902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721603155136108,
      "backward_entropy": 0.09891930648258754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.5868682861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020000009681098163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722091913223267,
      "backward_entropy": 0.09886842114584786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.63482666015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00029992684721946716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722559809684753,
      "backward_entropy": 0.09894343784877233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.19326782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039817095967009664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372300684452057,
      "backward_entropy": 0.09887114592960902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.0115203857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004956907941959798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723435997962952,
      "backward_entropy": 0.09887203148433141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.06475830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005946332239545882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372385025024414,
      "backward_entropy": 0.0989457198551723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.03878784179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006939326412975788,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724246621131897,
      "backward_entropy": 0.0989393847329276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.5176544189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007934914901852608,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724622130393982,
      "backward_entropy": 0.09894728660583496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.98683166503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.000891593168489635,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724979758262634,
      "backward_entropy": 0.09894516638347081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.45103454589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009902406018227339,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725319504737854,
      "backward_entropy": 0.09887536082948957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.25694274902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010903674410656095,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725639879703522,
      "backward_entropy": 0.09895062446594238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001191518153063953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725942373275757,
      "backward_entropy": 0.09887621232441493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.1332244873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012942987959831953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726232945919037,
      "backward_entropy": 0.0989560570035662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.39947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013960795477032661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726502656936646,
      "backward_entropy": 0.09895109278815133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.55706787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00149955740198493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372675895690918,
      "backward_entropy": 0.09887771947043282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.2781219482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016031538834795356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372699737548828,
      "backward_entropy": 0.09896363530840192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.4994659423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017071118345484138,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372721940279007,
      "backward_entropy": 0.09896603652409144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.22059631347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001813512179069221,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13727429509162903,
      "backward_entropy": 0.0989685228892735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.658935546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019195863278582692,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13727623224258423,
      "backward_entropy": 0.09897089856011528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.04318237304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002026459202170372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372780054807663,
      "backward_entropy": 0.09887925216129848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.05775451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021339026279747486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13727962970733643,
      "backward_entropy": 0.09887938840048653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.72959899902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022428040392696857,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372811198234558,
      "backward_entropy": 0.09897773606436593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.3622283935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002353489166125655,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728243112564087,
      "backward_entropy": 0.09897996698107038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.27731323242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002463877433910966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372835487127304,
      "backward_entropy": 0.09895867960793632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.33364868164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0025765872560441494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728450238704681,
      "backward_entropy": 0.0989595821925572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.40061950683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026896244380623102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372852623462677,
      "backward_entropy": 0.09887969493865967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.50894165039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002800678601488471,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728579878807068,
      "backward_entropy": 0.09898802212306432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.22018432617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0029120291583240032,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728615641593933,
      "backward_entropy": 0.0989897336278643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.0501251220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0030260845087468624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728633522987366,
      "backward_entropy": 0.09896247727530343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.88905334472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003140955464914441,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728633522987366,
      "backward_entropy": 0.09896315847124372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.42257690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032580681145191193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728618621826172,
      "backward_entropy": 0.09887827294213432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033724219538271427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728585839271545,
      "backward_entropy": 0.09887786422457014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.74131774902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0034851550590246916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728532195091248,
      "backward_entropy": 0.09887705530439105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.70005798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035995577927678823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728460669517517,
      "backward_entropy": 0.09887628895895821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.34927368164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003715338883921504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728369772434235,
      "backward_entropy": 0.09896525314876012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.5998077392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038211497012525797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372826099395752,
      "backward_entropy": 0.09887385368347168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.74461364746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0039270962588489056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728134334087372,
      "backward_entropy": 0.09887191227504186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.87188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040345280431210995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13727989792823792,
      "backward_entropy": 0.09900263377598353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.07818603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00414092093706131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372782588005066,
      "backward_entropy": 0.09886777400970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.98158264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004246094264090061,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13727641105651855,
      "backward_entropy": 0.09896337985992432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.72101593017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004350669216364622,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372745931148529,
      "backward_entropy": 0.09900444746017456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.56048583984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004450586624443531,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372726857662201,
      "backward_entropy": 0.09900482211794172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.112548828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004552763421088457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13727064430713654,
      "backward_entropy": 0.09896058695656913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.67413330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0046569835394620895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726845383644104,
      "backward_entropy": 0.09885283027376447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.82872009277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004761794116348028,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372660994529724,
      "backward_entropy": 0.09900592054639544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.63775634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004865963943302631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726359605789185,
      "backward_entropy": 0.0988459587097168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.98458862304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00497277220711112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726089894771576,
      "backward_entropy": 0.09895603997366768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.94998168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005079710856080055,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725802302360535,
      "backward_entropy": 0.0990067550114223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.9224853515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005189963616430759,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372549831867218,
      "backward_entropy": 0.09900702748979841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.69427490234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005296169780194759,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725197315216064,
      "backward_entropy": 0.0989518676485334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.45819091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0054000080563127995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724879920482635,
      "backward_entropy": 0.09882630620683942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.25106811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005500555504113436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372455358505249,
      "backward_entropy": 0.09882143565586635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.1558074951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0056003788486123085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724204897880554,
      "backward_entropy": 0.09894577094486781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.20062255859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0057023209519684315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723838329315186,
      "backward_entropy": 0.09894354002816337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.6336212158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005800915416330099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723456859588623,
      "backward_entropy": 0.09894107069287982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.13300323486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00590316578745842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372305452823639,
      "backward_entropy": 0.09879962035587855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.31993103027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00600099703297019,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722644746303558,
      "backward_entropy": 0.09900705303464617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.49568939208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006098028272390366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722211122512817,
      "backward_entropy": 0.0989331603050232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.9773406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006191040854901075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372177004814148,
      "backward_entropy": 0.09878029142107282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.17120361328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006285577546805143,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372130662202835,
      "backward_entropy": 0.09900630371911186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.08712768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006380217615514994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372082382440567,
      "backward_entropy": 0.09892348732267107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.28102111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0064764185808598995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137203186750412,
      "backward_entropy": 0.0989201579775129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.0724639892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006573694292455912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719791173934937,
      "backward_entropy": 0.09875115326472692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.7003631591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006670775823295116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719242811203003,
      "backward_entropy": 0.09874346426555089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.14424896240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006765282712876797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718685507774353,
      "backward_entropy": 0.09873551981789726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.95626831054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006855755113065243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718119263648987,
      "backward_entropy": 0.09872698783874512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.07464599609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0069412835873663425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13717548549175262,
      "backward_entropy": 0.09900193555014473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.72735595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007024736609309912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716959953308105,
      "backward_entropy": 0.09870814425604683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.35726928710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00710932957008481,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137163445353508,
      "backward_entropy": 0.09900002820151192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2531280517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007193476893007755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13715709745883942,
      "backward_entropy": 0.09868772540773664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.22003173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007278838194906712,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715049624443054,
      "backward_entropy": 0.09887872423444476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.38138580322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007365297060459852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714365661144257,
      "backward_entropy": 0.09866639545985631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.48011779785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007448425982147455,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713672757148743,
      "backward_entropy": 0.09899575369698661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.76776123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00753438426181674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712948560714722,
      "backward_entropy": 0.09886114937918526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.1317901611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007624279707670212,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712191581726074,
      "backward_entropy": 0.0989937356540135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.23440551757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00771379517391324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711418211460114,
      "backward_entropy": 0.09862057651792254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.7528076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0078042298555374146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710622489452362,
      "backward_entropy": 0.09884355749402728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.41094207763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007892729714512825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13709813356399536,
      "backward_entropy": 0.09883735861097064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.96470642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007977941073477268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708999752998352,
      "backward_entropy": 0.0988306999206543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.09503173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008070317097008228,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708138465881348,
      "backward_entropy": 0.09898921421595983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.19346618652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008163300342857838,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707253336906433,
      "backward_entropy": 0.09898856707981654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.11746978759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008260728791356087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706323504447937,
      "backward_entropy": 0.09855251652853829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.5827178955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00835369061678648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705384731292725,
      "backward_entropy": 0.09880670479365758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.24871063232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008450036868453026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704408705234528,
      "backward_entropy": 0.09880061660494123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.7326202392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008542254567146301,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703428208827972,
      "backward_entropy": 0.09879389830998012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.81832122802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008631951175630093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702431321144104,
      "backward_entropy": 0.09850496905190605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.02694702148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008717699907720089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137014240026474,
      "backward_entropy": 0.09877874170030866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.54508209228516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008805005811154842,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700386881828308,
      "backward_entropy": 0.09898347514016288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.23594665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008888975717127323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369933933019638,
      "backward_entropy": 0.09846217291695732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.4127197265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008976204320788383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698256015777588,
      "backward_entropy": 0.09898140600749425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.9217987060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009065995924174786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697132468223572,
      "backward_entropy": 0.09874574627195086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9761505126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00916092935949564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695964217185974,
      "backward_entropy": 0.09873807430267334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.55694580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009254833683371544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694778084754944,
      "backward_entropy": 0.09840747288295201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.43597412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009351996704936028,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693542778491974,
      "backward_entropy": 0.09897918360573905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.08141326904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009450837969779968,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369227170944214,
      "backward_entropy": 0.09897890261241368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.72401428222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009543578140437603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369100660085678,
      "backward_entropy": 0.09836662667138237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.1799774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009642791002988815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368967741727829,
      "backward_entropy": 0.09835372652326312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.80829620361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009744392707943916,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368829756975174,
      "backward_entropy": 0.09897792339324951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.02687072753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009839346632361412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13686923682689667,
      "backward_entropy": 0.09897733586175102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.38604736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009935935959219933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685506582260132,
      "backward_entropy": 0.09831057276044573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.06112670898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010033870115876198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684046268463135,
      "backward_entropy": 0.09829512664249965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.490234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010124647058546543,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13682612776756287,
      "backward_entropy": 0.09897547960281372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.48793029785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010217621922492981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681131601333618,
      "backward_entropy": 0.09864086764199394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.59469604492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010313778184354305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679590821266174,
      "backward_entropy": 0.09863054752349854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.12506103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010411765426397324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678008317947388,
      "backward_entropy": 0.09822821617126465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.227783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01050969585776329,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676384091377258,
      "backward_entropy": 0.09821152687072754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.03839111328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0106046786531806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674737513065338,
      "backward_entropy": 0.09819356032780238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.85641479492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010699930600821972,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673046231269836,
      "backward_entropy": 0.0989717926297869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.574951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010799432173371315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367127150297165,
      "backward_entropy": 0.0985760007585798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.7760314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01090182363986969,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669440150260925,
      "backward_entropy": 0.09814054625374931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.2782745361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011011533439159393,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366749256849289,
      "backward_entropy": 0.09897141797201973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.6075439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01112385280430317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665460050106049,
      "backward_entropy": 0.09811070135661534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.7510986328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0112324682995677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663391768932343,
      "backward_entropy": 0.09853583574295044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.5108642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01134389080107212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366124451160431,
      "backward_entropy": 0.09807722909109932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.8573760986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011450998485088348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13659092783927917,
      "backward_entropy": 0.09851397786821638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.0133819580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01155593991279602,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656921684741974,
      "backward_entropy": 0.09850182703563146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.43824005126953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011658595874905586,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654722273349762,
      "backward_entropy": 0.09897077083587646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.14453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011753310449421406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652567565441132,
      "backward_entropy": 0.09799855947494507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.72920989990234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011845160275697708,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13650378584861755,
      "backward_entropy": 0.0989680290222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.80276489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01193325873464346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648183643817902,
      "backward_entropy": 0.09794881514140538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.24969482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012022088281810284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645857572555542,
      "backward_entropy": 0.09842336177825928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.65523529052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01211595255881548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13643397390842438,
      "backward_entropy": 0.09789844921657018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.53323364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012204546481370926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640949130058289,
      "backward_entropy": 0.09838989802769252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.88877868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012291019782423973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638460636138916,
      "backward_entropy": 0.09784603118896484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.6316223144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012375473976135254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635918498039246,
      "backward_entropy": 0.09781785522188459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.0348663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012469355948269367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13633184134960175,
      "backward_entropy": 0.09833641563143049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.02964782714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012565260753035545,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13630366325378418,
      "backward_entropy": 0.09895132269178118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.77496337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012661164626479149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362747848033905,
      "backward_entropy": 0.09774373258863177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.25555419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012761288322508335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362452208995819,
      "backward_entropy": 0.09828970261982509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.0503387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012858088128268719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621589541435242,
      "backward_entropy": 0.09827351570129395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.40130615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012954439036548138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361858993768692,
      "backward_entropy": 0.09825679234095983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.57498168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013050851412117481,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13615527749061584,
      "backward_entropy": 0.09894534519740514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.28395080566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0131502291187644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13612359762191772,
      "backward_entropy": 0.09894451073237828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.43019104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013249344192445278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609132170677185,
      "backward_entropy": 0.09759133202689034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.95733642578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013348453678190708,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13605843484401703,
      "backward_entropy": 0.0989427992275783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3075714111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013447100296616554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13602478802204132,
      "backward_entropy": 0.09753852231161934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.83470153808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013542450033128262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359909474849701,
      "backward_entropy": 0.0981531994683402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.60134887695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013637734577059746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13595640659332275,
      "backward_entropy": 0.09747739349092756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.02647399902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013729947619140148,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359216272830963,
      "backward_entropy": 0.09893694094249181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.38714599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013820809312164783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13588662445545197,
      "backward_entropy": 0.09740722179412842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.58877563476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013910936191678047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585126399993896,
      "backward_entropy": 0.0980650782585144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.40682983398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014001565985381603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358150839805603,
      "backward_entropy": 0.09804150036403111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.12911987304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014094485901296139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13577783107757568,
      "backward_entropy": 0.09801891020366124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.78233337402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014189223758876324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573861122131348,
      "backward_entropy": 0.09726318291255406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.26100158691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014277972280979156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356995701789856,
      "backward_entropy": 0.0972237501825605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.3579559326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014364923350512981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13566015660762787,
      "backward_entropy": 0.09718329565865653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01445570308715105,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13561901450157166,
      "backward_entropy": 0.09891607080187116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.95474243164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014547163620591164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557688891887665,
      "backward_entropy": 0.09710453237806048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.64292907714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014640266075730324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13553336262702942,
      "backward_entropy": 0.09787138870784215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9846954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014732185751199722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13548922538757324,
      "backward_entropy": 0.09702350412096296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.74705505371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014821996912360191,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13544483482837677,
      "backward_entropy": 0.09890804971967425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.07000732421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014912726357579231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353994458913803,
      "backward_entropy": 0.09693903582436698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.1808624267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015004165470600128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13535302877426147,
      "backward_entropy": 0.09689640998840332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.14471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015097391791641712,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13530516624450684,
      "backward_entropy": 0.09773816381181989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.6739959716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015188267454504967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13525710999965668,
      "backward_entropy": 0.0989007864679609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.41580200195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015281694941222668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13520771265029907,
      "backward_entropy": 0.09676609720502581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.23504638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01537263486534357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13515806198120117,
      "backward_entropy": 0.09672183649880546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.24293518066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015466798096895218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13510645925998688,
      "backward_entropy": 0.09762332269123622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4779052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015561442822217941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13505388796329498,
      "backward_entropy": 0.09663304260798863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.12765502929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015657316893339157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13499975204467773,
      "backward_entropy": 0.0975640160696847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.53392028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01575198769569397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13494451344013214,
      "backward_entropy": 0.09653949737548828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.32415771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01584237813949585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13488934934139252,
      "backward_entropy": 0.09648761578968593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.80130004882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015933535993099213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13483290374279022,
      "backward_entropy": 0.09888704333986555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.5541229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016024913638830185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347751021385193,
      "backward_entropy": 0.09638076169150216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.6375732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016116848215460777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13471612334251404,
      "backward_entropy": 0.09739455154963902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.91566467285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01620892994105816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13465571403503418,
      "backward_entropy": 0.09626773425510951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.28631591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01630045659840107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13459467887878418,
      "backward_entropy": 0.09620967081614903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.22320556640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01639462634921074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13453207910060883,
      "backward_entropy": 0.0961553794997079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016489073634147644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344682276248932,
      "backward_entropy": 0.09609981094087873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.33355712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01658412627875805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13440322875976562,
      "backward_entropy": 0.09604458298001971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.68614196777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016680754721164703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343364715576172,
      "backward_entropy": 0.09717585359300886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.7677764892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0167726781219244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342700570821762,
      "backward_entropy": 0.09713563748768397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.32463836669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016863351687788963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342027485370636,
      "backward_entropy": 0.0970935480935233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.34796142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016949674114584923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13413557410240173,
      "backward_entropy": 0.09704736300877162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.99111938476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017028039321303368,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.134070485830307,
      "backward_entropy": 0.09885285581861224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.77328491210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017107034102082253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13400408625602722,
      "backward_entropy": 0.09694312300000872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.83535766601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01718932017683983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13393530249595642,
      "backward_entropy": 0.0968925952911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.84303283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017271846532821655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13386546075344086,
      "backward_entropy": 0.09684175252914429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.09247589111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017351219430565834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13379567861557007,
      "backward_entropy": 0.09678772517613002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.80599975585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017425792291760445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13372641801834106,
      "backward_entropy": 0.0952751636505127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.22653198242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017502853646874428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13365507125854492,
      "backward_entropy": 0.09667196444102696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.58155822753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017578663304448128,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1335829794406891,
      "backward_entropy": 0.09880805015563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.1177215576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017655054107308388,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13350945711135864,
      "backward_entropy": 0.09880045482090541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.2367401123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017732098698616028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13343454897403717,
      "backward_entropy": 0.09489081587110247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.33001708984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017808163538575172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333589255809784,
      "backward_entropy": 0.09642619746071952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.0517120361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017884813249111176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1332818567752838,
      "backward_entropy": 0.09877795832497734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.16169738769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01796535588800907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13320210576057434,
      "backward_entropy": 0.09630290099552699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.82711791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018040284514427185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13312408328056335,
      "backward_entropy": 0.09623774460383824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.57394409179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018115686252713203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13304440677165985,
      "backward_entropy": 0.0987572159085955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.76519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018189210444688797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13296480476856232,
      "backward_entropy": 0.09610247611999512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.44231414794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018263988196849823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328837275505066,
      "backward_entropy": 0.09603401592799596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.37913513183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01833510585129261,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1328032910823822,
      "backward_entropy": 0.09873306751251221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.4229736328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018402932211756706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1327233612537384,
      "backward_entropy": 0.09872322423117501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.22113037109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018469292670488358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326429694890976,
      "backward_entropy": 0.09380136217389788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.8134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01854155771434307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13255815207958221,
      "backward_entropy": 0.09368133544921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.330810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01861056126654148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324741095304489,
      "backward_entropy": 0.09355647223336357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.2324676513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018682803958654404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13238736987113953,
      "backward_entropy": 0.09557713781084333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.19708251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018757959827780724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13229811191558838,
      "backward_entropy": 0.09550327914101737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.03164672851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018837183713912964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13220548629760742,
      "backward_entropy": 0.09867552348545619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.03848266601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018915319815278053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13211223483085632,
      "backward_entropy": 0.09536073037556239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.5589141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018995415419340134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13201650977134705,
      "backward_entropy": 0.0952879786491394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.2190704345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019077399745583534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13191846013069153,
      "backward_entropy": 0.09284083332334246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.29754638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019162284210324287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13181734085083008,
      "backward_entropy": 0.09514376095363072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.94293212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019245656207203865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13171587884426117,
      "backward_entropy": 0.09259309087480817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.74148559570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019327426329255104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316138654947281,
      "backward_entropy": 0.09499016829899379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01940366066992283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13151440024375916,
      "backward_entropy": 0.09232725415910993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.5045928955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019477786496281624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13141515851020813,
      "backward_entropy": 0.09218783038003105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.25303649902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019556041806936264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13131219148635864,
      "backward_entropy": 0.09472523416791644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.98970794677734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019639797508716583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13120494782924652,
      "backward_entropy": 0.09862342051097325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.12779235839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0197158120572567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1311013400554657,
      "backward_entropy": 0.09861648082733154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.43814086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019784072414040565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13100072741508484,
      "backward_entropy": 0.09162441321781703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.2589569091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01985548995435238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13089677691459656,
      "backward_entropy": 0.09434310027531215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.64907836914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019931210204958916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13078878819942474,
      "backward_entropy": 0.091317960194179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.331356048583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020007742568850517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1306789517402649,
      "backward_entropy": 0.09415020261492048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.16156005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020076243206858635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1305740773677826,
      "backward_entropy": 0.09404172216142927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.75160217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020146053284406662,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13046669960021973,
      "backward_entropy": 0.09393276487077985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.70225524902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020211292430758476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13036151230335236,
      "backward_entropy": 0.09066792896815709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.60614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02027682401239872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13025511801242828,
      "backward_entropy": 0.09369988100869316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.5891571044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0203426294028759,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13014762103557587,
      "backward_entropy": 0.09358101231711251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.6126251220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020414015278220177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1300356388092041,
      "backward_entropy": 0.09014734200068883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.79359436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020492812618613243,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1299172043800354,
      "backward_entropy": 0.09336796828678676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.90383911132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020571433007717133,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12979863584041595,
      "backward_entropy": 0.09850040503910609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.08883666992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020645150914788246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1296829879283905,
      "backward_entropy": 0.093153749193464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.12574768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020715463906526566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12956862151622772,
      "backward_entropy": 0.08949594838278634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.30538940429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02078944817185402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12945088744163513,
      "backward_entropy": 0.09292292594909668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.40521240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020862026140093803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12933349609375,
      "backward_entropy": 0.08916468279702323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.96389770507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02092968113720417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12921851873397827,
      "backward_entropy": 0.09268246378217425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.55023193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02099556475877762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12910296022891998,
      "backward_entropy": 0.08879351615905762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.707275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021055273711681366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12899070978164673,
      "backward_entropy": 0.09240984916687012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.51773071289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021122882142663002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12887172400951385,
      "backward_entropy": 0.09228067738669259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.47308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02119584195315838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12874752283096313,
      "backward_entropy": 0.08821486575262887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4232940673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021274935454130173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12861695885658264,
      "backward_entropy": 0.08804442201341901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.33502197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021355371922254562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12848471105098724,
      "backward_entropy": 0.091934221131461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.50065612792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02143491618335247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12835180759429932,
      "backward_entropy": 0.08770455632890974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.76260375976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021508632227778435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1282220184803009,
      "backward_entropy": 0.09840573583330427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.2999725341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021580517292022705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12809239327907562,
      "backward_entropy": 0.09839751039232526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.87982177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021652648225426674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12796160578727722,
      "backward_entropy": 0.08710928474153791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.08078002929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02172786369919777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12782695889472961,
      "backward_entropy": 0.09128132888248988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.26593017578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02180437184870243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12768983840942383,
      "backward_entropy": 0.08671091284070696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.4413299560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02188093215227127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12755218148231506,
      "backward_entropy": 0.09101541553224836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.69000244140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02195916324853897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12741249799728394,
      "backward_entropy": 0.08632091113499232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.90771484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022038403898477554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1272706836462021,
      "backward_entropy": 0.09075360638754708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.02589416503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022110097110271454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12713374197483063,
      "backward_entropy": 0.08590662479400635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.9522705078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022184966132044792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1269926279783249,
      "backward_entropy": 0.08569436413901192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.03533172607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022261328995227814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1268494576215744,
      "backward_entropy": 0.08548295497894287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.24574279785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022335534915328026,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1267068237066269,
      "backward_entropy": 0.09834107330867223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.79067993164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02241280861198902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12656034529209137,
      "backward_entropy": 0.09002033301762172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.4512710571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022488227114081383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1264147013425827,
      "backward_entropy": 0.08481824398040771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.53656768798828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022561101242899895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12627165019512177,
      "backward_entropy": 0.0983215229851859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.61360931396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0226291436702013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12613186240196228,
      "backward_entropy": 0.08435213565826416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.3643798828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02269488386809826,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12599363923072815,
      "backward_entropy": 0.0982966423034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.1947479248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022756511345505714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258581280708313,
      "backward_entropy": 0.08384415081569127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.56182861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022823933511972427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12571559846401215,
      "backward_entropy": 0.08899382182529994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.81675720214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022894691675901413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12556804716587067,
      "backward_entropy": 0.08332839182444982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.4672393798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022965693846344948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12541913986206055,
      "backward_entropy": 0.08306568009512764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.35379028320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023038309067487717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12526729702949524,
      "backward_entropy": 0.0884617907660348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.02821350097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023108085617423058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1251177191734314,
      "backward_entropy": 0.08252558537891932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.774169921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023182986304163933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12496224045753479,
      "backward_entropy": 0.0880974360874721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.01634216308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023260874673724174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12480257451534271,
      "backward_entropy": 0.08792448043823242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.0749053955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023343296721577644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12463800609111786,
      "backward_entropy": 0.0877610615321568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.66204833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02342682145535946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12447209656238556,
      "backward_entropy": 0.08759864739009313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.407958984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023515518754720688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12429995834827423,
      "backward_entropy": 0.08126666716166905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.57518005371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02360443025827408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12412701547145844,
      "backward_entropy": 0.09821757248469762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.03855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023695018142461777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12395161390304565,
      "backward_entropy": 0.08712669781276158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.66226959228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023786867037415504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12377379834651947,
      "backward_entropy": 0.08053539480481829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.58778381347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023875882849097252,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12359899282455444,
      "backward_entropy": 0.0867912769317627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.6725845336914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023969493806362152,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12341852486133575,
      "backward_entropy": 0.09822931459971837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.96258544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02405960112810135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12324096262454987,
      "backward_entropy": 0.08643652711595808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.68548583984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024151144549250603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12306098639965057,
      "backward_entropy": 0.0982292720249721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.19600677490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02424556016921997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12287726998329163,
      "backward_entropy": 0.07922991684504918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.69659423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02433602884411812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12269651889801025,
      "backward_entropy": 0.07894309929439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.76950073242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024427777156233788,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12251333892345428,
      "backward_entropy": 0.08567385162625994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.53319549560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02451472356915474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12233498692512512,
      "backward_entropy": 0.08546154839651925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53104400634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024596210569143295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12216304242610931,
      "backward_entropy": 0.07803868395941597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.19770050048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024670759215950966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1219983771443367,
      "backward_entropy": 0.08498953921454293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.39629364013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02474033832550049,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1218380555510521,
      "backward_entropy": 0.08472962890352521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.84716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024808866903185844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12167809903621674,
      "backward_entropy": 0.07699484484536308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.43675994873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024875067174434662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1215202808380127,
      "backward_entropy": 0.07663139275142125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.14857482910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024940453469753265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12136225402355194,
      "backward_entropy": 0.08391926969800677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.02098083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025007130578160286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12120284140110016,
      "backward_entropy": 0.08364661250795637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.69105529785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025071073323488235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12104515731334686,
      "backward_entropy": 0.07551830155508858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.31016540527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025141095742583275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12088039517402649,
      "backward_entropy": 0.07515614373343331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.47122192382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025211723521351814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12071450054645538,
      "backward_entropy": 0.08282236542020525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.99495697021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025284288451075554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12054567039012909,
      "backward_entropy": 0.08255189657211304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.50064086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02535419538617134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12037990242242813,
      "backward_entropy": 0.07405256373541695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.81861877441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02541840821504593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202206239104271,
      "backward_entropy": 0.07366230658122472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.85486602783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02548271231353283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12006160616874695,
      "backward_entropy": 0.07327484233038765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.27874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02553750015795231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11991475522518158,
      "backward_entropy": 0.07286145857402257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.72384643554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025590691715478897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11976797878742218,
      "backward_entropy": 0.08102069582257952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.00296020507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02564498968422413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11961985379457474,
      "backward_entropy": 0.0978464228766305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.29283142089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02570309117436409,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11946601420640945,
      "backward_entropy": 0.09781718254089355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.82180786132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025764012709259987,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11930704861879349,
      "backward_entropy": 0.09779012203216553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.61634063720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025827603414654732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1191435307264328,
      "backward_entropy": 0.07971835136413574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.90171813964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025888795033097267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11898183077573776,
      "backward_entropy": 0.07028208460126605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.19342803955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025948088616132736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11882183700799942,
      "backward_entropy": 0.07904497214726039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.94943237304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026005934923887253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11866416037082672,
      "backward_entropy": 0.06936256800379072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.81159210205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026067320257425308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11850211024284363,
      "backward_entropy": 0.07834968396595546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.75201416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026130013167858124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11833785474300385,
      "backward_entropy": 0.06845841237476893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.15878295898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02619939111173153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11816686391830444,
      "backward_entropy": 0.06803743328366961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.65998077392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026272671297192574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11799155175685883,
      "backward_entropy": 0.06762446675981794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.45140075683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026343543082475662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781994998455048,
      "backward_entropy": 0.0672072981085096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.0887680053711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026418304070830345,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11764409393072128,
      "backward_entropy": 0.09757472787584577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.9014663696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026492049917578697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1174701452255249,
      "backward_entropy": 0.06639280489512853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.12609100341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026561230421066284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11730136722326279,
      "backward_entropy": 0.06596148014068604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.6367645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0266293715685606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1171332597732544,
      "backward_entropy": 0.06551868574959892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.46429443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0267048217356205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11695705354213715,
      "backward_entropy": 0.07541380609784808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.22315979003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026785453781485558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11677573621273041,
      "backward_entropy": 0.07510740416390556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.69100952148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026865433901548386,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11659480631351471,
      "backward_entropy": 0.09752569879804339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.70893859863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026945436373353004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11641483008861542,
      "backward_entropy": 0.0744690213884626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.5460968017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02702360227704048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11623722314834595,
      "backward_entropy": 0.06345222677503314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.1798553466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027107931673526764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11605288088321686,
      "backward_entropy": 0.07382217475346156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.90019989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027194837108254433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11586648225784302,
      "backward_entropy": 0.07351440191268921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.43997192382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027275852859020233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11568702757358551,
      "backward_entropy": 0.07318165472575597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.88962936401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027353931218385696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11551251262426376,
      "backward_entropy": 0.06179760183606829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.85147857666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027423027902841568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11535027623176575,
      "backward_entropy": 0.07246599878583636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0036163330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027491791173815727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11518913507461548,
      "backward_entropy": 0.06089890003204346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.94947814941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027564765885472298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1150234043598175,
      "backward_entropy": 0.07172574315752302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.18533325195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02764265611767769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11485179513692856,
      "backward_entropy": 0.07137154255594526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.14125061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027717262506484985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11468400806188583,
      "backward_entropy": 0.059577839715140204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.47388458251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027787646278738976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11452187597751617,
      "backward_entropy": 0.07061695201056344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.39083099365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02785738930106163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11436084657907486,
      "backward_entropy": 0.0702282360621861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.28348541259766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027928192168474197,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11419905722141266,
      "backward_entropy": 0.09740928241184779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.18667984008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027996594086289406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11404024064540863,
      "backward_entropy": 0.0694456696510315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.59464645385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028057793155312538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11388974636793137,
      "backward_entropy": 0.05721080303192139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.27720260620117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028112757951021194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11374679952859879,
      "backward_entropy": 0.06857454776763916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.24867248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02816389501094818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11360882967710495,
      "backward_entropy": 0.056156703404017856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.80177307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028217006474733353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11347019672393799,
      "backward_entropy": 0.055643950189862935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.60769653320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028269922360777855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11333250999450684,
      "backward_entropy": 0.06721760971205575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.5429916381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028320563957095146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11319711059331894,
      "backward_entropy": 0.05461266211100987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.54898071289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028369653970003128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.113064244389534,
      "backward_entropy": 0.054091147014072964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.07456970214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02842053398489952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11292986571788788,
      "backward_entropy": 0.06584092974662781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.43820190429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02848113887012005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11278568208217621,
      "backward_entropy": 0.053109237125941684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.03653717041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02854229137301445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11264145374298096,
      "backward_entropy": 0.06501153537205287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.42012023925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028604071587324142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11249734461307526,
      "backward_entropy": 0.0645971851689475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.34979248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028663519769906998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11235728114843369,
      "backward_entropy": 0.05170418109212603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.31800079345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028723454102873802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1122167557477951,
      "backward_entropy": 0.05123141833714077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.8362579345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028782213106751442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11207762360572815,
      "backward_entropy": 0.05074984686715262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.52189636230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02884676679968834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11193326115608215,
      "backward_entropy": 0.06290660585675921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.58085250854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028908435255289078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11179280281066895,
      "backward_entropy": 0.049835107156208584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.41136169433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02896588109433651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1116575300693512,
      "backward_entropy": 0.04935869574546814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.5563507080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02902861498296261,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11151622235774994,
      "backward_entropy": 0.06163714613233294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.61557388305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029094960540533066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11137181520462036,
      "backward_entropy": 0.04844096728733608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.96287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02915644459426403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11123321950435638,
      "backward_entropy": 0.04796945197241647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9941864013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029215900227427483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1110987588763237,
      "backward_entropy": 0.047500469854899814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.40209197998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029284141957759857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11095602810382843,
      "backward_entropy": 0.04706724200929914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.41416931152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029347853735089302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11081963777542114,
      "backward_entropy": 0.0466206499508449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.17868041992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02941514365375042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11068025976419449,
      "backward_entropy": 0.05918113674436297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.4144744873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029485663399100304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11053840816020966,
      "backward_entropy": 0.0457622834614345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.28770446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029564062133431435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11039042472839355,
      "backward_entropy": 0.04537122164453779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.66561889648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02963872440159321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11024871468544006,
      "backward_entropy": 0.04497542977333069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.68153381347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971246838569641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11010786145925522,
      "backward_entropy": 0.04456676755632673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.67671585083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029785852879285812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10996803641319275,
      "backward_entropy": 0.04416035754340036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.2139892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029854200780391693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10983516275882721,
      "backward_entropy": 0.04374094520296369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.76508331298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029927320778369904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10969853401184082,
      "backward_entropy": 0.05651754140853882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.46175003051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030001670122146606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10956188291311264,
      "backward_entropy": 0.05614125728607178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.68724822998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030070826411247253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10943157970905304,
      "backward_entropy": 0.042528893266405375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9305877685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030141418799757957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10930050164461136,
      "backward_entropy": 0.05534952027457101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.27249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03021795116364956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1091645359992981,
      "backward_entropy": 0.054974964686802456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.88485717773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03029084950685501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10903366655111313,
      "backward_entropy": 0.05458628705569676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.12403869628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030370913445949554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1088968962430954,
      "backward_entropy": 0.09682966130120414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.933292388916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03044324554502964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1087680459022522,
      "backward_entropy": 0.04050345080239432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.28424835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030509300529956818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10864686220884323,
      "backward_entropy": 0.053396373987197876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.6468963623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030577175319194794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10852471739053726,
      "backward_entropy": 0.039641107831682475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.55514144897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030649853870272636,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10839936137199402,
      "backward_entropy": 0.05258438842637198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.2572250366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030717451125383377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10827948153018951,
      "backward_entropy": 0.038806957857949395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.33285522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03078347258269787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10816134512424469,
      "backward_entropy": 0.051750366176877706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.0507583618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03084682673215866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1080469936132431,
      "backward_entropy": 0.03793915680476597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.93690490722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030908964574337006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10793403536081314,
      "backward_entropy": 0.03749666895185198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.70278930664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030975110828876495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10781867802143097,
      "backward_entropy": 0.05048513412475586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.12457275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03104383498430252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.107703298330307,
      "backward_entropy": 0.03666973114013672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.921119689941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03111446462571621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10758762806653976,
      "backward_entropy": 0.04970668043409075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.04560089111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03118080645799637,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10747745633125305,
      "backward_entropy": 0.049300900527409146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.886314392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0312447939068079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10737073421478271,
      "backward_entropy": 0.03546661351408277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.57089233398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03130337968468666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10726974159479141,
      "backward_entropy": 0.0484473534992763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.12643432617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03136147931218147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10716941952705383,
      "backward_entropy": 0.04800968510763986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.16883850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03142096847295761,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10706868022680283,
      "backward_entropy": 0.04758144276482718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.03006744384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03147674351930618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1069713830947876,
      "backward_entropy": 0.0337855155978884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.24454498291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03153238818049431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10687457025051117,
      "backward_entropy": 0.033358403614589145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7215576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03158995509147644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10677747428417206,
      "backward_entropy": 0.03294609699930463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.7914810180664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03165105730295181,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10667940974235535,
      "backward_entropy": 0.045864267008645196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.53030395507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03171514719724655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10658003389835358,
      "backward_entropy": 0.04547461015837533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.71815490722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03177742287516594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10648385435342789,
      "backward_entropy": 0.031815022230148315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.78277587890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03184603527188301,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10638466477394104,
      "backward_entropy": 0.0965134927204677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.30677032470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03191347420215607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10628704726696014,
      "backward_entropy": 0.031131395271846225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.68991088867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198155388236046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10618984699249268,
      "backward_entropy": 0.03078583095754896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.61482238769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032050538808107376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10609348118305206,
      "backward_entropy": 0.04362577199935913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.84608459472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03212025389075279,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10599783062934875,
      "backward_entropy": 0.0301153872694288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.81524658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032187506556510925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10590523481369019,
      "backward_entropy": 0.02977873384952545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.7242660522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03225246071815491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10581526160240173,
      "backward_entropy": 0.0425267049244472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.87326049804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032320164144039154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1057245209813118,
      "backward_entropy": 0.04216858744621277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.64117431640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032390046864748,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10563284158706665,
      "backward_entropy": 0.09655964374542236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.56356048583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03245586156845093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10554514080286026,
      "backward_entropy": 0.04147406986781529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.27698516845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032526034861803055,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1054559126496315,
      "backward_entropy": 0.09657818930489677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.97691345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03259808570146561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10536602139472961,
      "backward_entropy": 0.027840392930167063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.08055114746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03266612067818642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1052803099155426,
      "backward_entropy": 0.02752815399851118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.173133850097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03273482993245125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10519483685493469,
      "backward_entropy": 0.0272162812096732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.45600891113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03279948979616165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1051127165555954,
      "backward_entropy": 0.039792346102850776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.54887008666992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032862190157175064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10503286123275757,
      "backward_entropy": 0.039433181285858154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.642024993896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032921791076660156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10495591163635254,
      "backward_entropy": 0.03906818798610142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.843265533447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032978422939777374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10488134622573853,
      "backward_entropy": 0.025899516684668406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.63155364990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033033013343811035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10480991005897522,
      "backward_entropy": 0.025571989161627635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.38296508789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03308996930718422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10473759472370148,
      "backward_entropy": 0.037972841944013326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.488285064697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03315502777695656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10466094315052032,
      "backward_entropy": 0.024961724877357483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.64307403564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03321531414985657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10458826273679733,
      "backward_entropy": 0.037316552230290005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.71358489990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033275898545980453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10451622307300568,
      "backward_entropy": 0.024363223995481218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.261985778808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0333431176841259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1044415533542633,
      "backward_entropy": 0.024090517844472612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.51531982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033405326306819916,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10437094420194626,
      "backward_entropy": 0.03635684507233756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.32999038696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03346914052963257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10429959744215012,
      "backward_entropy": 0.02352693889822279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.66303253173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03353172913193703,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10423052310943604,
      "backward_entropy": 0.09658043725149972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.40434265136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03359716758131981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10416004061698914,
      "backward_entropy": 0.035422325134277344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.34591674804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03366087004542351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10409126430749893,
      "backward_entropy": 0.03511449268886021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.89213180541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033730678260326385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10402008146047592,
      "backward_entropy": 0.02244975311415536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.30109405517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03379854932427406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10395106673240662,
      "backward_entropy": 0.034543671778270175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.86627960205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033861711621284485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10388565808534622,
      "backward_entropy": 0.034245963607515605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.8697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03392670676112175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10382024198770523,
      "backward_entropy": 0.03395753460271018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.44827270507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03399479016661644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10375237464904785,
      "backward_entropy": 0.03368094989231655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.8384246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034064244478940964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10368457436561584,
      "backward_entropy": 0.021197855472564697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.21227264404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03414217382669449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10361221432685852,
      "backward_entropy": 0.020983979105949402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.82936477661133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034221816807985306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10354004055261612,
      "backward_entropy": 0.02077393659523555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.42811584472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034298572689294815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10347016155719757,
      "backward_entropy": 0.020558846848351613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.61365509033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0343715064227581,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10340344905853271,
      "backward_entropy": 0.032453066536358426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.42308044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03444064036011696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10333914309740067,
      "backward_entropy": 0.03219442282404218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.00563430786133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03451073169708252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10327459871768951,
      "backward_entropy": 0.019892628703798567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.4937744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03457915037870407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10321186482906342,
      "backward_entropy": 0.03168608886854989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.68877410888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0346478708088398,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10315032303333282,
      "backward_entropy": 0.03144262518201556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.60258483886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0347164124250412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10308943688869476,
      "backward_entropy": 0.01924917314733778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.57330322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03478339686989784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1030302420258522,
      "backward_entropy": 0.03095805857862745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.0656967163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034847576171159744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10297290235757828,
      "backward_entropy": 0.03071288125855582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.56892395019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03491218388080597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10291561484336853,
      "backward_entropy": 0.03047295127596174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.02581024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03497274965047836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10286113619804382,
      "backward_entropy": 0.018410159008843557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.63197708129883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0350373201072216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10280574858188629,
      "backward_entropy": 0.029995971492358615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.48387908935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03510110080242157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10275161266326904,
      "backward_entropy": 0.018020583050591604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.298770904541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035164184868335724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10269862413406372,
      "backward_entropy": 0.017831468156405857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.01451873779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035223282873630524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10264751315116882,
      "backward_entropy": 0.017635260309491838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.38348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03528342396020889,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10259667038917542,
      "backward_entropy": 0.01744112159524645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.06065368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03534610942006111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10254484415054321,
      "backward_entropy": 0.01725472935608455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.76531219482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03540482372045517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10249487310647964,
      "backward_entropy": 0.017060465046337674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.62488555908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035463444888591766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10244588553905487,
      "backward_entropy": 0.016872550759996687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.7423095703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03552199900150299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10239766538143158,
      "backward_entropy": 0.016689779503004893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.895549774169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03558611869812012,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10234756767749786,
      "backward_entropy": 0.028005572302000865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.30893325805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03564515709877014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10230031609535217,
      "backward_entropy": 0.016342649502413615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.0637092590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03570396080613136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10225357115268707,
      "backward_entropy": 0.027597810540880476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.229279518127441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035760555416345596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10220737010240555,
      "backward_entropy": 0.01598773364509855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.83161163330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03581146150827408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10216446220874786,
      "backward_entropy": 0.015804332281861986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.27493286132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03586572781205177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211972892284393,
      "backward_entropy": 0.015629066952637265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.81911849975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03592616319656372,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207335650920868,
      "backward_entropy": 0.026778210486684526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.8880615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035985976457595825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202714800834656,
      "backward_entropy": 0.015302480331489019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.81280517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03604690730571747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198080539703369,
      "backward_entropy": 0.015139896954808916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.94389343261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03611067309975624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10193418711423874,
      "backward_entropy": 0.026231542229652405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.93290710449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0361764132976532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10188683122396469,
      "backward_entropy": 0.014834511492933546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.64321899414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03624158352613449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184039175510406,
      "backward_entropy": 0.014684907027653285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.07701873779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03631024435162544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10179310292005539,
      "backward_entropy": 0.014539456793240138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.80076599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03637904301285744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10174567997455597,
      "backward_entropy": 0.014394019331250871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.01828956604004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03644814342260361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10169869661331177,
      "backward_entropy": 0.014250768082482474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.66036987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036511801183223724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10165413469076157,
      "backward_entropy": 0.014103114604949951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.259742736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657752275466919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10160902887582779,
      "backward_entropy": 0.013957182211535317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.11170959472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036642272025346756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10156421363353729,
      "backward_entropy": 0.013810673994677407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.83153533935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03670770674943924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10151954740285873,
      "backward_entropy": 0.013666971453598567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.75690460205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0367724746465683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10147556662559509,
      "backward_entropy": 0.024598257882254466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.661476135253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0368436761200428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10142982006072998,
      "backward_entropy": 0.024456905467169627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.30345916748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03691057115793228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10138571262359619,
      "backward_entropy": 0.024304930652890886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.21308135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03697944059967995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10134156048297882,
      "backward_entropy": 0.02415738148348672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.6777572631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037048570811748505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10129709541797638,
      "backward_entropy": 0.02401105420930045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.48971557617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03712106868624687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10125213861465454,
      "backward_entropy": 0.012883253395557404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.85702133178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03719644248485565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10120677202939987,
      "backward_entropy": 0.023751573903220042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.0251235961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03726887330412865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011628806591034,
      "backward_entropy": 0.012650551540510995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.77503204345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03734314814209938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10111910849809647,
      "backward_entropy": 0.012543401547840663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.41712951660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03741998225450516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10107474029064178,
      "backward_entropy": 0.012436964682170324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.457916259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749934211373329,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1010298877954483,
      "backward_entropy": 0.012334386152880532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.88285827636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03757502883672714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1009863018989563,
      "backward_entropy": 0.012225603418690818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.92639923095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0376533642411232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10094240307807922,
      "backward_entropy": 0.023040882178715298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.08980560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0377328135073185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10089879482984543,
      "backward_entropy": 0.022933768374579295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.96574401855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781184181571007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10085581243038177,
      "backward_entropy": 0.011926719120570592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.90735626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03789028152823448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10081321746110916,
      "backward_entropy": 0.01183000419821058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.10244750976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037970803678035736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10077008605003357,
      "backward_entropy": 0.02261937516076224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.77070617675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03805186599493027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10072694718837738,
      "backward_entropy": 0.011633119412830897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.84766387939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038131024688482285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10068503022193909,
      "backward_entropy": 0.011536795113767897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.195486068725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03820527344942093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10064435750246048,
      "backward_entropy": 0.02229068534714835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.618913650512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038274120539426804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10060600191354752,
      "backward_entropy": 0.022174234901155745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.65973663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03833918273448944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.100568987429142,
      "backward_entropy": 0.011228565658841814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.73392486572266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03840482980012894,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1005309671163559,
      "backward_entropy": 0.09806653431483678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.81249237060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03847263380885124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10049274563789368,
      "backward_entropy": 0.02182136050292424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.77213668823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03854379057884216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1004536971449852,
      "backward_entropy": 0.021714074271065847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.85363006591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038613755255937576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10041502118110657,
      "backward_entropy": 0.021605600203786577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.23609161376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03867863118648529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10037803649902344,
      "backward_entropy": 0.021494182092802867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.23965072631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03874162957072258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1003415584564209,
      "backward_entropy": 0.010631218552589417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.90835189819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038804568350315094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003052219748497,
      "backward_entropy": 0.021274315459387644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.771732330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03886619210243225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10026958584785461,
      "backward_entropy": 0.021173042910439626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.76792907714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03892483189702034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10023468732833862,
      "backward_entropy": 0.01034996977874211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.379234313964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038984086364507675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10019999742507935,
      "backward_entropy": 0.02096832650048392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.43651580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039039820432662964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10016672313213348,
      "backward_entropy": 0.01017628503697259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.52420806884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039093539118766785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10013417154550552,
      "backward_entropy": 0.010093209998948234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.38766479492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039150796830654144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10010065883398056,
      "backward_entropy": 0.02070096560886928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.230295181274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03921382501721382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10006557404994965,
      "backward_entropy": 0.02061824713434492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.98765182495117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039273954927921295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10003118962049484,
      "backward_entropy": 0.02053341269493103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.97970199584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933453932404518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09999680519104004,
      "backward_entropy": 0.009781205228396825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.84405517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039393894374370575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0999627560377121,
      "backward_entropy": 0.00970678563628878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.05286407470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03945228084921837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09992903470993042,
      "backward_entropy": 0.020302153059414456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.06905364990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039506696164608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09989623725414276,
      "backward_entropy": 0.009557390851633889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.355716705322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039565954357385635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09986188262701035,
      "backward_entropy": 0.009484933955328805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.57459259033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039625611156225204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09982757270336151,
      "backward_entropy": 0.009415043251855033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.89810562133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03968317061662674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09979411959648132,
      "backward_entropy": 0.020008657659803118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.41266632080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03974245488643646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09975993633270264,
      "backward_entropy": 0.01994488707610539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.58673858642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03979969397187233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0997265875339508,
      "backward_entropy": 0.01988715784890311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.70306396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03985865041613579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09969259798526764,
      "backward_entropy": 0.019826020513262068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.21647262573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0399179570376873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09965848922729492,
      "backward_entropy": 0.009096701230321611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.38276672363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03997908532619476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0996239185333252,
      "backward_entropy": 0.01970945511545454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2078079730272293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04004424437880516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09958797693252563,
      "backward_entropy": 0.008976952305861883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.30960083007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040102310478687286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09955405443906784,
      "backward_entropy": 0.00891358352133206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.883230209350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04016364365816116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09951916337013245,
      "backward_entropy": 0.008853657969406672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.32651138305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04022238031029701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09948501735925674,
      "backward_entropy": 0.008792799498353685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.24214553833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04028022289276123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09945100545883179,
      "backward_entropy": 0.008733278938702174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.61283302307129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04033995047211647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09941644966602325,
      "backward_entropy": 0.019358204943793162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99460220336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04039744287729263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09938260912895203,
      "backward_entropy": 0.019307677234922136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.577544212341309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04045424982905388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09934894740581512,
      "backward_entropy": 0.01926020852157048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.975358963012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04050649330019951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09931662678718567,
      "backward_entropy": 0.008514642715454102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.85645294189453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04055584967136383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09928536415100098,
      "backward_entropy": 0.09839003426688057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.226774215698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040609441697597504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09925229102373123,
      "backward_entropy": 0.019132492797715322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.213558197021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040661510080099106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09921988844871521,
      "backward_entropy": 0.0083676954465253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.69709396362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04071582108736038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09918655455112457,
      "backward_entropy": 0.019057597432817732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.59678649902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04077138006687164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0991528332233429,
      "backward_entropy": 0.008274222591093608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.933534622192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04082775115966797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09911869466304779,
      "backward_entropy": 0.01899566182068416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.352126121520996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04088218882679939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09908507764339447,
      "backward_entropy": 0.008184227560247694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.003143310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04093248024582863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09905283153057098,
      "backward_entropy": 0.018935412168502808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.90913009643555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040982820093631744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09902048110961914,
      "backward_entropy": 0.018907642790249417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.163509368896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04103321209549904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09898802638053894,
      "backward_entropy": 0.00805686307804925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.706485748291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04108631610870361,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09895463287830353,
      "backward_entropy": 0.01885616566453661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.88276672363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041139356791973114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09892122447490692,
      "backward_entropy": 0.007978304688419615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.5062141418457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04119465872645378,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09888695180416107,
      "backward_entropy": 0.01881253719329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.26211929321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04124968498945236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09885261952877045,
      "backward_entropy": 0.00790240615606308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.26666831970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04130161553621292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09881941229104996,
      "backward_entropy": 0.007864942508084434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.28440856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04135207459330559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09878630936145782,
      "backward_entropy": 0.018749088048934937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.13443374633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04140521585941315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09875214844942093,
      "backward_entropy": 0.007789666099207742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.962646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04146081581711769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0987171083688736,
      "backward_entropy": 0.018702660288129534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.94817543029785,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041519924998283386,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09868082404136658,
      "backward_entropy": 0.09855019194739205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.59159851074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04157710075378418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09864521026611328,
      "backward_entropy": 0.007684252624000821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.59203338623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04163758084177971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09860818088054657,
      "backward_entropy": 0.007651579699345997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.705156326293945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04169849678874016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09857095777988434,
      "backward_entropy": 0.0076194629073143005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.31413269042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04175717383623123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0985344648361206,
      "backward_entropy": 0.007586263120174408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.81962585449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04181655868887901,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.098497673869133,
      "backward_entropy": 0.018607554691178457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.83136749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04187915101647377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09845970571041107,
      "backward_entropy": 0.007523762328284127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.65085983276367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04194321483373642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09842101484537125,
      "backward_entropy": 0.09863623550959996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.53883171081543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042008765041828156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09838168323040009,
      "backward_entropy": 0.007462981023958751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.59714126586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042070381343364716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09834372997283936,
      "backward_entropy": 0.018575429916381836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.1358528137207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04213244095444679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09830546379089355,
      "backward_entropy": 0.007406370448214667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.01215934753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04219609871506691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09826649725437164,
      "backward_entropy": 0.007379033735820225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.931724548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04225737974047661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09822823107242584,
      "backward_entropy": 0.007352947124413082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.8459529876709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04231632500886917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09819075465202332,
      "backward_entropy": 0.007325681724718639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.907894134521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04237336665391922,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09815388172864914,
      "backward_entropy": 0.01856589104448046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.31758499145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042431142181158066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0981166884303093,
      "backward_entropy": 0.007273728826216289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.15196228027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04249089956283569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09807854890823364,
      "backward_entropy": 0.007247860942568097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.00497055053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042552508413791656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09803947061300278,
      "backward_entropy": 0.01856135470526559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.816314697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04261333867907524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09800054877996445,
      "backward_entropy": 0.01856501187597002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.21144104003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042675867676734924,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09796109050512314,
      "backward_entropy": 0.09877227885382515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.473880767822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04273875802755356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09792069345712662,
      "backward_entropy": 0.00715646254164832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.172243118286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04280298948287964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09787988662719727,
      "backward_entropy": 0.01857706904411316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.08570098876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04286474734544754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09783994406461716,
      "backward_entropy": 0.00711195170879364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.64305114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04292438179254532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09780075401067734,
      "backward_entropy": 0.018586765442575728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.21273422241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04298447445034981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0977611243724823,
      "backward_entropy": 0.0070706675095217565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.307584762573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04304370656609535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09772171080112457,
      "backward_entropy": 0.018593400716781616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.762176513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309850558638573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0976840928196907,
      "backward_entropy": 0.007029963391167777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.11836242675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04315163567662239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09764710068702698,
      "backward_entropy": 0.0070098574672426495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.183048248291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043205901980400085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0976094901561737,
      "backward_entropy": 0.0069894322327205115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.02565002441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043262455612421036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09757062047719955,
      "backward_entropy": 0.006968613181795392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.86236572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043321095407009125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09753061830997467,
      "backward_entropy": 0.006947510476623263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.58430480957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043381668627262115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09748953580856323,
      "backward_entropy": 0.018611533301217214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.60575866699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0434427447617054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09744800627231598,
      "backward_entropy": 0.0069074322070394245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.242027282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04350678250193596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09740491956472397,
      "backward_entropy": 0.018616429397038052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.19453430175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356955736875534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09736223518848419,
      "backward_entropy": 0.00686873442360333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.99613952636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043634966015815735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09731820225715637,
      "backward_entropy": 0.018613955804279873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.80665588378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04370022565126419,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0972740575671196,
      "backward_entropy": 0.006826211299215045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.689361572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043766576796770096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09722919762134552,
      "backward_entropy": 0.006803597722734723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.63383674621582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383270442485809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09718414396047592,
      "backward_entropy": 0.006781059716429029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.512901306152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04389740526676178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09713960438966751,
      "backward_entropy": 0.018583895904677256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.07720947265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04396084323525429,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09709551930427551,
      "backward_entropy": 0.01857858044760568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.33187866210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044025614857673645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09705062955617905,
      "backward_entropy": 0.018572747707366943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.803040504455566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409542679786682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09700296819210052,
      "backward_entropy": 0.006699578038283757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.7700309753418,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044159576296806335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0969579815864563,
      "backward_entropy": 0.09890891824449811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.46175479888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04422364756464958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09691283106803894,
      "backward_entropy": 0.01856279798916408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.78778839111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04428393021225929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09686948359012604,
      "backward_entropy": 0.006644029702459063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.34799861907959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04434331879019737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09682634472846985,
      "backward_entropy": 0.006626132343496595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.12105178833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044399362057447433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09678484499454498,
      "backward_entropy": 0.006608811872346061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.89418029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04445995017886162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09674061834812164,
      "backward_entropy": 0.00659121253660747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.91303253173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0445246547460556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09669387340545654,
      "backward_entropy": 0.006573739860739026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.211669921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044589247554540634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09664692729711533,
      "backward_entropy": 0.018542436616761342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.13032913208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044652458280324936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09660053253173828,
      "backward_entropy": 0.006538952567747661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.46067810058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471690580248833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09655319899320602,
      "backward_entropy": 0.006520786455699376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.306846618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04478129372000694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09650592505931854,
      "backward_entropy": 0.006503252046448844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.870878219604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04484554007649422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09645789861679077,
      "backward_entropy": 0.006485729877437864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.21314239501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04490596428513527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09641221165657043,
      "backward_entropy": 0.006469157125268664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.131460189819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04496419429779053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09636758267879486,
      "backward_entropy": 0.006453290049518857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.73884582519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502050578594208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09632375091314316,
      "backward_entropy": 0.006438723632267543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.649333000183105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045077431946992874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09627944231033325,
      "backward_entropy": 0.0064233701143945965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.76987838745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04513126239180565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09623678773641586,
      "backward_entropy": 0.006408887782267162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.543535232543945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045187246054410934,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0961923897266388,
      "backward_entropy": 0.09894382102148873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.216590881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04524020850658417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09614978730678558,
      "backward_entropy": 0.006380108850342887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.872711181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04529416188597679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09610635042190552,
      "backward_entropy": 0.01853699343545096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.96044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045347798615694046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09606296569108963,
      "backward_entropy": 0.018539573465074812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.338287353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0454024001955986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09601869434118271,
      "backward_entropy": 0.006340121584279197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.98323059082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545418173074722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09597589075565338,
      "backward_entropy": 0.006328814263854708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.46068000793457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04550953209400177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09593042731285095,
      "backward_entropy": 0.018554676856313432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.266857147216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045564454048871994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09588493406772614,
      "backward_entropy": 0.01856140579496111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.189119338989258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04561769589781761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09584037959575653,
      "backward_entropy": 0.006295669823884964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.151399612426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045669399201869965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09579674899578094,
      "backward_entropy": 0.006285379507711956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.051895141601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04572096839547157,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09575299918651581,
      "backward_entropy": 0.09895769187382289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.92668533325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577241465449333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09570926427841187,
      "backward_entropy": 0.006265365651675633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.77033233642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04582621902227402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09566318988800049,
      "backward_entropy": 0.006255729922226497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.60846710205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045882128179073334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09561552107334137,
      "backward_entropy": 0.006245809474161693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.62863540649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04593992978334427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09556616842746735,
      "backward_entropy": 0.01860217111451285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.5194034576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599698260426521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0955171212553978,
      "backward_entropy": 0.006226382085255214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.11098861694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04605339467525482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09546815603971481,
      "backward_entropy": 0.018613306539399282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.473817825317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04611162468791008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0954175740480423,
      "backward_entropy": 0.018618881702423096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.187448501586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04616785794496536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09536818414926529,
      "backward_entropy": 0.018626549414225986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.07879066467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04622350260615349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09531888365745544,
      "backward_entropy": 0.00619400611945561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.455570220947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04627859219908714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09526979923248291,
      "backward_entropy": 0.01864415407180786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.86023712158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633559286594391,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09521886706352234,
      "backward_entropy": 0.006180159215416227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.437744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04639187082648277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09516830742359161,
      "backward_entropy": 0.018658661416598728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.640666961669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046448707580566406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09511703252792358,
      "backward_entropy": 0.00616614893078804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.53057289123535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04650485888123512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09506598114967346,
      "backward_entropy": 0.006159521107162748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.237510681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465603731572628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09501513838768005,
      "backward_entropy": 0.00615315671477999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.732154846191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046618930995464325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09496136009693146,
      "backward_entropy": 0.006146393184150968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.29401397705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466754212975502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09490898996591568,
      "backward_entropy": 0.006140493388686862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.56211280822754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04673359543085098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0948546826839447,
      "backward_entropy": 0.018696712596075877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.973346710205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04678967595100403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09480182081460953,
      "backward_entropy": 0.018701755574771335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.795413970947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04684509336948395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.094749316573143,
      "backward_entropy": 0.0061229680265699115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.876370429992676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04690227657556534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09469499439001083,
      "backward_entropy": 0.018710517457553318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.05652618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04695625975728035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09464335441589355,
      "backward_entropy": 0.006111747452190944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.537755966186523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047010939568281174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09459082782268524,
      "backward_entropy": 0.0061062537133693695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.503604888916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047065045684576035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09453858435153961,
      "backward_entropy": 0.006100835544722421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.318111419677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712218418717384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09448334574699402,
      "backward_entropy": 0.006094505744321006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.905662536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471784882247448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0944286435842514,
      "backward_entropy": 0.006088352096932275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.550752639770508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04723286256194115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09437547624111176,
      "backward_entropy": 0.00608281631554876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.246742248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0472843237221241,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09432469308376312,
      "backward_entropy": 0.018717139959335327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.670984268188477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047336678951978683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09427281469106674,
      "backward_entropy": 0.0060735105403832024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.59539031982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047387491911649704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09422208368778229,
      "backward_entropy": 0.0060693009623459405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.69550323486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0474369078874588,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0941724181175232,
      "backward_entropy": 0.018718163881983076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.448444366455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748624190688133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09412238746881485,
      "backward_entropy": 0.006062039307185582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.75196075439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04753432050347328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09407319873571396,
      "backward_entropy": 0.006058926561049053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.50122833251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04758477210998535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09402154386043549,
      "backward_entropy": 0.01872036712510245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.298633575439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047636184841394424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0939682275056839,
      "backward_entropy": 0.018718994089535305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.196571350097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047687284648418427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09391513466835022,
      "backward_entropy": 0.006047411688736507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.048240661621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047738101333379745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09386210143566132,
      "backward_entropy": 0.018715519990239824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.997188568115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047786325216293335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09381158649921417,
      "backward_entropy": 0.09899013383047921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.92340850830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04783686622977257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09375837445259094,
      "backward_entropy": 0.018712861197335378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.849529266357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04788599908351898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09370630979537964,
      "backward_entropy": 0.006035814327853066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.777565002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04793385788798332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09365534782409668,
      "backward_entropy": 0.01871026839528765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.51122283935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04798056185245514,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09360535442829132,
      "backward_entropy": 0.09899170058114189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.024070739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04802853986620903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09355363994836807,
      "backward_entropy": 0.0060305190937859675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.70407485961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048081111162900925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09349654614925385,
      "backward_entropy": 0.006027136530194964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.306543350219727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048130884766578674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0934421718120575,
      "backward_entropy": 0.006024650165012905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.20697021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048180438578128815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09338770061731339,
      "backward_entropy": 0.0186951288155147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.330867767333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048229802399873734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09333308786153793,
      "backward_entropy": 0.018690645694732666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.010498046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0482778325676918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09327965974807739,
      "backward_entropy": 0.018686901245798384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.64154815673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832581430673599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09322598576545715,
      "backward_entropy": 0.0060159872685159954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.516977310180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04837489128112793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09317071735858917,
      "backward_entropy": 0.006014002220971244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.713109970092773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04842492565512657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09311394393444061,
      "backward_entropy": 0.018671548792294095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.95948028564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04847469553351402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09305715560913086,
      "backward_entropy": 0.006009356251784733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.39747619628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04852306470274925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09300167858600616,
      "backward_entropy": 0.01865981093474797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.21441650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04857470840215683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09294188022613525,
      "backward_entropy": 0.006004748599869865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.576712131500244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048629309982061386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09287819266319275,
      "backward_entropy": 0.0060009849922997615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.09840202331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048679761588573456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09281942248344421,
      "backward_entropy": 0.005999110106910978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.574052810668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04872756451368332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09276336431503296,
      "backward_entropy": 0.018625412668500627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.004337310791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0487741120159626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0927085354924202,
      "backward_entropy": 0.018618681601115634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.29301071166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882068932056427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0926533192396164,
      "backward_entropy": 0.0059952209038393834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.803359985351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04887291043996811,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09259070456027985,
      "backward_entropy": 0.01860042767865317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.426446437835693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048924580216407776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09252835065126419,
      "backward_entropy": 0.0059895797499588555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.399925231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04897234961390495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09247083961963654,
      "backward_entropy": 0.0059883615800312585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.499242782592773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04902224615216255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09241008013486862,
      "backward_entropy": 0.005986689989055906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.04894256591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049071796238422394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09234941750764847,
      "backward_entropy": 0.005985364850078311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.9490966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04911987856030464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09229033440351486,
      "backward_entropy": 0.005984274936573846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.89912223815918,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049170032143592834,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0922282338142395,
      "backward_entropy": 0.09899558339800153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.372943878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049218662083148956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09216742217540741,
      "backward_entropy": 0.018533834389277866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.247098922729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04926817864179611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0921052023768425,
      "backward_entropy": 0.01852514488356454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.449153900146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04931851103901863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0920415073633194,
      "backward_entropy": 0.005982100963592529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.996299743652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04936617240309715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09198115766048431,
      "backward_entropy": 0.005983031221798488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.87145233154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049414779990911484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09191906452178955,
      "backward_entropy": 0.005983829498291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.44849681854248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04946419224143028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09185539186000824,
      "backward_entropy": 0.01849364595753806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.376093864440918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0495121069252491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09179338812828064,
      "backward_entropy": 0.005984064191579819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.30367374420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955872520804405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.091732919216156,
      "backward_entropy": 0.005985269056899207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.310909271240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04960411787033081,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09167379140853882,
      "backward_entropy": 0.01846911438873836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.216598510742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049649521708488464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09161426872015,
      "backward_entropy": 0.0059880656855446955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.244544982910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969485476613045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09155432879924774,
      "backward_entropy": 0.005988367434058871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.018009185791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04974455013871193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09148760139942169,
      "backward_entropy": 0.018435239791870117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.882686614990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04979270324110985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09142247587442398,
      "backward_entropy": 0.01842055789061955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.72764778137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04984274506568909,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09135421365499496,
      "backward_entropy": 0.018404394388198853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.859787940979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04989445209503174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09128279238939285,
      "backward_entropy": 0.005981936518635068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.515079498291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04994332417845726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09121550619602203,
      "backward_entropy": 0.018370656030518667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757802963256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049992885440588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09114663302898407,
      "backward_entropy": 0.005979781704289573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.41437530517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05003976821899414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09108154475688934,
      "backward_entropy": 0.018338961260659353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.80290222167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050086427479982376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09101635217666626,
      "backward_entropy": 0.005978770554065704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.413187980651855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013614147901535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0909460186958313,
      "backward_entropy": 0.005977730133703777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.56087589263916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05018424615263939,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09087738394737244,
      "backward_entropy": 0.01829054738794054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006267102900892496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05022979900240898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09081275761127472,
      "backward_entropy": 0.005977477878332138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.40378189086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050270915031433105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09075526893138885,
      "backward_entropy": 0.005979267082044056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.138262748718262,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05031449347734451,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09069317579269409,
      "backward_entropy": 0.09899766956056867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.448938369750977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050357088446617126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09063225239515305,
      "backward_entropy": 0.0182369840996606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.67058563232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05040091276168823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09056879580020905,
      "backward_entropy": 0.005983296781778336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.579233169555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050444796681404114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09050474315881729,
      "backward_entropy": 0.018210723996162415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.868881225585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0504886731505394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09044022858142853,
      "backward_entropy": 0.00598606892994472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.99860191345215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05053151771426201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09037714451551437,
      "backward_entropy": 0.005988092294761113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008257757872343063,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050575513392686844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09031146764755249,
      "backward_entropy": 0.005989495664834976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.673369407653809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05061528831720352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09025311470031738,
      "backward_entropy": 0.005993324731077466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.681486129760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05065444856882095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0901954174041748,
      "backward_entropy": 0.018155745097569058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.60500717163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05069506913423538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09013467282056808,
      "backward_entropy": 0.006001719406672886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.954504013061523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05073915049433708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09006713330745697,
      "backward_entropy": 0.006003888589995248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.876625061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05078530311584473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08999527245759964,
      "backward_entropy": 0.006005472902740751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.337851524353027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050831183791160583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08992350101470947,
      "backward_entropy": 0.018103286623954773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.109041213989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050875719636678696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08985377848148346,
      "backward_entropy": 0.018087510551725115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.19837474822998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05092112347483635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08978192508220673,
      "backward_entropy": 0.01806874998978206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.129883766174316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05096524581313133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08971203863620758,
      "backward_entropy": 0.006009667579616819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.117130279541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05100822448730469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0896439179778099,
      "backward_entropy": 0.006011015602520534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.664264678955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05105329677462578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08957117050886154,
      "backward_entropy": 0.006011696798460824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.926254272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109599977731705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08950269222259521,
      "backward_entropy": 0.006012366818530219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.99739646911621,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051137667149305344,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08943584561347961,
      "backward_entropy": 0.0990004369190761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.573938369750977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05118253454566002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08936213701963425,
      "backward_entropy": 0.01794611556189401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.190828323364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05122930929064751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0892840027809143,
      "backward_entropy": 0.0060133566813809535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.43327522277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05127665773034096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08920420706272125,
      "backward_entropy": 0.0060126882578645435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.386978149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051321472972631454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0891292542219162,
      "backward_entropy": 0.0060133492308003566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.509509086608887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051364023238420486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08905817568302155,
      "backward_entropy": 0.006015552473919732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.15476655960083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05140560120344162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08898868411779404,
      "backward_entropy": 0.0060193102274622235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.88330841064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05144413188099861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08892540633678436,
      "backward_entropy": 0.006023681589535305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010652385652065277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0514860562980175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0888541042804718,
      "backward_entropy": 0.0060256001140390125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.344064712524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05152390897274017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08879127353429794,
      "backward_entropy": 0.017786726355552673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010813090950250626,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05156215652823448,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0887271910905838,
      "backward_entropy": 0.09900097336087908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.102230072021484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05159669369459152,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08867081999778748,
      "backward_entropy": 0.09900130544389997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.125286102294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051629915833473206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08861695230007172,
      "backward_entropy": 0.017739010708672658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.05493927001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166400969028473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.088560551404953,
      "backward_entropy": 0.006048263715846198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.975801467895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051698897033929825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0885019302368164,
      "backward_entropy": 0.006053702639681953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.854564666748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051735520362854004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08843889087438583,
      "backward_entropy": 0.017695744122777666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.779054641723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051774606108665466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08836998045444489,
      "backward_entropy": 0.006062323493616921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.74171257019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05181487649679184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08829793334007263,
      "backward_entropy": 0.017653465270996094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.746028900146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051855240017175674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08822518587112427,
      "backward_entropy": 0.01762965534414564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9024527072906494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189467966556549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08815411478281021,
      "backward_entropy": 0.006067461733307157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.37112808227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05193128064274788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08808925747871399,
      "backward_entropy": 0.0060703930045877185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.42011833190918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05196927487850189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08802071213722229,
      "backward_entropy": 0.006071850657463074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.172203063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05200757458806038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08795091509819031,
      "backward_entropy": 0.017534871186528887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.880434036254883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05204709991812706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0878777801990509,
      "backward_entropy": 0.00607370851295335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.749813079833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052088744938373566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08779922127723694,
      "backward_entropy": 0.017477942364556447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.079439163208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05213230475783348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08771534264087677,
      "backward_entropy": 0.006072694701807839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.477394104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05217556655406952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08763173222541809,
      "backward_entropy": 0.006072117281811578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.733360767364502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052220556885004044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08754351735115051,
      "backward_entropy": 0.00607129984668323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.109404563903809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05226214602589607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08746311813592911,
      "backward_entropy": 0.006072023617369788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.757322311401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052302587777376175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08738502860069275,
      "backward_entropy": 0.006072548883301871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.288663864135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05234595388174057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08729924261569977,
      "backward_entropy": 0.006071906536817551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.541566848754883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052389971911907196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08721126616001129,
      "backward_entropy": 0.006070871438298907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.841780662536621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05243353173136711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08712391555309296,
      "backward_entropy": 0.0060690103897026604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.188448429107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05247582867741585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08703920245170593,
      "backward_entropy": 0.006068906613758632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.279322624206543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052515968680381775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08695937693119049,
      "backward_entropy": 0.006070301468883242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1050567626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05255609750747681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08687896281480789,
      "backward_entropy": 0.0060719964759690425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.642621994018555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05259423330426216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08680329471826553,
      "backward_entropy": 0.006074264113392148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.530226707458496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052633609622716904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08672367036342621,
      "backward_entropy": 0.006077897867986134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.4703369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052672129124403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08664557337760925,
      "backward_entropy": 0.006083056330680847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.946387767791748,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052709780633449554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08656932413578033,
      "backward_entropy": 0.006088244595697948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.69803810119629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0527457520365715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08649705350399017,
      "backward_entropy": 0.006094946392944881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.57945442199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052784066647291183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08641786873340607,
      "backward_entropy": 0.006101635949952262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.0478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05282449349761009,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08633217215538025,
      "backward_entropy": 0.0170272450361933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.94147491455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05286584049463272,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08624334633350372,
      "backward_entropy": 0.09900149277278356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.10569953918457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05290795490145683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08615180850028992,
      "backward_entropy": 0.006123227732522147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.7556209564209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052948951721191406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08606267720460892,
      "backward_entropy": 0.006132412701845169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.974324226379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052993517369031906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0859631896018982,
      "backward_entropy": 0.0061392321118286675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.206036567687988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053036581724882126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08586736023426056,
      "backward_entropy": 0.006146318146160671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.842435836791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05307912826538086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08577263355255127,
      "backward_entropy": 0.006151687353849411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.28818130493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05312035605311394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08568105846643448,
      "backward_entropy": 0.016928084194660187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.41240692138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316215381026268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08558739721775055,
      "backward_entropy": 0.006160947893347059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.857661247253418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320547893643379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08548875153064728,
      "backward_entropy": 0.006163509296519416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.581618309020996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05324830859899521,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08539094775915146,
      "backward_entropy": 0.016853336777005876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.684477806091309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05328970402479172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08529685437679291,
      "backward_entropy": 0.006168745458126068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.744790077209473,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05333072692155838,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08520328998565674,
      "backward_entropy": 0.09900461775915963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.88616180419922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05337239429354668,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08510713279247284,
      "backward_entropy": 0.09900447300502233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.524479866027832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05341638624668121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08500352501869202,
      "backward_entropy": 0.006172373358692441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.56646156311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05346062779426575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0848986953496933,
      "backward_entropy": 0.006171434053352901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.344329833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05350694805383682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08478698134422302,
      "backward_entropy": 0.006169522447245461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0502562522888184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053554240614175797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08467165380716324,
      "backward_entropy": 0.006167688007865634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041647911071777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05359765887260437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0845680832862854,
      "backward_entropy": 0.0061652325093746185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.949413299560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053639549762010574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08446860313415527,
      "backward_entropy": 0.006163886615208217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.875608444213867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05368177592754364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08436758816242218,
      "backward_entropy": 0.006161116595779147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.73198127746582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05372350290417671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08426733314990997,
      "backward_entropy": 0.006159257143735886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.703298568725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05376569181680679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08416489511728287,
      "backward_entropy": 0.006158151796885899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.617846488952637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0538073405623436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08406345546245575,
      "backward_entropy": 0.01639907274927412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7767558097839355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053848493844270706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0839630663394928,
      "backward_entropy": 0.006157197590385165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.453635215759277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05388747155666351,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08386895060539246,
      "backward_entropy": 0.006159098020621708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.890605926513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05392622575163841,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08377493917942047,
      "backward_entropy": 0.09899769510541644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.376327514648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053967297077178955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08367294818162918,
      "backward_entropy": 0.006161349160330636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.199969291687012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05401238054037094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08355718106031418,
      "backward_entropy": 0.006160905318600791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.652015686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05405643209815025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08344452828168869,
      "backward_entropy": 0.006158687174320221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02312834933400154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054101426154375076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08332814276218414,
      "backward_entropy": 0.006156158234391894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.390377044677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414197966456413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08322645723819733,
      "backward_entropy": 0.006155404129198619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024143006652593613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418376252055168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08312000334262848,
      "backward_entropy": 0.006153930510793414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.398411273956299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054221365600824356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08302764594554901,
      "backward_entropy": 0.006153249314853123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.362091064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05425701662898064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0829414427280426,
      "backward_entropy": 0.006153706461191177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.284172058105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429093912243843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08286073803901672,
      "backward_entropy": 0.006155670753547123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.926641464233398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05432583764195442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08277593553066254,
      "backward_entropy": 0.01592922423567091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.110194206237793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054359957575798035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08269321173429489,
      "backward_entropy": 0.015897634838308607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.421783447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0543949231505394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08260710537433624,
      "backward_entropy": 0.0061608680656978065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.931050300598145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05442985147237778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08252064138650894,
      "backward_entropy": 0.006161352885620934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.714366436004639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05446579307317734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08242979645729065,
      "backward_entropy": 0.015793398022651672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.115952491760254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054500825703144073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08234120905399323,
      "backward_entropy": 0.015764972993305752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.08322811126709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05453415587544441,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08225847035646439,
      "backward_entropy": 0.01573880761861801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5365753173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05456585809588432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08218138664960861,
      "backward_entropy": 0.006179429590702057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518679141998291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0545954629778862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08211131393909454,
      "backward_entropy": 0.006188042461872101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.992491722106934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05462481826543808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08204137533903122,
      "backward_entropy": 0.0061982518860272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4949796199798584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054652951657772064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08197571337223053,
      "backward_entropy": 0.015657433441707065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39597749710083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054679110646247864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08191728591918945,
      "backward_entropy": 0.006217154009001595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.131202697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05470512434840202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08185915648937225,
      "backward_entropy": 0.006224386394023895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312166690826416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473444610834122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08178816735744476,
      "backward_entropy": 0.006229816270726067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.267551898956299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476335808634758,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0817183256149292,
      "backward_entropy": 0.01555747538805008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223409175872803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05479198321700096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08164901286363602,
      "backward_entropy": 0.015530359532151903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.796865463256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05482043698430061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08157960325479507,
      "backward_entropy": 0.00624794459768704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.395847797393799,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05484772101044655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.081514373421669,
      "backward_entropy": 0.006255109395299639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.383058786392212,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05487321317195892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08145563304424286,
      "backward_entropy": 0.006263916513749531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023725206032395363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05489708483219147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08140268176794052,
      "backward_entropy": 0.015446649066039495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.049394607543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05491861328482628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08135867863893509,
      "backward_entropy": 0.006284483309303012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.323481559753418,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05494294315576553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08130346238613129,
      "backward_entropy": 0.09899989196232387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275989532470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054968301206827164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08124347031116486,
      "backward_entropy": 0.006301819745983396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.5227689743042,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05499439686536789,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0811803787946701,
      "backward_entropy": 0.09900085415158953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.168582916259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05502205342054367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08111073821783066,
      "backward_entropy": 0.015341926898275102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2939534187316895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05505023151636124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08103863894939423,
      "backward_entropy": 0.006321082157748086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.059223175048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05507652461528778,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08097358047962189,
      "backward_entropy": 0.015292348606245858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.005645751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055103518068790436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08090528845787048,
      "backward_entropy": 0.006334983344588961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.254194974899292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055131133645772934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08083406090736389,
      "backward_entropy": 0.006341436079570225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.11781120300293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055156879127025604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08076993376016617,
      "backward_entropy": 0.006348954779761178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84538459777832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055184245109558105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0806986466050148,
      "backward_entropy": 0.006356968411377498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.407521724700928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055212195962667465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08062448352575302,
      "backward_entropy": 0.006364890507289341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.916494369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05523897334933281,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08055496215820312,
      "backward_entropy": 0.006372159080845969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.517884254455566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055267177522182465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08047915250062943,
      "backward_entropy": 0.006378834268876484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.931690216064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05529499799013138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08040456473827362,
      "backward_entropy": 0.01511510887316295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.296499729156494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055324818938970566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08032171428203583,
      "backward_entropy": 0.006388622735227857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511669158935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055353257805109024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08024436235427856,
      "backward_entropy": 0.006391955805676324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.350244045257568,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538212135434151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08016479015350342,
      "backward_entropy": 0.006395503878593445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.587309837341309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05541038513183594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08008771389722824,
      "backward_entropy": 0.006396672555378505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.339455604553223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055440645664930344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08000195771455765,
      "backward_entropy": 0.006397300000701632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.342960357666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05547109618782997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07991497218608856,
      "backward_entropy": 0.0063981424484934124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.315587997436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0555025190114975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07982346415519714,
      "backward_entropy": 0.006398910922663552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12261438369751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05553552135825157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07972510159015656,
      "backward_entropy": 0.006398331373929977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092621803283691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05556751415133476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07963091135025024,
      "backward_entropy": 0.01482110470533371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.025455474853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055599331855773926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07953764498233795,
      "backward_entropy": 0.006392616246427808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.939369201660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055629562586545944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07945071160793304,
      "backward_entropy": 0.006390033555882317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02654433250427246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05566143989562988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07935641705989838,
      "backward_entropy": 0.006386596709489822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.756977081298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055690061300992966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07927632331848145,
      "backward_entropy": 0.006383135914802551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9070963859558105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055720653384923935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07918676733970642,
      "backward_entropy": 0.006382218429020473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.51123046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055749740451574326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07910345494747162,
      "backward_entropy": 0.006381762347051075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.40400218963623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05578136071562767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0790087878704071,
      "backward_entropy": 0.006381044430392129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9198964834213257,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05581521615386009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07890419661998749,
      "backward_entropy": 0.006379604339599609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.303028106689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055846504867076874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0788104385137558,
      "backward_entropy": 0.006379760269607816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8898481130599976,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055879272520542145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07870996743440628,
      "backward_entropy": 0.0063797176948615485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.119945526123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055909547954797745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07862025499343872,
      "backward_entropy": 0.006380600588662284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191841125488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05594140663743019,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07852307707071304,
      "backward_entropy": 0.014375884618077959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.752907752990723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05597406253218651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07842151075601578,
      "backward_entropy": 0.006385819720370429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.429584980010986,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05600877106189728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07831054925918579,
      "backward_entropy": 0.0063892970127718786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02770964242517948,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0560423918068409,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07820380479097366,
      "backward_entropy": 0.006394817360809871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.425531387329102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056072644889354706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07811230421066284,
      "backward_entropy": 0.006400547921657562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.297097206115723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056105129420757294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0780104473233223,
      "backward_entropy": 0.0064054929784366065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.248560428619385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056136514991521835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07791361212730408,
      "backward_entropy": 0.006408671183245522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0270164143294096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056167103350162506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07781976461410522,
      "backward_entropy": 0.006413655089480537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.310586929321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05619468539953232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07773944735527039,
      "backward_entropy": 0.006419858762196132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7265968322753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056223899126052856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07765161991119385,
      "backward_entropy": 0.014136237757546561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.088301181793213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05625099316239357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07757310569286346,
      "backward_entropy": 0.006430479032652718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3759005069732666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056277647614479065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0774960145354271,
      "backward_entropy": 0.014087479029382979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.67960262298584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05630318447947502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0774240493774414,
      "backward_entropy": 0.006445489823818207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28442668914795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05632910132408142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07734932005405426,
      "backward_entropy": 0.006452805229595729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941879749298096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05635599419474602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0772702544927597,
      "backward_entropy": 0.006458036069359098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.90673303604126,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0563824363052845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0771927610039711,
      "backward_entropy": 0.013991849763052804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.47932243347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05640839412808418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07711730897426605,
      "backward_entropy": 0.006469527525561196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.845100402832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05643485486507416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07703839242458344,
      "backward_entropy": 0.006478234593357358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7899298667907715,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05646436661481857,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07694496214389801,
      "backward_entropy": 0.09899650301252093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1765522956848145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05649320036172867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07685411721467972,
      "backward_entropy": 0.006492261375699725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8413262367248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05652064085006714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07676948606967926,
      "backward_entropy": 0.00650096737912723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.676715850830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05654888227581978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07668078690767288,
      "backward_entropy": 0.006508299282618931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.252384185791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0565764345228672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07659518718719482,
      "backward_entropy": 0.00651526397892407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.124495029449463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05660540610551834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07650268077850342,
      "backward_entropy": 0.013810292950698308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.602627754211426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05663425475358963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07641059160232544,
      "backward_entropy": 0.006523420235940388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.013362407684326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05666511505842209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07630859315395355,
      "backward_entropy": 0.006525753864220211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.407225608825684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056695714592933655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0762074813246727,
      "backward_entropy": 0.006528373275484357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.896675109863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05672807618975639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07609763741493225,
      "backward_entropy": 0.006529199757746288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.299679279327393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05676007270812988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07598887383937836,
      "backward_entropy": 0.0065316132136753625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.912242889404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05679215490818024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0758800059556961,
      "backward_entropy": 0.0065299272537231445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.15521240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05682221055030823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07578177005052567,
      "backward_entropy": 0.006525219018970217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4439133405685425,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05685262754559517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07568156719207764,
      "backward_entropy": 0.013530129832880837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.619819641113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05688058212399483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07559370994567871,
      "backward_entropy": 0.013483472168445587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.961058616638184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05690856650471687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07550499588251114,
      "backward_entropy": 0.006510548825774874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.152637958526611,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05693701654672623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07541395723819733,
      "backward_entropy": 0.006505143961736134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.110540390014648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056964483112096786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07532808184623718,
      "backward_entropy": 0.006497718393802643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.382086992263794,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05699124187231064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07524530589580536,
      "backward_entropy": 0.006491803697177342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7187395095825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05701586976647377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07517368346452713,
      "backward_entropy": 0.006484986415931157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.004907131195068,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0570412278175354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07509858906269073,
      "backward_entropy": 0.006476403879267829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.971371650695801,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05706615746021271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0750245675444603,
      "backward_entropy": 0.00647137314081192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3345379829406738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057090695947408676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07495194673538208,
      "backward_entropy": 0.006469324763332095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.787164688110352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057113442569971085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0748884379863739,
      "backward_entropy": 0.006468259330306735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.15773868560791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05713801085948944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07481466233730316,
      "backward_entropy": 0.006469853222370148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8454182147979736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05716288834810257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07473854720592499,
      "backward_entropy": 0.00647407876593726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8135414123535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05718724802136421,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07466490566730499,
      "backward_entropy": 0.006478397973946163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5330772399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05721113830804825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07459354400634766,
      "backward_entropy": 0.00648291887981551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.990427494049072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057233888655900955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07452806085348129,
      "backward_entropy": 0.006486688341413226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.178847312927246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057257089763879776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07445962727069855,
      "backward_entropy": 0.0064928898853915075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6911990642547607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05728142708539963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07438407838344574,
      "backward_entropy": 0.012890446398939406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.449540138244629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057305265218019485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07431107014417648,
      "backward_entropy": 0.006512075662612915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.432549476623535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05732805281877518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07424340397119522,
      "backward_entropy": 0.0065220291061060766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.98219108581543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734977498650551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0741814374923706,
      "backward_entropy": 0.006530433893203735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.117054462432861,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05737265571951866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07411254197359085,
      "backward_entropy": 0.006540726338114057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.542635917663574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057397108525037766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07403478026390076,
      "backward_entropy": 0.01279638069016593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.673608779907227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057421036064624786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07395963370800018,
      "backward_entropy": 0.006560805120638439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7832183837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05744509398937225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0738835334777832,
      "backward_entropy": 0.006569934742791312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.72998571395874,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05746990814805031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07380301505327225,
      "backward_entropy": 0.006578567836965833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1574043035507202,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05749542638659477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07371821999549866,
      "backward_entropy": 0.0065873488783836365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3908283710479736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575190894305706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07364306598901749,
      "backward_entropy": 0.006597302321876798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.691275596618652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05754218250513077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0735711008310318,
      "backward_entropy": 0.006605326064995357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.230964183807373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05756663531064987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0734916478395462,
      "backward_entropy": 0.006611519626208714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.478969573974609,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575898177921772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07341916859149933,
      "backward_entropy": 0.006616498742784772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1926462650299072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0576137937605381,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07334180176258087,
      "backward_entropy": 0.006621743419340679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.383688449859619,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05763649567961693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07327160239219666,
      "backward_entropy": 0.00662511054958616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2766523361206055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057659946382045746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07319705188274384,
      "backward_entropy": 0.012542083859443665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.334048748016357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768335238099098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07312296330928802,
      "backward_entropy": 0.006627491010086877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.194087505340576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05770811066031456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0730406865477562,
      "backward_entropy": 0.0066284409591129845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.149962902069092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057732753455638885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07295899093151093,
      "backward_entropy": 0.006628433508532388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0740530490875244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05775739252567291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07287658751010895,
      "backward_entropy": 0.006629619215215955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.062764883041382,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05778063088655472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07280252873897552,
      "backward_entropy": 0.006628707051277161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032790184020996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05780329555273056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07273133099079132,
      "backward_entropy": 0.006627509104354041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.966482162475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057827431708574295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07265079766511917,
      "backward_entropy": 0.006630745849439076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.956904888153076,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057853419333696365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07255914807319641,
      "backward_entropy": 0.006636007555893489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.846719264984131,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05787903442978859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07246998697519302,
      "backward_entropy": 0.006638989916869572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9499592781066895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05790581926703453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07237289845943451,
      "backward_entropy": 0.0066463228847299305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8765320777893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057931069284677505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0722845122218132,
      "backward_entropy": 0.006653371666158948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9057952165603638,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057955604046583176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07219986617565155,
      "backward_entropy": 0.006661813706159592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7516088485717773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05797895789146423,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07212114334106445,
      "backward_entropy": 0.012159093150070735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.557326793670654,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0580022893846035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07204240560531616,
      "backward_entropy": 0.006682517273085458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.764073610305786,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058026738464832306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07195687294006348,
      "backward_entropy": 0.0066920194242681775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.538285732269287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05805046856403351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07187522947788239,
      "backward_entropy": 0.0121005294578416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7102413177490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05807476118206978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07178960740566254,
      "backward_entropy": 0.00671199443084853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6763241291046143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05809825658798218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07170868664979935,
      "backward_entropy": 0.012061744928359985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6535258293151855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058121208101511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07163015007972717,
      "backward_entropy": 0.006731428738151278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.631666898727417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05814354494214058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07155495882034302,
      "backward_entropy": 0.012025845902306693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025812719017267227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058165207505226135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07148393988609314,
      "backward_entropy": 0.012002734201295035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.43064022064209,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.058184776455163956,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07142452895641327,
      "backward_entropy": 0.09899752480643136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.244828701019287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05820457637310028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07136358320713043,
      "backward_entropy": 0.006766626877444131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.874746799468994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058225080370903015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07129859924316406,
      "backward_entropy": 0.011934676340648107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.151235580444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058247312903404236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07122328132390976,
      "backward_entropy": 0.006776638329029083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.935376167297363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058270279318094254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07114222645759583,
      "backward_entropy": 0.006784736577953611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4581191539764404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058294158428907394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07105567306280136,
      "backward_entropy": 0.011861846915313176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.624383568763733,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0583171471953392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07097487151622772,
      "backward_entropy": 0.006794347294739315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4084465503692627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05833898484706879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.070900097489357,
      "backward_entropy": 0.0067993950630937305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1595230102539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05836007744073868,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07083038240671158,
      "backward_entropy": 0.09899711608886719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.357304573059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05838124081492424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07075951248407364,
      "backward_entropy": 0.00680364402277129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5628924369812012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058401789516210556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07069247215986252,
      "backward_entropy": 0.0068046338856220245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7901231050491333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058421339839696884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07063096761703491,
      "backward_entropy": 0.006806058543069022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.53706693649292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05843939259648323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07057861983776093,
      "backward_entropy": 0.006806771670069013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2754106521606445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05845661088824272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07053117454051971,
      "backward_entropy": 0.006806522607803345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2504987716674805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05847347900271416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07048654556274414,
      "backward_entropy": 0.006802770708288465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4990729093551636,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05849017575383186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07044263184070587,
      "backward_entropy": 0.0067989858133452276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.941577911376953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05850613862276077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07040320336818695,
      "backward_entropy": 0.0989889417375837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.915350914001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058522529900074005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0703609436750412,
      "backward_entropy": 0.006789342633315495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.173675537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058539338409900665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07031582295894623,
      "backward_entropy": 0.0067851852093424115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8647494316101074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05855602025985718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07027098536491394,
      "backward_entropy": 0.006782190608126777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24860143661499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05857308208942413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0702233612537384,
      "backward_entropy": 0.011330437447343553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5075795650482178,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058591410517692566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07016824185848236,
      "backward_entropy": 0.011291381503854479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1600189208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05861048027873039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07010787725448608,
      "backward_entropy": 0.006773851279701505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.076418876647949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05863077566027641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07003950327634811,
      "backward_entropy": 0.006773812962429864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.048801898956299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05865040048956871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06997554004192352,
      "backward_entropy": 0.00677121856382915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.035004138946533,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05866963788866997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06991346925497055,
      "backward_entropy": 0.006770804524421692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0094358921051025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058689869940280914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06984542310237885,
      "backward_entropy": 0.006768988711493356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.985221266746521,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05870949849486351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.069781094789505,
      "backward_entropy": 0.011081908430371965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9635376930236816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05872868746519089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06971903145313263,
      "backward_entropy": 0.011048657553536552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6632676124572754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058747511357069016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06965875625610352,
      "backward_entropy": 0.006767134581293378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2969324588775635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058765050023794174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06960578262805939,
      "backward_entropy": 0.006771361189229148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2814514636993408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05878164991736412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0695592612028122,
      "backward_entropy": 0.006772632045405251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5105316638946533,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05879754573106766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0695168599486351,
      "backward_entropy": 0.0067741333373955315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6442148685455322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058813925832509995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06947064399719238,
      "backward_entropy": 0.010909455163138253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.245920181274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05882904306054115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06943247467279434,
      "backward_entropy": 0.006781489721366337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8426744937896729,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058843668550252914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06939699500799179,
      "backward_entropy": 0.006785841924803597,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.795077464319766,
    "avg_log_Z": -0.057808673568069936,
    "success_rate": 1.0,
    "avg_reward": 72.9,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.18,
      "2": 0.79
    },
    "avg_forward_entropy": 0.0726637789607048,
    "avg_backward_entropy": 0.010402678128864086,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}