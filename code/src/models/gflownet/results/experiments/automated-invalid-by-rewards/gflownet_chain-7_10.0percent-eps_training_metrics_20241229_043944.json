{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09886564527239118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09894756759916033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.90826416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665704429149628,
      "backward_entropy": 0.09888061455317906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.8692169189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000001202570274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664746284484863,
      "backward_entropy": 0.09894930464880806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.81222534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019999989308416843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663765788078308,
      "backward_entropy": 0.09888476984841484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.05165100097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002979914133902639,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13662773370742798,
      "backward_entropy": 0.09887964384896415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.0203857421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0003963101771660149,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366174966096878,
      "backward_entropy": 0.09888408865247454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.44390869140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004956984776072204,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13660693168640137,
      "backward_entropy": 0.09888849939618792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.86709594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000595823279581964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13659608364105225,
      "backward_entropy": 0.09895745345524379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.16383361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006964349304325879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365850269794464,
      "backward_entropy": 0.09895907981055123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.58990478515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007969588623382151,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365736871957779,
      "backward_entropy": 0.09890122924532209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.54937744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008973510120995343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656216859817505,
      "backward_entropy": 0.09896225588662284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.47555541992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009976404253393412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13655027747154236,
      "backward_entropy": 0.09890918220792498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.1827392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010989948641508818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653779029846191,
      "backward_entropy": 0.09896515096936907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.96388244628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012006245087832212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13652506470680237,
      "backward_entropy": 0.09896654742104667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013018724275752902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651210069656372,
      "backward_entropy": 0.09890426908220563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.66387939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014034771593287587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364988386631012,
      "backward_entropy": 0.09890586989266532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.24269104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015066280029714108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648509979248047,
      "backward_entropy": 0.09890757288251605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.41114807128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016087917611002922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13647133111953735,
      "backward_entropy": 0.09890917369297572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.91363525390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017086374573409557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13645750284194946,
      "backward_entropy": 0.09893558706556048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.57147216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018102851463481784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13644321262836456,
      "backward_entropy": 0.09891223055975777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.6848907470703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019126690458506346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13642866909503937,
      "backward_entropy": 0.09894226278577532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.01197814941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020143131259828806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641393184661865,
      "backward_entropy": 0.09894546440669469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.64129638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002116760239005089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13639891147613525,
      "backward_entropy": 0.09891676902770996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.35337829589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002216413151472807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13638398051261902,
      "backward_entropy": 0.09898074184145246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.87271118164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002314722863957286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13636915385723114,
      "backward_entropy": 0.0989544221333095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.82748413085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00241436087526381,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13635438680648804,
      "backward_entropy": 0.09898336444582258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.17706298828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025151302106678486,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13633909821510315,
      "backward_entropy": 0.09895996536527361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.46998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002614184282720089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632380962371826,
      "backward_entropy": 0.09896257093974523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.3531036376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027134655974805355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630829751491547,
      "backward_entropy": 0.09892501149858747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.1929473876953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0028146724216639996,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13629233837127686,
      "backward_entropy": 0.09896761178970337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.4114532470703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002914866665378213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13627633452415466,
      "backward_entropy": 0.09896993637084961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.25193786621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003015268826857209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362600326538086,
      "backward_entropy": 0.0989288602556501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.2701416015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00311508821323514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362435519695282,
      "backward_entropy": 0.09899154731205531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.1689910888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003217445919290185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13622653484344482,
      "backward_entropy": 0.09893132959093366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.6987609863281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033159200102090836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13620972633361816,
      "backward_entropy": 0.09897831508091517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.0071563720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034171841107308865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13619232177734375,
      "backward_entropy": 0.09899437427520752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.0564270019531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003520101308822632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617445528507233,
      "backward_entropy": 0.09898218086787633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1435546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036250969860702753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361560970544815,
      "backward_entropy": 0.09898407118661064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.15614318847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0037266789004206657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361379325389862,
      "backward_entropy": 0.09893710272652763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.018310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038288813084363937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13611944019794464,
      "backward_entropy": 0.09893806491579328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.59170532226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003930865786969662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610047101974487,
      "backward_entropy": 0.09893897601536342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.99761962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004030487034469843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360810399055481,
      "backward_entropy": 0.09899866580963135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.3469696044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004130368586629629,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13606107234954834,
      "backward_entropy": 0.0989921944481986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.51589965820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004230220802128315,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13604065775871277,
      "backward_entropy": 0.0989936079297747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.8605499267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004331166390329599,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13601964712142944,
      "backward_entropy": 0.09899498735155378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.27561950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004432817921042442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13599814474582672,
      "backward_entropy": 0.0990008967263358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.7627716064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004534386098384857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597626984119415,
      "backward_entropy": 0.09894355705806188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.7759246826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00463596498593688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13595399260520935,
      "backward_entropy": 0.09900185891560145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.52650451660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004738337360322475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13593140244483948,
      "backward_entropy": 0.09900229317801339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.0128631591797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004840261768549681,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13590854406356812,
      "backward_entropy": 0.09900108405521937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.83941650390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004941874649375677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13588541746139526,
      "backward_entropy": 0.09900300843375069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.33287048339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005046673119068146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13586145639419556,
      "backward_entropy": 0.09894680976867676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.28700256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005149872042238712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358374059200287,
      "backward_entropy": 0.098947354725429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.3498992919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005251642316579819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581326603889465,
      "backward_entropy": 0.0989478315625872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.8352813720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005353156011551619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578879833221436,
      "backward_entropy": 0.0990041834967477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.42172241210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005454530008137226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357639878988266,
      "backward_entropy": 0.09900441340037755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.7893829345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005556854885071516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573862612247467,
      "backward_entropy": 0.09894915989467076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.73052978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00566054368391633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13571269810199738,
      "backward_entropy": 0.09894956861223493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.56222534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005765422713011503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356862485408783,
      "backward_entropy": 0.09894993475505284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.045654296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005869555287063122,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356595754623413,
      "backward_entropy": 0.09900520529065814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.37733459472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0059731099754571915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13563252985477448,
      "backward_entropy": 0.09900535004479545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.86517333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0060750218108296394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13560540974140167,
      "backward_entropy": 0.09900546073913574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.66685485839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006175560411065817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355781853199005,
      "backward_entropy": 0.09900554588862828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.05169677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006271775346249342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13555140793323517,
      "backward_entropy": 0.09900556291852679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.71588134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0063713002018630505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13552358746528625,
      "backward_entropy": 0.0990055969783238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.69308471679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006471394561231136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354953646659851,
      "backward_entropy": 0.09901305607386998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.73377990722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0065684993751347065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354672908782959,
      "backward_entropy": 0.09900558846337455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.1548309326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006667648907750845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354384571313858,
      "backward_entropy": 0.09895098209381104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.48287963867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006767682731151581,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13540907204151154,
      "backward_entropy": 0.09900551182883126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.67205810546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006865417119115591,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13537977635860443,
      "backward_entropy": 0.09901463985443115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.39451599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006963629741221666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13534994423389435,
      "backward_entropy": 0.0989506755556379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.99441528320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007059730123728514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13532018661499023,
      "backward_entropy": 0.09895048822675433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.34468841552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007155334111303091,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13529041409492493,
      "backward_entropy": 0.09895038604736328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.7992401123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0072460779920220375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352611482143402,
      "backward_entropy": 0.09895014762878418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.22134399414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007335595786571503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352316290140152,
      "backward_entropy": 0.09900466884885516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.59808349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00742392148822546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13520188629627228,
      "backward_entropy": 0.09900447300502233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.31529235839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007508758455514908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351725459098816,
      "backward_entropy": 0.09894901514053345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.5484161376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007595566101372242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351425051689148,
      "backward_entropy": 0.09894857236317225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.94244384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007685619406402111,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13511145114898682,
      "backward_entropy": 0.09900374923433576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.59078979492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0077773830853402615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13508003950119019,
      "backward_entropy": 0.09900350230080741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.36141967773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00786454789340496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13504944741725922,
      "backward_entropy": 0.09900318724768502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.528076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00795162282884121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13501855731010437,
      "backward_entropy": 0.09894631590162005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.4891815185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00803576223552227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349879652261734,
      "backward_entropy": 0.09894554104123797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.51324462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008118456229567528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13495729863643646,
      "backward_entropy": 0.0990018333707537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.33013916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008201250806450844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13492617011070251,
      "backward_entropy": 0.09900129692895072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.61154174804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008283725008368492,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348947137594223,
      "backward_entropy": 0.09901726245880127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.98101043701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0083653898909688,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13486313819885254,
      "backward_entropy": 0.09901731354849679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.66839599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008443809114396572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13483189046382904,
      "backward_entropy": 0.09899943215506417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.62628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008522294461727142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348002851009369,
      "backward_entropy": 0.09899872541427612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.07986450195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008600854314863682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347683221101761,
      "backward_entropy": 0.09899798461369105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.4708709716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008678176440298557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347363293170929,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.4987335205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00875550601631403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13470396399497986,
      "backward_entropy": 0.09899638380323138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.90525817871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008833076804876328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134671151638031,
      "backward_entropy": 0.09893488883972168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.48214721679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0089133745059371,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13463717699050903,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.7516326904297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008993849158287048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13460271060466766,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.74853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009072719141840935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13456818461418152,
      "backward_entropy": 0.09899300336837769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.75421142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00915423035621643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13453252613544464,
      "backward_entropy": 0.0989921944481986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.70425415039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009236924350261688,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13449609279632568,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.6569366455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009320688433945179,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13445895910263062,
      "backward_entropy": 0.09899051700319562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.53140258789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009406822733581066,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13442090153694153,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.62596130371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009493463672697544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13438206911087036,
      "backward_entropy": 0.09892455169132777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.48748779296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009579581208527088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13434277474880219,
      "backward_entropy": 0.09898785182407924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.61399841308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009667851030826569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13430249691009521,
      "backward_entropy": 0.09892191205705915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.62158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009754217229783535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13426239788532257,
      "backward_entropy": 0.09898597002029419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.34266662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009840553626418114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13422177731990814,
      "backward_entropy": 0.09891913618360247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9900665283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00992152001708746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13418236374855042,
      "backward_entropy": 0.09891756091799055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.23385620117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0100029231980443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13414230942726135,
      "backward_entropy": 0.09891600268227714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.21746826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010085619054734707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13410139083862305,
      "backward_entropy": 0.0989816529410226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.35073852539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010168028995394707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13406015932559967,
      "backward_entropy": 0.09891274997166224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.7256622314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010249173268675804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1340188831090927,
      "backward_entropy": 0.09897925172533308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.67616271972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010330555960536003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1339767575263977,
      "backward_entropy": 0.09897797448294503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.55577087402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010412163101136684,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13393400609493256,
      "backward_entropy": 0.09901712621961321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.1592559814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010493755340576172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13389067351818085,
      "backward_entropy": 0.09890541008540563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.92906188964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010572456754744053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13384783267974854,
      "backward_entropy": 0.0989032472882952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.6863250732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010647859424352646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13380557298660278,
      "backward_entropy": 0.09897222689219884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.2494659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010723115876317024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13376279175281525,
      "backward_entropy": 0.09889863218579974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.66851806640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010796848684549332,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13372088968753815,
      "backward_entropy": 0.09901666641235352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.10842895507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01087086834013462,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13367782533168793,
      "backward_entropy": 0.09896717752729144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.9732208251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01094700489193201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13363313674926758,
      "backward_entropy": 0.09889154774802071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.5338134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01102285273373127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13358765840530396,
      "backward_entropy": 0.09896366085324969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.88006591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011100772768259048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13354066014289856,
      "backward_entropy": 0.09888642174857003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.53875732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011178242042660713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1334930807352066,
      "backward_entropy": 0.0989600419998169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.93328857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011254138313233852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334453821182251,
      "backward_entropy": 0.09888087000165667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.34970092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01133051235228777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333969533443451,
      "backward_entropy": 0.09895621027265276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.82867431640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011402911506593227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13334938883781433,
      "backward_entropy": 0.09901571273803711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.0370635986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011476170271635056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13330140709877014,
      "backward_entropy": 0.09887149504252843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.86471557617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01154914777725935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13325360417366028,
      "backward_entropy": 0.09894985812050956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.74127197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011623434722423553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13320471346378326,
      "backward_entropy": 0.09886465753827776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.35719299316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011698668822646141,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13315486907958984,
      "backward_entropy": 0.09901507411684309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.33341217041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011773332953453064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13310469686985016,
      "backward_entropy": 0.09885741983141218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.8650894165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011845193803310394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13305507600307465,
      "backward_entropy": 0.09894074712480817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.08816528320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011912316083908081,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13300678133964539,
      "backward_entropy": 0.09893815858023507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.89376068115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011983795091509819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13295617699623108,
      "backward_entropy": 0.09893562112535749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.73703002929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012053428217768669,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1329057216644287,
      "backward_entropy": 0.0990140438079834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.8936004638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01213089283555746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13285154104232788,
      "backward_entropy": 0.09901387350899833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.92579650878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012211635708808899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13279545307159424,
      "backward_entropy": 0.09892807688031878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.2207260131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012290576472878456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13273951411247253,
      "backward_entropy": 0.09892555645533971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.40440368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012364218011498451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13268525898456573,
      "backward_entropy": 0.09882703849247523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.62033081054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012440153397619724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13262943923473358,
      "backward_entropy": 0.09882307052612305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.13180541992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012519575655460358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13257154822349548,
      "backward_entropy": 0.09881917067936488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.68878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01259697787463665,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13251397013664246,
      "backward_entropy": 0.0990128857748849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.21774291992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012672943994402885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13245640695095062,
      "backward_entropy": 0.09891157490866524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.56658172607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012751249596476555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13239717483520508,
      "backward_entropy": 0.098908645766122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.04155731201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01282445713877678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13233965635299683,
      "backward_entropy": 0.0988025154386248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.47064971923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012893679551780224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13228343427181244,
      "backward_entropy": 0.09879801954541888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.38235473632812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012959182262420654,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13222838938236237,
      "backward_entropy": 0.09901148080825806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.40667724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013024229556322098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13217297196388245,
      "backward_entropy": 0.09889464718954903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8460235595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013089132495224476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13211701810359955,
      "backward_entropy": 0.0988908324922834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.62374877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013154525309801102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13206025958061218,
      "backward_entropy": 0.09888693264552526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.88258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013218379579484463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13200363516807556,
      "backward_entropy": 0.09888286249978202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.6544189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01328336726874113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13194584846496582,
      "backward_entropy": 0.09876653126307897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.03152465820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013351986184716225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13188567757606506,
      "backward_entropy": 0.09887473923819405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.32659912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013419641181826591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13182538747787476,
      "backward_entropy": 0.09875544479915074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.85205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013488463126122952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13176387548446655,
      "backward_entropy": 0.09874993562698364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.17301177978516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013560185208916664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1317003071308136,
      "backward_entropy": 0.09900764056614467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8321990966797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013628249987959862,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13163800537586212,
      "backward_entropy": 0.09900720630373273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.4575653076172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013695437461137772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1315755695104599,
      "backward_entropy": 0.09900673798152379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.41735076904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013762499205768108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13151253759860992,
      "backward_entropy": 0.09872624703816005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.02366638183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01382315345108509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13145232200622559,
      "backward_entropy": 0.09884369373321533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.86932373046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013886755332350731,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13138988614082336,
      "backward_entropy": 0.09883874654769897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.7954559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013951756060123444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313260793685913,
      "backward_entropy": 0.09883378233228411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.76976013183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014017019420862198,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13126152753829956,
      "backward_entropy": 0.09900425161634173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.10098266601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01408454217016697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13119497895240784,
      "backward_entropy": 0.09882376875196185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.57054138183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014153714291751385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1311269849538803,
      "backward_entropy": 0.09881877899169922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.04345703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01422350574284792,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.131058007478714,
      "backward_entropy": 0.09900298288890294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.70364379882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014300844632089138,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13098418712615967,
      "backward_entropy": 0.09900275298527308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.93658447265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014380991458892822,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13090810179710388,
      "backward_entropy": 0.09900262526103429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.27362060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014459779486060143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13083210587501526,
      "backward_entropy": 0.09880030155181885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.54112243652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014536956325173378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13075634837150574,
      "backward_entropy": 0.09865835734776088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.99433898925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014612027443945408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1306811422109604,
      "backward_entropy": 0.09879039015088763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.39777374267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014681723900139332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1306084841489792,
      "backward_entropy": 0.09864412886755806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.63546752929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014745119027793407,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13053900003433228,
      "backward_entropy": 0.09900084563664027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9390869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014807580970227718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1304693967103958,
      "backward_entropy": 0.09877164874758039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.38697814941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014871129766106606,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1303984373807907,
      "backward_entropy": 0.09899953433445521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.95916748046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014930577017366886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13032938539981842,
      "backward_entropy": 0.09875767571585518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.376220703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014990679919719696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1302592158317566,
      "backward_entropy": 0.09875036137444633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.92254638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015049939975142479,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13018888235092163,
      "backward_entropy": 0.09874282564435687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.15765380859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015110170468688011,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13011735677719116,
      "backward_entropy": 0.09873531545911517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.06488037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01517320703715086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1300431191921234,
      "backward_entropy": 0.09872788190841675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.05715942382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015240062959492207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1299658715724945,
      "backward_entropy": 0.09899510656084333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.58180236816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015310619957745075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12988585233688354,
      "backward_entropy": 0.09871375560760498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.05325317382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01538490317761898,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12980273365974426,
      "backward_entropy": 0.09899428912571498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.15785217285156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015459839254617691,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12971846759319305,
      "backward_entropy": 0.0989939911024911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.47608947753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015533044934272766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12963466346263885,
      "backward_entropy": 0.09869357517787389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.84417724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015601087361574173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12955355644226074,
      "backward_entropy": 0.09868584360395159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.5624237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01566886343061924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12947188317775726,
      "backward_entropy": 0.09851038455963135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.49663543701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015741856768727303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12938599288463593,
      "backward_entropy": 0.09867079768862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.9164276123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015810271725058556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12930256128311157,
      "backward_entropy": 0.09866279363632202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.64582061767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01588398590683937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1292155236005783,
      "backward_entropy": 0.0984827961240496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.56633758544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015953686088323593,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12913066148757935,
      "backward_entropy": 0.09864717721939087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4731903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016021380200982094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12904690206050873,
      "backward_entropy": 0.09846198558807373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.1103973388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016088875010609627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12896397709846497,
      "backward_entropy": 0.09845123972211565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.57841491699219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01615854911506176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1288786679506302,
      "backward_entropy": 0.09898885658809117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.28848266601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016223277896642685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12879624962806702,
      "backward_entropy": 0.09861137185777936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.82913208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01628812775015831,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12871302664279938,
      "backward_entropy": 0.09860140936715263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.31012725830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016351625323295593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12863004207611084,
      "backward_entropy": 0.09898602962493896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.1867218017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01641405187547207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12854710221290588,
      "backward_entropy": 0.09838810988834926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.88290405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016480961814522743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12846030294895172,
      "backward_entropy": 0.09857017653329032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.9064483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016549134626984596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12837180495262146,
      "backward_entropy": 0.09836247989109584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.588134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01661684177815914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12828291952610016,
      "backward_entropy": 0.09854962144579206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.13055419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0166851244866848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12819284200668335,
      "backward_entropy": 0.09853913102831159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.74969482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01675442047417164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12810134887695312,
      "backward_entropy": 0.09852850437164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.19163513183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016827547922730446,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280062198638916,
      "backward_entropy": 0.09898074184145246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.0989532470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016902050003409386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12790930271148682,
      "backward_entropy": 0.09829837935311454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.64146423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016979999840259552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12780901789665222,
      "backward_entropy": 0.09849921294621058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.79129028320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01705709844827652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12770864367485046,
      "backward_entropy": 0.09848946332931519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.65836334228516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0171321053057909,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12760911881923676,
      "backward_entropy": 0.09897969450269427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.23900604248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017204947769641876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12751059234142303,
      "backward_entropy": 0.0982494865145002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.87107849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017271481454372406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12741635739803314,
      "backward_entropy": 0.09823405742645264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.01101684570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01734100840985775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.127318874001503,
      "backward_entropy": 0.09844253744397845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.08302307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017409075051546097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12722186744213104,
      "backward_entropy": 0.0982037101473127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.34976196289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017476752400398254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12712439894676208,
      "backward_entropy": 0.09818737847464425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.66531372070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01754586212337017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12702494859695435,
      "backward_entropy": 0.09817103828702654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.08355712890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01761583797633648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12692400813102722,
      "backward_entropy": 0.09815410205296107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.6431121826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017689550295472145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12681926786899567,
      "backward_entropy": 0.09813766820090157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.93295288085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017764246091246605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12671300768852234,
      "backward_entropy": 0.09897201401846749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.40444946289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017838777974247932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1266060620546341,
      "backward_entropy": 0.09810531139373779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.67706298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01791393756866455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1264978051185608,
      "backward_entropy": 0.09833557265145439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.49769592285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017992330715060234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12638598680496216,
      "backward_entropy": 0.09832290240696498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.93057250976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0180687103420496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12627515196800232,
      "backward_entropy": 0.09830934660775321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.40374755859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018148068338632584,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12616094946861267,
      "backward_entropy": 0.09896951062338692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.5751724243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01822623796761036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12604697048664093,
      "backward_entropy": 0.0982821158000401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.21372985839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018300775438547134,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12593543529510498,
      "backward_entropy": 0.09896806308201381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.86556243896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018378926441073418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12581992149353027,
      "backward_entropy": 0.09825183664049421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.86502075195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018453937023878098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12570641934871674,
      "backward_entropy": 0.09823541981833321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.93544006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018526414409279823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1255943924188614,
      "backward_entropy": 0.09821775981358119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.853271484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018597204238176346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12548311054706573,
      "backward_entropy": 0.09896366936819893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7742919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018672317266464233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12536713480949402,
      "backward_entropy": 0.09789769990103585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.69256591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018746405839920044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12525129318237305,
      "backward_entropy": 0.09816379206521171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.27955627441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018819579854607582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12513548135757446,
      "backward_entropy": 0.09785109758377075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.64093017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01889479160308838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1250169575214386,
      "backward_entropy": 0.09812586648123604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.96456909179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018971692770719528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12489600479602814,
      "backward_entropy": 0.09810706547328404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.49758911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019046340137720108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12477652728557587,
      "backward_entropy": 0.09777711118970599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.4127655029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019120624288916588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12465667724609375,
      "backward_entropy": 0.09775136198316302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.56404113769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01919458620250225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12453633546829224,
      "backward_entropy": 0.09772506781986781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.22997283935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019263235852122307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1244204193353653,
      "backward_entropy": 0.0980215242930821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.95903015136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019329391419887543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12430629134178162,
      "backward_entropy": 0.0979964988572257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.8776092529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019389605149626732,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12419740110635757,
      "backward_entropy": 0.09763172694614955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.03546142578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01945430040359497,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12408299744129181,
      "backward_entropy": 0.09894298655646187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.4725341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01952269673347473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12396431714296341,
      "backward_entropy": 0.0975672687802996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.21682739257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01959606446325779,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12384000420570374,
      "backward_entropy": 0.0989394017628261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.1366729736328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019671810790896416,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12371257692575455,
      "backward_entropy": 0.09893827778952462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.5305938720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019746676087379456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1235852912068367,
      "backward_entropy": 0.09748193195887975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.56137084960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01982392556965351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12345480173826218,
      "backward_entropy": 0.09782430103846959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.49300384521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019900597631931305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1233242005109787,
      "backward_entropy": 0.09780034848621913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.7721405029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019973397254943848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12319682538509369,
      "backward_entropy": 0.09739123071943011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.28292083740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020045628771185875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12306924164295197,
      "backward_entropy": 0.09735707725797381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.43563842773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020114127546548843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12294483184814453,
      "backward_entropy": 0.0973194922719683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.48721313476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020178325474262238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12282423675060272,
      "backward_entropy": 0.09728004251207624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.12247467041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020244669169187546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12270070612430573,
      "backward_entropy": 0.09764860357557024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.03646850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02031003125011921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12257743626832962,
      "backward_entropy": 0.09761432238987514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.9234161376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02037835866212845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12245018035173416,
      "backward_entropy": 0.09716277463095528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.94912719726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020449355244636536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1223192811012268,
      "backward_entropy": 0.09754773548671178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.86215209960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020527411252260208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12218023836612701,
      "backward_entropy": 0.09751856327056885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.16483306884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020609991624951363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1220356673002243,
      "backward_entropy": 0.09749168157577515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.3136215209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020689820870757103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12189342081546783,
      "backward_entropy": 0.09701884644372123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.98590087890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020765943452715874,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12175452709197998,
      "backward_entropy": 0.09890615940093994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.81405639648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02084469236433506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12161228060722351,
      "backward_entropy": 0.097399183682033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.28582000732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020918138325214386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1214752346277237,
      "backward_entropy": 0.09736428941999163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.97442626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02098696306347847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1213427260518074,
      "backward_entropy": 0.09732730899538312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.62454223632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021055813878774643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12120945751667023,
      "backward_entropy": 0.09681308269500732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.17141723632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02112034521996975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12108045071363449,
      "backward_entropy": 0.09676427500588554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.6326446533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02118145301938057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1209547370672226,
      "backward_entropy": 0.09671344075884138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.79925537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021249203011393547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12082074582576752,
      "backward_entropy": 0.09666624239512853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.95742797851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02131848968565464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12068430334329605,
      "backward_entropy": 0.09661878006798881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.294189453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021387621760368347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12054727971553802,
      "backward_entropy": 0.09887706381934029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.57952880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02145969308912754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12040624022483826,
      "backward_entropy": 0.09704506397247314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.18133544921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02153743803501129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025811523199081,
      "backward_entropy": 0.09647834300994873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.82591247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02161433733999729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1201103925704956,
      "backward_entropy": 0.0969718439238412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.63018798828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02169308252632618,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11995980143547058,
      "backward_entropy": 0.09693507637296404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.85023498535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021772420033812523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11980834603309631,
      "backward_entropy": 0.09689826624734062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.42266845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02185075916349888,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11965726315975189,
      "backward_entropy": 0.09628662892750331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.44503021240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021924011409282684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11951181292533875,
      "backward_entropy": 0.09623236315590995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.51663208007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02199408784508705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11936961114406586,
      "backward_entropy": 0.09617470843451363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.95420837402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02206302434206009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11922816932201385,
      "backward_entropy": 0.09611586162022182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.73712921142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022132180631160736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11908585578203201,
      "backward_entropy": 0.0960561888558524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.00362396240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022198736667633057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1189461499452591,
      "backward_entropy": 0.09599376576287406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.07182312011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022261062636971474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11881111562252045,
      "backward_entropy": 0.09655250821794782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.90519714355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022322727367281914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186763122677803,
      "backward_entropy": 0.09585624081747872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9092559814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022378116846084595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11854895949363708,
      "backward_entropy": 0.09642666578292847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.12306213378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022436361759901047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1184173971414566,
      "backward_entropy": 0.09570639474051339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.7153549194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022492149844765663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11828836798667908,
      "backward_entropy": 0.09629361970084054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.03318786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022547949105501175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11815927177667618,
      "backward_entropy": 0.09622366939272199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.34697723388672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02260642871260643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11802635341882706,
      "backward_entropy": 0.09615395750318255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.9268798828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02266227826476097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11789675056934357,
      "backward_entropy": 0.09608021804264613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.29530334472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022719725966453552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11776454001665115,
      "backward_entropy": 0.09600797721317836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.71215057373047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02278018929064274,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11762802302837372,
      "backward_entropy": 0.09877213409968785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.43710327148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022840064018964767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11749187856912613,
      "backward_entropy": 0.09511424813951765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.56546783447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022902246564626694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11735236644744873,
      "backward_entropy": 0.09579316207340785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.49234008789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022960176691412926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11721806228160858,
      "backward_entropy": 0.09571409225463867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.19554138183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02301427535712719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1170884445309639,
      "backward_entropy": 0.09562890018735613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.10436248779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02306986413896084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11695640534162521,
      "backward_entropy": 0.09554331643240792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.50633239746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023120908066630363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11683004349470139,
      "backward_entropy": 0.09545115062168666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.03536987304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023167690262198448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11670894175767899,
      "backward_entropy": 0.09535268374851771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.66034698486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023217368870973587,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11658371984958649,
      "backward_entropy": 0.09868936879294259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.85499572753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023266304284334183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1164589673280716,
      "backward_entropy": 0.09428216729845319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.09413146972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023318227380514145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11632981896400452,
      "backward_entropy": 0.09506566183907646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.42591857910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023372067138552666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11619773507118225,
      "backward_entropy": 0.09405568667820521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.54193878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02343222126364708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11605708301067352,
      "backward_entropy": 0.09488368885857719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.13165283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023489171639084816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11592045426368713,
      "backward_entropy": 0.0938394410269601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.83181762695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023549461737275124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11577912420034409,
      "backward_entropy": 0.09373300416128975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.0329360961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023612109944224358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11563444137573242,
      "backward_entropy": 0.0936259457043239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.49816131591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023669704794883728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11549651622772217,
      "backward_entropy": 0.09351113864353724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.94187927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023726586252450943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11535979807376862,
      "backward_entropy": 0.093390839440482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.22351837158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023782378062605858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11522413045167923,
      "backward_entropy": 0.09431364706584386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.50370025634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02383670024573803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11509048193693161,
      "backward_entropy": 0.09420726128986903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.82936096191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02388920448720455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11495894938707352,
      "backward_entropy": 0.09409524713243757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.77536010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02394329570233822,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11482515931129456,
      "backward_entropy": 0.09398290940693446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.22227478027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02399543486535549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1146935522556305,
      "backward_entropy": 0.09386529241289411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.0594482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024049710482358932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11455892026424408,
      "backward_entropy": 0.09374945504324776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.05056762695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02409994788467884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442969739437103,
      "backward_entropy": 0.0924511466707502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.20304107666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024153802543878555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11429528892040253,
      "backward_entropy": 0.09230894701821464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.78334045410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024202823638916016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11416760087013245,
      "backward_entropy": 0.09337553807667323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.19241333007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024255599826574326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11403454840183258,
      "backward_entropy": 0.09200629166194371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.2732925415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02431192249059677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11389635503292084,
      "backward_entropy": 0.09313271726880755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.45172119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02436419017612934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11376394331455231,
      "backward_entropy": 0.09300497600010463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.98198699951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024422774091362953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11362281441688538,
      "backward_entropy": 0.09156385489872523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.78153991699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024480612948536873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11348270624876022,
      "backward_entropy": 0.09141021115439278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.0768280029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024533240124583244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11334991455078125,
      "backward_entropy": 0.09124548094613212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.14895629882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02459122985601425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11320970952510834,
      "backward_entropy": 0.09249600342341832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.30414581298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024647092446684837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11307238042354584,
      "backward_entropy": 0.0923599260193961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.94972229003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02469879388809204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11294102668762207,
      "backward_entropy": 0.09075893674577985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.49054718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02475224994122982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11280722916126251,
      "backward_entropy": 0.09207171201705933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.05929565429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024804551154375076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11267495900392532,
      "backward_entropy": 0.09041415793555123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.8162384033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024863226339221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11253398656845093,
      "backward_entropy": 0.09178754261561803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.7368392944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02492569014430046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11238804459571838,
      "backward_entropy": 0.09165421554020473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.67257690429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024982677772641182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1122499480843544,
      "backward_entropy": 0.08990170274462018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.15901947021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025044303387403488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11210561543703079,
      "backward_entropy": 0.08972607340131487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.49871826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02510465681552887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11196307837963104,
      "backward_entropy": 0.08954957553318568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.42200469970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02516370266675949,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11182236671447754,
      "backward_entropy": 0.09107015814099993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.86532592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02521761879324913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11168906092643738,
      "backward_entropy": 0.09090743746076312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9261703491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025269508361816406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11155876517295837,
      "backward_entropy": 0.0907371895653861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.54000854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025322239845991135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11142729967832565,
      "backward_entropy": 0.08877614566258021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.21800231933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02537272870540619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11129917204380035,
      "backward_entropy": 0.09038458551679339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.3122100830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02542712725698948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11116570234298706,
      "backward_entropy": 0.08835209267480033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.2069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02548649162054062,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11102558672428131,
      "backward_entropy": 0.09004523924418859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.84703063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025545289739966393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11088653653860092,
      "backward_entropy": 0.08987351826259068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.73729705810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0256052128970623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11074623465538025,
      "backward_entropy": 0.08773001602717809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.10626220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025663062930107117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11060889065265656,
      "backward_entropy": 0.08750964914049421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.38937377929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025718100368976593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11047586798667908,
      "backward_entropy": 0.0872828449521746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.91107177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025771213695406914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11034618318080902,
      "backward_entropy": 0.08911287784576416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.10530853271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025821994990110397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11021958291530609,
      "backward_entropy": 0.08889872687203544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.19552612304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02587474137544632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1100904643535614,
      "backward_entropy": 0.0980865444455828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.90192413330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025931067764759064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10995663702487946,
      "backward_entropy": 0.0884829078401838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.00365447998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02598648890852928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10982457548379898,
      "backward_entropy": 0.08826980420521327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.28832244873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026041794568300247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10969303548336029,
      "backward_entropy": 0.08805300508226667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.57136535644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026094231754541397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10956576466560364,
      "backward_entropy": 0.08782498325620379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.00827026367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026142437011003494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10944472253322601,
      "backward_entropy": 0.08758234977722168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.02303314208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026193778961896896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10931937396526337,
      "backward_entropy": 0.08500246490750994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.44387817382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026245616376399994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10919363796710968,
      "backward_entropy": 0.09794565609523229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.3297348022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026295131072402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10907125473022461,
      "backward_entropy": 0.08685532638004848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.0809097290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026344040408730507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10895015299320221,
      "backward_entropy": 0.08660446746008736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.14244842529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02639205940067768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10883044451475143,
      "backward_entropy": 0.08388502257210868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.148902893066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026433337479829788,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10872077941894531,
      "backward_entropy": 0.0978412117276873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.6446304321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02646704576909542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10862202942371368,
      "backward_entropy": 0.08577488149915423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.33871459960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026504114270210266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10851848125457764,
      "backward_entropy": 0.08548980099814278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.26773834228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02654203027486801,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10841377079486847,
      "backward_entropy": 0.08520440544400897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.9782485961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02658255770802498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1083054393529892,
      "backward_entropy": 0.08492582184927804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.83407211303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026623256504535675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1081971675157547,
      "backward_entropy": 0.08464197601590838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.04848098754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026659825816750526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10809491574764252,
      "backward_entropy": 0.08434210504804339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.84872817993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02669399604201317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10799625515937805,
      "backward_entropy": 0.08403047493525914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.5922393798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026725053787231445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10790200531482697,
      "backward_entropy": 0.08107233047485352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.19273376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02676190249621868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10779991745948792,
      "backward_entropy": 0.08340024948120117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.33403778076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026798024773597717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10769931972026825,
      "backward_entropy": 0.08308769975389753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.12086486816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02683761529624462,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10759420692920685,
      "backward_entropy": 0.08278063365391322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.89017486572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026882173493504524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10748301446437836,
      "backward_entropy": 0.08248405797140938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.86187744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02692527137696743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10737401247024536,
      "backward_entropy": 0.08218085765838623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.65853881835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02697022072970867,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10726321488618851,
      "backward_entropy": 0.08187982865742274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.75543212890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02702181413769722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.107143834233284,
      "backward_entropy": 0.08159795829227992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.18093872070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027081014588475227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10701501369476318,
      "backward_entropy": 0.07852503231593541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.0721435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0271441750228405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10688251256942749,
      "backward_entropy": 0.08108182464327131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.48237228393555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02720239944756031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10675741732120514,
      "backward_entropy": 0.07792279550007411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.589599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027255050837993622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10663938522338867,
      "backward_entropy": 0.07759356498718262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.539669036865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027310114353895187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.106519415974617,
      "backward_entropy": 0.0802187408719744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.43728256225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027358071878552437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1064099669456482,
      "backward_entropy": 0.07989834036145892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.27175903320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027403170242905617,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10630375146865845,
      "backward_entropy": 0.07956877776554652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.52197265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027450524270534515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10619552433490753,
      "backward_entropy": 0.07924372809273857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.2584228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027501041069626808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10608363896608353,
      "backward_entropy": 0.07590347528457642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.3019790649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027551451697945595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10597222298383713,
      "backward_entropy": 0.07556714330400739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.65972137451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027602536603808403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10586095601320267,
      "backward_entropy": 0.07522132566996984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.67670440673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027655720710754395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10574749112129211,
      "backward_entropy": 0.07487033094678607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.49915313720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027708200737833977,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10563580691814423,
      "backward_entropy": 0.07763297217232841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.53782653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02776096574962139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1055239588022232,
      "backward_entropy": 0.07730826309749059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.23330688476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02781178429722786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10541518032550812,
      "backward_entropy": 0.07697399173464094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.34634399414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02787007950246334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10529763996601105,
      "backward_entropy": 0.0734676548412868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.77395629882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027928315103054047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10518085211515427,
      "backward_entropy": 0.09707894495555333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.65731811523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027986688539385796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10506559908390045,
      "backward_entropy": 0.07601753302982875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.32181549072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028041861951351166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1049552634358406,
      "backward_entropy": 0.07235942568097796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.0701904296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028094712644815445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10484851896762848,
      "backward_entropy": 0.07529070547648839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.31021881103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028148818761110306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10474295914173126,
      "backward_entropy": 0.07492325135639735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.0410385131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028204794973134995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10463294386863708,
      "backward_entropy": 0.07457131147384644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.55986022949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028263209387660027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10451897978782654,
      "backward_entropy": 0.07079840557915824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.42576599121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028321439400315285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1044076532125473,
      "backward_entropy": 0.07388068948473249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.84278869628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02837560884654522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10430267453193665,
      "backward_entropy": 0.07351050206593104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.07401275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028431138023734093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10419648140668869,
      "backward_entropy": 0.0731425370488848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.70390319824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028488827869296074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10408852994441986,
      "backward_entropy": 0.07277629205158778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.38008117675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02854273095726967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10398592799901962,
      "backward_entropy": 0.07239291497639247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.59336853027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028594909235835075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10388598591089249,
      "backward_entropy": 0.06835154976163592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.28936004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02864443138241768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10379092395305634,
      "backward_entropy": 0.06790242024830409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.00774383544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028698790818452835,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10368992388248444,
      "backward_entropy": 0.0967855794089181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.73685455322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028754010796546936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10358859598636627,
      "backward_entropy": 0.07081821986607142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.81598663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028808537870645523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10348919779062271,
      "backward_entropy": 0.06662119286400932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.81477355957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028859296813607216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10339508950710297,
      "backward_entropy": 0.07001164129802159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.48179626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028909647837281227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10330336540937424,
      "backward_entropy": 0.06570649572781154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.23664855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028958721086382866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.103213369846344,
      "backward_entropy": 0.06916099786758423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.609466552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029004234820604324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10312870889902115,
      "backward_entropy": 0.06871874843324934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.46333312988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029047304764389992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10304708778858185,
      "backward_entropy": 0.06826897604124886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.53155517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02909116819500923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10296446084976196,
      "backward_entropy": 0.067824729851314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.660831451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029137618839740753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287801921367645,
      "backward_entropy": 0.06334083420889718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.21952056884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02918139658868313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279684513807297,
      "backward_entropy": 0.06695222003119332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.03578186035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029223894700407982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10271812975406647,
      "backward_entropy": 0.06649789639881679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.10069274902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02926824800670147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10263790190219879,
      "backward_entropy": 0.06605393545968193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.69175720214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029314083978533745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10255666077136993,
      "backward_entropy": 0.06560771805899483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.166709899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029359973967075348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10247630625963211,
      "backward_entropy": 0.06516098550387792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.12850189208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02940240688621998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10240013897418976,
      "backward_entropy": 0.060465293271200996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.52750015258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029447315260767937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10232062637805939,
      "backward_entropy": 0.06425735780170985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.92569732666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029490012675523758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10224419832229614,
      "backward_entropy": 0.059511704104287286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.80020904541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02953427843749523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.102166548371315,
      "backward_entropy": 0.0633553649697985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.39839172363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02957754395902157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209169238805771,
      "backward_entropy": 0.06290188005992345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.82672119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029623840004205704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201340913772583,
      "backward_entropy": 0.0624616231237139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.77645111083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029669348150491714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10193659365177155,
      "backward_entropy": 0.06201930556978498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.63001251220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02971731871366501,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185770690441132,
      "backward_entropy": 0.05719107389450073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.73227310180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029760055243968964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10178816318511963,
      "backward_entropy": 0.05669863734926496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.67710876464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029799623414874077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10172254592180252,
      "backward_entropy": 0.060656500714165826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.17971801757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029842834919691086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10165287554264069,
      "backward_entropy": 0.09589847496577672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.084964752197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029885657131671906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10158371925354004,
      "backward_entropy": 0.055223090308053155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.79690170288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029926853254437447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10151656717061996,
      "backward_entropy": 0.059270892824445455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.04331970214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029963046312332153,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1014566719532013,
      "backward_entropy": 0.09577134677342006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.03640747070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030001286417245865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10139431804418564,
      "backward_entropy": 0.053746163845062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.72544860839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030044348910450935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1013253927230835,
      "backward_entropy": 0.05789119856698172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.12635040283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030093614012002945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10124921053647995,
      "backward_entropy": 0.05748774324144636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.10459899902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030144577845931053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10117392241954803,
      "backward_entropy": 0.05709091254643032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.09400939941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030195802450180054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10109981149435043,
      "backward_entropy": 0.05668778930391584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.57901000976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030248943716287613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10102392733097076,
      "backward_entropy": 0.05628346545355661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.91305541992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030304016545414925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10094720125198364,
      "backward_entropy": 0.05588623455592564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.69650268554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030358223244547844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10087339580059052,
      "backward_entropy": 0.05547611628259931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.86981964111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03041115216910839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10080121457576752,
      "backward_entropy": 0.05506007160459246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.40165710449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030470654368400574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10072305798530579,
      "backward_entropy": 0.05466720887592861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.29544067382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03052838332951069,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10064877569675446,
      "backward_entropy": 0.05426536287580218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.80636596679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03058510832488537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10057529807090759,
      "backward_entropy": 0.04891401955059597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.9557876586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030647171661257744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10049520432949066,
      "backward_entropy": 0.05350242342267718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.43505859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030707255005836487,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10041794925928116,
      "backward_entropy": 0.09563313211713519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.46832275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03076518513262272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10034419596195221,
      "backward_entropy": 0.05274468234607151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.48910522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030826536938548088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1002662256360054,
      "backward_entropy": 0.05238223075866699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.0490493774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030888255685567856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1001880019903183,
      "backward_entropy": 0.05202998859541757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.650611877441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030948283150792122,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10011368244886398,
      "backward_entropy": 0.05167021495955331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.05927276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031004758551716805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10004422068595886,
      "backward_entropy": 0.046174470867429464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.07959747314453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031066110357642174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09997034072875977,
      "backward_entropy": 0.09566429683140346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.85370635986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03112799860537052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09989723563194275,
      "backward_entropy": 0.050549958433423726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.3089599609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03118862956762314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09982629120349884,
      "backward_entropy": 0.0501727078642164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.51349639892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031247759237885475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09975791722536087,
      "backward_entropy": 0.049791042293821065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.74578094482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03130681812763214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09969024360179901,
      "backward_entropy": 0.04941454104014805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.14908218383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031366217881441116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09962208569049835,
      "backward_entropy": 0.04378606166158404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.79634094238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03141970932483673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956087917089462,
      "backward_entropy": 0.04338065215519497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.00597381591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03146965801715851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09950635582208633,
      "backward_entropy": 0.04294516784804208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.659141540527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03151965141296387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0994512066245079,
      "backward_entropy": 0.042523430926459174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.86739349365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03156355768442154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09940500557422638,
      "backward_entropy": 0.042071708611079624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.48269653320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03161086514592171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09935387969017029,
      "backward_entropy": 0.041643070323126655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.706329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03166414424777031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09929585456848145,
      "backward_entropy": 0.0412391551903316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.90438079833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031712938100099564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0992446094751358,
      "backward_entropy": 0.040813710008348734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.31387710571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031768351793289185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09918518364429474,
      "backward_entropy": 0.04583141207695007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.915374755859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031822606921195984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09912773966789246,
      "backward_entropy": 0.045461054359163554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.40449523925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031873997300863266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09907515347003937,
      "backward_entropy": 0.03961916480745588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.90142059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03192697837948799,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09902243316173553,
      "backward_entropy": 0.039205197777066915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.7365493774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03197581321001053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09897562116384506,
      "backward_entropy": 0.044287575142724175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.89213562011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03202672675251961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09892849624156952,
      "backward_entropy": 0.043890220778329034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.15958023071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0320831798017025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0988747626543045,
      "backward_entropy": 0.03794001255716596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.88319396972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03213869035243988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0988229289650917,
      "backward_entropy": 0.03753430928502764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.0167007446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03219539672136307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09877067804336548,
      "backward_entropy": 0.04278765405927386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.70779418945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0322522297501564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09871932119131088,
      "backward_entropy": 0.0424303582736424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.29529571533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03231043368577957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09866687655448914,
      "backward_entropy": 0.036363920995167325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.58268737792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03236779570579529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09861539304256439,
      "backward_entropy": 0.041739276477268765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.53680419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032422985881567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09856675565242767,
      "backward_entropy": 0.04139812503542219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.57431411743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03247911110520363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09851720929145813,
      "backward_entropy": 0.041065803595951626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.46792221069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03253120183944702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09847287833690643,
      "backward_entropy": 0.040721037558146884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.28376770019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03258151188492775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09843116998672485,
      "backward_entropy": 0.034484458821160455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.51577377319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03263310715556145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09838864952325821,
      "backward_entropy": 0.03411648954663958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.53554153442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03268098831176758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09835102409124374,
      "backward_entropy": 0.033735611609050205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.99322509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03272901102900505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09831351786851883,
      "backward_entropy": 0.033360104475702555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.79190826416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03278288617730141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09826934337615967,
      "backward_entropy": 0.03902595383780343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.09798049926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03283945098519325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09822467714548111,
      "backward_entropy": 0.0326262755053384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.0582275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03289535269141197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09818059206008911,
      "backward_entropy": 0.03837479863848005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.13787078857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032953135669231415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09813566505908966,
      "backward_entropy": 0.03805677379880633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.93941497802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03301820531487465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09808435291051865,
      "backward_entropy": 0.03157171607017517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.92996978759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033087264746427536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09802877902984619,
      "backward_entropy": 0.03751721126692636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.16751861572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03315570577979088,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09797516465187073,
      "backward_entropy": 0.037253660815102715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.97465515136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033224813640117645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09792236983776093,
      "backward_entropy": 0.036990340266908915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.52936553955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03329293802380562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09787092357873917,
      "backward_entropy": 0.03671810456684658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.05134582519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03335575386881828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09782575815916061,
      "backward_entropy": 0.03642726370266506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.181671142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03342023119330406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0977809727191925,
      "backward_entropy": 0.036148292677743096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.042911529541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033481415361166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0977403074502945,
      "backward_entropy": 0.029244222811290195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.95220184326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033539656549692154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09770292043685913,
      "backward_entropy": 0.03556416503020695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.00089263916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03359667956829071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.097667396068573,
      "backward_entropy": 0.03526828331606729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.43834686279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03365620598196983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09762837737798691,
      "backward_entropy": 0.034994231803076606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.772764205932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03371180593967438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09759465605020523,
      "backward_entropy": 0.027876272797584534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.95346069335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03376208618283272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09756787121295929,
      "backward_entropy": 0.034418780888829915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.8986587524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03381738066673279,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09753423929214478,
      "backward_entropy": 0.027218133211135864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.337127685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03387441486120224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09749792516231537,
      "backward_entropy": 0.03392078621046884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.30339050292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033929843455553055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09746336936950684,
      "backward_entropy": 0.03369075059890747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.32291030883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033989809453487396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09742400050163269,
      "backward_entropy": 0.03348581280027117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.48845672607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03404892608523369,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0973857045173645,
      "backward_entropy": 0.09555820056370326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.59490966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034114982932806015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09733906388282776,
      "backward_entropy": 0.03309623045580728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.134780883789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034185707569122314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09728775918483734,
      "backward_entropy": 0.032931538564818244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.95954513549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03424978256225586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09724557399749756,
      "backward_entropy": 0.025357012237821306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.9007568359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03431125357747078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09720765799283981,
      "backward_entropy": 0.025099428636687144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.39274978637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034371402114629745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09717263281345367,
      "backward_entropy": 0.03235996620995658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.592674255371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034427594393491745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0971418023109436,
      "backward_entropy": 0.03215093697820391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.3084831237793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03448302298784256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09711243212223053,
      "backward_entropy": 0.03193742675440652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.2460708618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0345359668135643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09708532691001892,
      "backward_entropy": 0.03173627597945077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.14698791503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034589510411024094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09705948829650879,
      "backward_entropy": 0.0315257864339011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.27606964111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03464261442422867,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09703496098518372,
      "backward_entropy": 0.0313117653131485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.87706756591797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03469414636492729,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09701143950223923,
      "backward_entropy": 0.09572936807359968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.53817367553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03474742919206619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09698645770549774,
      "backward_entropy": 0.022895734225000654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.3074951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03480054810643196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09696238487958908,
      "backward_entropy": 0.022628637296812876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.784908294677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034859031438827515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09693317115306854,
      "backward_entropy": 0.03051781015736716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.392024993896484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034915484488010406,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09690573066473007,
      "backward_entropy": 0.09576226132256645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.15486145019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03496856242418289,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09688295423984528,
      "backward_entropy": 0.030140165771756853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.61833190917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03502250835299492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0968589335680008,
      "backward_entropy": 0.02996771676199777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.59305191040039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03508017957210541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09682930260896683,
      "backward_entropy": 0.029822057911327908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.85102462768555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03513321653008461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09680534154176712,
      "backward_entropy": 0.021148466638156345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.76556396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03518348187208176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09678495675325394,
      "backward_entropy": 0.02950532947267805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.25851821899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035233017057180405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09676529467105865,
      "backward_entropy": 0.029350838490894864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.6229248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035277217626571655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09675239771604538,
      "backward_entropy": 0.029186759676252092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.01551055908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0353250689804554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09673522412776947,
      "backward_entropy": 0.02902721507208688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.11691284179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03537677600979805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09671357274055481,
      "backward_entropy": 0.028886292661939348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.48668670654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03543158993124962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09668944776058197,
      "backward_entropy": 0.01978071246828352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.96086883544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03549327328801155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0966578871011734,
      "backward_entropy": 0.028632983565330505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.70847511291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03555337339639664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0966276228427887,
      "backward_entropy": 0.02851983266217368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.94143295288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03561069443821907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09660056978464127,
      "backward_entropy": 0.019180287207875932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.72071838378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566960617899895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09657129645347595,
      "backward_entropy": 0.028320748891149248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.23108673095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035731494426727295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09653833508491516,
      "backward_entropy": 0.018821009567805698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.70455551147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035796500742435455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09650297462940216,
      "backward_entropy": 0.028149943266596113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.88850402832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035856373608112335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09647374600172043,
      "backward_entropy": 0.028050273656845093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.33030319213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035913992673158646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09644830226898193,
      "backward_entropy": 0.027935645409992764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.76228332519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035972848534584045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0964210256934166,
      "backward_entropy": 0.02782227098941803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.18825149536133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0360293984413147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09639715403318405,
      "backward_entropy": 0.027695285422461375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.69478225708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036085788160562515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09637428820133209,
      "backward_entropy": 0.027570358344486783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.03670883178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03614375740289688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09635092318058014,
      "backward_entropy": 0.027455432074410573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.51552963256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0361989326775074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09633088111877441,
      "backward_entropy": 0.02734523585864476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.606964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03625448793172836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09630988538265228,
      "backward_entropy": 0.02724593026297433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.127140045166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03631003573536873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0962882786989212,
      "backward_entropy": 0.0271472590310233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.90561294555664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03636352717876434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09627009928226471,
      "backward_entropy": 0.02703293945108141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.2221565246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641337901353836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09625609219074249,
      "backward_entropy": 0.016519027096884593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.27762508392334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036462847143411636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09624219685792923,
      "backward_entropy": 0.01633706582444055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.01689529418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03650739789009094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09623441845178604,
      "backward_entropy": 0.026712102549416677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.22874450683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036552123725414276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0962262973189354,
      "backward_entropy": 0.026613192898886546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.82204818725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03659730777144432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0962175726890564,
      "backward_entropy": 0.015788660517760685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.546566009521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03664585202932358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09620457887649536,
      "backward_entropy": 0.01562153228691646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.91572189331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03669135272502899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09619560092687607,
      "backward_entropy": 0.02633004742009299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.27692413330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036736465990543365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09618711471557617,
      "backward_entropy": 0.015287594071456365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.034786224365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036788806319236755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09617049247026443,
      "backward_entropy": 0.02617325953074864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.9501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036838941276073456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09615619480609894,
      "backward_entropy": 0.014978859041418349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.867679595947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03688710182905197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0961441695690155,
      "backward_entropy": 0.014822622495038169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.91661834716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036933500319719315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09613433480262756,
      "backward_entropy": 0.014667587620871407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.04459762573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036983028054237366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09612025320529938,
      "backward_entropy": 0.025886514357158115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.25306701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03703486919403076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09610344469547272,
      "backward_entropy": 0.0258286999804633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.78213882446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03709029778838158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09608179330825806,
      "backward_entropy": 0.01424520994935717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.35671615600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037144970148801804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09606093168258667,
      "backward_entropy": 0.025739254696028575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.63548469543457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03719746321439743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09604297578334808,
      "backward_entropy": 0.013981074094772339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.62258911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037247177213430405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0960279181599617,
      "backward_entropy": 0.01385711772101266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.611454010009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03730054944753647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0960092693567276,
      "backward_entropy": 0.025642690914017812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.64653015136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037352897226810455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09599229693412781,
      "backward_entropy": 0.025609469839504788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.75967407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03740599751472473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09597381949424744,
      "backward_entropy": 0.013485785041536604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.37744903564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03746309503912926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09594994783401489,
      "backward_entropy": 0.013372046606881278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.005069732666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03752048313617706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09592608362436295,
      "backward_entropy": 0.013258032500743866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.25950622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03757680952548981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0959034264087677,
      "backward_entropy": 0.0131437001483781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.28520202636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03763318434357643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09588199853897095,
      "backward_entropy": 0.025487716708864485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.05331802368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037694383412599564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09585382044315338,
      "backward_entropy": 0.012915400522095817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.06005859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03775663673877716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09582532197237015,
      "backward_entropy": 0.025440141558647156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.56599426269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037822626531124115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0957936942577362,
      "backward_entropy": 0.02541149514062064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.80198669433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03788640350103378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09576502442359924,
      "backward_entropy": 0.012571307165282113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.252838134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03795180842280388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.095735102891922,
      "backward_entropy": 0.02532700981412615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.013490676879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03801802173256874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09570367634296417,
      "backward_entropy": 0.02528294495173863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.89009094238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03807971253991127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0956772044301033,
      "backward_entropy": 0.025242775678634644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.865291595458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03814259171485901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0956496074795723,
      "backward_entropy": 0.012096168739455087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.682466506958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03820376843214035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09562397003173828,
      "backward_entropy": 0.02516929805278778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.56415557861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03826127201318741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09560173749923706,
      "backward_entropy": 0.02514080490384783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.02394485473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03831778094172478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09558095037937164,
      "backward_entropy": 0.02511173060962132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.848388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03837747871875763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09555573016405106,
      "backward_entropy": 0.011661400752408164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.90223693847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038439057767391205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09552717208862305,
      "backward_entropy": 0.025071293115615845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.305545806884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038500044494867325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09549850225448608,
      "backward_entropy": 0.025076033813612803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.05436706542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03855840489268303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09547264873981476,
      "backward_entropy": 0.025078760726111277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.51001739501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038615550845861435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09544862806797028,
      "backward_entropy": 0.011297406894820077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.054811477661133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03866884112358093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.095429927110672,
      "backward_entropy": 0.011203673269067491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.44010925292969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03872028738260269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09541276097297668,
      "backward_entropy": 0.025059670209884644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.10586929321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03877200186252594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09539446234703064,
      "backward_entropy": 0.011027637336935316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.06733703613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03882548213005066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09537557512521744,
      "backward_entropy": 0.02505682408809662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.36539840698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0388798750936985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09535562247037888,
      "backward_entropy": 0.02504963959966387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.97707748413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038933638483285904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09533576667308807,
      "backward_entropy": 0.025042137929371426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.679595947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03898783400654793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09531493484973907,
      "backward_entropy": 0.010672059442315782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.436738967895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039042878895998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0952933207154274,
      "backward_entropy": 0.010583511420658656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.49496459960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03909609839320183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09527461230754852,
      "backward_entropy": 0.010497264564037323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.68193435668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03915558010339737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09524698555469513,
      "backward_entropy": 0.025004863739013672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.66117858886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03921698033809662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09521663188934326,
      "backward_entropy": 0.0103364640048572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.70724105834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039277225732803345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09518797695636749,
      "backward_entropy": 0.01025912378515516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.533042907714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03933826833963394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09515856206417084,
      "backward_entropy": 0.02500290104321071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.86544418334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03939790278673172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09513051062822342,
      "backward_entropy": 0.010090351104736328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.12596893310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03945741057395935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0951027125120163,
      "backward_entropy": 0.024955283318247114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.79710578918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03951379656791687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09507998824119568,
      "backward_entropy": 0.02490991141114916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.67594909667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03956811875104904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09505972266197205,
      "backward_entropy": 0.00981378129550389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.629390716552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039624445140361786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09503589570522308,
      "backward_entropy": 0.009722858667373657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.772361755371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03967873007059097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09501401335000992,
      "backward_entropy": 0.024796583822795322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.465877532958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039732616394758224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09499271959066391,
      "backward_entropy": 0.009548959987504142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.65198516845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03978472575545311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09497366845607758,
      "backward_entropy": 0.009466404361384255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.7473258972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039836376905441284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.094955675303936,
      "backward_entropy": 0.00938473003251212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.18750762939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039888907223939896,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09493564069271088,
      "backward_entropy": 0.02468731999397278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.52253341674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039939962327480316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09491701424121857,
      "backward_entropy": 0.024667952741895403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.46354675292969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03999366983771324,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09489446878433228,
      "backward_entropy": 0.09762920652117048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.12617492675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0400528647005558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09486294537782669,
      "backward_entropy": 0.024667607886450633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.019145965576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04011092707514763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09483440220355988,
      "backward_entropy": 0.024674258061817715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.01744842529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04016641154885292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09480905532836914,
      "backward_entropy": 0.008953900209495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.524478912353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040225084871053696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09478011727333069,
      "backward_entropy": 0.008883258061749595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.72841453552246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04028098285198212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09475406259298325,
      "backward_entropy": 0.024672774331910268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62790298461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04033467546105385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09473077952861786,
      "backward_entropy": 0.024674064346722195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.32182693481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04038412123918533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09471286833286285,
      "backward_entropy": 0.024676706109728132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.35462188720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040436238050460815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09469151496887207,
      "backward_entropy": 0.008627406188419886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.25515365600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04048808664083481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09467049688100815,
      "backward_entropy": 0.024685976760728017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.0383415222168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04053970053792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09464915096759796,
      "backward_entropy": 0.024692116039139882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.8803596496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04059236869215965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0946265310049057,
      "backward_entropy": 0.008443075631346022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.88612747192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04064612463116646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09460200369358063,
      "backward_entropy": 0.024708168847220286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.91351318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04070032015442848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09457685798406601,
      "backward_entropy": 0.024705094950539724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.71381378173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04075378552079201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09455235302448273,
      "backward_entropy": 0.024694928101130893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.275901794433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040807005017995834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09452851116657257,
      "backward_entropy": 0.00819212624004909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.15959930419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04085667431354523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09451106190681458,
      "backward_entropy": 0.008124089666775294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.392744064331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040903426706790924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0944976657629013,
      "backward_entropy": 0.024646454623767307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.69090270996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040950752794742584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0944824069738388,
      "backward_entropy": 0.00798960349389485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.98992156982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04100111126899719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09446203708648682,
      "backward_entropy": 0.024629839829036167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.947422981262207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04105241969227791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09443995356559753,
      "backward_entropy": 0.0246192067861557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.58343505859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04110068455338478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09442222118377686,
      "backward_entropy": 0.024602817637579783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.148582458496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041150905191898346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09440021216869354,
      "backward_entropy": 0.024605250784329007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.39240264892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04120374470949173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09437384456396103,
      "backward_entropy": 0.024612282003675188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.630613327026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04125453531742096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09435088187456131,
      "backward_entropy": 0.02460622787475586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.57396125793457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0413028858602047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09433151036500931,
      "backward_entropy": 0.007577162768159594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.65179443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041351933032274246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09431049227714539,
      "backward_entropy": 0.007527955940791539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.379207611083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041405949741601944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09428133070468903,
      "backward_entropy": 0.024634701865059987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.470840454101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04146245867013931,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09424913674592972,
      "backward_entropy": 0.02465149760246277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.51374435424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041515715420246124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09422159194946289,
      "backward_entropy": 0.02466593257018498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.750789642333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04157277196645737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09418885409832001,
      "backward_entropy": 0.024685257247516086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986818790435791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041627898812294006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09415900707244873,
      "backward_entropy": 0.007284961640834808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.69376754760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0416782945394516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09413564205169678,
      "backward_entropy": 0.02471640706062317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.18100357055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041731152683496475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09410779178142548,
      "backward_entropy": 0.007185568234750203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.044097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041781265288591385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09408421814441681,
      "backward_entropy": 0.024742424488067627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.395978927612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041832879185676575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09405839443206787,
      "backward_entropy": 0.007094149078641619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.82775115966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041882991790771484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09403452277183533,
      "backward_entropy": 0.024787447282246182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.66720199584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041934479027986526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09400847554206848,
      "backward_entropy": 0.02480970961706979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.94681167602539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04198744520545006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0939795970916748,
      "backward_entropy": 0.02484030382973807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.120216369628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04203754663467407,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09395475685596466,
      "backward_entropy": 0.0982438325881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.69921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04208618029952049,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09393201768398285,
      "backward_entropy": 0.024889286075319563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.51091003417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04213891178369522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09390268474817276,
      "backward_entropy": 0.024911007710865567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.722660064697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04219544306397438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09386718273162842,
      "backward_entropy": 0.02493752752031599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.9793815612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04224888235330582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09383615851402283,
      "backward_entropy": 0.02496645280293056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.82341766357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04230334609746933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0938035175204277,
      "backward_entropy": 0.024994675602231706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.65148162841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04235714673995972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09377177804708481,
      "backward_entropy": 0.006683213370186942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.56937599182129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042410824447870255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0937395840883255,
      "backward_entropy": 0.025039093835013255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.50414276123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04246427118778229,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09370739012956619,
      "backward_entropy": 0.025065996817180088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.41623306274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0425172783434391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09367518126964569,
      "backward_entropy": 0.025089902537209646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.2520809173584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04257209599018097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09364012628793716,
      "backward_entropy": 0.025100263101714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.215068817138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04262668266892433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09360473603010178,
      "backward_entropy": 0.02511461079120636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.72627258300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04268059879541397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09357070177793503,
      "backward_entropy": 0.02512214013508388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.11429214477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04273911565542221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09352925419807434,
      "backward_entropy": 0.02512721504483904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.68439483642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04279535263776779,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09349088370800018,
      "backward_entropy": 0.025129741856030056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.759647369384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04285254329442978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09345067292451859,
      "backward_entropy": 0.006319684641701835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.9145450592041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042909033596515656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09341135621070862,
      "backward_entropy": 0.006280702671834401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.88512420654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04296310991048813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09337560832500458,
      "backward_entropy": 0.02516243713242667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.737703323364258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04302064701914787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09333354234695435,
      "backward_entropy": 0.025170262370790755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.24208068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043075788766145706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09329508244991302,
      "backward_entropy": 0.025168633886746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.45355224609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313558712601662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09324890375137329,
      "backward_entropy": 0.006112399910177503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.72906494140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04319377988576889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09320530295372009,
      "backward_entropy": 0.025195074932915822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.979698181152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0432489812374115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09316639602184296,
      "backward_entropy": 0.006047000310250691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.50023651123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04330400750041008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09312708675861359,
      "backward_entropy": 0.025273501873016357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.633992195129395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043360184878110886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09308447688817978,
      "backward_entropy": 0.02532249689102173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.27760314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043413009494543076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09304752200841904,
      "backward_entropy": 0.025362048830304827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.653989791870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043466970324516296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09300850331783295,
      "backward_entropy": 0.005935411368097577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.872196674346924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04352020099759102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09297093749046326,
      "backward_entropy": 0.005903095006942749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.90119171142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356983304023743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09293895959854126,
      "backward_entropy": 0.0058757370071751734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.90226936340332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04361840337514877,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09290832281112671,
      "backward_entropy": 0.02551655258451189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.866479873657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043665360659360886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09288033097982407,
      "backward_entropy": 0.005818542625222888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.136804580688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043708689510822296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09285818040370941,
      "backward_entropy": 0.025569341012409756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.509788513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043752990663051605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09283417463302612,
      "backward_entropy": 0.02560279199055263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.154017448425293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04379914328455925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09280695021152496,
      "backward_entropy": 0.02563678366797311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3979593813419342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04384348914027214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09278219938278198,
      "backward_entropy": 0.02568120402949197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.188899993896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043883066624403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09276576340198517,
      "backward_entropy": 0.0056735000440052575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.39870262145996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043925169855356216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09274450689554214,
      "backward_entropy": 0.0056474485567637855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.68762969970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043966952711343765,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.092723548412323,
      "backward_entropy": 0.09864401817321777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.27568435668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044009532779455185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09270089864730835,
      "backward_entropy": 0.005596316818680082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.522863388061523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04405489191412926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09267252683639526,
      "backward_entropy": 0.02586780914238521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.01082229614258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04410068690776825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09264358878135681,
      "backward_entropy": 0.0055356813328606745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.61001205444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044149041175842285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0926099568605423,
      "backward_entropy": 0.005502413958311081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.501953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04419861361384392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09257340431213379,
      "backward_entropy": 0.02590882352420262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.130037307739258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04424918442964554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09253448247909546,
      "backward_entropy": 0.005433441272803715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.246177673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044299978762865067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09249398112297058,
      "backward_entropy": 0.025924322860581533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.279579162597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04435184970498085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0924517810344696,
      "backward_entropy": 0.02593842787402017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.860776901245117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04440596327185631,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09240517020225525,
      "backward_entropy": 0.025950152959142412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.798095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044459640979766846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09235885739326477,
      "backward_entropy": 0.025963370289121355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.71269989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044512420892715454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0923134982585907,
      "backward_entropy": 0.02596269122191838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.609100341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0445665679872036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09226513653993607,
      "backward_entropy": 0.025977826544216702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.442546844482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04462163895368576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.092215396463871,
      "backward_entropy": 0.025999086243765696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.312695503234863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04467637091875076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09216587990522385,
      "backward_entropy": 0.026026606559753418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.296972274780273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04472845420241356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09212061762809753,
      "backward_entropy": 0.005168434232473373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.129432678222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044777654111385345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09208056330680847,
      "backward_entropy": 0.026096258844648088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.12135124206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044828154146671295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09203754365444183,
      "backward_entropy": 0.026127681136131287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.14745807647705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044877488166093826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09199615567922592,
      "backward_entropy": 0.026164084672927856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.87682342529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044924311339855194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0919593870639801,
      "backward_entropy": 0.026197761297225952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.932355880737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04497168958187103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09192141890525818,
      "backward_entropy": 0.026239603757858276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.73357582092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04501801356673241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09188514947891235,
      "backward_entropy": 0.005026380930628095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.97939682006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045064449310302734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09184806048870087,
      "backward_entropy": 0.005002269787447793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.388662338256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04510847106575966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09181541949510574,
      "backward_entropy": 0.02633319582257952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.259735107421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0451538972556591,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0917794480919838,
      "backward_entropy": 0.02634855466229575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0729451179504395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04520097002387047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09173962473869324,
      "backward_entropy": 0.004921216517686844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.786252975463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04524432122707367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09170708060264587,
      "backward_entropy": 0.004893174661057336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.21597671508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04528586193919182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09167806804180145,
      "backward_entropy": 0.004866482956068856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.28596878051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045328181236982346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09164740145206451,
      "backward_entropy": 0.026431975620133535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.75777816772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04537474736571312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09160763025283813,
      "backward_entropy": 0.026451057621410916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.932542324066162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04542246088385582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09156499803066254,
      "backward_entropy": 0.0047863902790205816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.564041137695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04546688124537468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09152956306934357,
      "backward_entropy": 0.026482258524213518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.450706481933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04550948739051819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09149718284606934,
      "backward_entropy": 0.02651117103440421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.71942901611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045553360134363174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09146107733249664,
      "backward_entropy": 0.004708439111709595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.6163272857666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04559750109910965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09142379462718964,
      "backward_entropy": 0.026529320648738315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.39881706237793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04564233869314194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09138412028551102,
      "backward_entropy": 0.026546697531427656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.906410217285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568514972925186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09134890884160995,
      "backward_entropy": 0.004628452339342662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.305683135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04572737589478493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0913143903017044,
      "backward_entropy": 0.026590849672045027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.34033966064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04576810821890831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09128252416849136,
      "backward_entropy": 0.004581945815256664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.715585708618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045811619609594345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09124503284692764,
      "backward_entropy": 0.026642224618366787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.13692283630371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04585474357008934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09120795875787735,
      "backward_entropy": 0.004533860300268445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.50384521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04589838907122612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09117023646831512,
      "backward_entropy": 0.004511108355862754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.83369827270508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04594381898641586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09112758934497833,
      "backward_entropy": 0.026726322514670237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.868675231933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04599189758300781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09107860922813416,
      "backward_entropy": 0.026752009987831116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.010272979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04604034498333931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09102849662303925,
      "backward_entropy": 0.00444679068667548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.692392349243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046086423099040985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0909830778837204,
      "backward_entropy": 0.02682684361934662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.963436126708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04613306000828743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09093602001667023,
      "backward_entropy": 0.026874410254614695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.85015106201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04618089646100998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09088582545518875,
      "backward_entropy": 0.02691364288330078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.819376945495605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04622989147901535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09083257615566254,
      "backward_entropy": 0.026948309370449612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.61450958251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04627688229084015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09078333526849747,
      "backward_entropy": 0.004352348457489695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.996397018432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046325698494911194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09072931110858917,
      "backward_entropy": 0.027062526771000454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.16497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04637330770492554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09067784994840622,
      "backward_entropy": 0.004324248060584068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.860224723815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0464211143553257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09062577039003372,
      "backward_entropy": 0.0043103207967111045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.795313835144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04646797105669975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09057554602622986,
      "backward_entropy": 0.02725242716925485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.560054779052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046513963490724564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09052644670009613,
      "backward_entropy": 0.027320755379540578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.450714111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04655788093805313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09048151969909668,
      "backward_entropy": 0.027386910149029324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.606938362121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046606793999671936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09042461216449738,
      "backward_entropy": 0.02744255747113909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.870439529418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665445163846016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09037025272846222,
      "backward_entropy": 0.004242438290800367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.551572799682617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046704646199941635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09030971676111221,
      "backward_entropy": 0.0042283255606889725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.59974479675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04675497114658356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09024816751480103,
      "backward_entropy": 0.02761732680456979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.377031326293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04680737480521202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09018130600452423,
      "backward_entropy": 0.02767787660871233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.312496185302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046859096735715866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09011530131101608,
      "backward_entropy": 0.027727603912353516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.15921974182129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04691281542181969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09004373848438263,
      "backward_entropy": 0.027776390314102173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.108171463012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04696856066584587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0899672731757164,
      "backward_entropy": 0.004158509629113334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.76681137084961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702224209904671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08989536017179489,
      "backward_entropy": 0.004143883607217244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.87026596069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04707947373390198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08981424570083618,
      "backward_entropy": 0.02791051140853337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.866641998291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047135744243860245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08973467350006104,
      "backward_entropy": 0.004106450293745313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.529699325561523,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047190286219120026,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08965863287448883,
      "backward_entropy": 0.09891516821725028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.874096870422363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04724545031785965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0895804837346077,
      "backward_entropy": 0.028021288769585744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.818882942199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047297731041908264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08950883150100708,
      "backward_entropy": 0.028072208166122437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.773231506347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04734772816300392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08944179862737656,
      "backward_entropy": 0.028139173984527588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.279796600341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04740070179104805,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08936756104230881,
      "backward_entropy": 0.0989281449999128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.933399200439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04745316505432129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0892934799194336,
      "backward_entropy": 0.028249740600585938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.090818405151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04750632122159004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08921673148870468,
      "backward_entropy": 0.028304093650409153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.296868324279785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047558773308992386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08914146572351456,
      "backward_entropy": 0.003997589062367167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.575523376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04760926216840744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0890708714723587,
      "backward_entropy": 0.028388561947005137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.148832321166992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04766068607568741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08899649977684021,
      "backward_entropy": 0.028430700302124023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.983301162719727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04771055653691292,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08892565965652466,
      "backward_entropy": 0.028474575706890652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.226839065551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04776224493980408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08884921669960022,
      "backward_entropy": 0.028511268751961843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.76317834854126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047814641147851944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08877060562372208,
      "backward_entropy": 0.0039211176335811615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.56085205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04786314070224762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08870158344507217,
      "backward_entropy": 0.0039066097566059655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.342422485351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04791371524333954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08862655609846115,
      "backward_entropy": 0.003891938499041966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.253278732299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04796378314495087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08855167031288147,
      "backward_entropy": 0.028668601598058428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165166854858398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04801322892308235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08847834914922714,
      "backward_entropy": 0.02869332049574171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.542911529541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048060134053230286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08841104805469513,
      "backward_entropy": 0.0038422058735574994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.43634033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04810817167162895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08833999931812286,
      "backward_entropy": 0.028749423367636546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.61136245727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0481569878757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08826609700918198,
      "backward_entropy": 0.028772256204060147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.391218185424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04820996895432472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08818013966083527,
      "backward_entropy": 0.028793283871241977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.700592041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0482608824968338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08809936046600342,
      "backward_entropy": 0.02880673961980002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.96257972717285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048311132937669754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08802010864019394,
      "backward_entropy": 0.028816329581396922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048362139612436295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08793790638446808,
      "backward_entropy": 0.0037350510912282126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.099146842956543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04841509088873863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08784922957420349,
      "backward_entropy": 0.028857011880193437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.18555450439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04846634343266487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08776511996984482,
      "backward_entropy": 0.028889651809419905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.74395751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048520006239414215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08767417818307877,
      "backward_entropy": 0.0036868546158075333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.640745162963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048575159162282944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08757766336202621,
      "backward_entropy": 0.028929978609085083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.02140998840332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048627108335494995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08748949319124222,
      "backward_entropy": 0.003654609833444868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.924877166748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04867832362651825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08740272372961044,
      "backward_entropy": 0.028975763491221836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496355056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04872909560799599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08731679618358612,
      "backward_entropy": 0.029003907527242388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.743873596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04877724498510361,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08723790943622589,
      "backward_entropy": 0.029038229158946445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.408540725708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882516339421272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08715882152318954,
      "backward_entropy": 0.003595292568206787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.572519302368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04887058585882187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08708617091178894,
      "backward_entropy": 0.0035813929779188974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.65654754638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04891611263155937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08701284229755402,
      "backward_entropy": 0.029152525322777883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.52644157409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048963770270347595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08693242073059082,
      "backward_entropy": 0.0035555511713027954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.232364654541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04901333525776863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08684593439102173,
      "backward_entropy": 0.02923121622630528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189996719360352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04906059801578522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08676572889089584,
      "backward_entropy": 0.0035316627472639084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.149190902709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049105629324913025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0866914615035057,
      "backward_entropy": 0.029341548681259155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.044567108154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049149371683597565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08661993592977524,
      "backward_entropy": 0.02939208916255406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.942955017089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049194347113370895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08654451370239258,
      "backward_entropy": 0.02944321504661015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.901284217834473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049240417778491974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08646548539400101,
      "backward_entropy": 0.029493723596845354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.737138748168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0492863804101944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08638570457696915,
      "backward_entropy": 0.029545617955071584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.734127044677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049333032220602036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08630278706550598,
      "backward_entropy": 0.02958653654370989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.52397346496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04937935620546341,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08622020483016968,
      "backward_entropy": 0.029623861823763167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.707202911376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049426525831222534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08613500744104385,
      "backward_entropy": 0.0034396973039422718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.47925853729248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04947258532047272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08605242520570755,
      "backward_entropy": 0.029706652675356184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.21137809753418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04951842129230499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08596969395875931,
      "backward_entropy": 0.02975118798868997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.725682735443115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04956468939781189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08588478714227676,
      "backward_entropy": 0.0034022325915949686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.231075286865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0496089905500412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08580511808395386,
      "backward_entropy": 0.02981980996472495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.150653839111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04965314641594887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08572560548782349,
      "backward_entropy": 0.02985801867076329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.336536407470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969716817140579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08564622700214386,
      "backward_entropy": 0.0033648977322237833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.852966785430908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04974035546183586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08556880801916122,
      "backward_entropy": 0.02993661803858621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.613670349121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049780651926994324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.085500068962574,
      "backward_entropy": 0.029991613967078074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.492629051208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049822308123111725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08542634546756744,
      "backward_entropy": 0.030041752117020742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.114566802978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04986192658543587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08535857498645782,
      "backward_entropy": 0.030086817485945567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.98346519470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04990076646208763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08529246598482132,
      "backward_entropy": 0.030127810580389842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.382111549377441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994220286607742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08521758019924164,
      "backward_entropy": 0.0032993190522704807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.740300178527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04998168721795082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08514866977930069,
      "backward_entropy": 0.030209449785096303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.665700912475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050018493086099625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08508811146020889,
      "backward_entropy": 0.030254351241247996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.417780876159668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05005799978971481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08501720428466797,
      "backward_entropy": 0.030291384884289334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.686041831970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050097763538360596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08494573086500168,
      "backward_entropy": 0.030324940170560564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.27836799621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050134748220443726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0848831906914711,
      "backward_entropy": 0.03036183544567653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.730642318725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05017229914665222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0848177820444107,
      "backward_entropy": 0.03039802610874176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134644508361816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05021125450730324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08474679291248322,
      "backward_entropy": 0.030427681548254832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.0427188873291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05024855211377144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08468115329742432,
      "backward_entropy": 0.003205391179238047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5953733921051025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05028844252228737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08460643887519836,
      "backward_entropy": 0.030492312141827176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.83333969116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050325747579336166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08453994989395142,
      "backward_entropy": 0.030536826167787825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.4259033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05036582425236702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08446349948644638,
      "backward_entropy": 0.03058741773877825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.373573303222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050405289977788925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08438865095376968,
      "backward_entropy": 0.030643944229398454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.516979217529297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050443924963474274,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08431575447320938,
      "backward_entropy": 0.09898970808301653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.644766807556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050485026091337204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08423440158367157,
      "backward_entropy": 0.0031456385872193743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.932926177978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05052655562758446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08415068686008453,
      "backward_entropy": 0.030807597296578542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.494880676269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05056941136717796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0840616375207901,
      "backward_entropy": 0.030874750443867276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.39366340637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05061236023902893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08397190272808075,
      "backward_entropy": 0.03094534363065447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.033468246459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050658103078603745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0838722437620163,
      "backward_entropy": 0.031003407069614956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.54180145263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0507025383412838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08377611637115479,
      "backward_entropy": 0.031063090477670943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.913576126098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074795335531235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0836760401725769,
      "backward_entropy": 0.003102610685995647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.365638494491577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05079207569360733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0835796669125557,
      "backward_entropy": 0.03119537660053798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.48524284362793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050832923501729965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08349452912807465,
      "backward_entropy": 0.003089179950101035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.787952423095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05087560787796974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08340252190828323,
      "backward_entropy": 0.031308380620820184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.056854248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05092193931341171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08329656720161438,
      "backward_entropy": 0.03134353458881378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.783327102661133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05096879228949547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08318792283535004,
      "backward_entropy": 0.0030586301748241696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.262586832046509,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05101529881358147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08308005332946777,
      "backward_entropy": 0.031420494828905375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2468690872192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05105847492814064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08298367261886597,
      "backward_entropy": 0.031471233282770426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.665891647338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05109831690788269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08289900422096252,
      "backward_entropy": 0.031515862260546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.485305786132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113920941948891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08280999213457108,
      "backward_entropy": 0.031556516885757446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.48377799987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0511799082159996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08272098004817963,
      "backward_entropy": 0.03158687906605857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.391608238220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05122161656618118,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08262769132852554,
      "backward_entropy": 0.031617349811962674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1892924308776855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05126415565609932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08253049105405807,
      "backward_entropy": 0.0029868933239153455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.154979705810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0513044036924839,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08244122564792633,
      "backward_entropy": 0.0029746126383543015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.115166187286377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05134238675236702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0823599100112915,
      "backward_entropy": 0.03167700554643359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.054362297058105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05137885734438896,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08228354156017303,
      "backward_entropy": 0.03169791400432587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.018584251403809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141573026776314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08220522105693817,
      "backward_entropy": 0.0029357440237488064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1142689660191536,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05145211145281792,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08212831616401672,
      "backward_entropy": 0.0989997046334403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926689147949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051484715193510056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08206573128700256,
      "backward_entropy": 0.03176849228995187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.733217239379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05151718109846115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08200342208147049,
      "backward_entropy": 0.031793875353676934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10773273557424545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051551274955272675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08193377405405045,
      "backward_entropy": 0.0318155437707901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.58767032623291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05158241093158722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08187545090913773,
      "backward_entropy": 0.03185520853315081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.634916305541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051615551114082336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08180882036685944,
      "backward_entropy": 0.0028685730482850757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.44243049621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05164925754070282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08173923194408417,
      "backward_entropy": 0.03194223131452288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65998649597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051684439182281494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08166342973709106,
      "backward_entropy": 0.03197779825755528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.287650108337402,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05171932280063629,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0815882608294487,
      "backward_entropy": 0.09899987493242536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.745333671569824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051755670458078384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08150683343410492,
      "backward_entropy": 0.032069465943745205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519983291625977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051790568977594376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08143030852079391,
      "backward_entropy": 0.03212146035262516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.266406059265137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05182511731982231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0813547819852829,
      "backward_entropy": 0.03217819333076477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429313659667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051860108971595764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08127732574939728,
      "backward_entropy": 0.03223020476954324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.621715068817139,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051894597709178925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08120153099298477,
      "backward_entropy": 0.002797973741378103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8462398052215576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051927924156188965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08112969994544983,
      "backward_entropy": 0.0027910087789808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29855728149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05195917934179306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08106566220521927,
      "backward_entropy": 0.03242422214576176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256952285766602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05199046805500984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08100126683712006,
      "backward_entropy": 0.03250546327659062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219837188720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052021902054548264,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08093556761741638,
      "backward_entropy": 0.09900612490517753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.175259590148926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05205308273434639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08087025582790375,
      "backward_entropy": 0.0027703429971422467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.821393966674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052084457129240036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08080384135246277,
      "backward_entropy": 0.032779936279569356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.759249448776245,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05211644619703293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0807345062494278,
      "backward_entropy": 0.032864979335239956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.714476585388184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05214657634496689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08067219704389572,
      "backward_entropy": 0.032959938049316406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.374319076538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052177544683218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08060567080974579,
      "backward_entropy": 0.033048304063933234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.242557525634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052207618951797485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08054238557815552,
      "backward_entropy": 0.03314213241849627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.79025936126709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05223933234810829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08047191798686981,
      "backward_entropy": 0.03322217507021768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895505428314209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05227350816130638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08039040863513947,
      "backward_entropy": 0.03329255325453622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.439006805419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230719968676567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08031035959720612,
      "backward_entropy": 0.03336062175886972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.239296913146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05234137922525406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08022762089967728,
      "backward_entropy": 0.002723158470221928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.202810287475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05237388238310814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08015111088752747,
      "backward_entropy": 0.002714441290923527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.274151802062988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05240529030561447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08007864654064178,
      "backward_entropy": 0.03353830533368247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.683585166931152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05243714898824692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08000466227531433,
      "backward_entropy": 0.033585235476493835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.642276287078857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05246865376830101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07993122190237045,
      "backward_entropy": 0.03362957068852016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.610953330993652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052499834448099136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0798584595322609,
      "backward_entropy": 0.03367138760430472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.051197052001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05253256857395172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07977847754955292,
      "backward_entropy": 0.03370992626462664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518923282623291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05256565287709236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07969619333744049,
      "backward_entropy": 0.03374063542910984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.392890930175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0525980070233345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07961682975292206,
      "backward_entropy": 0.00264578392463071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08327420055866241,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05263194441795349,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07953023910522461,
      "backward_entropy": 0.033782594970294406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.250919342041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05266260355710983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07945714145898819,
      "backward_entropy": 0.002623629623225757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08101066946983337,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05269505828619003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07937587797641754,
      "backward_entropy": 0.033846540110451837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.713423728942871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052724439650774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07930745929479599,
      "backward_entropy": 0.002604798546859196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.86860466003418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052754584699869156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07923546433448792,
      "backward_entropy": 0.03392535660948072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4587724208831787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05278376489877701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07916703820228577,
      "backward_entropy": 0.033969568354742866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.93824291229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05281127616763115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07910554856061935,
      "backward_entropy": 0.034025909645216804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.517003059387207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052840448915958405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0790361538529396,
      "backward_entropy": 0.034069261380604336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.85053062438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287020653486252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07896348834037781,
      "backward_entropy": 0.002560830009835107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.076532363891602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052904028445482254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.078872911632061,
      "backward_entropy": 0.03411981889179775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07672710716724396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05293694883584976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.078785240650177,
      "backward_entropy": 0.034124523401260376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.598027229309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05296669900417328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07871118932962418,
      "backward_entropy": 0.03413627403123038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.239001274108887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05299801751971245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0786304920911789,
      "backward_entropy": 0.03415042161941528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.62888765335083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053029850125312805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.078547403216362,
      "backward_entropy": 0.002502808613436563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.865243911743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053060416132211685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07846895605325699,
      "backward_entropy": 0.03418778947421482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.324723720550537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05309078097343445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07839059829711914,
      "backward_entropy": 0.0024822958345924106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.790227890014648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05311913043260574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07832078635692596,
      "backward_entropy": 0.03424560597964695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.208381652832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314738303422928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07825124263763428,
      "backward_entropy": 0.0024632995149918963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.498215675354004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05317720025777817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07817462086677551,
      "backward_entropy": 0.0342977408851896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.272376775741577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05320615693926811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0781012773513794,
      "backward_entropy": 0.0024445511932883945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.451467990875244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053233347833156586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07803566008806229,
      "backward_entropy": 0.03437939924853189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.610526084899902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05325976759195328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07797318696975708,
      "backward_entropy": 0.034427838666098456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.405275821685791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053286150097846985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07791019976139069,
      "backward_entropy": 0.034468701907566617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543290615081787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05331194028258324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07784952223300934,
      "backward_entropy": 0.002414125683052199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.509060382843018,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05333785340189934,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07778776437044144,
      "backward_entropy": 0.09900868790490287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.474613189697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05336403474211693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07772435247898102,
      "backward_entropy": 0.03462146861212594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1930408477783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05339060723781586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07765863090753555,
      "backward_entropy": 0.03468443240438189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4146857261657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05341546609997749,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07760073244571686,
      "backward_entropy": 0.03474505032811846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274709701538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053440410643815994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07754194736480713,
      "backward_entropy": 0.03479700216225216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.449178695678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053464874625205994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07748487591743469,
      "backward_entropy": 0.03485703042575291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1469926834106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05349026247859001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07742296159267426,
      "backward_entropy": 0.034905433654785156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.213642597198486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053514305502176285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07736682146787643,
      "backward_entropy": 0.03496520859854562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.196908473968506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05353783443570137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07731270790100098,
      "backward_entropy": 0.0023582343544278827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1168785095214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053560640662908554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07726170867681503,
      "backward_entropy": 0.09901192358561925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2069292068481445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053582292050123215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07721585780382156,
      "backward_entropy": 0.0023455784789153506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1397929191589355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053604308515787125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07716792821884155,
      "backward_entropy": 0.03518512419291905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.182164192199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05362584441900253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07712173461914062,
      "backward_entropy": 0.03522817577634539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.124181747436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053648658096790314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0770689845085144,
      "backward_entropy": 0.0023238427404846463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.082337379455566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053671661764383316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0770147368311882,
      "backward_entropy": 0.03529182927949088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060544490814209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05369408428668976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07696302235126495,
      "backward_entropy": 0.03531802126339504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.029406547546387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053716231137514114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07691195607185364,
      "backward_entropy": 0.035355325256075175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.990673542022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053739678114652634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07685454934835434,
      "backward_entropy": 0.0353941193648747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.896195411682129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05376423895359039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07679136842489243,
      "backward_entropy": 0.0022828656115702222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.940421104431152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05379149317741394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07671481370925903,
      "backward_entropy": 0.03546645811625889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.005580425262451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05381877347826958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07663735747337341,
      "backward_entropy": 0.03550852196557181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.756021499633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05384428799152374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0765681266784668,
      "backward_entropy": 0.03555254425321307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.772562503814697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0538715235888958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07649040222167969,
      "backward_entropy": 0.03559352244649615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7241692543029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05389922112226486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07641037553548813,
      "backward_entropy": 0.03561933125768389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.676079750061035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392752215266228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07632683962583542,
      "backward_entropy": 0.0022356949214424405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8395767211914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05395640805363655,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07623983919620514,
      "backward_entropy": 0.09901097842625209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.462942123413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05398424342274666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0761575773358345,
      "backward_entropy": 0.03569364121982029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6617279052734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05401352420449257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07606789469718933,
      "backward_entropy": 0.03572113173348563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.625800132751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05404248833656311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07597926259040833,
      "backward_entropy": 0.035750857421330044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.744643211364746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05407111719250679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07589173316955566,
      "backward_entropy": 0.035780170134135654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.720271587371826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05409851670265198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07580982893705368,
      "backward_entropy": 0.03580450585910252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.170671463012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054124996066093445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07573208957910538,
      "backward_entropy": 0.035833925008773804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113297462463379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054152961820364,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0756470113992691,
      "backward_entropy": 0.03585880994796753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.650670289993286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05418216809630394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07555558532476425,
      "backward_entropy": 0.03587624856403896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8385961055755615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05421021580696106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07546903938055038,
      "backward_entropy": 0.03589865565299988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.161109924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05423640459775925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07539142668247223,
      "backward_entropy": 0.0359258268560682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.883947372436523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0542634055018425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0753093883395195,
      "backward_entropy": 0.03595734919820513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.070520401000977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05429189279675484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07521937787532806,
      "backward_entropy": 0.035989927394049506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050501298159360886,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432085320353508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07512666285037994,
      "backward_entropy": 0.0021223295480012894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514270067214966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0543467216193676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07504929602146149,
      "backward_entropy": 0.03603909696851458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.938897132873535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05437174811959267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07497590780258179,
      "backward_entropy": 0.03606049929346357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.896780490875244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054397664964199066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07489774376153946,
      "backward_entropy": 0.03608714256967817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.554471015930176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05442433059215546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07481522858142853,
      "backward_entropy": 0.0020902900557432857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.807969093322754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054452553391456604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07472451031208038,
      "backward_entropy": 0.03615255440984454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4053447246551514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05448118597269058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07463111728429794,
      "backward_entropy": 0.03618471963065011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.049370765686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05450836196541786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07454487681388855,
      "backward_entropy": 0.0020681249776056836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.016855239868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054535288363695145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07445961236953735,
      "backward_entropy": 0.036223411560058594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.630006313323975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05456185340881348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07437565177679062,
      "backward_entropy": 0.03623795509338379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.585009574890137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05458887666463852,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07428885996341705,
      "backward_entropy": 0.03624776005744934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045398786664009094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05461657792329788,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07419851422309875,
      "backward_entropy": 0.03626820870808193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2726120948791504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05464174225926399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07412070780992508,
      "backward_entropy": 0.036299824714660645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.065043449401855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054666053503751755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07404696196317673,
      "backward_entropy": 0.036332522119794576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.419044017791748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054691847413778305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07396536320447922,
      "backward_entropy": 0.036359740155083795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6276668310165405,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05471845716238022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0738794207572937,
      "backward_entropy": 0.0020075859501957893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.337334156036377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05474323779344559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07380232959985733,
      "backward_entropy": 0.03643214276858738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859931945800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476882681250572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07372076064348221,
      "backward_entropy": 0.036471545696258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.701411247253418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05479595437645912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07363049685955048,
      "backward_entropy": 0.0019893466628023554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.585239052772522,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05482282489538193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0735413208603859,
      "backward_entropy": 0.036555311509541104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.640144348144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05484800413250923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07346081733703613,
      "backward_entropy": 0.03660598823002407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.701793670654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05487310513854027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07338064908981323,
      "backward_entropy": 0.03665776337896075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.090470790863037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05490105226635933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07328541576862335,
      "backward_entropy": 0.03670076813016619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0443105697631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05492917075753212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07318941503763199,
      "backward_entropy": 0.03673228195735386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982603073120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054956041276454926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07309895753860474,
      "backward_entropy": 0.036761701107025146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5213568210601807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05498504266142845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07299664616584778,
      "backward_entropy": 0.0019500982016324997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.447744369506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05501198396086693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07290486246347427,
      "backward_entropy": 0.03683487432343619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.957772970199585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055038489401340485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07281500101089478,
      "backward_entropy": 0.03686561754771641,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.166756786368787,
    "avg_log_Z": -0.053713740631937984,
    "success_rate": 1.0,
    "avg_reward": 27.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.75,
      "2": 0.22
    },
    "avg_forward_entropy": 0.07671672999858856,
    "avg_backward_entropy": 0.029946694101340005,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}