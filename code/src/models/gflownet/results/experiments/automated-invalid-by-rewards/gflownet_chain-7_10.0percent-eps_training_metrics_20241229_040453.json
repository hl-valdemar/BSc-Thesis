{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09896508284977504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09900755541665214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.7839813232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722100853919983,
      "backward_entropy": 0.09897748061588832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.74496459960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721495866775513,
      "backward_entropy": 0.09898051193782262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.8076171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0001999998785322532,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372087150812149,
      "backward_entropy": 0.09898344108036586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.66705322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000300230662105605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720229268074036,
      "backward_entropy": 0.09896998746054513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.71861267089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004000009794253856,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719572126865387,
      "backward_entropy": 0.0989889417375837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.255126953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005003309343010187,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718897104263306,
      "backward_entropy": 0.0989915302821568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.5411376953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.000601076812017709,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718204200267792,
      "backward_entropy": 0.0989939911024911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.6586608886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007024146616458893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717493414878845,
      "backward_entropy": 0.09901244299752372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.8648681640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008044144487939775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13716761767864227,
      "backward_entropy": 0.0989776338849749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.85031127929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009066398488357663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716012239456177,
      "backward_entropy": 0.09901368618011475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.23846435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010073068551719189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371525377035141,
      "backward_entropy": 0.09901424816676549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.2059326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011061284458264709,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714487850666046,
      "backward_entropy": 0.0989816699709211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3163299560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012063742615282536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371370106935501,
      "backward_entropy": 0.09898288760866437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.1082763671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013054473092779517,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371290236711502,
      "backward_entropy": 0.09900791304452079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.40586853027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014059272361919284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371208280324936,
      "backward_entropy": 0.09900941167558942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.9532775878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001505255582742393,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137112557888031,
      "backward_entropy": 0.09901077406747001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.05030822753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016053452854976058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371041089296341,
      "backward_entropy": 0.09898721320288521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.42564392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017049753805622458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709552586078644,
      "backward_entropy": 0.09901727948869977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.68380737304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018041630974039435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708685338497162,
      "backward_entropy": 0.09898906094687325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.05628967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019036473240703344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707804679870605,
      "backward_entropy": 0.0990179010799953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1785888671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002003332134336233,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706928491592407,
      "backward_entropy": 0.09901603630610875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.55699157714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002100369893014431,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706046342849731,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.05584716796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002198026515543461,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705146312713623,
      "backward_entropy": 0.09899213484355382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.7857666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002295390935614705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704225420951843,
      "backward_entropy": 0.09901884623936244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.14837646484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002391168149188161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703319430351257,
      "backward_entropy": 0.09899326733180455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.1341552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024870415218174458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370241492986679,
      "backward_entropy": 0.0989937356540135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.3801727294922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025814473628997803,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701502978801727,
      "backward_entropy": 0.09901937416621617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3790283203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026754147838801146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370057761669159,
      "backward_entropy": 0.09899439130510602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.83529663085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002767329104244709,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699647784233093,
      "backward_entropy": 0.09901997021266393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.3624572753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002856706501916051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698720932006836,
      "backward_entropy": 0.09899459566388812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8285675048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002949424786493182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369776427745819,
      "backward_entropy": 0.09899459566388812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.2732849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003041996853426099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696792721748352,
      "backward_entropy": 0.09901981694357735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.87423706054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003137503284960985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695792853832245,
      "backward_entropy": 0.0989944509097508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.74725341796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032341908663511276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694773614406586,
      "backward_entropy": 0.09902074507304601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.1829833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033312540035694838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369374543428421,
      "backward_entropy": 0.09901998724256243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.7313690185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034282668493688107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692674040794373,
      "backward_entropy": 0.09899378674370903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.53302001953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003525305772200227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691556453704834,
      "backward_entropy": 0.09899347169058663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.98687744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00362324807792902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13690412044525146,
      "backward_entropy": 0.09899309703281947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.87130737304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003720326814800501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689234852790833,
      "backward_entropy": 0.09899265425545829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.0059051513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038192274514585733,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13688021898269653,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8695068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00391541188582778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686805963516235,
      "backward_entropy": 0.09902011496680123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.2959747314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004010920878499746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685563206672668,
      "backward_entropy": 0.09902010645185198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.20156860351562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004104368854314089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368432193994522,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.16213989257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004197395406663418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683056831359863,
      "backward_entropy": 0.09902006387710571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 288.8728942871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004290057346224785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681767880916595,
      "backward_entropy": 0.0990200298173087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.8524627685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004386670887470245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680428266525269,
      "backward_entropy": 0.09901999575751168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67759704589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004481574986129999,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679072260856628,
      "backward_entropy": 0.09898667676108223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.95864868164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004572492092847824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677732646465302,
      "backward_entropy": 0.09901990209306989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.00192260742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004662470426410437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676422834396362,
      "backward_entropy": 0.09901983397347587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.55105590820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004753201734274626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675081729888916,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.10003662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004844685550779104,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673707842826843,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9808349609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004936920944601297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672302663326263,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.56866455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00502620218321681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670898973941803,
      "backward_entropy": 0.09901951040540423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.58241271972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005113765597343445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13669487833976746,
      "backward_entropy": 0.09897913251604352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.1374206542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0052014668472111225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136680468916893,
      "backward_entropy": 0.09901929753167289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.4675750732422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0052932025864720345,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13666552305221558,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.42391967773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005382962990552187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665053248405457,
      "backward_entropy": 0.09901906762804304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.405029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00547301210463047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13663533329963684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.58460998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005564924329519272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366197168827057,
      "backward_entropy": 0.09901881217956543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.13882446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005654612090438604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13660401105880737,
      "backward_entropy": 0.09897058350699288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.70086669921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005741521250456572,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658832013607025,
      "backward_entropy": 0.09902097497667585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67288208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005826021544635296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13657274842262268,
      "backward_entropy": 0.09896724564688546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.22811889648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0059074657037854195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13655735552310944,
      "backward_entropy": 0.09896544047764369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.9604034423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005988048855215311,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654205203056335,
      "backward_entropy": 0.09902090685708183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.03768920898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006069868337363005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365266740322113,
      "backward_entropy": 0.09901771375111171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.30538940429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006147467996925116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365114450454712,
      "backward_entropy": 0.0990174753325326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.92721557617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0062257032841444016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13649596273899078,
      "backward_entropy": 0.0990172369139535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.16917419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0063023814000189304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364803910255432,
      "backward_entropy": 0.0990169814654759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2718505859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006382001098245382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13646407425403595,
      "backward_entropy": 0.0989537068775722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.7286376953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006459856405854225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13644756376743317,
      "backward_entropy": 0.09901646205357142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9688720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0065331957302987576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643164932727814,
      "backward_entropy": 0.0989493727684021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.37486267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006606621202081442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364155262708664,
      "backward_entropy": 0.09901585749217443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.99710083007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006679120939224958,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363992542028427,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.0845489501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006749492138624191,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13638287782669067,
      "backward_entropy": 0.09902051516941615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9429168701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0068247318267822266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13636592030525208,
      "backward_entropy": 0.09893999780927386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.95806884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0068975831381976604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13634908199310303,
      "backward_entropy": 0.09893756253378731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.42190551757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006971766706556082,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13633185625076294,
      "backward_entropy": 0.0990203789302281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.22654724121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007049085106700659,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13631421327590942,
      "backward_entropy": 0.09893269198281425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.65550231933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007128560449928045,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13629622757434845,
      "backward_entropy": 0.09902031081063407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.2284393310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00720854802057147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13627785444259644,
      "backward_entropy": 0.09892780440194267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.89947509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007292402908205986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362587809562683,
      "backward_entropy": 0.09901263884135655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.07574462890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007371081504970789,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13624006509780884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.773681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007448394317179918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13622123003005981,
      "backward_entropy": 0.09901172774178642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.56150817871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007525718305259943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362021565437317,
      "backward_entropy": 0.0990112338747297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.23130798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0075993225909769535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13618318736553192,
      "backward_entropy": 0.09901067188807897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.87364196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007674398832023144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13616397976875305,
      "backward_entropy": 0.09901010138647896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.47605895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0077494969591498375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361445188522339,
      "backward_entropy": 0.09900950534003121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.65897369384766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007826813496649265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13612446188926697,
      "backward_entropy": 0.09902000427246094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.0563201904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007900616154074669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361045390367508,
      "backward_entropy": 0.09890295778002058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.86370849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007973356172442436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360843926668167,
      "backward_entropy": 0.09900754690170288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.91363525390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008049667812883854,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360628604888916,
      "backward_entropy": 0.09901988506317139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1593017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008128233253955841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136040598154068,
      "backward_entropy": 0.09889388084411621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.72691345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008205465041100979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13601791858673096,
      "backward_entropy": 0.09900540964944023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.26451110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008281601592898369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13599492609500885,
      "backward_entropy": 0.09888746057237897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.65667724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008360675536096096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359708309173584,
      "backward_entropy": 0.09900384289877755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.48358154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008438486605882645,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13594666123390198,
      "backward_entropy": 0.09901975733893258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.6254119873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008518306538462639,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13592177629470825,
      "backward_entropy": 0.09901973179408483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.0287322998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00859967153519392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13589602708816528,
      "backward_entropy": 0.09887552261352539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.8003692626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008680653758347034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13586997985839844,
      "backward_entropy": 0.09887269565037318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.55075073242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008761576376855373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584363460540771,
      "backward_entropy": 0.0989992448261806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.31529235839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008842277340590954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358170211315155,
      "backward_entropy": 0.09899818045752388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.65151977539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008925904519855976,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13578957319259644,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.54002380371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009008773602545261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13576190173625946,
      "backward_entropy": 0.09899599211556571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.05430603027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00908978283405304,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135734423995018,
      "backward_entropy": 0.0990195529801505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.067138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009171866811811924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13570627570152283,
      "backward_entropy": 0.09885316235678536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.53643798828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009252279065549374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13567779958248138,
      "backward_entropy": 0.09899164949144636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.25537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009333492256700993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13564857840538025,
      "backward_entropy": 0.09899003165108818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.33905029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009414524771273136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13561905920505524,
      "backward_entropy": 0.09898831163133893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0354766845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009493924677371979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13558924198150635,
      "backward_entropy": 0.09898647240230016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.47354125976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009570451453328133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13555921614170074,
      "backward_entropy": 0.09883336509977068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.64796447753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009646008722484112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13552890717983246,
      "backward_entropy": 0.09882890326636178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.03016662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009721644222736359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13549800217151642,
      "backward_entropy": 0.09898015430995397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.7092742919922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009798482991755009,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13546627759933472,
      "backward_entropy": 0.09901881217956543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.16845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009873021394014359,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13543465733528137,
      "backward_entropy": 0.09881517716816493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.24264526367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009948345832526684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13540193438529968,
      "backward_entropy": 0.09897288254329137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.13906860351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010021633468568325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13536886870861053,
      "backward_entropy": 0.09880497625895909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.11248779296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010089275427162647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13533616065979004,
      "backward_entropy": 0.09879927124295916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.7529296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010155175812542439,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353028118610382,
      "backward_entropy": 0.09901797771453857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.32781982421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01022136677056551,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13526907563209534,
      "backward_entropy": 0.09901773929595947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.84393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010294794104993343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13523328304290771,
      "backward_entropy": 0.09895740236554827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.3991241455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010369950905442238,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1351965069770813,
      "backward_entropy": 0.09901742424283709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.57345581054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010445533320307732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13515904545783997,
      "backward_entropy": 0.09877070358821324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.84494018554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010521700605750084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13512101769447327,
      "backward_entropy": 0.098947354725429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.60072326660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01059783436357975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350821852684021,
      "backward_entropy": 0.09875898701804024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.09140014648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010677910409867764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13504213094711304,
      "backward_entropy": 0.09875325645719256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.83604431152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010753180831670761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13500292599201202,
      "backward_entropy": 0.09893630232129778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.78683471679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010833615437150002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13496188819408417,
      "backward_entropy": 0.09893247059413365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.37154388427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01091745961457491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13491934537887573,
      "backward_entropy": 0.09892866441181727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.4374237060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010996028780937195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13487771153450012,
      "backward_entropy": 0.09892443248203822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.11141967773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011075109243392944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13483570516109467,
      "backward_entropy": 0.09872098479952131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.59381103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011152735911309719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13479317724704742,
      "backward_entropy": 0.0987136960029602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.76600646972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01123166922479868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347496211528778,
      "backward_entropy": 0.09870638166155134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.98678588867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011311972513794899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13470476865768433,
      "backward_entropy": 0.09869897365570068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.0927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011395871639251709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13465800881385803,
      "backward_entropy": 0.09890139954430717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.81134033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011484364047646523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13460929691791534,
      "backward_entropy": 0.09889692919594902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.95684814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011573425494134426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13455991446971893,
      "backward_entropy": 0.09889239924294609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.48761749267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011661487631499767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13450977206230164,
      "backward_entropy": 0.09888754572187151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.22702026367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011744766496121883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13445980846881866,
      "backward_entropy": 0.09901494639260429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.12950134277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011831438168883324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344081461429596,
      "backward_entropy": 0.09865455968039376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.6031036376953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011923253536224365,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1343543380498886,
      "backward_entropy": 0.09901477609361921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.0192108154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012018815614283085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13429886102676392,
      "backward_entropy": 0.09864013535635811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.30760192871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012112610973417759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1342429369688034,
      "backward_entropy": 0.09886118343898229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.9224853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01220054179430008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341884732246399,
      "backward_entropy": 0.09862370150429862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.12384033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012284276075661182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13413478434085846,
      "backward_entropy": 0.09884882824761528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.71800231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012371258810162544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134079247713089,
      "backward_entropy": 0.09884244203567505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.33010864257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012455415911972523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13402418792247772,
      "backward_entropy": 0.09883565562111991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.98428344726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012540051713585854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13396768271923065,
      "backward_entropy": 0.09882848603384835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.81234741210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0126182297244668,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13391277194023132,
      "backward_entropy": 0.09901327746255058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.62847900390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012696636840701103,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13385705649852753,
      "backward_entropy": 0.09901285171508789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.11573028564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012774564325809479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13380126655101776,
      "backward_entropy": 0.09880382674080986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.85585021972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012847905047237873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13374635577201843,
      "backward_entropy": 0.09879471574510847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.08543395996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012923169881105423,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13368980586528778,
      "backward_entropy": 0.0985208409173148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.93798828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012997622601687908,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13363268971443176,
      "backward_entropy": 0.09901068891797747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.499755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01307507511228323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335732489824295,
      "backward_entropy": 0.09876619918005806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.83018493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013150119222700596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335136443376541,
      "backward_entropy": 0.09847969668252128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.58831787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013227146118879318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13345268368721008,
      "backward_entropy": 0.09874531200953893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.15440368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013307219371199608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13339000940322876,
      "backward_entropy": 0.09873507704053607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.90135192871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01338593102991581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333266943693161,
      "backward_entropy": 0.09872445038386754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.84445190429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013462227769196033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13326336443424225,
      "backward_entropy": 0.09871309995651245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.46722412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013536356389522552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1331997811794281,
      "backward_entropy": 0.09840655326843262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.84583282470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013612613081932068,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13313473761081696,
      "backward_entropy": 0.09868877274649483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.30413818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013683146797120571,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1330713927745819,
      "backward_entropy": 0.0983736515045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.77713012695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013752203434705734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1330077350139618,
      "backward_entropy": 0.0986614567892892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.8054656982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013821056112647057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329430192708969,
      "backward_entropy": 0.09833739485059466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.53260803222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013893434777855873,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1328756958246231,
      "backward_entropy": 0.09900174822126116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.84786987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013966305181384087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13280677795410156,
      "backward_entropy": 0.0986173152923584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.38255310058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014038807712495327,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13273723423480988,
      "backward_entropy": 0.09900001117161342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.0671615600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01410957332700491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326674520969391,
      "backward_entropy": 0.09858474561146327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.91876220703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01417631283402443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13259869813919067,
      "backward_entropy": 0.09824669361114502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.45358276367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014247252605855465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325274258852005,
      "backward_entropy": 0.09854904242924281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.93891143798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014315295964479446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.132456436753273,
      "backward_entropy": 0.09853026696613856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.2369842529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014381135813891888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323859840631485,
      "backward_entropy": 0.09818504537854876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.47962951660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014453599229454994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13231155276298523,
      "backward_entropy": 0.09816546099526542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.23928833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01452549360692501,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322360336780548,
      "backward_entropy": 0.09847216946738106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.77874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014590853825211525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1321631669998169,
      "backward_entropy": 0.09845072882516044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.65728759765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014659020118415356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13208739459514618,
      "backward_entropy": 0.09899001462118966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.11629486083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014726527966558933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13201187551021576,
      "backward_entropy": 0.09840769427163261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9466552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014789500273764133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1319383829832077,
      "backward_entropy": 0.09805245058877128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.51005554199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014849142171442509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13186538219451904,
      "backward_entropy": 0.09802552631923131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.52462768554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014903037808835506,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13179413974285126,
      "backward_entropy": 0.0989835262298584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.5271453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014964654110372066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13171739876270294,
      "backward_entropy": 0.09830904858452934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.42074584960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015025702305138111,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13163985311985016,
      "backward_entropy": 0.09794406379972186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.30267333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015087798237800598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13156099617481232,
      "backward_entropy": 0.0979171735899789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.6826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01515238732099533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1314803659915924,
      "backward_entropy": 0.09789064952305385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.5068130493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015220068395137787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13139641284942627,
      "backward_entropy": 0.09786490883146014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.47003936767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015283011831343174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13131316006183624,
      "backward_entropy": 0.09783618790762764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.34809875488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015342960134148598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312304586172104,
      "backward_entropy": 0.09780553409031459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.97244262695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015400517731904984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1311485767364502,
      "backward_entropy": 0.09777341570172991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.3423309326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015463282354176044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13106223940849304,
      "backward_entropy": 0.09774362189429146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.11016845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015526588074862957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13097375631332397,
      "backward_entropy": 0.09771382808685303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8297576904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01559224259108305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13088300824165344,
      "backward_entropy": 0.09768411091395787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.33218383789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015658266842365265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13079038262367249,
      "backward_entropy": 0.09765388284410749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9606170654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0157250314950943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1306963860988617,
      "backward_entropy": 0.09796464443206787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.45089721679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015792272984981537,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13060086965560913,
      "backward_entropy": 0.09896801199231829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.3986587524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01585572585463524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13050612807273865,
      "backward_entropy": 0.09755698272160121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.21084594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015913790091872215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13041481375694275,
      "backward_entropy": 0.097518937928336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.5684356689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01597057282924652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13032308220863342,
      "backward_entropy": 0.09747936044420515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9154815673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016030149534344673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13022814691066742,
      "backward_entropy": 0.09777232578822545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.10918426513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0160908754914999,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13013064861297607,
      "backward_entropy": 0.09896129369735718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.1530303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016148783266544342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13003379106521606,
      "backward_entropy": 0.0973592826298305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.10152435302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016206948086619377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12993600964546204,
      "backward_entropy": 0.0973146983555385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.09942626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016261251643300056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12983980774879456,
      "backward_entropy": 0.09758874348231725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.34226989746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016315581277012825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12974143028259277,
      "backward_entropy": 0.09721711703709193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.20774841308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01637323573231697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296398639678955,
      "backward_entropy": 0.0974859254700797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.68763732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016427991911768913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.129538431763649,
      "backward_entropy": 0.09743133613041469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.29296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01648436114192009,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12943421304225922,
      "backward_entropy": 0.09706577232905797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.9792938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016541989520192146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12932716310024261,
      "backward_entropy": 0.09701375450406756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.18817138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01659986935555935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12921886146068573,
      "backward_entropy": 0.09695979527064733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.33415985107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016666168347001076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12910407781600952,
      "backward_entropy": 0.09690984657832555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.33706665039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016730453819036484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12898938357830048,
      "backward_entropy": 0.09685678141457695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.11248779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016797222197055817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12887230515480042,
      "backward_entropy": 0.0970948508807591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.56121826171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016864744946360588,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12875372171401978,
      "backward_entropy": 0.09674853937966484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.87435913085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016931554302573204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128634512424469,
      "backward_entropy": 0.09697907311575753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.83092498779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016995416954159737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12851755321025848,
      "backward_entropy": 0.09691775696618217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.894287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01705632358789444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284019947052002,
      "backward_entropy": 0.09685305186680385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.52220153808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017115483060479164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1282857209444046,
      "backward_entropy": 0.09893168721880231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.72064971923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017178410664200783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12816405296325684,
      "backward_entropy": 0.0964302590915135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.0338592529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017239708453416824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804262340068817,
      "backward_entropy": 0.09664270707539149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.35470581054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017301268875598907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.127920463681221,
      "backward_entropy": 0.09656956366130284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.15522003173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01736418530344963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1277962028980255,
      "backward_entropy": 0.09622347354888916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.36004638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017425289377570152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12767164409160614,
      "backward_entropy": 0.0964171290397644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.88946533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017483437433838844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12754826247692108,
      "backward_entropy": 0.09633331639426095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.55029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0175356213003397,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12742695212364197,
      "backward_entropy": 0.09891082559313093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.2815399169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01758594438433647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12730661034584045,
      "backward_entropy": 0.0961444548198155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.75296020507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017644453793764114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12717854976654053,
      "backward_entropy": 0.09581513064248222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.6788330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017701923847198486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12705054879188538,
      "backward_entropy": 0.09572742666516985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.92526245117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0177630428224802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12691938877105713,
      "backward_entropy": 0.09586857046399798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.14234924316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017821231856942177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12678925693035126,
      "backward_entropy": 0.09577179806573051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.0110321044922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017879461869597435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12665706872940063,
      "backward_entropy": 0.09888545104435512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.97430419921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017941098660230637,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1265215426683426,
      "backward_entropy": 0.0988819854600089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.0121612548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018003055825829506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12638521194458008,
      "backward_entropy": 0.09526279994419642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.9706573486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018070681020617485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.126242533326149,
      "backward_entropy": 0.09537664481571742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.51779174804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018140379339456558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12609638273715973,
      "backward_entropy": 0.09527920825140816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.18122100830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01821204647421837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1259469836950302,
      "backward_entropy": 0.0949775150844029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.86129760742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018276764079928398,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12580221891403198,
      "backward_entropy": 0.09886871065412249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.34420776367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018345581367611885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12565293908119202,
      "backward_entropy": 0.09496567930494036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.07333374023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0184137262403965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12550336122512817,
      "backward_entropy": 0.09485594715390887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.27388763427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018480440601706505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12535527348518372,
      "backward_entropy": 0.09474483558109828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.82488250732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018545471131801605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12520796060562134,
      "backward_entropy": 0.09443199634552002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.1162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018608788028359413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1250610649585724,
      "backward_entropy": 0.09450920139040266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.275634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018673451617360115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12491221725940704,
      "backward_entropy": 0.09438710553305489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.94076538085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018736250698566437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12476205080747604,
      "backward_entropy": 0.09406088931219918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.3323516845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018798084929585457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1246134415268898,
      "backward_entropy": 0.09883613245827812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.55889129638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0188633780926466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12446144223213196,
      "backward_entropy": 0.09400199140821185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.6193389892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018925713375210762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12431171536445618,
      "backward_entropy": 0.0936598266874041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.94231414794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01899067685008049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12415681779384613,
      "backward_entropy": 0.09373516695840019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.92118072509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019051361829042435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12400589883327484,
      "backward_entropy": 0.09338016169411796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.7038116455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019108500331640244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12385915219783783,
      "backward_entropy": 0.0934468422617231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.81822204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019169624894857407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12370679527521133,
      "backward_entropy": 0.0933065755026681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.81966400146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01922832988202572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12355516850948334,
      "backward_entropy": 0.09292217663356236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.63504028320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019286327064037323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1234031617641449,
      "backward_entropy": 0.093010527747018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.94222259521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019341060891747475,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12325527518987656,
      "backward_entropy": 0.0987689665385655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.41424560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01939539797604084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1231054961681366,
      "backward_entropy": 0.09269635166440691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3523178100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019447708502411842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1229558140039444,
      "backward_entropy": 0.09252892221723284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.3798370361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01949702575802803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12280847132205963,
      "backward_entropy": 0.09235372713633946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.74875259399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019550710916519165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12265413999557495,
      "backward_entropy": 0.09217990296227592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.69644927978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019596591591835022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1225069910287857,
      "backward_entropy": 0.09199076039450509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.67289733886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019642585888504982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12235696613788605,
      "backward_entropy": 0.09149266992296491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.76815795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019687514752149582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1222066581249237,
      "backward_entropy": 0.09159469604492188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.49341583251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019741373136639595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12204355001449585,
      "backward_entropy": 0.09140450613839286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.06851959228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019793398678302765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12188136577606201,
      "backward_entropy": 0.09120735100337438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.4639778137207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01984536461532116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12171854078769684,
      "backward_entropy": 0.09100777762276786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.61348724365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01988971047103405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12156358361244202,
      "backward_entropy": 0.09048650945935931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.86334991455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019933389499783516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.121408611536026,
      "backward_entropy": 0.09057537998471941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.56813049316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019978169351816177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12125292420387268,
      "backward_entropy": 0.09035883631025042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.80695343017578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020023342221975327,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12109442055225372,
      "backward_entropy": 0.09858808347157069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.360595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020064691081643105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1209396943449974,
      "backward_entropy": 0.08990475109645299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.55973052978516,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02010679431259632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12078237533569336,
      "backward_entropy": 0.09855326584407262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.67085266113281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020145079120993614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1206267774105072,
      "backward_entropy": 0.08941950116838727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.45756530761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020183145999908447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12047043442726135,
      "backward_entropy": 0.08916653905596052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.09002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020222533494234085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12031151354312897,
      "backward_entropy": 0.08891196761812482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.10275268554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02026611566543579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12014627456665039,
      "backward_entropy": 0.08828376020703997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.01255798339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0203119907528162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11997753381729126,
      "backward_entropy": 0.08802786895206996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.35379028320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020358135923743248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11980541050434113,
      "backward_entropy": 0.08776978084019252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.66920471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02040182426571846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11963579803705215,
      "backward_entropy": 0.0878951975277492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.29190063476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020444614812731743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11946575343608856,
      "backward_entropy": 0.08762442214148385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.48407745361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02049102634191513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11928880214691162,
      "backward_entropy": 0.08735549449920654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.77625274658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020539509132504463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1191086620092392,
      "backward_entropy": 0.08708786964416504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.87754821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020583610981702805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11893272399902344,
      "backward_entropy": 0.08640224593026298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.99337768554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020628733560442924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11875571310520172,
      "backward_entropy": 0.08652285167149135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.28794860839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02067255973815918,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11857785284519196,
      "backward_entropy": 0.09832218715122767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.72042846679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020720072090625763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11839316785335541,
      "backward_entropy": 0.08593882833208356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.681884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020763225853443146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11821265518665314,
      "backward_entropy": 0.08563216243471418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.42073822021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020806020125746727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11803318560123444,
      "backward_entropy": 0.08532323156084333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.57268524169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020846771076321602,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11785601824522018,
      "backward_entropy": 0.09824195078441075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.17036437988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020888440310955048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11767645180225372,
      "backward_entropy": 0.0846840228353228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.59888458251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020931048318743706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11749346554279327,
      "backward_entropy": 0.0843595096043178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.86164093017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020974313840270042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11730679869651794,
      "backward_entropy": 0.08366838523319789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.68961334228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02101980708539486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11711619049310684,
      "backward_entropy": 0.08335211447307042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.77249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021066300570964813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692507565021515,
      "backward_entropy": 0.0981412444795881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.760009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02111916057765484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11672353744506836,
      "backward_entropy": 0.08305409124919347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.94766998291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02117803879082203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11651360243558884,
      "backward_entropy": 0.08275078024183001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.88970947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021234987303614616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11630702018737793,
      "backward_entropy": 0.08243874141148158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.40052795410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02129465341567993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11609666049480438,
      "backward_entropy": 0.08213067054748535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.30073547363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021355167031288147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11588391661643982,
      "backward_entropy": 0.0814981119973319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.17439270019531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021413715556263924,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1156751811504364,
      "backward_entropy": 0.09809369700295585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.04885864257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021470502018928528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11546970903873444,
      "backward_entropy": 0.0811735647065299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.974853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021525710821151733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1152670681476593,
      "backward_entropy": 0.08049258163997106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.88406372070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021580837666988373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11506395787000656,
      "backward_entropy": 0.080142080783844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.91667938232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021640250459313393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11485336720943451,
      "backward_entropy": 0.08017165320260185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.79450988769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021700799465179443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1146416962146759,
      "backward_entropy": 0.07945419209344047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.10499572753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021760664880275726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442937701940536,
      "backward_entropy": 0.0795038172176906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.38177490234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02182144671678543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1142154335975647,
      "backward_entropy": 0.07916133744376046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.24217224121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021884575486183167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1139969676733017,
      "backward_entropy": 0.0788203307560512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.35063171386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021943438798189163,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11378292739391327,
      "backward_entropy": 0.09800897325788226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.77230072021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02199876494705677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11357316374778748,
      "backward_entropy": 0.07807256494249616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.0498504638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022054079920053482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11336326599121094,
      "backward_entropy": 0.07724484375544957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.19717407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02211637608706951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11314086616039276,
      "backward_entropy": 0.07731584140232631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.84827423095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022180628031492233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11291325092315674,
      "backward_entropy": 0.07694159235273089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.21598052978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02224085107445717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11269202083349228,
      "backward_entropy": 0.07654866150447301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.7519989013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02229725569486618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11247528344392776,
      "backward_entropy": 0.07613723618643624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.70602416992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02235983870923519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11225098371505737,
      "backward_entropy": 0.07575018065316337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.66871643066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022418489679694176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11203190684318542,
      "backward_entropy": 0.07491419996534075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.51863098144531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022478098049759865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11181037127971649,
      "backward_entropy": 0.0978757313319615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.07691955566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02253773622214794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11159306764602661,
      "backward_entropy": 0.07409334182739258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.73802185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022595496848225594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11137929558753967,
      "backward_entropy": 0.0741362316267831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.61603546142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02265043370425701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11117175221443176,
      "backward_entropy": 0.07322663068771362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.24383544921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022702839225530624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11096946150064468,
      "backward_entropy": 0.07329930577959333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.47582244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022751042619347572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11077401041984558,
      "backward_entropy": 0.07285872527531215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.89414978027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022794118151068687,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11058732867240906,
      "backward_entropy": 0.0977341617856707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.86056518554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022839616984128952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11039355397224426,
      "backward_entropy": 0.07194461992808751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.79104614257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022886069491505623,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11019597947597504,
      "backward_entropy": 0.07086104154586792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.61978149414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022931760177016258,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10999777913093567,
      "backward_entropy": 0.09763802800859724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.26870727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022978805005550385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10979902744293213,
      "backward_entropy": 0.07055486525808062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.54603576660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023025158792734146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10960060358047485,
      "backward_entropy": 0.07008397153445653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.82771301269531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023073887452483177,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10939650237560272,
      "backward_entropy": 0.09754948956625802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.17752838134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023123428225517273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10919105261564255,
      "backward_entropy": 0.06846226113183158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.04408264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023175057023763657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10898123681545258,
      "backward_entropy": 0.06869703957012721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.55657958984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023227430880069733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10877180099487305,
      "backward_entropy": 0.06823810509272984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.4909896850586,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023275956511497498,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10857046395540237,
      "backward_entropy": 0.09745453085218157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.98434448242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023325664922595024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10836705565452576,
      "backward_entropy": 0.06653392740658351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.995849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02337770164012909,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10815964639186859,
      "backward_entropy": 0.06684017181396484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.66960906982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02343328483402729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10794666409492493,
      "backward_entropy": 0.0663919108254569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.34765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02348756417632103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10773555934429169,
      "backward_entropy": 0.06510414396013532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.8544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023539239540696144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10752902925014496,
      "backward_entropy": 0.06461171592984881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7785186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02359282225370407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1073182225227356,
      "backward_entropy": 0.0641229408127921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.23577117919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02364957518875599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10709987580776215,
      "backward_entropy": 0.06448678459439959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.4881591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023704877123236656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10688365995883942,
      "backward_entropy": 0.06399231723376683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.96207427978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023763583973050117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10666275024414062,
      "backward_entropy": 0.06351172924041748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.43001937866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023822121322155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1064421683549881,
      "backward_entropy": 0.06302319254193987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.78681182861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02387627400457859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10622868686914444,
      "backward_entropy": 0.06251646791185651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3878631591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02393255941569805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10601092875003815,
      "backward_entropy": 0.06201472452708653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.94573974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02399515174329281,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10578359663486481,
      "backward_entropy": 0.06067862680980137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.73255920410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02406020276248455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10555155575275421,
      "backward_entropy": 0.06105623926435198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.22750091552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024133481085300446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1053067147731781,
      "backward_entropy": 0.060603746346064975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.88156509399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024204060435295105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10506841540336609,
      "backward_entropy": 0.059292418616158624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.997802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024267146363854408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10484115034341812,
      "backward_entropy": 0.058798330170767646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.11785888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024334002286195755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10460448265075684,
      "backward_entropy": 0.059125619275229316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.51978302001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02439999394118786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1043706089258194,
      "backward_entropy": 0.05783305849347796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.8702621459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02446540631353855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10413900017738342,
      "backward_entropy": 0.05810544320515224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.52566909790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02452869899570942,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10391101241111755,
      "backward_entropy": 0.056838503905705044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.73522186279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024587497115135193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10369442403316498,
      "backward_entropy": 0.057047090360096524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.239566802978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02464837022125721,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10347715020179749,
      "backward_entropy": 0.05651978935514178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.94170379638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024703210219740868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10327018797397614,
      "backward_entropy": 0.055260726383754184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.19522094726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024757144972682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10306396335363388,
      "backward_entropy": 0.05541004453386579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.20408630371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024811357259750366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1028556227684021,
      "backward_entropy": 0.05417839969907488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.06777954101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024861887097358704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10265501588582993,
      "backward_entropy": 0.05427040798323495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.74797058105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0249177236109972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10244427621364594,
      "backward_entropy": 0.05371234246662685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.160343170166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024969851598143578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10224254429340363,
      "backward_entropy": 0.05254781246185303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.16523742675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02501712180674076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205090045928955,
      "backward_entropy": 0.05256661346980503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3422393798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025061210617423058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10186435282230377,
      "backward_entropy": 0.051408273833138604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.61349487304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025111695751547813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10166697204113007,
      "backward_entropy": 0.05141323804855347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.32298278808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025160083547234535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1014719158411026,
      "backward_entropy": 0.05084267684391567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.7850112915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025208402425050735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1012778952717781,
      "backward_entropy": 0.04978121178490775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.47296905517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02525515668094158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10108783841133118,
      "backward_entropy": 0.04923255102975028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.58358001708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025306345894932747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10088802874088287,
      "backward_entropy": 0.049140134028026035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.992919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025358514860272408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1006857305765152,
      "backward_entropy": 0.04858310307775225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.12854766845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025407278910279274,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10049077868461609,
      "backward_entropy": 0.09658552067620414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.28225708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025454530492424965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10029897093772888,
      "backward_entropy": 0.04744185720171247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.64608001708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025505270808935165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10010412335395813,
      "backward_entropy": 0.046589472464152744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.1626968383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025554440915584564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09991320967674255,
      "backward_entropy": 0.046067186764308383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.83072662353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025603480637073517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0997227132320404,
      "backward_entropy": 0.0455464848450252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.97312927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025655200704932213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09952571243047714,
      "backward_entropy": 0.04525922451700483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.0490951538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025703800842165947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09933510422706604,
      "backward_entropy": 0.044710512672151835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.53719329833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025753747671842575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09914162009954453,
      "backward_entropy": 0.04399421385356358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.11248779296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025808295235037804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09894036501646042,
      "backward_entropy": 0.04349948678697858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.04629516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02586866356432438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0987323671579361,
      "backward_entropy": 0.043162524700164795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.512821197509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02592632733285427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.098528191447258,
      "backward_entropy": 0.04266252262251718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.5869369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025980234146118164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0983315110206604,
      "backward_entropy": 0.04214914781706674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.69971466064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026032811030745506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09814213216304779,
      "backward_entropy": 0.041642137936183383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.12957763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026084046810865402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09795662015676498,
      "backward_entropy": 0.04113911305155073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.88981628417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026141280308365822,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09776018559932709,
      "backward_entropy": 0.04061075619288853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.84513473510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026197925209999084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09756499528884888,
      "backward_entropy": 0.040190815925598145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.38875579833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02625163272023201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09737954288721085,
      "backward_entropy": 0.0397159925528935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.55740356445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026308156549930573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0971883162856102,
      "backward_entropy": 0.039251787321908135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.89797973632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026369059458374977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0969914123415947,
      "backward_entropy": 0.03881351862634931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.51631927490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026432091370224953,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09679079055786133,
      "backward_entropy": 0.03833457401820591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.39909362792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026498541235923767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09658686071634293,
      "backward_entropy": 0.03796553611755371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.81793975830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0265672504901886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09638360142707825,
      "backward_entropy": 0.037569948605128696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.02300262451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02663891203701496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09617489576339722,
      "backward_entropy": 0.03718547310147967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.34119415283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026708872988820076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09597089886665344,
      "backward_entropy": 0.03672289848327637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.538509368896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026778969913721085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0957670658826828,
      "backward_entropy": 0.036410284893853326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.202880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02684498019516468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09557291120290756,
      "backward_entropy": 0.03602390629904611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.96703338623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026906756684184074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09538544714450836,
      "backward_entropy": 0.035620146564074924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.89354705810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026966076344251633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09520035982131958,
      "backward_entropy": 0.03507491520472935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.1340103149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027027590200304985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09501013904809952,
      "backward_entropy": 0.0347815603017807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.50138092041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027088291943073273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09482087194919586,
      "backward_entropy": 0.03436086859021868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.952781677246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02715173177421093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09462989866733551,
      "backward_entropy": 0.03396487874644143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.53392028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02720973826944828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09444662928581238,
      "backward_entropy": 0.033543371728488376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.230926513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02727154642343521,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09425579011440277,
      "backward_entropy": 0.03301471046039036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.93315124511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02732962928712368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09407113492488861,
      "backward_entropy": 0.03270296113831656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.80116271972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02739047072827816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09388428926467896,
      "backward_entropy": 0.032197222113609314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.829833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027449699118733406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09370175004005432,
      "backward_entropy": 0.03188655631882804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.50998306274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027511296793818474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09351229667663574,
      "backward_entropy": 0.0314134167773383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.509521484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027569377794861794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0933295339345932,
      "backward_entropy": 0.031086715204375132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.40584564208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027628827840089798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09314446151256561,
      "backward_entropy": 0.030638980013983592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.94651985168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02768666483461857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09296318888664246,
      "backward_entropy": 0.030253627470561435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.72154235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027738777920603752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09279462695121765,
      "backward_entropy": 0.02985496606145586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.71820068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027795705944299698,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09261788427829742,
      "backward_entropy": 0.02949881340776171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.317359924316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02785150147974491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09244544804096222,
      "backward_entropy": 0.029115717325891768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.48152160644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027903039008378983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0922807827591896,
      "backward_entropy": 0.028713864939553396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.99195098876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02795395441353321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09211747348308563,
      "backward_entropy": 0.02833502633231027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.19338989257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02800123207271099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09196020662784576,
      "backward_entropy": 0.027953049966267178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.17344665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028052469715476036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09179361164569855,
      "backward_entropy": 0.027571133204868863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.68682098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028103046119213104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0916290134191513,
      "backward_entropy": 0.027201552476201738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.41563415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02815335802733898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09146708250045776,
      "backward_entropy": 0.026841625571250916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.098388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02820747345685959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.091297946870327,
      "backward_entropy": 0.026496272001947676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.88877868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028265101835131645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09112535417079926,
      "backward_entropy": 0.026168697646686008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.66403198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02832742966711521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09094539284706116,
      "backward_entropy": 0.02585926651954651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.2973403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028390880674123764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09076222777366638,
      "backward_entropy": 0.025549015828541348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.01988983154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02845398522913456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09058128297328949,
      "backward_entropy": 0.025238452213151113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.67789459228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028516871854662895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0904015302658081,
      "backward_entropy": 0.02493364896093096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.89325714111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028581175953149796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09021912515163422,
      "backward_entropy": 0.024727010301181247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.45951461791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028644895181059837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09003619104623795,
      "backward_entropy": 0.02435132009642465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.26327514648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028706947341561317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08985773473978043,
      "backward_entropy": 0.0241580924817494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.043212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028770269826054573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08967673778533936,
      "backward_entropy": 0.023764959403446743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.53563690185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028832079842686653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08949892222881317,
      "backward_entropy": 0.023475187165396556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.08217239379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02889680117368698,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0893181562423706,
      "backward_entropy": 0.02319794680391039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.71380615234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02895694598555565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08914639800786972,
      "backward_entropy": 0.022910788655281067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.03276062011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02901574969291687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08897476643323898,
      "backward_entropy": 0.022622270243508474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.73661804199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029070405289530754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0888095498085022,
      "backward_entropy": 0.02232385958944048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.1974868774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029121562838554382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08865071833133698,
      "backward_entropy": 0.022208537374223982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.94003677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029176941141486168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08848340809345245,
      "backward_entropy": 0.02175047355038779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.63388061523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029231691733002663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08831837773323059,
      "backward_entropy": 0.02169632911682129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.22358703613281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029287133365869522,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08815255761146545,
      "backward_entropy": 0.09619013752256121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.25098419189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029343493282794952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08798588812351227,
      "backward_entropy": 0.02120635552065713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.50920867919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029400428757071495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08781754225492477,
      "backward_entropy": 0.020707769053322927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.76591491699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029459534212946892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08764587342739105,
      "backward_entropy": 0.020461295332227434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.7499885559082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02951822243630886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08747819811105728,
      "backward_entropy": 0.02022454994065421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.85176086425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029573356732726097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08731837570667267,
      "backward_entropy": 0.019982382655143738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.69369125366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029627980664372444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08715954422950745,
      "backward_entropy": 0.019741630979946682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.01559448242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02968216873705387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08700022101402283,
      "backward_entropy": 0.01950383186340332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.33333969116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02973741479218006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0868377685546875,
      "backward_entropy": 0.019594058394432068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.17983627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029789546504616737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08668242394924164,
      "backward_entropy": 0.019041855420385088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.32808685302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029841626062989235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08652563393115997,
      "backward_entropy": 0.01881576861654009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.00321960449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02989780902862549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08636151254177094,
      "backward_entropy": 0.01860462554863521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.92280197143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02995782345533371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08619189262390137,
      "backward_entropy": 0.018406512481825694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.83135986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030014341697096825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08602920919656754,
      "backward_entropy": 0.018205276557377408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.6865005493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03007192723453045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08586438000202179,
      "backward_entropy": 0.01801017565386636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.92363739013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030130429193377495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08569880574941635,
      "backward_entropy": 0.018215047461645945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.50780487060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030190933495759964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08552800118923187,
      "backward_entropy": 0.017627818243844167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.19660186767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030247977003455162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08536466956138611,
      "backward_entropy": 0.017434996153627123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.89335632324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03030592016875744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08519915491342545,
      "backward_entropy": 0.017245147909436907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.68087768554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030363162979483604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08503362536430359,
      "backward_entropy": 0.01705390853541238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.16189193725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030421562492847443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08486610651016235,
      "backward_entropy": 0.016872080309050425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.19770812988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030478324741125107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0847032219171524,
      "backward_entropy": 0.016694479754992893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.013004302978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0305317472666502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08454564213752747,
      "backward_entropy": 0.01650851219892502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.98674392700195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03058389015495777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08439244329929352,
      "backward_entropy": 0.016816915145942142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.01665496826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030634725466370583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08424021303653717,
      "backward_entropy": 0.016142237399305617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.639625549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03068995289504528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08407924324274063,
      "backward_entropy": 0.015972850578171865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.614891052246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030740968883037567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0839262455701828,
      "backward_entropy": 0.015800329191344126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.50566864013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03079085424542427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08377401530742645,
      "backward_entropy": 0.015628205878393992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.04782104492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030841033905744553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08361884951591492,
      "backward_entropy": 0.015457945210593087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.24623107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030897121876478195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0834532082080841,
      "backward_entropy": 0.01530057511159352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.0164794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030951637774705887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08329051733016968,
      "backward_entropy": 0.015732955719743456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.021568298339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031004978343844414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08313141763210297,
      "backward_entropy": 0.01498662680387497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.59896850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031055936589837074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08297803997993469,
      "backward_entropy": 0.015449947544506617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.76993560791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031108517199754715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08282024413347244,
      "backward_entropy": 0.014679357409477234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.533485412597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03116682730615139,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08265228569507599,
      "backward_entropy": 0.09659593445914132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.33373260498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031223652884364128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08248750120401382,
      "backward_entropy": 0.014398966516767229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.17489624023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03128478676080704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08231286704540253,
      "backward_entropy": 0.014274945216519492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.25511932373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03134958818554878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08213426917791367,
      "backward_entropy": 0.014157404857022422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.69294738769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03141627088189125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08195149898529053,
      "backward_entropy": 0.014044127293995448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.6442756652832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031485967338085175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08176194131374359,
      "backward_entropy": 0.013936078974178858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.48306274414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031554073095321655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08157393336296082,
      "backward_entropy": 0.01382204464503697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.89083862304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03162388876080513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08138398826122284,
      "backward_entropy": 0.013715706765651703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.95600128173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03169636055827141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08118878304958344,
      "backward_entropy": 0.013613826462200709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.39896774291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031764548271894455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08100350201129913,
      "backward_entropy": 0.013507547123091561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.12112045288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031832750886678696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08081493526697159,
      "backward_entropy": 0.013399624398776464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.93227005004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03190116211771965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08062739670276642,
      "backward_entropy": 0.01329337911946433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.50495910644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03196972236037254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08043912053108215,
      "backward_entropy": 0.013189175299235753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.428205490112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03204112872481346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0802445113658905,
      "backward_entropy": 0.013091768537248884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.27801513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0321083664894104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08005934208631516,
      "backward_entropy": 0.012988888791629247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.27272033691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032175976783037186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07987351715564728,
      "backward_entropy": 0.012888747666563307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.90294647216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03224920481443405,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07967555522918701,
      "backward_entropy": 0.09725583451134819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.226036071777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03232208266854286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07947896420955658,
      "backward_entropy": 0.012704970581190926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.66706085205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0323919951915741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07928793132305145,
      "backward_entropy": 0.013498191322599138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.871978759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03246323764324188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07909374684095383,
      "backward_entropy": 0.013419679233006068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.48630142211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03253190219402313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07890499383211136,
      "backward_entropy": 0.012427381106785365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.73435974121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03259555622935295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07872834801673889,
      "backward_entropy": 0.013257384300231934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.3614444732666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03265862539410591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07855224609375,
      "backward_entropy": 0.012241893580981664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.308195114135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03271722048521042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07838689535856247,
      "backward_entropy": 0.012147362743105208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.269012451171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0327717587351799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0782308578491211,
      "backward_entropy": 0.013003130044255937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.19970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03282668814063072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07807274907827377,
      "backward_entropy": 0.011957989207335882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.91378021240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032880451530218124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0779162123799324,
      "backward_entropy": 0.01186351158789226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.90119934082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03293729946017265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07775284349918365,
      "backward_entropy": 0.011773480900696345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.41727447509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03299303725361824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07759205996990204,
      "backward_entropy": 0.011684810476643699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.68843460083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0330529622733593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07742170989513397,
      "backward_entropy": 0.011601764176573073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.680118560791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03311137855052948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07725603878498077,
      "backward_entropy": 0.011517698211329324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.11783981323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033167291432619095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07709577679634094,
      "backward_entropy": 0.011434680649212428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.44900512695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03322460502386093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07692928612232208,
      "backward_entropy": 0.011351549199649267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.87194538116455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033286064863204956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07675252854824066,
      "backward_entropy": 0.011275666100638253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.54439926147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03334217518568039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07659122347831726,
      "backward_entropy": 0.011199487107140678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.34427261352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03339982032775879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07642586529254913,
      "backward_entropy": 0.011124958949429649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.50235366821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03345894813537598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07625776529312134,
      "backward_entropy": 0.011053974074976785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.37921142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03351806476712227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07608887553215027,
      "backward_entropy": 0.010984535728182112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.2064208984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03357705473899841,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07591897249221802,
      "backward_entropy": 0.09771863051823207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.64279556274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033636029809713364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07574857026338577,
      "backward_entropy": 0.010846128421170371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.99122619628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03369627892971039,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07557553052902222,
      "backward_entropy": 0.011852542204516274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.177541732788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03375907242298126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07539679110050201,
      "backward_entropy": 0.011795404766287123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587591171264648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03381754085421562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07522798329591751,
      "backward_entropy": 0.010649184031145913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.99667739868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03387096896767616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07507188618183136,
      "backward_entropy": 0.010582000017166138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.45699691772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033923596143722534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07491613179445267,
      "backward_entropy": 0.010514112455504281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.42776489257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03397414833307266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07476530969142914,
      "backward_entropy": 0.010443764073508126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.240751266479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03402942791581154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07460366934537888,
      "backward_entropy": 0.010377517768314906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.33362579345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034082625061273575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07444751262664795,
      "backward_entropy": 0.01031337252685002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.4291877746582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03414160758256912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07427438348531723,
      "backward_entropy": 0.010256169097764152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.882442474365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03419925272464752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07410641014575958,
      "backward_entropy": 0.011324316263198853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.43531036376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425844758749008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07393442839384079,
      "backward_entropy": 0.01014255519424166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.535404205322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03431771323084831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07376162707805634,
      "backward_entropy": 0.01008859702519008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.349796295166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03437827527523041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0735861212015152,
      "backward_entropy": 0.010036582393305642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.788211822509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03443999961018562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07340742647647858,
      "backward_entropy": 0.009985559753009252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.66095733642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034500278532505035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07323262840509415,
      "backward_entropy": 0.00993519595691136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07601766288280487,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03455927222967148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07306168973445892,
      "backward_entropy": 0.009885681527001517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.71721649169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03461184725165367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07290735840797424,
      "backward_entropy": 0.009832488639014108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.32658386230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034667715430259705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07274351269006729,
      "backward_entropy": 0.009783084903444563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.22618103027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034722670912742615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07258142530918121,
      "backward_entropy": 0.009733797184058599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.10975646972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0347767174243927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07241973280906677,
      "backward_entropy": 0.009683449353490556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.961822509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03483131155371666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0722566694021225,
      "backward_entropy": 0.009634034974234445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.78053283691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0348864383995533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07209313660860062,
      "backward_entropy": 0.009586073458194733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.74921417236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494326025247574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07192394882440567,
      "backward_entropy": 0.00953933596611023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.741697311401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034999098628759384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07175794243812561,
      "backward_entropy": 0.009493060410022736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.790857315063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035052742809057236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0715964287519455,
      "backward_entropy": 0.00944614942584719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.727863311767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035103119909763336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07144366204738617,
      "backward_entropy": 0.010551050305366516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.75926971435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035150617361068726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07129845023155212,
      "backward_entropy": 0.009349581386361803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.99248123168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03520190715789795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07114160060882568,
      "backward_entropy": 0.009305682565484728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.08900451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03525405377149582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07098352909088135,
      "backward_entropy": 0.009263610201222556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.71974182128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035305723547935486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07082712650299072,
      "backward_entropy": 0.009222793791975294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.45489501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03535820171236992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07066758722066879,
      "backward_entropy": 0.009182844843183244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.13075256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03540760278701782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07051676511764526,
      "backward_entropy": 0.00914182301078524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.61953353881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035459328442811966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07035979628562927,
      "backward_entropy": 0.00910234877041408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.9107608795166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035514429211616516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07019494473934174,
      "backward_entropy": 0.01021669592176165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.22724151611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035567499697208405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07003483921289444,
      "backward_entropy": 0.010178386100700923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.32418441772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03561747819185257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06988254189491272,
      "backward_entropy": 0.008991783218724387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.49844360351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03566716983914375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06973032653331757,
      "backward_entropy": 0.00895489752292633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.0559139251709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035724151879549026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06955868005752563,
      "backward_entropy": 0.008921365652765547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.469886779785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03577769547700882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06939758360385895,
      "backward_entropy": 0.01002784286226545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.404817581176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03583189472556114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0692346841096878,
      "backward_entropy": 0.008854445070028305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.31982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035884179174900055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06907734274864197,
      "backward_entropy": 0.008821436337062291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.65043258666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035934753715991974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06892512738704681,
      "backward_entropy": 0.008789072611502238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.92361831665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035985011607408524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06877368688583374,
      "backward_entropy": 0.008756957948207855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.140987396240234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03603624552488327,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06861909478902817,
      "backward_entropy": 0.09825738838740758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.62397003173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036089617758989334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06845848262310028,
      "backward_entropy": 0.00869721280676978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.0848388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03614738583564758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0682855099439621,
      "backward_entropy": 0.008670336433819361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.07252502441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03620787337422371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06810544431209564,
      "backward_entropy": 0.008645011910370417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.64778518676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03626706451177597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0679292157292366,
      "backward_entropy": 0.008619612881115504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.618101119995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03632880747318268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06774670630693436,
      "backward_entropy": 0.008595545909234456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.185359954833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03638788312673569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06757130473852158,
      "backward_entropy": 0.009651527873107366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156099319458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03644205629825592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0674096941947937,
      "backward_entropy": 0.008543622280870165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.360015869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03649182245135307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06726139783859253,
      "backward_entropy": 0.008515777864626475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.282594680786133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036540109664201736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06711681932210922,
      "backward_entropy": 0.00954786581652505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.33717346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03658706694841385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06697636842727661,
      "backward_entropy": 0.008461583937917436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.13036346435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036635302007198334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06683240830898285,
      "backward_entropy": 0.09837423052106585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.06752014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036682210862636566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06669269502162933,
      "backward_entropy": 0.008411136588879995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.96712303161621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036729179322719574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06655228137969971,
      "backward_entropy": 0.008386080818516868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.97551155090332,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03677619993686676,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06641137599945068,
      "backward_entropy": 0.09839367866516113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.71267318725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681954741477966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06628154218196869,
      "backward_entropy": 0.008335688284465246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.51079177856445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03686454892158508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06614652276039124,
      "backward_entropy": 0.009308915053095137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.790542602539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03691224008798599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06600406765937805,
      "backward_entropy": 0.008287990731852395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.53945922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03695745766162872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06586829572916031,
      "backward_entropy": 0.009243716086660112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.03736114501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03701148182153702,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06570705771446228,
      "backward_entropy": 0.09842438357216972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.434595108032227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03706728294491768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06554147601127625,
      "backward_entropy": 0.008224082844597953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.12826919555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037121016532182693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0653819665312767,
      "backward_entropy": 0.008203841745853424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.26189422607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03717410936951637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06522456556558609,
      "backward_entropy": 0.00818372517824173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.6281852722168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03722542151808739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06507181376218796,
      "backward_entropy": 0.009091500725064958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.48805618286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03727755695581436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06491686403751373,
      "backward_entropy": 0.008144740015268326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.34511184692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03733043372631073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06476016342639923,
      "backward_entropy": 0.009031565061637334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.565162658691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037383995950222015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06460104882717133,
      "backward_entropy": 0.008108488151005335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.22672176361084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03743692860007286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06444405019283295,
      "backward_entropy": 0.008090595049517495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.9245719909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037486907094717026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0642956793308258,
      "backward_entropy": 0.008945332041808538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.56817102432251,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03753786161541939,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06414413452148438,
      "backward_entropy": 0.008917726576328278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.137569427490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03758477419614792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06400568783283234,
      "backward_entropy": 0.008037675704274858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.03533935546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03763166442513466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06386709213256836,
      "backward_entropy": 0.008019515978438514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.973658561706543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037678543478250504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06372880935668945,
      "backward_entropy": 0.00800180115870067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.925474166870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03772298991680145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06359852850437164,
      "backward_entropy": 0.007983446653400148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.60548782348633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03776524215936661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06347513198852539,
      "backward_entropy": 0.007964649902922767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.231117248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781041502952576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0633426234126091,
      "backward_entropy": 0.007946849933692388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.69270324707031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0378546267747879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06321276724338531,
      "backward_entropy": 0.007929851966244834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.079132080078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03790281340479851,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06307066977024078,
      "backward_entropy": 0.09854342256273542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.345346450805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037949755787849426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06293215602636337,
      "backward_entropy": 0.007900602583374296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.5439338684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037996646016836166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06279375404119492,
      "backward_entropy": 0.007886507681437902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.13627052307129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0380447618663311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062652088701725,
      "backward_entropy": 0.007872775729213442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.777652740478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038092732429504395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06251125037670135,
      "backward_entropy": 0.007858567472015108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.925926208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03813936933875084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062374867498874664,
      "backward_entropy": 0.007843886635133199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.026649475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038186050951480865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062238261103630066,
      "backward_entropy": 0.007829767784902028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.53957176208496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038233961910009384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06209810450673103,
      "backward_entropy": 0.007815767611776079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.767635345458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03828062862157822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06196150183677673,
      "backward_entropy": 0.007802356566701617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.8826904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038328517228364944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06182117015123367,
      "backward_entropy": 0.007789541035890579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.4945182800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038379911333322525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06167077273130417,
      "backward_entropy": 0.007777503558567592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.3565559387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03843206539750099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06151735037565231,
      "backward_entropy": 0.007766237216336387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.32072830200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038484837859869,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.061363644897937775,
      "backward_entropy": 0.008352783641644887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.040369033813477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03854179382324219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061195842921733856,
      "backward_entropy": 0.007746104151010513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.86143493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03859652951359749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06103607267141342,
      "backward_entropy": 0.007736301847866603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.692222595214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038653966039419174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06086868420243263,
      "backward_entropy": 0.007726134466273444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.683435440063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03871269151568413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060697704553604126,
      "backward_entropy": 0.007716077246836254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.3193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03877008706331253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06053154543042183,
      "backward_entropy": 0.007704698613711766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.72822093963623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038828663527965546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06036228686571121,
      "backward_entropy": 0.0076928335641111645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.94007110595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03888358548283577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06020517647266388,
      "backward_entropy": 0.007679915853909084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.96543884277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038939982652664185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0600438117980957,
      "backward_entropy": 0.007667148751871926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.543798446655273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038996532559394836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059882134199142456,
      "backward_entropy": 0.00765480101108551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.20520782470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03904964029788971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05973169207572937,
      "backward_entropy": 0.007641775267464774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.929405212402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03910091146826744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05958693102002144,
      "backward_entropy": 0.008044041693210602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.04096984863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03915506601333618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05943382531404495,
      "backward_entropy": 0.007615961666618075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.22953796386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03921075165271759,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05927611142396927,
      "backward_entropy": 0.007979631423950195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.67405319213867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03926651552319527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059118807315826416,
      "backward_entropy": 0.007589266768523625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.76813507080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0393236018717289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058958590030670166,
      "backward_entropy": 0.0075761111719267705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.38982009887695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039378270506858826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058805763721466064,
      "backward_entropy": 0.007561683654785156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.558189392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0394367016851902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05864076316356659,
      "backward_entropy": 0.007548425878797259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.484092712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039492830634117126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05848361924290657,
      "backward_entropy": 0.007537392101117543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.73338317871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039546675980091095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05833425372838974,
      "backward_entropy": 0.007525767066649028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.13880920410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03960210457444191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0581793375313282,
      "backward_entropy": 0.007516356451170785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.597469329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03965768218040466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05802461504936218,
      "backward_entropy": 0.007506840463195529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.471254348754883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03971221670508385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0578734427690506,
      "backward_entropy": 0.007496922676052366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.67404556274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039765868335962296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057725176215171814,
      "backward_entropy": 0.007664769355739866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.322700500488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03981994837522507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057575419545173645,
      "backward_entropy": 0.007479187101125717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.847036361694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03986986353993416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05743853375315666,
      "backward_entropy": 0.007473064320428031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.26805877685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039918236434459686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057306498289108276,
      "backward_entropy": 0.007467596658638546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.34702682495117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0399673767387867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057172540575265884,
      "backward_entropy": 0.007461164678846087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.18050003051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04001835733652115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057033125311136246,
      "backward_entropy": 0.007454439997673035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.84462547302246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04007095471024513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05688900500535965,
      "backward_entropy": 0.007507591375282833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.41493034362793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04012386500835419,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056744568049907684,
      "backward_entropy": 0.007440137011664254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.548248291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04017501696944237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05660533905029297,
      "backward_entropy": 0.007434958325965064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.276609420776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040226683020591736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056464821100234985,
      "backward_entropy": 0.007429693958589009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.126240730285645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04027637466788292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05633131042122841,
      "backward_entropy": 0.007422385471207755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.14925765991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04032338410615921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05620615556836128,
      "backward_entropy": 0.007416292492832456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.010929107666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040372446179389954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05607479065656662,
      "backward_entropy": 0.007410520953791482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.79316711425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041999951004982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05594797432422638,
      "backward_entropy": 0.00740579462477139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.8029842376709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04047060385346413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05581222474575043,
      "backward_entropy": 0.007400164646761758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.76729965209961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040520455688238144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05567964166402817,
      "backward_entropy": 0.007261385875088828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.690582275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04056866839528084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05555238574743271,
      "backward_entropy": 0.007385256034987313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.174591064453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04061536118388176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05543003976345062,
      "backward_entropy": 0.00737830890076501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.71240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04066399857401848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05530202016234398,
      "backward_entropy": 0.007371801350797925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.457355499267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04070987552404404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05518323928117752,
      "backward_entropy": 0.007364289036818913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.377714157104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04075441136956215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05506950244307518,
      "backward_entropy": 0.007356350975377219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.54707717895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040797773748636246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0549594983458519,
      "backward_entropy": 0.007348612483058657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.4891996383667,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04084346070885658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0548408143222332,
      "backward_entropy": 0.09876792771475655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.467456817626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040886882692575455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05473014712333679,
      "backward_entropy": 0.007337495684623718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059459760785102844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040928006172180176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.054627180099487305,
      "backward_entropy": 0.006991192698478699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.301998138427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040964942425489426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05453764647245407,
      "backward_entropy": 0.006960553782326835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.55826187133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041006870567798615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054433003067970276,
      "backward_entropy": 0.007316222148282188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.31140899658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104917496442795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05432690680027008,
      "backward_entropy": 0.007310907755579267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.80071449279785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041094820946455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054210834205150604,
      "backward_entropy": 0.007304054817983082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.832265853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041139155626297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05409920960664749,
      "backward_entropy": 0.0072973982564040595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.306983947753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041184525936841965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.053984634578228,
      "backward_entropy": 0.00680919736623764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.069087982177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04123393073678017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05385861545801163,
      "backward_entropy": 0.007282697196517672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.43242835998535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04128488153219223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05372842401266098,
      "backward_entropy": 0.00727405132991927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.967660903930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041336044669151306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05359838157892227,
      "backward_entropy": 0.007264278829097748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.159446716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04138406366109848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053479310125112534,
      "backward_entropy": 0.007252896470682961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.230981826782227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143247380852699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053359948098659515,
      "backward_entropy": 0.007239902125937598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.516115188598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04147922247648239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053245414048433304,
      "backward_entropy": 0.007227744374956403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.404727935791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041525498032569885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053132425993680954,
      "backward_entropy": 0.007215559482574463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.294267654418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04157138988375664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.053021397441625595,
      "backward_entropy": 0.006518133516822543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.219276428222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041616976261138916,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052911438047885895,
      "backward_entropy": 0.006481609174183437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.830917358398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04166200011968613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052804309874773026,
      "backward_entropy": 0.007179440132209233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.004179000854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04170573502779007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05270114541053772,
      "backward_entropy": 0.007166745407240731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.670185089111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041749175637960434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05259951949119568,
      "backward_entropy": 0.007152925644602094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.611470222473145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041791580617427826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05250076949596405,
      "backward_entropy": 0.007142262799399239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.70006561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041832905262708664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05240564048290253,
      "backward_entropy": 0.0071323056306157795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.196051597595215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04187426343560219,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052310358732938766,
      "backward_entropy": 0.006250322397266116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.392168045043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04191262274980545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05222424864768982,
      "backward_entropy": 0.007114369954381671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.510786056518555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041950397193431854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05213988199830055,
      "backward_entropy": 0.007108270057610103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.57638168334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04198965057730675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052051085978746414,
      "backward_entropy": 0.007102108959640775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.344783782958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042033519595861435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05194879323244095,
      "backward_entropy": 0.0070971665637833735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.13203239440918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042080383747816086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051837459206581116,
      "backward_entropy": 0.00709176276411329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.99107551574707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04212784394621849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.051724955439567566,
      "backward_entropy": 0.09875891889844622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.015927314758301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04217588156461716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051610931754112244,
      "backward_entropy": 0.007082789071968624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.64803695678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042220357805490494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05150765925645828,
      "backward_entropy": 0.007082329796893256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.789915084838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04226682707667351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.051397956907749176,
      "backward_entropy": 0.005976054285253797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.692684173583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042311809957027435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05129338800907135,
      "backward_entropy": 0.007083894951002938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.785358428955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042355652898550034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05119200423359871,
      "backward_entropy": 0.007088049181870052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.90127944946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04239721968770027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05109772831201553,
      "backward_entropy": 0.007092574877398354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.69619369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04244178533554077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05099537968635559,
      "backward_entropy": 0.00709401975784983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.973859786987305,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042489293962717056,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.050884515047073364,
      "backward_entropy": 0.09878210510526385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.321475982666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04253717139363289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05077359825372696,
      "backward_entropy": 0.007098697125911713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.803524971008301,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04258757457137108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050655119121074677,
      "backward_entropy": 0.0071012308554989955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.86868667602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042633987963199615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05054916441440582,
      "backward_entropy": 0.007104270160198212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.43958282470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042679812759160995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.050445474684238434,
      "backward_entropy": 0.005768094211816788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.93155860900879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427260622382164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050341349095106125,
      "backward_entropy": 0.007106092359338488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.767852783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042773857712745667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050233110785484314,
      "backward_entropy": 0.007105662886585508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.852901458740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042823031544685364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0501214973628521,
      "backward_entropy": 0.007105099303381783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213235855102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04287028685212135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0500158853828907,
      "backward_entropy": 0.007103356399706432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.690139770507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04291479289531708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049918483942747116,
      "backward_entropy": 0.007100808833326612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.61951446533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04295788332819939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04982538893818855,
      "backward_entropy": 0.007098003157547542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.00751495361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04300399497151375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04972357302904129,
      "backward_entropy": 0.007098200065749032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.944602966308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043049633502960205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0496232807636261,
      "backward_entropy": 0.007099334682737078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.41183090209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04309449344873428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04952627420425415,
      "backward_entropy": 0.0070961543491908485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911453247070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313763976097107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04943529888987541,
      "backward_entropy": 0.007089570164680481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.61562728881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04317841678857803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04935150966048241,
      "backward_entropy": 0.007082962564059666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.86703872680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04321916401386261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04926739260554314,
      "backward_entropy": 0.007077740771429879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.41942024230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04326098784804344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049180179834365845,
      "backward_entropy": 0.007074851010526929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702674865722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04330272227525711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04909320920705795,
      "backward_entropy": 0.007073824426957539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.556642532348633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043342385441064835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04901208356022835,
      "backward_entropy": 0.007074932966913495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.642072677612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043382853269577026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048929572105407715,
      "backward_entropy": 0.007072141660111291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.82481861114502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0434255450963974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04884020984172821,
      "backward_entropy": 0.005299823092562812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.411149978637695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04346686601638794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04875526204705238,
      "backward_entropy": 0.007074498172317233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.851001739501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0435098297894001,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04866648465394974,
      "backward_entropy": 0.007071274731840406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.593554496765137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04355254024267197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048578619956970215,
      "backward_entropy": 0.00706937483378819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.63678741455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04359397292137146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048494625836610794,
      "backward_entropy": 0.0070677101612091064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.601778030395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04363546893000603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048409368842840195,
      "backward_entropy": 0.007069844220365796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.382247924804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043676529079675674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04832669347524643,
      "backward_entropy": 0.007068720247064318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.402408599853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04371645674109459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04824722558259964,
      "backward_entropy": 0.007068326962845666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.30394744873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04375620558857918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04816877841949463,
      "backward_entropy": 0.0070662179163524085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.280710220336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04379584640264511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04809104651212692,
      "backward_entropy": 0.007063666092497962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.10071563720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383839666843414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04800550639629364,
      "backward_entropy": 0.007061583655221122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10448771715164185,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388066753745079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04792081564664841,
      "backward_entropy": 0.007061210594006947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019017219543457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391870275139809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04784819483757019,
      "backward_entropy": 0.007061645920787539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.954489707946777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043954845517873764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047780975699424744,
      "backward_entropy": 0.007062003016471863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.732877731323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04398946836590767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047717586159706116,
      "backward_entropy": 0.007065091282129288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.6766357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0440247543156147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047651857137680054,
      "backward_entropy": 0.0070721762520926336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.604049682617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044060442596673965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04758510738611221,
      "backward_entropy": 0.007079236209392548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.642399787902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409641772508621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047517940402030945,
      "backward_entropy": 0.0070850130702768055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.279029846191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04413187876343727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04745165631175041,
      "backward_entropy": 0.007093530680452075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.721343040466309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04416857659816742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0473824106156826,
      "backward_entropy": 0.004849473280566079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.060026168823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04420359805226326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04731779173016548,
      "backward_entropy": 0.007108096565519061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.415949821472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04424000531435013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047249339520931244,
      "backward_entropy": 0.00711609103849956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.110432624816895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04427569359540939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04718295857310295,
      "backward_entropy": 0.007124286677156176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10053057223558426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431166872382164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04711594060063362,
      "backward_entropy": 0.007131623902491161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.576506614685059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044344060122966766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04705895483493805,
      "backward_entropy": 0.0071390776761940545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.886555671691895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04437478259205818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04700733721256256,
      "backward_entropy": 0.007140731172902244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.798628568649292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044406261295080185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04695369675755501,
      "backward_entropy": 0.0071427976446492335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.783040046691895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04443540796637535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046906836330890656,
      "backward_entropy": 0.007143421364682061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.01541805267334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04446519911289215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046858519315719604,
      "backward_entropy": 0.007141255906649998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.989940643310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04449502006173134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046809546649456024,
      "backward_entropy": 0.00714270185147013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.712528705596924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0445246659219265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04676133394241333,
      "backward_entropy": 0.007144194096326828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30242919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044552288949489594,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04671856015920639,
      "backward_entropy": 0.004592881138835635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.9930362701416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457895830273628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04667844623327255,
      "backward_entropy": 0.0071466341614723206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.837882995605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446077436208725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04663216322660446,
      "backward_entropy": 0.007148241358143943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.95291519165039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04463612660765648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04658804088830948,
      "backward_entropy": 0.007144753422055926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.159721374511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044668104499578476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046534936875104904,
      "backward_entropy": 0.007139629019158227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.68280029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04469875618815422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04648517072200775,
      "backward_entropy": 0.007135371012347085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.570289611816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04473288729786873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04642604663968086,
      "backward_entropy": 0.007130710674183709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.9949951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04476645961403847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04636862501502037,
      "backward_entropy": 0.007127716072968074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.429612159729004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04480037838220596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04631020501255989,
      "backward_entropy": 0.007124413869210652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.30082130432129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044833943247795105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04625227674841881,
      "backward_entropy": 0.007125837994473321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.946093559265137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04486856609582901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04619240388274193,
      "backward_entropy": 0.007123378770692008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.074508666992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04490145295858383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046137645840644836,
      "backward_entropy": 0.007119600261960711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.566534996032715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04493570700287819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0460788868367672,
      "backward_entropy": 0.007117295903818948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.472454786300659,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04497052729129791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04601828008890152,
      "backward_entropy": 0.0071201931153024945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4706056118011475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04500267654657364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04596509039402008,
      "backward_entropy": 0.007121448005948748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.379135131835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04503228887915611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04591920226812363,
      "backward_entropy": 0.0071190765925816125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.021040916442871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04506264999508858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045871347188949585,
      "backward_entropy": 0.007117577961512974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.520814895629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04509265348315239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045824624598026276,
      "backward_entropy": 0.007115672741617475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.454795837402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045124322175979614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04577334225177765,
      "backward_entropy": 0.007115563111645835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.125868797302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045157290995121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04571916162967682,
      "backward_entropy": 0.0071139899747712275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.46564483642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04519039765000343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045665301382541656,
      "backward_entropy": 0.007109457893030984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.156890869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04522579535841942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04560527577996254,
      "backward_entropy": 0.007108013544763837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.480621814727783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045262157917022705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04554300010204315,
      "backward_entropy": 0.0071058087050914764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.44959831237793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04529670998454094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045485541224479675,
      "backward_entropy": 0.007104851305484772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.540778160095215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045329563319683075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04543264955282211,
      "backward_entropy": 0.007103777889694486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.493860244750977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0453619658946991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04538074508309364,
      "backward_entropy": 0.007105376039232526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.68851089477539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04539388790726662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04533010721206665,
      "backward_entropy": 0.007108149251767567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2129878997802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04542700573801994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0452767089009285,
      "backward_entropy": 0.007108760199376515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35593032836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04545760154724121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045230086892843246,
      "backward_entropy": 0.007108151912689209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.390668869018555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04548768699169159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04518517106771469,
      "backward_entropy": 0.007105931107486997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.288029670715332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0455193854868412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045135803520679474,
      "backward_entropy": 0.0071071673716817585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.20269775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04555139318108559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04508599638938904,
      "backward_entropy": 0.0038750464362757547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.116390228271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045584872364997864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0450320839881897,
      "backward_entropy": 0.007111555763653347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.094549179077148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04561866447329521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044977396726608276,
      "backward_entropy": 0.007117244814123426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.046581268310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045650724321603775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04492780566215515,
      "backward_entropy": 0.007120497524738312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.860519409179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568195343017578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04488087818026543,
      "backward_entropy": 0.007118763668196542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.90591049194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04571449011564255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.044829968363046646,
      "backward_entropy": 0.003779293437089239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860170364379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04574640095233917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04478124901652336,
      "backward_entropy": 0.00711691752076149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774829864501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04577767848968506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044734325259923935,
      "backward_entropy": 0.007115343851702554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.848377227783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04580864682793617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04468779265880585,
      "backward_entropy": 0.007117432143007006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.413262367248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045838404446840286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044643983244895935,
      "backward_entropy": 0.007122174437556948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9645438194274902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04586963728070259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04459654167294502,
      "backward_entropy": 0.00712856969663075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.446374893188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045898500829935074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04455528035759926,
      "backward_entropy": 0.0036680826119014193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7154011726379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04592778533697128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04451344162225723,
      "backward_entropy": 0.0071345386760575434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5090970993042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04595600813627243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044473905116319656,
      "backward_entropy": 0.007138474711350032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.024486541748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04598391801118851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044435322284698486,
      "backward_entropy": 0.007140661988939557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057731110602617264,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046013303101062775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044393330812454224,
      "backward_entropy": 0.007141767335789544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.369131088256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04604011029005051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04435679316520691,
      "backward_entropy": 0.007149531905140195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.884941816329956,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04607023671269417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04431260749697685,
      "backward_entropy": 0.007156204964433398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.297140121459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04609781876206398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04427561163902283,
      "backward_entropy": 0.007155741431883403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210516929626465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04612492397427559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04424023628234863,
      "backward_entropy": 0.007150991686752864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.165021896362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04615192860364914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04420487582683563,
      "backward_entropy": 0.007148110972983497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15947151184082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04617884382605553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04416954144835472,
      "backward_entropy": 0.007146964115755898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.412731647491455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046205341815948486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044135935604572296,
      "backward_entropy": 0.007142011608396258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04720687866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04623095691204071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04410427063703537,
      "backward_entropy": 0.003439431743962424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.370148181915283,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04625648260116577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0440727137029171,
      "backward_entropy": 0.007136196430240359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.187114715576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04628109186887741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04404349625110626,
      "backward_entropy": 0.007133005453007562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.091023445129395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04630749672651291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04400995746254921,
      "backward_entropy": 0.007131429655211312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.057602882385254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633570462465286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04397144168615341,
      "backward_entropy": 0.007134350282805306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.380053520202637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04636513814330101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04393064230680466,
      "backward_entropy": 0.007134380085127694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.229679584503174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046395037323236465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04388868063688278,
      "backward_entropy": 0.007135092679943357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.265422821044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04642344266176224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043850697576999664,
      "backward_entropy": 0.007133256644010544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.661338806152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046452272683382034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043812096118927,
      "backward_entropy": 0.007130736751215798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07102901488542557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648079350590706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04377388954162598,
      "backward_entropy": 0.007130362093448639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.57853364944458,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04650671035051346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04374159127473831,
      "backward_entropy": 0.09881927285875593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.514209270477295,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465325303375721,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04370885714888573,
      "backward_entropy": 0.0071392666016306195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.888195037841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046558454632759094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04367586225271225,
      "backward_entropy": 0.007146717182227543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.351325035095215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046586763113737106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04363740235567093,
      "backward_entropy": 0.007153019841228213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.428603172302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046616330742836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043596260249614716,
      "backward_entropy": 0.00715821555682591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09168154001235962,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466451495885849,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04355746507644653,
      "backward_entropy": 0.007158617355993816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.91034460067749,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667112976312637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04352520406246185,
      "backward_entropy": 0.007160418267760958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.659969329833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046696096658706665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043495334684848785,
      "backward_entropy": 0.007161551288196019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.967394828796387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046721819788217545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043463774025440216,
      "backward_entropy": 0.0071626390729631695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.907234191894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04674914479255676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043428339064121246,
      "backward_entropy": 0.007165398980890002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.82193374633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04677777364850044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04339011013507843,
      "backward_entropy": 0.007167612335511616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0704345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046807631850242615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043349288403987885,
      "backward_entropy": 0.007170154047863824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.736001491546631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046837061643600464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04330907762050629,
      "backward_entropy": 0.007175179464476449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.691054344177246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04686504602432251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04327249526977539,
      "backward_entropy": 0.007178162889821189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.654604911804199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04689185321331024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043238576501607895,
      "backward_entropy": 0.0071814219866480145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.17800521850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046917662024497986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043206892907619476,
      "backward_entropy": 0.007186063698359898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.651045799255371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04694407060742378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0431738942861557,
      "backward_entropy": 0.007189781005893435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.536908149719238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046972453594207764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043137021362781525,
      "backward_entropy": 0.007189869348491941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09660889208316803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047002796083688736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04309582710266113,
      "backward_entropy": 0.007190204624618802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07476729899644852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04703007638454437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04306161403656006,
      "backward_entropy": 0.007190652723823275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.27049446105957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047054797410964966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043032847344875336,
      "backward_entropy": 0.007194670183318002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.00003433227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047081805765628815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04299905151128769,
      "backward_entropy": 0.007198554064546313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.902698516845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711008816957474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04296228289604187,
      "backward_entropy": 0.007202700312648501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.554603099822998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04713969677686691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04292244464159012,
      "backward_entropy": 0.007210202515125275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.479249477386475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04716862365603447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04288432002067566,
      "backward_entropy": 0.0072158197207110265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.693467140197754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047197189182043076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042846761643886566,
      "backward_entropy": 0.007224107427256448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50853443145752,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04722681641578674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04280702769756317,
      "backward_entropy": 0.007230891180889947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.468378067016602,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04725662246346474,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.042767077684402466,
      "backward_entropy": 0.09884331056049891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.232356071472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04728638380765915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04272768273949623,
      "backward_entropy": 0.0028479035411562237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.367677688598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04731477051973343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04269128292798996,
      "backward_entropy": 0.00724507389324052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.231486797332764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04734431207180023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04265222325921059,
      "backward_entropy": 0.007251370698213577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.162907123565674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737310856580734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042615123093128204,
      "backward_entropy": 0.007255256708179202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.147500038146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740142449736595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042578935623168945,
      "backward_entropy": 0.007260770670005253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.063587188720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047430798411369324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04254050552845001,
      "backward_entropy": 0.007266675787312644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.065703392028809,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04746042937040329,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.042501382529735565,
      "backward_entropy": 0.09885393721716744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.91876220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748913645744324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04246494174003601,
      "backward_entropy": 0.007277143853051322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.949253082275391,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047519296407699585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04242585599422455,
      "backward_entropy": 0.007274630878652845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.92684268951416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04754866287112236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042388804256916046,
      "backward_entropy": 0.007271973150117057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.841833114624023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04757710546255112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04235436022281647,
      "backward_entropy": 0.007265755108424595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.70518159866333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04760504886507988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04232073575258255,
      "backward_entropy": 0.0026985196662800653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9837665557861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04763326793909073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042286284267902374,
      "backward_entropy": 0.007261266133614949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.743724822998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04765940085053444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04225631058216095,
      "backward_entropy": 0.0072602129408291406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.395627975463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04768497869372368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0422278568148613,
      "backward_entropy": 0.007256218365260533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.622262001037598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04771184176206589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042196325957775116,
      "backward_entropy": 0.007255119936806815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.766324281692505,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04773840308189392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04216524958610535,
      "backward_entropy": 0.007257307746580669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.047298431396484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04776376113295555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.042136821895837784,
      "backward_entropy": 0.09884656327111381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.955191612243652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047790851444005966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04210515320301056,
      "backward_entropy": 0.007258036306926182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6973724365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04781955108046532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04207059368491173,
      "backward_entropy": 0.007255040109157562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.765807151794434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784668982028961,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042039595544338226,
      "backward_entropy": 0.007250076958111354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.383019924163818,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0478755459189415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04200490191578865,
      "backward_entropy": 0.007247433066368103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1069416999816895,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04790373146533966,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.041971608996391296,
      "backward_entropy": 0.0988407049860273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7974134683609009,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04793188348412514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04193885624408722,
      "backward_entropy": 0.007244352783475604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8217061758041382,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047958213835954666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041909389197826385,
      "backward_entropy": 0.007248001971415111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.339579582214355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04798256233334541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04188445582985878,
      "backward_entropy": 0.0072505782757486615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.501800775527954,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04800890386104584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0418543815612793,
      "backward_entropy": 0.0072548432009560725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.863499164581299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803388938307762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04182794690132141,
      "backward_entropy": 0.007256196013518742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.732081651687622,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04805891588330269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.041801996529102325,
      "backward_entropy": 0.0024543372648102896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7642590999603271,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048082418739795685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041778579354286194,
      "backward_entropy": 0.007252254656382969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3957743644714355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04810414835810661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04175908863544464,
      "backward_entropy": 0.007251313222306115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9781975746154785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812503978610039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04174143075942993,
      "backward_entropy": 0.0072496820773397174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604259014129639,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04814619943499565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04172254353761673,
      "backward_entropy": 0.007253187043326241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.783624649047852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816801846027374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04170224815607071,
      "backward_entropy": 0.007256065628358296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118921279907227,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04819193109869957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04167729616165161,
      "backward_entropy": 0.09883240291050502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06357315182685852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04821690171957016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04165036976337433,
      "backward_entropy": 0.007260527993951525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.597171783447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04823959618806839,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04162811487913132,
      "backward_entropy": 0.007266677916049957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9390130043029785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048263996839523315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041603073477745056,
      "backward_entropy": 0.0072686342256409785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.207303047180176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04828937351703644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041576188057661057,
      "backward_entropy": 0.007269910403660366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6158175468444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04831352457404137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04155191779136658,
      "backward_entropy": 0.0023144701761858805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.196557998657227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04833608865737915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041530489921569824,
      "backward_entropy": 0.007274405764681953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5994505882263184,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04835937172174454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04150719568133354,
      "backward_entropy": 0.0072824837906020025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149030685424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048381078988313675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041486985981464386,
      "backward_entropy": 0.007291785840477262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.089507579803467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04840477555990219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0414627343416214,
      "backward_entropy": 0.007300900029284614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.016356468200684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04842878505587578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04143816977739334,
      "backward_entropy": 0.007308280893734523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.978621482849121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04845445975661278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041410431265830994,
      "backward_entropy": 0.007314740547112056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.456004619598389,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048480357974767685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04138223081827164,
      "backward_entropy": 0.007322140038013458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.332009315490723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04850584641098976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04135502502322197,
      "backward_entropy": 0.007331946066447667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.926346778869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048532210290431976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04132577031850815,
      "backward_entropy": 0.007340956479310989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5384905338287354,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048557572066783905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04129800572991371,
      "backward_entropy": 0.007355073732989175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.318234920501709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048580776900053024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0412752665579319,
      "backward_entropy": 0.0022120952074016842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28520393371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04860373213887215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04125261306762695,
      "backward_entropy": 0.007370610322271075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.06536865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048626452684402466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04123017191886902,
      "backward_entropy": 0.007379424359117236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4937154054641724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04865005239844322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04120628163218498,
      "backward_entropy": 0.002184350575719561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.675317764282227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048671655356884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04118695110082626,
      "backward_entropy": 0.007382947419370923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1012490913271904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048695776611566544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04116235673427582,
      "backward_entropy": 0.007382966045822416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.78306245803833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04871726781129837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04114339500665665,
      "backward_entropy": 0.007379770811114993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7818779945373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048737868666648865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04112611711025238,
      "backward_entropy": 0.007376616554600852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.425168037414551,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04875965043902397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04110649973154068,
      "backward_entropy": 0.0073738353593008855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7028632164001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04878159239888191,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04108712822198868,
      "backward_entropy": 0.00736665991800172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.290271282196045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04880430921912193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041066765785217285,
      "backward_entropy": 0.0073554302964891705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.271742343902588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882753640413284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04104505106806755,
      "backward_entropy": 0.007349837039198194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9453213214874268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04885096102952957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04102299362421036,
      "backward_entropy": 0.0073439750288214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6098365783691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04887387156486511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04100210964679718,
      "backward_entropy": 0.007336951792240143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5824477672576904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488959439098835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04098234325647354,
      "backward_entropy": 0.007334183901548386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.349797010421753,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04891732335090637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04096338897943497,
      "backward_entropy": 0.00733652338385582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.068283557891846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893701151013374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04094799607992172,
      "backward_entropy": 0.00733478633420808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.011609077453613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048957161605358124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040931738913059235,
      "backward_entropy": 0.007330930126564843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5108723640441895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04897791147232056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040914155542850494,
      "backward_entropy": 0.007329463958740234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.15962553024292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04899803176522255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040897518396377563,
      "backward_entropy": 0.0073324500450066155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.722151517868042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04901929199695587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04087884724140167,
      "backward_entropy": 0.007335382380655834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.073357582092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04904003441333771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04086160659790039,
      "backward_entropy": 0.007332938590220043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.621279001235962,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04906171187758446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040842875838279724,
      "backward_entropy": 0.007328766797270093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.770411968231201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04908326268196106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040824078023433685,
      "backward_entropy": 0.007329135068825313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.397367238998413,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04910529777407646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04080405831336975,
      "backward_entropy": 0.007333148803029742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.554356575012207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04912649095058441,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04078545421361923,
      "backward_entropy": 0.007339266794068473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.947599411010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049147337675094604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040767595171928406,
      "backward_entropy": 0.007343294365065438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2094917297363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04916996508836746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04074632748961449,
      "backward_entropy": 0.0073507119502340046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835124969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049190957099199295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04072809964418411,
      "backward_entropy": 0.007357807031699589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3041532039642334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04921362176537514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0407065823674202,
      "backward_entropy": 0.007366251200437546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.622557163238525,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923528805375099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040686946362257004,
      "backward_entropy": 0.007374939109597888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.454381465911865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049257759004831314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040666066110134125,
      "backward_entropy": 0.007381261459418705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1535661220550537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928053542971611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04064440727233887,
      "backward_entropy": 0.007390248988355909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.318307399749756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049301691353321075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04062563180923462,
      "backward_entropy": 0.007399701114211764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.357019424438477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932243004441261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04060781002044678,
      "backward_entropy": 0.007406047944511686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.313889980316162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049343425780534744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040589600801467896,
      "backward_entropy": 0.007410780659743718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.299353122711182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04936470463871956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04057091102004051,
      "backward_entropy": 0.007415052503347397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.149817943572998,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04938598349690437,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.040552616119384766,
      "backward_entropy": 0.09884353194917951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1723368167877197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04940635338425636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04053594917058945,
      "backward_entropy": 0.007414527237415314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.168015241622925,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04942641034722328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040519796311855316,
      "backward_entropy": 0.007414277110780988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1067540645599365,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04944593831896782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040505167096853256,
      "backward_entropy": 0.0074093884655407494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.106656074523926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04946460202336311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04049219936132431,
      "backward_entropy": 0.007404451391526631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.053188323974609,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948430880904198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04047703742980957,
      "backward_entropy": 0.0074002934353692195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.003544330596924,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04950619861483574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040457725524902344,
      "backward_entropy": 0.007397809731108802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0296015739440918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952891916036606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04043692350387573,
      "backward_entropy": 0.007398313709667751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.990485906600952,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0495501309633255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040418460965156555,
      "backward_entropy": 0.007403278989451272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9475715160369873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04957079887390137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04040125757455826,
      "backward_entropy": 0.0074050336011818475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9668235778808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049591150134801865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04038462042808533,
      "backward_entropy": 0.0017348531899707659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.906170129776001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04961065202951431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04036935046315193,
      "backward_entropy": 0.0017268970342619078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.74114990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496298223733902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0403546579182148,
      "backward_entropy": 0.007412435753004891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.708278656005859,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964996501803398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04033823311328888,
      "backward_entropy": 0.007415120090757098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7228376865386963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04967085272073746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04032070189714432,
      "backward_entropy": 0.007416009370769773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06711023300886154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04969209432601929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04030224680900574,
      "backward_entropy": 0.0074209294148853844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.486711502075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971117153763771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04028758406639099,
      "backward_entropy": 0.007424321557794299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8508065938949585,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497315488755703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040270913392305374,
      "backward_entropy": 0.0074249931744166785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0409158319234848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975098744034767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04025585576891899,
      "backward_entropy": 0.007426070315497262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5726535320281982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04976873844861984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04024320840835571,
      "backward_entropy": 0.0016635639060820853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.783820629119873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04978693276643753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040229883044958115,
      "backward_entropy": 0.007439425481217248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8039005994796753,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049804627895355225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04021700471639633,
      "backward_entropy": 0.007450324616261891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.338369369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04982145130634308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04020584747195244,
      "backward_entropy": 0.007455524057149887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.624966621398926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983937367796898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04019274562597275,
      "backward_entropy": 0.007460648460047585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5735692977905273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04985692352056503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04018067941069603,
      "backward_entropy": 0.007460933178663254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.734876275062561,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04987448453903198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040168292820453644,
      "backward_entropy": 0.0074648261070251465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.189669609069824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04989129304885864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04015728831291199,
      "backward_entropy": 0.007467442325183323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3356692790985107,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04990921914577484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04014416038990021,
      "backward_entropy": 0.0074727822627340046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.67159104347229,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04992756247520447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04013026878237724,
      "backward_entropy": 0.007479339838027954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055993661284446716,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049945294857025146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04011719673871994,
      "backward_entropy": 0.0074888185731002265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.043473720550537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049961257725954056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04010709375143051,
      "backward_entropy": 0.0074977704456874305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.004493713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049978435039520264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04009467363357544,
      "backward_entropy": 0.007509062332766396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.760457992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0499967485666275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04008001089096069,
      "backward_entropy": 0.0015824341348239354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05501238629221916,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05001652240753174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04006263241171837,
      "backward_entropy": 0.09886208602360316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.449678421020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050034306943416595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0400487557053566,
      "backward_entropy": 0.007551879755088261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8200168609619141,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050054021179676056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04003172367811203,
      "backward_entropy": 0.007564755954912731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5658122301101685,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007224157452583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04001723229885101,
      "backward_entropy": 0.007575599210602897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.308393716812134,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050089675933122635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.040004029870033264,
      "backward_entropy": 0.00758546165057591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7622272968292236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010683462023735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039991363883018494,
      "backward_entropy": 0.007592764816113881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.716804027557373,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050124913454055786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0399770624935627,
      "backward_entropy": 0.007600993982383183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.214259624481201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05014391988515854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03996099531650543,
      "backward_entropy": 0.007612241165978568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.218308448791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016280710697174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03994470089673996,
      "backward_entropy": 0.007627904415130615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9026520252227783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018129199743271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03992914408445358,
      "backward_entropy": 0.007640970072575978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4829844236373901,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020000785589218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03991318121552467,
      "backward_entropy": 0.0076536206262452266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.868300437927246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0502176508307457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03989933058619499,
      "backward_entropy": 0.007659876453025001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5360066890716553,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050235357135534286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.03988559544086456,
      "backward_entropy": 0.09889066219329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8120133876800537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050253599882125854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03987132012844086,
      "backward_entropy": 0.007656793509210859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.11769962310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050271835178136826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03985732048749924,
      "backward_entropy": 0.007649775594472885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0806849002838135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05028940364718437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03984486684203148,
      "backward_entropy": 0.007636606693267822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7199797630310059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050306543707847595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03983322158455849,
      "backward_entropy": 0.0076220594346523285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6986631155014038,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05032239854335785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03982355445623398,
      "backward_entropy": 0.007608196032898766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.00807523727417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05033727362751961,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03981509059667587,
      "backward_entropy": 0.007599123886653355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6447572708129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05035215988755226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.039806559681892395,
      "backward_entropy": 0.007592342793941498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3287203311920166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05036747828125954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.03979727625846863,
      "backward_entropy": 0.0014523931645921298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3389488458633423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05038229376077652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03978864476084709,
      "backward_entropy": 0.007582880024399076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.947255253791809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503963865339756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.03978167101740837,
      "backward_entropy": 0.007575440619673047,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.4603310852870344,
    "avg_log_Z": -0.04946581855416298,
    "success_rate": 1.0,
    "avg_reward": 81.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.07,
      "2": 0.9
    },
    "avg_forward_entropy": 0.04051395032554865,
    "avg_backward_entropy": 0.00978442440341626,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}