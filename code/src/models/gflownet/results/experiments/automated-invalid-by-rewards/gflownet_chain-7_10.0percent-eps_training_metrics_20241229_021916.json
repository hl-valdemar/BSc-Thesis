{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09899352278028216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.09352111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707034289836884,
      "backward_entropy": 0.09902024269104004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.59671020507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706809282302856,
      "backward_entropy": 0.09901974882398333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.40223693847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00020003033569082618,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137065589427948,
      "backward_entropy": 0.0989995002746582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.14540100097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003003210586030036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706287741661072,
      "backward_entropy": 0.0990119321005685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.0321502685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000399462558561936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370600461959839,
      "backward_entropy": 0.09901296240942818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.74496459960938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004977991338819265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370571255683899,
      "backward_entropy": 0.09900685719081334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.04542541503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005970699712634087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137053981423378,
      "backward_entropy": 0.09901557649884905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.64454650878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006956624565646052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705065846443176,
      "backward_entropy": 0.09901446955544609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.34381103515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000792650505900383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704726099967957,
      "backward_entropy": 0.0990163769040789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.40553283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008904185961000621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370435655117035,
      "backward_entropy": 0.09901200022016253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.2720489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009878352284431458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703975081443787,
      "backward_entropy": 0.0990106463432312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.69552612304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010859542526304722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703566789627075,
      "backward_entropy": 0.09901823316301618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.57798767089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001184565480798483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703137636184692,
      "backward_entropy": 0.0990076916558402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.73150634765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012834317749366164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13702698051929474,
      "backward_entropy": 0.09901827573776245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.93475341796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013816445134580135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13702251017093658,
      "backward_entropy": 0.0990189824785505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.28697204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0014811318833380938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701771199703217,
      "backward_entropy": 0.09900287219456264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.9383087158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015800948021933436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701267540454865,
      "backward_entropy": 0.09900118623461042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.89891052246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016803480684757233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700711727142334,
      "backward_entropy": 0.09899945769991193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017816658364608884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700121641159058,
      "backward_entropy": 0.09899769510541644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.2776336669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018809452885761857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699525594711304,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.78836059570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019784574396908283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369892656803131,
      "backward_entropy": 0.09902083873748779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.75811767578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002074538031592965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698315620422363,
      "backward_entropy": 0.09899246692657471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.07740783691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021693792659789324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13697689771652222,
      "backward_entropy": 0.09902098349162511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.42642211914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022605375852435827,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697078824043274,
      "backward_entropy": 0.09898906094687325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.89024353027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023535145446658134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369641125202179,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.77104949951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002444489160552621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695736229419708,
      "backward_entropy": 0.0989857486316136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.92434692382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025309771299362183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369507610797882,
      "backward_entropy": 0.09902068546840123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.58271026611328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026186611503362656,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694383203983307,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.47592163085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027038089465349913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13693681359291077,
      "backward_entropy": 0.09898096323013306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.7590789794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002786449622362852,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692982494831085,
      "backward_entropy": 0.09897942202431816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.51351165771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00286831590346992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369227170944214,
      "backward_entropy": 0.09897792339324951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.23683166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029483092948794365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691549003124237,
      "backward_entropy": 0.0989764758518764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3624267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003032151609659195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369074583053589,
      "backward_entropy": 0.09902077913284302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.73951721191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0031180402729660273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368989646434784,
      "backward_entropy": 0.09902073655809675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.13058471679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003203087719157338,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689024746418,
      "backward_entropy": 0.09901983397347587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.01458740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003289654152467847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688135147094727,
      "backward_entropy": 0.09902065140860421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.89471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033791461028158665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687190413475037,
      "backward_entropy": 0.0989701407296317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.8321075439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0034709940664470196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686209917068481,
      "backward_entropy": 0.0990206173488072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.45655822753906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003562487429007888,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685214519500732,
      "backward_entropy": 0.0990197743688311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4227752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036546585615724325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684211671352386,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.19775390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0037474411074072123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683198392391205,
      "backward_entropy": 0.09901985100337438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.4391326904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003839672775939107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682174682617188,
      "backward_entropy": 0.09896564483642578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.0348663330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00393276521936059,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13681122660636902,
      "backward_entropy": 0.09901998724256243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.9130859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00402437336742878,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13680045306682587,
      "backward_entropy": 0.09902003833225795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.36720275878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004117060452699661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678932189941406,
      "backward_entropy": 0.09896322659083776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.08462524414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004205042961984873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13677847385406494,
      "backward_entropy": 0.09896230697631836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.8379364013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004298200365155935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13676683604717255,
      "backward_entropy": 0.0989614725112915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.69154357910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004389582667499781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675513863563538,
      "backward_entropy": 0.09896056992667061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.07769775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004481833428144455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367432326078415,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.75189208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004576633218675852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673067092895508,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0013427734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046694776974618435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367180496454239,
      "backward_entropy": 0.0990204129900251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.74710083007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004764823243021965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670478761196136,
      "backward_entropy": 0.09895672116960798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.36056518554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0048637171275913715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366908699274063,
      "backward_entropy": 0.09902058328901019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.27052307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004961477126926184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667689263820648,
      "backward_entropy": 0.09902057477406093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.89932250976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0050633614882826805,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13666218519210815,
      "backward_entropy": 0.09902055774416242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.88592529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005164748057723045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664749264717102,
      "backward_entropy": 0.09895225082124982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.3685760498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005258845631033182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366334706544876,
      "backward_entropy": 0.09895094803401402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.23561096191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005353416316211224,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13661925494670868,
      "backward_entropy": 0.0990206343787057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1606903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005450948607176542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366046667098999,
      "backward_entropy": 0.09894837651933942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.32170867919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0055474149994552135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658994436264038,
      "backward_entropy": 0.09902047259466988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.4547348022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0056403945200145245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13657525181770325,
      "backward_entropy": 0.09894543886184692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.39422607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005728289484977722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13656103610992432,
      "backward_entropy": 0.09894372735704694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.57211303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005814820062369108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13654670119285583,
      "backward_entropy": 0.09902031932558332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.45480346679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005901627242565155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365320384502411,
      "backward_entropy": 0.09893993820462908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.30670166015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005988438613712788,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365172266960144,
      "backward_entropy": 0.09902060031890869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.73484802246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006074029020965099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650226593017578,
      "backward_entropy": 0.09893582548413958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.77389526367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006158403120934963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648727536201477,
      "backward_entropy": 0.09902000427246094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.62330627441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006238391622900963,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13647279143333435,
      "backward_entropy": 0.09902048110961914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.3734130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006321880500763655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645771145820618,
      "backward_entropy": 0.09901978288378034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.90257263183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006402542814612389,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13644294440746307,
      "backward_entropy": 0.09902038744517735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.7597198486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006488587707281113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13642704486846924,
      "backward_entropy": 0.09901952743530273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.5650177001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006573930382728577,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641071319580078,
      "backward_entropy": 0.09902027675083705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9845428466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006659119389951229,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363944262266159,
      "backward_entropy": 0.09891922133309501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.10150146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0067430404014885426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13637812435626984,
      "backward_entropy": 0.09901908465794154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.80459594726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006831680424511433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13636089861392975,
      "backward_entropy": 0.09901893990380424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.9320068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006921863649040461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13634294271469116,
      "backward_entropy": 0.09901879514966692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.17324829101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007014879956841469,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632376492023468,
      "backward_entropy": 0.09901999575751168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5285186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007109781261533499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13630403578281403,
      "backward_entropy": 0.09890681505203247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.47499084472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00720406137406826,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628394901752472,
      "backward_entropy": 0.09901992763791766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.7386016845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007298763375729322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13626360893249512,
      "backward_entropy": 0.09890201262065343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.9370574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007396728731691837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624246418476105,
      "backward_entropy": 0.09901806286403111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.43282318115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007494836114346981,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13622117042541504,
      "backward_entropy": 0.09901988506317139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.2261199951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007586096413433552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362009346485138,
      "backward_entropy": 0.09889498778751918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.766845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0076813786290585995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13617964088916779,
      "backward_entropy": 0.09889241627284459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.27386474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007775840349495411,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13615813851356506,
      "backward_entropy": 0.09888974257877894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.19528198242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007869706489145756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613632321357727,
      "backward_entropy": 0.09901716027941022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.36377716064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007964024320244789,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13611426949501038,
      "backward_entropy": 0.09901695592062813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.02874755859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0080531882122159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609269261360168,
      "backward_entropy": 0.09901669195720128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.4652099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008147818967700005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360698640346527,
      "backward_entropy": 0.09901646205357142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.40225219726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008240149356424809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360471099615097,
      "backward_entropy": 0.09901620660509382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.59783935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008329115808010101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13602451980113983,
      "backward_entropy": 0.09887204851422991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.34353637695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008418207056820393,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13600143790245056,
      "backward_entropy": 0.0990194593157087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.21139526367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008504267781972885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597847521305084,
      "backward_entropy": 0.0990152188709804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.08132934570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008594903163611889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135954350233078,
      "backward_entropy": 0.09886109828948975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.9317626953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008679073303937912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359310746192932,
      "backward_entropy": 0.09901918683733259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.04488372802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008766277693212032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13590706884860992,
      "backward_entropy": 0.09885314532688685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.55775451660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008848711848258972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13588370382785797,
      "backward_entropy": 0.0990136010306222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.34052276611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008925617672502995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13586097955703735,
      "backward_entropy": 0.09884425571986608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.76402282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009001296944916248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583776354789734,
      "backward_entropy": 0.09883906160082136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.64805603027344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00907840859144926,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13581407070159912,
      "backward_entropy": 0.09901842049189977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.54852294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009155207313597202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357908546924591,
      "backward_entropy": 0.09882848603384835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.43740844726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00922872219234705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357678771018982,
      "backward_entropy": 0.09901798622948783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.09681701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00929898489266634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13574525713920593,
      "backward_entropy": 0.0988165991646903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.40811920166016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009369824081659317,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13572214543819427,
      "backward_entropy": 0.09901741572788783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.61871337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00943627581000328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356995403766632,
      "backward_entropy": 0.0990076916558402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.82254791259766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009506863541901112,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13567575812339783,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.40181732177734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009572939947247505,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13565261662006378,
      "backward_entropy": 0.09901641947882515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.59202575683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009636830538511276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356295347213745,
      "backward_entropy": 0.09900454112461635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.46636962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009705484844744205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560497760772705,
      "backward_entropy": 0.09900345121111188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.33358764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009778120554983616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557948172092438,
      "backward_entropy": 0.09900246347699847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.12763214111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009851032868027687,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13555362820625305,
      "backward_entropy": 0.09901516778128487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.22879791259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009920497424900532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13552840054035187,
      "backward_entropy": 0.09900031770978655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.80064392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009988890029489994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355031132698059,
      "backward_entropy": 0.09899912561689105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.36434936523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010062865912914276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354762613773346,
      "backward_entropy": 0.09899811233792986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.1951141357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010145110078155994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354471743106842,
      "backward_entropy": 0.09899735450744629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.04331970214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010228326544165611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13541749119758606,
      "backward_entropy": 0.09899662222181048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.50486755371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010310477577149868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353878378868103,
      "backward_entropy": 0.09899582181658063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.54713439941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01039483305066824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13535742461681366,
      "backward_entropy": 0.09899510656084333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.882568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01048145443201065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13532616198062897,
      "backward_entropy": 0.09871176310947963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.42869567871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010571279563009739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13529396057128906,
      "backward_entropy": 0.09870728424617223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.03724670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01065785065293312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13526222109794617,
      "backward_entropy": 0.09899318218231201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.3583221435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01074689906090498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13522925972938538,
      "backward_entropy": 0.09869715145656041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.39718627929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010834455490112305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1351962834596634,
      "backward_entropy": 0.09869158267974854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.83114624023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010924255475401878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13516220450401306,
      "backward_entropy": 0.0986858606338501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.27822875976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011010963469743729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1351284384727478,
      "backward_entropy": 0.09867940630231585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.88381958007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011091288179159164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350959837436676,
      "backward_entropy": 0.09898875440870013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9417724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01116632018238306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13506436347961426,
      "backward_entropy": 0.0989871791430882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.03375244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01124407909810543,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13503184914588928,
      "backward_entropy": 0.0990149974822998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.5982666015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011321225203573704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13499920070171356,
      "backward_entropy": 0.0986464364188058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.44639587402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01139452587813139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13496725261211395,
      "backward_entropy": 0.09898194244929723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.66476440429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011461926624178886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349361389875412,
      "backward_entropy": 0.09862632410866874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.21002197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011524990200996399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13490590453147888,
      "backward_entropy": 0.09897683347974505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.112060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011593948118388653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13487400114536285,
      "backward_entropy": 0.09860357216426305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4373016357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011660355143249035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13484233617782593,
      "backward_entropy": 0.0985919748033796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.092529296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011727823875844479,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348099410533905,
      "backward_entropy": 0.09901139565876552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.0194320678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011802730150520802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13477502763271332,
      "backward_entropy": 0.09857010841369629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.1360626220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011874508112668991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13474048674106598,
      "backward_entropy": 0.09855897086007255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.84075164794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011946200393140316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13470575213432312,
      "backward_entropy": 0.09854803766523089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.7112274169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012012668885290623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346724033355713,
      "backward_entropy": 0.09895720652171544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.5910186767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012082125060260296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346375048160553,
      "backward_entropy": 0.09852413620267596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.07395935058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012155981734395027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346006542444229,
      "backward_entropy": 0.09895093100411552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.93447875976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012231927365064621,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345626264810562,
      "backward_entropy": 0.0985011202948434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.15616607666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012309449724853039,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345236748456955,
      "backward_entropy": 0.09848989759172712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.0236358642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012385230511426926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13448470830917358,
      "backward_entropy": 0.09894182000841413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.61903381347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012461205944418907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13444511592388153,
      "backward_entropy": 0.09846533196313041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.92572021484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012537836097180843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13440455496311188,
      "backward_entropy": 0.09900668689182826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.5817108154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012616639956831932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343625783920288,
      "backward_entropy": 0.09843889304569789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.72970581054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012698499485850334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343192160129547,
      "backward_entropy": 0.09842635904039655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.5576171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01277480460703373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342770755290985,
      "backward_entropy": 0.09900569915771484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.56698608398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012850002385675907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13423456251621246,
      "backward_entropy": 0.09900509459631783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.18527221679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01292487420141697,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1341918557882309,
      "backward_entropy": 0.09900452409471784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.70247650146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012995046563446522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13415008783340454,
      "backward_entropy": 0.09891130243028913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.80023956298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013061147183179855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341090202331543,
      "backward_entropy": 0.09890558038439069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.34213256835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013124586082994938,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13406848907470703,
      "backward_entropy": 0.09900119474955968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.27796936035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013191035017371178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13402646780014038,
      "backward_entropy": 0.09889325925282069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.83063507080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013254963792860508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13398477435112,
      "backward_entropy": 0.09888666016714913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.00563049316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013319263234734535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13394156098365784,
      "backward_entropy": 0.09899742262704032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.2742156982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013379925861954689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13389883935451508,
      "backward_entropy": 0.09824316842215401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.25469970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013447331264615059,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13385316729545593,
      "backward_entropy": 0.09822266442435128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.49569702148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013515614904463291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13380655646324158,
      "backward_entropy": 0.09885929312024798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.15274047851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013585668057203293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13375836610794067,
      "backward_entropy": 0.09818131583077568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.39129638671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013653208501636982,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13371041417121887,
      "backward_entropy": 0.09899163246154785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.58604431152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013725699856877327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13365985453128815,
      "backward_entropy": 0.09883932556424822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.52157592773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013801837339997292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13360744714736938,
      "backward_entropy": 0.09883338212966919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.34380340576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01388124655932188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13355326652526855,
      "backward_entropy": 0.09810228858675275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.44369506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013956734910607338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13350005447864532,
      "backward_entropy": 0.09808295965194702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.79434204101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014032498933374882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334460824728012,
      "backward_entropy": 0.09881457260676793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.47154235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014117097482085228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13338834047317505,
      "backward_entropy": 0.09804707765579224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014207984320819378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333276927471161,
      "backward_entropy": 0.09880564893995013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.54171752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014302458614110947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13326498866081238,
      "backward_entropy": 0.09880217484065465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.64320373535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014393792487680912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13320259749889374,
      "backward_entropy": 0.0980062484741211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.64744567871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014476676471531391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1331428736448288,
      "backward_entropy": 0.09798657894134521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.54586791992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014559217728674412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1330825239419937,
      "backward_entropy": 0.09899411882672991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.733154296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014644825831055641,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13302046060562134,
      "backward_entropy": 0.09899422100612096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.60546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014730462804436684,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1329575479030609,
      "backward_entropy": 0.09899416991642543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.14813232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014819478616118431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13289225101470947,
      "backward_entropy": 0.09876175437654768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.17780303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014909304678440094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328258514404297,
      "backward_entropy": 0.09787843908582415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.02357482910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01499647181481123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13275979459285736,
      "backward_entropy": 0.09785315820149013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.72544860839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015080925077199936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.132694274187088,
      "backward_entropy": 0.09782566343035017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.42018127441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015169698745012283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13262611627578735,
      "backward_entropy": 0.09780007600784302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.9629364013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015256745740771294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13255827128887177,
      "backward_entropy": 0.09777368818010602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.35601043701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015346422791481018,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13248853385448456,
      "backward_entropy": 0.09899214335850307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.57208251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015433303080499172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13241933286190033,
      "backward_entropy": 0.09771889448165894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.18190002441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015520923770964146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13234901428222656,
      "backward_entropy": 0.09868319545473371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6541748046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015610970556735992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13227680325508118,
      "backward_entropy": 0.09766081401279994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.33515167236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015699336305260658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13220471143722534,
      "backward_entropy": 0.09763060297284808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.17518615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01578570157289505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13213250041007996,
      "backward_entropy": 0.09759702001299177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.62062072753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015869947150349617,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13206037878990173,
      "backward_entropy": 0.09756092514310565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.20729064941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015960311517119408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13198445737361908,
      "backward_entropy": 0.09752841506685529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.5728759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016045674681663513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13191035389900208,
      "backward_entropy": 0.09749254158564977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.0009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01612061820924282,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1318405419588089,
      "backward_entropy": 0.09898109095437187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.76918029785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016197538003325462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13176894187927246,
      "backward_entropy": 0.09856233426502772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.53668212890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016263997182250023,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13170216977596283,
      "backward_entropy": 0.09735708577292305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.96597290039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016324950382113457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13163748383522034,
      "backward_entropy": 0.0989699193409511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.18120574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016391294077038765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13156908750534058,
      "backward_entropy": 0.09849199226924352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.78610229492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016457371413707733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1314999759197235,
      "backward_entropy": 0.09720289707183838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.5863265991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01652372069656849,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13142971694469452,
      "backward_entropy": 0.09715054716382708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.05128479003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01658831350505352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313588172197342,
      "backward_entropy": 0.09709580455507551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.41224670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016654515638947487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13128501176834106,
      "backward_entropy": 0.09839177983147758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.13311004638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016729673370718956,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13120481371879578,
      "backward_entropy": 0.09894658837999616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.62496948242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016802871599793434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13112479448318481,
      "backward_entropy": 0.09694537094661168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.33921813964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016874482855200768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13104471564292908,
      "backward_entropy": 0.0968949624470302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.17433166503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016948824748396873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13096195459365845,
      "backward_entropy": 0.0982954672404698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.23216247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017016910016536713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1308819204568863,
      "backward_entropy": 0.09678806577410017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.81175231933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017081402242183685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13080298900604248,
      "backward_entropy": 0.09672657081059047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.5597915649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017146553844213486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13072246313095093,
      "backward_entropy": 0.09820726939610072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.27992248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017209943383932114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13064205646514893,
      "backward_entropy": 0.09659765447889056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.41400909423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017265556380152702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13056588172912598,
      "backward_entropy": 0.09652585642678398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.11326599121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01732206717133522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13048820197582245,
      "backward_entropy": 0.09645419461386544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.29106903076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017387736588716507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13040393590927124,
      "backward_entropy": 0.09639314242771693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.89383697509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017453301697969437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1303188055753708,
      "backward_entropy": 0.09633128983633858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.41790771484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01751929521560669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13023234903812408,
      "backward_entropy": 0.0962681600025722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.73464965820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017582109197974205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13014698028564453,
      "backward_entropy": 0.09797212055751256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.26022338867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017643604427576065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1300615519285202,
      "backward_entropy": 0.0979360852922712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.28515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017706140875816345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12997440993785858,
      "backward_entropy": 0.09790047577449254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.53727722167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017766360193490982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.129888117313385,
      "backward_entropy": 0.09598256008965629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.7381134033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01781928911805153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12980619072914124,
      "backward_entropy": 0.09590073994227818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.11063385009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017877204343676567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12971992790699005,
      "backward_entropy": 0.09582320281437465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.59002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017935343086719513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12963266670703888,
      "backward_entropy": 0.09885385206767491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.93807983398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01799592189490795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12954282760620117,
      "backward_entropy": 0.09567167929240636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.77890014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01806057058274746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1294492483139038,
      "backward_entropy": 0.09765488760811943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.9200897216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018119430169463158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12935905158519745,
      "backward_entropy": 0.09552344254084996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.08213806152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018180856481194496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12926609814167023,
      "backward_entropy": 0.09756772858755929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.0878143310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01824815198779106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1291680485010147,
      "backward_entropy": 0.09537939514432635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.27392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01831665448844433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290683001279831,
      "backward_entropy": 0.09531142030443464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4840545654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01837952993810177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12897184491157532,
      "backward_entropy": 0.09523381505693708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.86992645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018444251269102097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12887316942214966,
      "backward_entropy": 0.09739995002746582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.81556701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018505113199353218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12877658009529114,
      "backward_entropy": 0.09507361480167933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.61729431152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01856164261698723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1286824345588684,
      "backward_entropy": 0.0949817384992327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.04495239257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018624965101480484,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12858206033706665,
      "backward_entropy": 0.09880660261426653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.09027099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01868649572134018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12848226726055145,
      "backward_entropy": 0.0972000275339399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.63419342041016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018752455711364746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12837812304496765,
      "backward_entropy": 0.0947274821145194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.59503173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018813597038388252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12827672064304352,
      "backward_entropy": 0.09710125412259783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.4810791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018877344205975533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12817232310771942,
      "backward_entropy": 0.09705084562301636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.42682647705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018935278058052063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807168066501617,
      "backward_entropy": 0.09699567726680211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.09752655029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018990052863955498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.127972811460495,
      "backward_entropy": 0.09693554469517299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.89993286132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01904374174773693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12787401676177979,
      "backward_entropy": 0.0968721764428275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.18850708007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01910340040922165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12776954472064972,
      "backward_entropy": 0.09681209496089391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.26824188232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019165867939591408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12766186892986298,
      "backward_entropy": 0.09403514862060547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.57740783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01922757923603058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12755391001701355,
      "backward_entropy": 0.0939347233091082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.52242279052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019284380599856377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12744933366775513,
      "backward_entropy": 0.09382479531424386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.97366333007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019337981939315796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1273466944694519,
      "backward_entropy": 0.09370921339307513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.29000854492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019395411014556885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1272399127483368,
      "backward_entropy": 0.0935971736907959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.33686065673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019453292712569237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1271318942308426,
      "backward_entropy": 0.09641810825892858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.66310119628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019511951133608818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12702234089374542,
      "backward_entropy": 0.09337298359189715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.22569274902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019568344578146935,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12691393494606018,
      "backward_entropy": 0.09869515895843506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.90866088867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01963670179247856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12679454684257507,
      "backward_entropy": 0.09621029240744454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.88130950927734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019702864810824394,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12667568027973175,
      "backward_entropy": 0.09868904522487096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.08706665039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01976862922310829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12655554711818695,
      "backward_entropy": 0.09607425757816859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.85977172851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019836323335766792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12643244862556458,
      "backward_entropy": 0.0960044094494411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.43801879882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01990540139377117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12630701065063477,
      "backward_entropy": 0.09593193871634347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.78585815429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019974714145064354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12618030607700348,
      "backward_entropy": 0.09263203825269427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.57987976074219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020045623183250427,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.126051127910614,
      "backward_entropy": 0.09867240701402936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.27670288085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020112905651330948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12592436373233795,
      "backward_entropy": 0.09570535591670445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.074951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020182548090815544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12579438090324402,
      "backward_entropy": 0.09229375634874616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.06615447998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020252397283911705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12566323578357697,
      "backward_entropy": 0.09217643737792969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.22736358642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020319592207670212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12553368508815765,
      "backward_entropy": 0.09546250956399101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.80074310302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020381586626172066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12540830671787262,
      "backward_entropy": 0.09536753382001605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.60032653808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020444583147764206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1252809762954712,
      "backward_entropy": 0.09176930359431676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.70974731445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020504586398601532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12515568733215332,
      "backward_entropy": 0.09162007059369769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.39634704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020564232021570206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12502983212471008,
      "backward_entropy": 0.09506621531077794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.30855560302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02061726711690426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1249098926782608,
      "backward_entropy": 0.09129636628287179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.77394104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020671876147389412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12478742003440857,
      "backward_entropy": 0.0948289121900286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.26296997070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02072613500058651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12466467171907425,
      "backward_entropy": 0.09095573425292969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.0389404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020780276507139206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12454082071781158,
      "backward_entropy": 0.09078036035810198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.96487426757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020835915580391884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12441446632146835,
      "backward_entropy": 0.09060626370566231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.04995727539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020890945568680763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12428809702396393,
      "backward_entropy": 0.09042818205697196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.29720306396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020943833515048027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1241631880402565,
      "backward_entropy": 0.09418438162122454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.86985778808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020993562415242195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12404094636440277,
      "backward_entropy": 0.09004621846335274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.03512573242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021037304773926735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12392449378967285,
      "backward_entropy": 0.09388548135757446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.12477111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021087773144245148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12380009889602661,
      "backward_entropy": 0.09374076979500907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.60476684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021135345101356506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12367819249629974,
      "backward_entropy": 0.09359086411339897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.3715362548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021187877282500267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12355029582977295,
      "backward_entropy": 0.09344989912850517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.69756317138672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02124849148094654,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12341324985027313,
      "backward_entropy": 0.0984018359865461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.8465118408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02130684070289135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12327806651592255,
      "backward_entropy": 0.0888829060963222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.25481414794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021367957815527916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12313917279243469,
      "backward_entropy": 0.09303759677069527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.32223510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021426012739539146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1230030208826065,
      "backward_entropy": 0.0885115350995745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.95162963867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021481700241565704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1228688508272171,
      "backward_entropy": 0.0883103609085083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.53750610351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021534496918320656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12273721396923065,
      "backward_entropy": 0.09256173883165632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.76754760742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021591048687696457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1226007342338562,
      "backward_entropy": 0.09239757912499565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.91563415527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021647021174430847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12246427685022354,
      "backward_entropy": 0.09222957917622157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.58116912841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021704282611608505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12232574075460434,
      "backward_entropy": 0.08749626364026751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.27146911621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021760914474725723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12218731641769409,
      "backward_entropy": 0.08728671073913574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.35675048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021815180778503418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12205132842063904,
      "backward_entropy": 0.09169975348881312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.63723754882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021876676008105278,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12190616130828857,
      "backward_entropy": 0.0982433727809361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.19424438476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02193932607769966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12175945192575455,
      "backward_entropy": 0.09135927472795759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.98995971679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022000843659043312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1216135248541832,
      "backward_entropy": 0.08645897252219063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.26602172851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0220637284219265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12146557867527008,
      "backward_entropy": 0.08625278302601405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.3038787841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022123470902442932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12132081389427185,
      "backward_entropy": 0.08603312288011823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.24556732177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022191880270838737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12116584181785583,
      "backward_entropy": 0.09064535583768572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.46991729736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022256998345255852,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12101435661315918,
      "backward_entropy": 0.08563429968697685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.16036987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02231714501976967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12086835503578186,
      "backward_entropy": 0.09026604039328438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.07457733154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02237664721906185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12072265148162842,
      "backward_entropy": 0.09006419352122716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.08773040771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022432789206504822,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12058040499687195,
      "backward_entropy": 0.0849313395363944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.42143249511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022492313757538795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12043367326259613,
      "backward_entropy": 0.08469510078430176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.94032287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022546861320734024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.120292529463768,
      "backward_entropy": 0.08940328870500837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.66586303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022610316053032875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12014059722423553,
      "backward_entropy": 0.08919230529240199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9814910888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022674640640616417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11998725682497025,
      "backward_entropy": 0.08398056030273438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.58853149414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022744910791516304,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11982668936252594,
      "backward_entropy": 0.0837658132825579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.32817077636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02281397022306919,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1196674257516861,
      "backward_entropy": 0.08354132516043526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.43411254882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02287975139915943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1195119172334671,
      "backward_entropy": 0.08330161230904716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.46903991699219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022943813353776932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11935814470052719,
      "backward_entropy": 0.08305167300360543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.93389129638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023000022396445274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11921407282352448,
      "backward_entropy": 0.08277322564806257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.0450439453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02305203303694725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1190749779343605,
      "backward_entropy": 0.08248097555977958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.67990112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023104708641767502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1189345270395279,
      "backward_entropy": 0.08735976900373187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.67091369628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02315538562834263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11879628896713257,
      "backward_entropy": 0.08190272535596575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.71217346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023209527134895325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186533123254776,
      "backward_entropy": 0.08681755406515938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.6617431640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023267189040780067,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11850570887327194,
      "backward_entropy": 0.09784771714891706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.36162567138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023324014618992805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11835899204015732,
      "backward_entropy": 0.08627811500004359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.78347778320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023379702121019363,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11821319907903671,
      "backward_entropy": 0.09779579298836845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.93740844726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023433344438672066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11806986480951309,
      "backward_entropy": 0.08569760833467756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.3803939819336,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023485790938138962,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.117927685379982,
      "backward_entropy": 0.097732526915414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.09775924682617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023540586233139038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11778251826763153,
      "backward_entropy": 0.08508690765925817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.12494659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02359018661081791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11764407157897949,
      "backward_entropy": 0.08477250167301723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.9967041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02364244870841503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11750221252441406,
      "backward_entropy": 0.08446644033704485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.06922149658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02369711920619011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11735734343528748,
      "backward_entropy": 0.08416713987077985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.075927734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023753374814987183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11721047759056091,
      "backward_entropy": 0.0975808926991054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.22418212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023807615041732788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1170661598443985,
      "backward_entropy": 0.08355373995644706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.46242904663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023867135867476463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1169152781367302,
      "backward_entropy": 0.07803121634892055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.396484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023919643834233284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11677345633506775,
      "backward_entropy": 0.08292136873517718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.61607360839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02396685630083084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11663860827684402,
      "backward_entropy": 0.0773666330746242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.55065155029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024023281410336494,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11649258434772491,
      "backward_entropy": 0.09743362665176392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.65602111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024077730253338814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11634919047355652,
      "backward_entropy": 0.08194102559770856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.39872741699219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024130813777446747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11620775610208511,
      "backward_entropy": 0.07642454760415214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.82278442382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02418653666973114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11606321483850479,
      "backward_entropy": 0.08129755939756121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.48825073242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024247070774435997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11591271311044693,
      "backward_entropy": 0.08098304271697998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.56727600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02430669590830803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11576354503631592,
      "backward_entropy": 0.08065877641950335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.6109390258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024363277480006218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11561837792396545,
      "backward_entropy": 0.08031560693468366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.31938171386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024421799927949905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11547107249498367,
      "backward_entropy": 0.07479315996170044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.06858825683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024474745616316795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11533133685588837,
      "backward_entropy": 0.07443118946892875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.0246124267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024532243609428406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11518621444702148,
      "backward_entropy": 0.07928032534463066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.43824768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024595845490694046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11503402888774872,
      "backward_entropy": 0.07896663461412702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.35513305664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024656882509589195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11488550156354904,
      "backward_entropy": 0.07863834074565343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.86396789550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024725861847400665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11472800374031067,
      "backward_entropy": 0.07315517323357719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.03189086914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024794992059469223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1145707368850708,
      "backward_entropy": 0.09717368228094918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.4578094482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024859003722667694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11442041397094727,
      "backward_entropy": 0.07252327033451625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.19343948364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024928292259573936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11426428705453873,
      "backward_entropy": 0.07740664482116699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.34800720214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02499021776020527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411809921264648,
      "backward_entropy": 0.07705977133342198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.11006927490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025045929476618767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11398032307624817,
      "backward_entropy": 0.07149124145507812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.6903076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025099115446209908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1138458102941513,
      "backward_entropy": 0.07628812960215978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.51004791259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025153301656246185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11371015012264252,
      "backward_entropy": 0.07071959120886666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.59092712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02520880103111267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11357277631759644,
      "backward_entropy": 0.07550128868647984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.20619201660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025270933285355568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1134282648563385,
      "backward_entropy": 0.06999333415712629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.53268432617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02532874420285225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11328984797000885,
      "backward_entropy": 0.07474970817565918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.12230682373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025388358160853386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1131497323513031,
      "backward_entropy": 0.06925754461969648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.11738586425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025447791442275047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11301039159297943,
      "backward_entropy": 0.06888710600989205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.1523208618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025505047291517258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11287431418895721,
      "backward_entropy": 0.06850269436836243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.83980178833008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025561388581991196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11274011433124542,
      "backward_entropy": 0.068113454750606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.19205474853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025615092366933823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11260990798473358,
      "backward_entropy": 0.07276034355163574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.7369384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025669479742646217,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11247937381267548,
      "backward_entropy": 0.0673137094293322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.05897521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025727927684783936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1123443990945816,
      "backward_entropy": 0.07195075069155012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.72451782226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02579163759946823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11220377683639526,
      "backward_entropy": 0.0665637126990727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.67169952392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025852635502815247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11206713318824768,
      "backward_entropy": 0.06617920313562665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.46562957763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02591058239340782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11193475127220154,
      "backward_entropy": 0.06577666316713605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.54679870605469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025968868285417557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11180272698402405,
      "backward_entropy": 0.0966670172555106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.61863708496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026023613288998604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11167575418949127,
      "backward_entropy": 0.06981384754180908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.12657165527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02608247846364975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11154459416866302,
      "backward_entropy": 0.0645551255771092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.5643310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026148853823542595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11140561103820801,
      "backward_entropy": 0.06418564915657043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.80760955810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026212556287646294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11127074062824249,
      "backward_entropy": 0.06380027532577515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.744319915771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02626999467611313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11114469170570374,
      "backward_entropy": 0.06338498422077724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.20474243164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026319963857531548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11102868616580963,
      "backward_entropy": 0.06758356094360352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.4970474243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02637840434908867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11090289056301117,
      "backward_entropy": 0.06713071039744786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.88743591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026439480483531952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11077462881803513,
      "backward_entropy": 0.06669652462005615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.89138412475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026498492807149887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11064958572387695,
      "backward_entropy": 0.061746848481042046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.82471466064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026553215458989143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11053037643432617,
      "backward_entropy": 0.06577089854649135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.29073333740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02660815790295601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11041200160980225,
      "backward_entropy": 0.06528623614992414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.52458190917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026664771139621735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1102927029132843,
      "backward_entropy": 0.06482388292040143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.39486312866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02671739086508751,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11017797887325287,
      "backward_entropy": 0.06003224849700928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.2796630859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02676706202328205,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11006741225719452,
      "backward_entropy": 0.0961688756942749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.26946258544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02681409940123558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10996059328317642,
      "backward_entropy": 0.059119931289127896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.70069885253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02685977704823017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1098557561635971,
      "backward_entropy": 0.09604457446507045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.967054843902588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026916954666376114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10973942279815674,
      "backward_entropy": 0.05824179308755057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.20829010009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02696284092962742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10963685810565948,
      "backward_entropy": 0.05778406347547259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.10404205322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02700858563184738,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10953549295663834,
      "backward_entropy": 0.09588979823248726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.61172103881836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027055835351347923,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10943326354026794,
      "backward_entropy": 0.09583285876682826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.7791519165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027099838480353355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10933561623096466,
      "backward_entropy": 0.0564197131565639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.01856231689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027143333107233047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10923899710178375,
      "backward_entropy": 0.05972531863621303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.18550109863281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02718905173242092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10914050042629242,
      "backward_entropy": 0.05921738488333566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.96036148071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027238816022872925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10903822630643845,
      "backward_entropy": 0.05873314823423113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.92019653320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027283145114779472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10894311964511871,
      "backward_entropy": 0.05465404902185712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.74124908447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027327239513397217,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1088489517569542,
      "backward_entropy": 0.05420647348676409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.2229232788086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027373386546969414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10875354707241058,
      "backward_entropy": 0.0954368965966361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.12966537475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027423841878771782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10865470767021179,
      "backward_entropy": 0.053351129804338725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.32664489746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027470091357827187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10856121778488159,
      "backward_entropy": 0.052917463438851495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.22193908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027521859854459763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10846284031867981,
      "backward_entropy": 0.05251029985291617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.7965087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027572007849812508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10836731642484665,
      "backward_entropy": 0.05533323969159808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.89957046508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027621695771813393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1082732155919075,
      "backward_entropy": 0.05169321809496198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.37908935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027669386938214302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10818217694759369,
      "backward_entropy": 0.05127356733594622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.6710205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027714882045984268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10809414833784103,
      "backward_entropy": 0.050840552364076884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.37733459472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027758849784731865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1080084964632988,
      "backward_entropy": 0.05040063602583749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.15442657470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027803709730505943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10792273283004761,
      "backward_entropy": 0.05289672527994428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.831233978271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027847370132803917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10783898830413818,
      "backward_entropy": 0.049540856054850986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.666582107543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02788730338215828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10775985568761826,
      "backward_entropy": 0.04909499202455793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.93354034423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02792186103761196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10768702626228333,
      "backward_entropy": 0.048624596425465176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.18692779541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027960391715168953,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10761070251464844,
      "backward_entropy": 0.04818524207387652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.8900146484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028008349239826202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10752588510513306,
      "backward_entropy": 0.05039099710328238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.21986389160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028054727241396904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10744397342205048,
      "backward_entropy": 0.04741769177573068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.09493255615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028100131079554558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10736404359340668,
      "backward_entropy": 0.04702890770775931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.20899200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028146710246801376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10728400945663452,
      "backward_entropy": 0.0490409391266959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.1993408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0281961802393198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1072022020816803,
      "backward_entropy": 0.04861806120191302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.12919235229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028245413675904274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10712139308452606,
      "backward_entropy": 0.048183522054127285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.471309661865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02829243429005146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10704342275857925,
      "backward_entropy": 0.045531617743628364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.30591583251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028337910771369934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10696828365325928,
      "backward_entropy": 0.04726014818464007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.11054229736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028387874364852905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10688954591751099,
      "backward_entropy": 0.04681822231837681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.23259735107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028438080102205276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10681138932704926,
      "backward_entropy": 0.04637753537722996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.99160385131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028488317504525185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10673399269580841,
      "backward_entropy": 0.045932918787002563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.20630645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028536798432469368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10665909945964813,
      "backward_entropy": 0.04547947645187378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.21402740478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028585325926542282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10658492147922516,
      "backward_entropy": 0.043315274374825616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.1058349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028640158474445343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10650594532489777,
      "backward_entropy": 0.04459910733359201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.28907012939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02869412489235401,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10642942786216736,
      "backward_entropy": 0.044191841568265645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.63424301147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0287516787648201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10635082423686981,
      "backward_entropy": 0.04233017138072422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.0042610168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028804853558540344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10627706348896027,
      "backward_entropy": 0.04337152412959507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.93596649169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028856344521045685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10620573908090591,
      "backward_entropy": 0.04294130206108093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.12049102783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02891414985060692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10613015294075012,
      "backward_entropy": 0.041327169963291714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.63780975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02897387184202671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10605413466691971,
      "backward_entropy": 0.042177783591406684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.01776123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029033873230218887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10597896575927734,
      "backward_entropy": 0.04072463512420654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.903289794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029095401987433434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10590353608131409,
      "backward_entropy": 0.04140163319451468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.36403274536133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029154954478144646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10583092272281647,
      "backward_entropy": 0.04012414387294224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.08982849121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0292096808552742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.105763278901577,
      "backward_entropy": 0.04060255203928266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3377580642700195,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029261143878102303,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10569934546947479,
      "backward_entropy": 0.09447602714811053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.03551483154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029303621500730515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10564400255680084,
      "backward_entropy": 0.03908546907561166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.421953201293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02935369499027729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10558299720287323,
      "backward_entropy": 0.03876682264464242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.38667678833008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029397977516055107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10552751272916794,
      "backward_entropy": 0.03842011519840786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.14258575439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029439512640237808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10547494143247604,
      "backward_entropy": 0.038443957056318014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.9650650024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02947722189128399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10542623698711395,
      "backward_entropy": 0.037699022463389804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.77157592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02952248975634575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10537196695804596,
      "backward_entropy": 0.0373719504901341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.63447952270508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029574569314718246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10531297326087952,
      "backward_entropy": 0.03707862751824515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.93315887451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029625046998262405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1052560806274414,
      "backward_entropy": 0.03677952289581299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.38186264038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029682260006666183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10519486665725708,
      "backward_entropy": 0.036451450416019986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.8386344909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029737409204244614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1051366776227951,
      "backward_entropy": 0.03624199117933001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.64962768554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02979114279150963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10508061200380325,
      "backward_entropy": 0.03596156409808567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.864776611328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029846033081412315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10502471029758453,
      "backward_entropy": 0.03537025196211679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.19365692138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029898006469011307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10497187077999115,
      "backward_entropy": 0.03541588144642966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.03597259521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029954079538583755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10491690039634705,
      "backward_entropy": 0.03515226926122393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.60426330566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030010316520929337,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10486264526844025,
      "backward_entropy": 0.03489143082073757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.38306427001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03007047064602375,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1048065572977066,
      "backward_entropy": 0.09430715015956334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.57814025878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030133018270134926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10474991053342819,
      "backward_entropy": 0.03442011560712542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.04404830932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030195148661732674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10469448566436768,
      "backward_entropy": 0.03334619104862213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.010910034179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030252959579229355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10464335978031158,
      "backward_entropy": 0.03393970217023577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.71047973632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03030574321746826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10459662973880768,
      "backward_entropy": 0.03264749263014112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.790830612182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03036174364387989,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10454843193292618,
      "backward_entropy": 0.033432573080062866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.47208786010742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030411913990974426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10450489819049835,
      "backward_entropy": 0.033157638141087124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.31404113769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030463432893157005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10446110367774963,
      "backward_entropy": 0.0328934873853411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.85042572021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030521264299750328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10441374778747559,
      "backward_entropy": 0.031276123864310126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.46772003173828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030583033338189125,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10436462610960007,
      "backward_entropy": 0.0944121139390128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.56666946411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03064855933189392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10431398451328278,
      "backward_entropy": 0.032236889004707336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.71443939208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030711203813552856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10426598787307739,
      "backward_entropy": 0.030370678220476423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.26185989379883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0307760052382946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10421749949455261,
      "backward_entropy": 0.03181512015206473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.92557907104492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030839262530207634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10417090356349945,
      "backward_entropy": 0.029789958681379045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.10239028930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030902093276381493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10412536561489105,
      "backward_entropy": 0.02949363206114088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.88153839111328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030964158475399017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10408105701208115,
      "backward_entropy": 0.09461496557508196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.15467071533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031023800373077393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10403899103403091,
      "backward_entropy": 0.028859029923166548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.96678161621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031085599213838577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1039964035153389,
      "backward_entropy": 0.03073491794722421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.512699127197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031147614121437073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1039545014500618,
      "backward_entropy": 0.030522086790629795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.2973403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031208498403429985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1039140373468399,
      "backward_entropy": 0.0279442412512643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.02647018432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03127187490463257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10387289524078369,
      "backward_entropy": 0.030133945601327077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.69546508789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031332679092884064,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10383443534374237,
      "backward_entropy": 0.09475192853382655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.62947082519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031397949904203415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1037944108247757,
      "backward_entropy": 0.029802256396838596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.04743957519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031461041420698166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10375624895095825,
      "backward_entropy": 0.029636006270136152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.132099151611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031524334102869034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10371871292591095,
      "backward_entropy": 0.029470622539520264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.4912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03158298507332802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1036844253540039,
      "backward_entropy": 0.026395110147339956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.78330993652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03164558857679367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10364868491888046,
      "backward_entropy": 0.026141468967710222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.54654693603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03170401602983475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1036156713962555,
      "backward_entropy": 0.028943987829344615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.73624420166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0317685641348362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10358026623725891,
      "backward_entropy": 0.025604801518576487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.311180114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031838033348321915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10354326665401459,
      "backward_entropy": 0.028623604348727634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.91385650634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03190291300415993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1035093441605568,
      "backward_entropy": 0.02508956619671413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.40557861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03196927160024643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10347528755664825,
      "backward_entropy": 0.024823448487690518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.65045166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032040052115917206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1034398153424263,
      "backward_entropy": 0.02458733320236206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.3543701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03211041912436485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10340522974729538,
      "backward_entropy": 0.027998536825180054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.35813903808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03218062222003937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10337142646312714,
      "backward_entropy": 0.02411952189036778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.47213745117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03224685788154602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10334017127752304,
      "backward_entropy": 0.023877575993537903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.85887145996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03231868892908096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10330715775489807,
      "backward_entropy": 0.023656549198286875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.84085083007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03239366412162781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10327364504337311,
      "backward_entropy": 0.027463297758783613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.66040802001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03247353434562683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10323882848024368,
      "backward_entropy": 0.027364905391420637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.40779113769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03255215287208557,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1032053530216217,
      "backward_entropy": 0.027262240648269653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.43415832519531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03263285756111145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10317175835371017,
      "backward_entropy": 0.027159705758094788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.13529586791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032714322209358215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10313865542411804,
      "backward_entropy": 0.022675252386501858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.935380935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03279440104961395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10310692340135574,
      "backward_entropy": 0.02248533070087433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.75981140136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032868314534425735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10307861119508743,
      "backward_entropy": 0.026863758053098406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.51993942260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03293954208493233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10305196046829224,
      "backward_entropy": 0.026745361941201345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.47608947753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033010631799697876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10302605479955673,
      "backward_entropy": 0.026632025837898254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.82949447631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308142349123955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10300035774707794,
      "backward_entropy": 0.021671488881111145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.22509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03314874693751335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1029767394065857,
      "backward_entropy": 0.026411290679659163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.744754791259766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033214107155799866,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10295431315898895,
      "backward_entropy": 0.09587272575923375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.19112777709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03327638655900955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10293346643447876,
      "backward_entropy": 0.021041248525891985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.45184326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03333497792482376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10291446000337601,
      "backward_entropy": 0.02601592881338937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.035625457763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033398717641830444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1028938740491867,
      "backward_entropy": 0.02589660882949829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.20527648925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033456746488809586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287590324878693,
      "backward_entropy": 0.02039852738380432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.08634376525879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03352149575948715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10285583883523941,
      "backward_entropy": 0.025683573314121792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.01242065429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03358013555407524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1028384119272232,
      "backward_entropy": 0.02555124248777117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.88976287841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03364172950387001,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282039642333984,
      "backward_entropy": 0.01979342315878187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.52085494995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03370431438088417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280218720436096,
      "backward_entropy": 0.01959970806326185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.4930648803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03376635164022446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10278432816267014,
      "backward_entropy": 0.025201080100876943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.19535827636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033831045031547546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10276609659194946,
      "backward_entropy": 0.0250879100390843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.473020553588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389550745487213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027488112449646,
      "backward_entropy": 0.01900695264339447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.97572326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03395288810133934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10273430496454239,
      "backward_entropy": 0.018803573080471585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.365936279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0340147502720356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10271866619586945,
      "backward_entropy": 0.018606694681303843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.088237762451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03407695144414902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10270306468009949,
      "backward_entropy": 0.018406621047428677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.32270812988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034134071320295334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10268938541412354,
      "backward_entropy": 0.02450929582118988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.780982971191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034189220517873764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10267657041549683,
      "backward_entropy": 0.02438080736568996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.6124267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034244656562805176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10266412794589996,
      "backward_entropy": 0.024267462747437612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.97612762451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0343015156686306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10265146195888519,
      "backward_entropy": 0.01759745180606842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.998897552490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034361694008111954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10263804346323013,
      "backward_entropy": 0.017420110957963125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.185516357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034418702125549316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10262588411569595,
      "backward_entropy": 0.02398836612701416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.24647521972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034477025270462036,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1026136726140976,
      "backward_entropy": 0.09602599484579903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.84635925292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034532330930233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10260249674320221,
      "backward_entropy": 0.01690751952784402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.0079116821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03458563610911369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1025921106338501,
      "backward_entropy": 0.02370933336871011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.00086212158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034643664956092834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10258075594902039,
      "backward_entropy": 0.01654445699283055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.13010025024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03470497950911522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10256870836019516,
      "backward_entropy": 0.02352607250213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.19210433959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03476525843143463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10255707055330276,
      "backward_entropy": 0.023438547338758196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.4433708190918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034826964139938354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10254551470279694,
      "backward_entropy": 0.016048312187194824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.63493728637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034885961562395096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10253503918647766,
      "backward_entropy": 0.023280045815876553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.865705490112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494721278548241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10252417623996735,
      "backward_entropy": 0.015735054654734477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.71102905273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03500416502356529,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10251455008983612,
      "backward_entropy": 0.015579521656036377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.27040100097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035067878663539886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10250343382358551,
      "backward_entropy": 0.02308892777987889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.33155059814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03513074666261673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10249286890029907,
      "backward_entropy": 0.015291097973074232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.96529769897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035194847732782364,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10248230397701263,
      "backward_entropy": 0.022976377180644443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.65253448486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035258255898952484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10247215628623962,
      "backward_entropy": 0.022927020277295793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.51943969726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03531923145055771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1024627834558487,
      "backward_entropy": 0.01488177478313446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.1657943725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035386741161346436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10245218127965927,
      "backward_entropy": 0.014760519777025496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.530025482177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03546042740345001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10244067013263702,
      "backward_entropy": 0.022835669772965566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.28629684448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035532329231500626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10242977738380432,
      "backward_entropy": 0.02282158817563738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.21005630493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03560294955968857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1024194210767746,
      "backward_entropy": 0.014441238982336861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.03092956542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03567616268992424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10240891575813293,
      "backward_entropy": 0.014343914176736559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.04680633544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.035747967660427094,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10239889472723007,
      "backward_entropy": 0.09650172506059919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.949188232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03582516685128212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10238800942897797,
      "backward_entropy": 0.022815421223640442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.58348846435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03590172156691551,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1023774966597557,
      "backward_entropy": 0.022814322795186723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.65445327758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03597668558359146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10236763209104538,
      "backward_entropy": 0.02281601514135088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.55614471435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036048125475645065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10235871374607086,
      "backward_entropy": 0.01386917382478714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.155555725097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03611639514565468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10235027223825455,
      "backward_entropy": 0.02279661808695112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.577571868896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03618406504392624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10234235972166061,
      "backward_entropy": 0.022794101919446672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.819618225097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03624582663178444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10233574360609055,
      "backward_entropy": 0.01357368060520717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.31420135498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03630911931395531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10232910513877869,
      "backward_entropy": 0.02278663856642587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.32706356048584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03637702763080597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10232171416282654,
      "backward_entropy": 0.022796801158360074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.58430862426758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036439478397369385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10231538116931915,
      "backward_entropy": 0.013317747839859553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.82268524169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036502789705991745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10230904072523117,
      "backward_entropy": 0.022809094616344998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.503016471862793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657040745019913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10230214893817902,
      "backward_entropy": 0.013141311705112457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.42703247070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036631714552640915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10229650139808655,
      "backward_entropy": 0.013043269515037537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.993371963500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03669752553105354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10229018330574036,
      "backward_entropy": 0.022784382104873657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.516700744628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0367591567337513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10228463262319565,
      "backward_entropy": 0.022764891386032104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.6816520690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681880235671997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10227949917316437,
      "backward_entropy": 0.012748164790017264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.218162536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036879763007164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10227425396442413,
      "backward_entropy": 0.012647313731057304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.81211471557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03693925961852074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10226936638355255,
      "backward_entropy": 0.022706070116588047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.89168930053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036998629570007324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10226460546255112,
      "backward_entropy": 0.01245784546647753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.02063751220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03705378994345665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10226050019264221,
      "backward_entropy": 0.012350878545216151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.80728149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03711117058992386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1022561714053154,
      "backward_entropy": 0.012250678879874093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.11353302001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037173908203840256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10225121676921844,
      "backward_entropy": 0.02261495590209961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.29909896850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03723390772938728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10224675387144089,
      "backward_entropy": 0.022585323878696988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.65945816040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037293631583452225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10224239528179169,
      "backward_entropy": 0.011958912014961243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.33708190917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037354446947574615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10223793238401413,
      "backward_entropy": 0.022517953600202287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.72250366210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03741694241762161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10223324596881866,
      "backward_entropy": 0.022493639162608554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.806608200073242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03748678043484688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10222803801298141,
      "backward_entropy": 0.022474548646381924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.774436950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03755083680152893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10222356021404266,
      "backward_entropy": 0.022457116416522434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.261241912841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03761397674679756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10221929848194122,
      "backward_entropy": 0.02243109473160335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.44209671020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03767523914575577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10221529006958008,
      "backward_entropy": 0.022409515721457347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.119340896606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03773628547787666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10221139341592789,
      "backward_entropy": 0.02238849231175014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.09408950805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0377955436706543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10220777988433838,
      "backward_entropy": 0.0112144159419196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.35555648803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037855327129364014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10220417380332947,
      "backward_entropy": 0.011133445160729545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.155330657958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037916265428066254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10220053791999817,
      "backward_entropy": 0.011048187102590288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.86154556274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037978511303663254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10219676792621613,
      "backward_entropy": 0.022327904190335954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.716758728027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03803849220275879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10219325870275497,
      "backward_entropy": 0.010877371898719243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.67927169799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038096699863672256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1021900624036789,
      "backward_entropy": 0.022280516369002207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.59379577636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0381586030125618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10218660533428192,
      "backward_entropy": 0.010712870529719762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.33705520629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038223449140787125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10218299925327301,
      "backward_entropy": 0.010638243385723658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.22050476074219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03829289227724075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10217900574207306,
      "backward_entropy": 0.022274404764175415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.28789520263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03836173191666603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10217514634132385,
      "backward_entropy": 0.010507827358586448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.85158157348633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038427818566560745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10217162221670151,
      "backward_entropy": 0.02229279705456325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.12532615661621,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03849653899669647,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10216796398162842,
      "backward_entropy": 0.09752878972462245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.083044052124023,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03856240212917328,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1021646112203598,
      "backward_entropy": 0.09754846777234759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.54896926879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038624607026576996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10216163098812103,
      "backward_entropy": 0.02229607743876321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.97945785522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038688018918037415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10215860605239868,
      "backward_entropy": 0.010163657367229462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.88658905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03875577449798584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10215531289577484,
      "backward_entropy": 0.022296456354004995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.64277648925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038826461881399155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10215190798044205,
      "backward_entropy": 0.01003857169832502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.7001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03890027105808258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10214834660291672,
      "backward_entropy": 0.00997452118567058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.99357604980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03897000104188919,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10214518010616302,
      "backward_entropy": 0.022329360246658325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.265609741210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03903919830918312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10214211046695709,
      "backward_entropy": 0.02235137564795358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.534543991088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039106111973524094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10213927924633026,
      "backward_entropy": 0.02237581355231149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.27882766723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039169516414403915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1021367534995079,
      "backward_entropy": 0.022404172590800693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.17753219604492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03923433646559715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10213416814804077,
      "backward_entropy": 0.022436041917119707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.41735076904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03930019959807396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10213156044483185,
      "backward_entropy": 0.009661683014460973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.856929779052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039362307637929916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212923586368561,
      "backward_entropy": 0.009610433663640703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.396297454833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03942594677209854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212685167789459,
      "backward_entropy": 0.022513232060841153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.300212860107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039485491812229156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212475061416626,
      "backward_entropy": 0.009503858430044991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.34791564941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0395415835082531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212288051843643,
      "backward_entropy": 0.022523782082966397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.75569534301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03960046544671059,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10212088376283646,
      "backward_entropy": 0.00939381867647171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.59171676635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03966263681650162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10211874544620514,
      "backward_entropy": 0.02257036098412105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.13468551635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03972775861620903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10211646556854248,
      "backward_entropy": 0.022597055350031172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.26456069946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039793550968170166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211420059204102,
      "backward_entropy": 0.009248418467385429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.77708435058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039857275784015656,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10211209207773209,
      "backward_entropy": 0.09797383206231254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.867265701293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039922237396240234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210995376110077,
      "backward_entropy": 0.022646921021597727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.808666229248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03998333960771561,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210803151130676,
      "backward_entropy": 0.022655150720051358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.92511749267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04004097729921341,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210627317428589,
      "backward_entropy": 0.02265625979219164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.517841339111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04009736329317093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210460424423218,
      "backward_entropy": 0.022659203835896084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.74697875976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040149103850126266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10210314393043518,
      "backward_entropy": 0.022654333284923008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.617351531982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040209826081991196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10210131108760834,
      "backward_entropy": 0.008872884724821364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.63865089416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040266938507556915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209965705871582,
      "backward_entropy": 0.022661553961890086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.601659774780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04032265767455101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209804773330688,
      "backward_entropy": 0.02265832679612296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.495803833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040376827120780945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209649801254272,
      "backward_entropy": 0.008700877960239137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.58583450317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04042981192469597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209499299526215,
      "backward_entropy": 0.008640137634107046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.348663330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04048807546496391,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209333896636963,
      "backward_entropy": 0.00858216785958835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.18977737426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04054466262459755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10209173709154129,
      "backward_entropy": 0.022603909884180342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.97859954833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04060186818242073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209013521671295,
      "backward_entropy": 0.008467774838209152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.036869049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04066695645451546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020883247256279,
      "backward_entropy": 0.022594045315470015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.42200469970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04073123633861542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208656638860703,
      "backward_entropy": 0.00836016982793808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.648658752441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04080292955040932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208464413881302,
      "backward_entropy": 0.008309473948819297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.49782943725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04087486118078232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208277404308319,
      "backward_entropy": 0.008257911673613958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.34580993652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04094691202044487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10208092629909515,
      "backward_entropy": 0.008204721978732519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.37417221069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041018977761268616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207913815975189,
      "backward_entropy": 0.022556396467345103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.26515579223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041089728474617004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020774096250534,
      "backward_entropy": 0.008094052118914468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.80544662475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04116540029644966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207563638687134,
      "backward_entropy": 0.02253287817750658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.991424560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04124116897583008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207389295101166,
      "backward_entropy": 0.02253283773149763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.44033432006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041315075010061264,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207223892211914,
      "backward_entropy": 0.02252727746963501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.19846725463867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04139380156993866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10207055509090424,
      "backward_entropy": 0.02252922739301409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.544904708862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04147649183869362,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10206885635852814,
      "backward_entropy": 0.02252896555832454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.856435775756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04155687987804413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020672395825386,
      "backward_entropy": 0.007811446807214192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.209030151367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04163361340761185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206573456525803,
      "backward_entropy": 0.007766713521310261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.116371154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04170582443475723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020643413066864,
      "backward_entropy": 0.007724985480308533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.035688400268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041779737919569016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10206295549869537,
      "backward_entropy": 0.02254584857395717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.46579360961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04185187444090843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206162929534912,
      "backward_entropy": 0.007638862090451377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.73990821838379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04192109778523445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10206037014722824,
      "backward_entropy": 0.007594004273414612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.376285552978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041989516466856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205914825201035,
      "backward_entropy": 0.022546399916921343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.208438873291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04205982759594917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205791890621185,
      "backward_entropy": 0.022546574473381042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.371917724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042127083986997604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205675661563873,
      "backward_entropy": 0.02253655024937221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.55828857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04219372570514679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.102055624127388,
      "backward_entropy": 0.0074198075703212196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.619998931884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04226088151335716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205449163913727,
      "backward_entropy": 0.007375996027673993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.44071578979492,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04233044385910034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10205337405204773,
      "backward_entropy": 0.09849733114242554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.356388568878174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042402081191539764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10205227136611938,
      "backward_entropy": 0.007297603147370475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.64190673828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042467765510082245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10205122828483582,
      "backward_entropy": 0.0225378509078707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.16841125488281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04253096505999565,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10205021500587463,
      "backward_entropy": 0.09852512393678937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.62496566772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04259968176484108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204917937517166,
      "backward_entropy": 0.0071725259934152874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.4249267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04266907274723053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10204817354679108,
      "backward_entropy": 0.02252861644540514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.41712188720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04273723065853119,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204719752073288,
      "backward_entropy": 0.007093576980488641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.14739227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04281073808670044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204622894525528,
      "backward_entropy": 0.007058551801102502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.99896240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288304224610329,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204529762268066,
      "backward_entropy": 0.00702667236328125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.79480743408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04295562952756882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10204438865184784,
      "backward_entropy": 0.02256928597177778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.96159553527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04302968084812164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.102043516933918,
      "backward_entropy": 0.02258418713297163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.65076446533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04309912398457527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10204265266656876,
      "backward_entropy": 0.022595758949007307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.664783477783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04316752776503563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020418107509613,
      "backward_entropy": 0.02260873998914446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.055442810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04323383793234825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10204100608825684,
      "backward_entropy": 0.022631113018308367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.88199996948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043302346020936966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204021632671356,
      "backward_entropy": 0.00684655351298196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.456886291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04337267950177193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203942656517029,
      "backward_entropy": 0.022671940071242198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.76723098754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0434461385011673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020386815071106,
      "backward_entropy": 0.02268840798309871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.31947326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04351961612701416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020379513502121,
      "backward_entropy": 0.0067614348871367315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.458003997802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043594181537628174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203725099563599,
      "backward_entropy": 0.006730544779981885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.28294372558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043663956224918365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203655064105988,
      "backward_entropy": 0.006697724972452436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.949974060058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04373423010110855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203586518764496,
      "backward_entropy": 0.022729486227035522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.404680252075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043809033930301666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203520953655243,
      "backward_entropy": 0.022740640810557773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.80555725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388199746608734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203458368778229,
      "backward_entropy": 0.006608770361968449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.611358165740967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04395504295825958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203397274017334,
      "backward_entropy": 0.022758368934903826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.018741607666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04402237385511398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020333468914032,
      "backward_entropy": 0.006553278969866889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.455801010131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04408885911107063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203273594379425,
      "backward_entropy": 0.02279222011566162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.941434860229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04415297880768776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020321324467659,
      "backward_entropy": 0.006501094038997378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.476070404052734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04421374946832657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10203151404857635,
      "backward_entropy": 0.02282931762082236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.57351303100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04427704960107803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020309180021286,
      "backward_entropy": 0.006451415164130074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.11722183227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04433969408273697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203033685684204,
      "backward_entropy": 0.006425767072609493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.349863052368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044400472193956375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202974081039429,
      "backward_entropy": 0.006401125873838153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.24256134033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044461026787757874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202915966510773,
      "backward_entropy": 0.006377487310341426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.399620056152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04452137276530266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202857851982117,
      "backward_entropy": 0.006354727915355137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.79709243774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04458285868167877,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.102028027176857,
      "backward_entropy": 0.02294806923185076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.924375534057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04464234039187431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202746093273163,
      "backward_entropy": 0.022964686155319214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.00016975402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044701527804136276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202691704034805,
      "backward_entropy": 0.022979425532477244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.870826721191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04476195201277733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202637314796448,
      "backward_entropy": 0.022995393191065108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.730796813964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044823192059993744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202585160732269,
      "backward_entropy": 0.0062337347439357215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.48915672302246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04488533362746239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020253598690033,
      "backward_entropy": 0.0230098409312112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.67789840698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04494690150022507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020248606801033,
      "backward_entropy": 0.023014449647494724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.30591583251953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04501355439424515,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10202443599700928,
      "backward_entropy": 0.09881282704217094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07786387950181961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045080434530973434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202403366565704,
      "backward_entropy": 0.006125750286238534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.032859802246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04514041543006897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202354192733765,
      "backward_entropy": 0.023008014474596297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.035439491271973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04519969969987869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202307999134064,
      "backward_entropy": 0.006065414420195988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.884458541870117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525440186262131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202254354953766,
      "backward_entropy": 0.006034907485757556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.811012268066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0453079491853714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202202200889587,
      "backward_entropy": 0.006006203591823578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.520273208618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0453605130314827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020214706659317,
      "backward_entropy": 0.005979289965970176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.665433883666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04541512951254845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202095657587051,
      "backward_entropy": 0.005955419902290616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.96304702758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04546881094574928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202044248580933,
      "backward_entropy": 0.005934649812323707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.697602272033691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045527078211307526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201998800039291,
      "backward_entropy": 0.02301616540976933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.232383728027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045582473278045654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201951116323471,
      "backward_entropy": 0.023038868393216814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8297576904296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563799500465393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020190417766571,
      "backward_entropy": 0.023061773606709073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.551212310791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568960517644882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201850533485413,
      "backward_entropy": 0.005861492561442512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.67696189880371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04573904722929001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201793909072876,
      "backward_entropy": 0.02312294500214713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.162609100341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045790448784828186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201742500066757,
      "backward_entropy": 0.023150177938597544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.16671371459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04584124684333801,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.102016881108284,
      "backward_entropy": 0.005816017942769187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.671377182006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045899320393800735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201649367809296,
      "backward_entropy": 0.023213309901101247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.19437026977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045957550406455994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201610624790192,
      "backward_entropy": 0.005787175680909838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.66520690917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04601692408323288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201574862003326,
      "backward_entropy": 0.02328442462853023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.776241302490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046078603714704514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201545804738998,
      "backward_entropy": 0.02331358620098659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.795562744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04613824188709259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201513767242432,
      "backward_entropy": 0.023339007581983293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.616714477539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04619889333844185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201483964920044,
      "backward_entropy": 0.005727680666106088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.529958724975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04625773802399635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201454907655716,
      "backward_entropy": 0.005712457001209259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.398170471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04631752148270607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201425850391388,
      "backward_entropy": 0.005696205688374383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.264371871948242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046378232538700104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201402008533478,
      "backward_entropy": 0.02343208236353738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.71135711669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04643985256552696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201379656791687,
      "backward_entropy": 0.023453918950898305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.60154914855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04650091379880905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201357305049896,
      "backward_entropy": 0.005649280335221972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.4967041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046561338007450104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201336443424225,
      "backward_entropy": 0.005633530340024403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.054136276245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04662139341235161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201315581798553,
      "backward_entropy": 0.005619061312505177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.597017288208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04667978733778,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201293230056763,
      "backward_entropy": 0.023550074015344893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.893622398376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04673926904797554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201272368431091,
      "backward_entropy": 0.023579224944114685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.078765869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04679684340953827,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.102012500166893,
      "backward_entropy": 0.023603845919881548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.97539520263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04685421660542488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201229155063629,
      "backward_entropy": 0.023629254528454373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.246556282043457,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04691127687692642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10201208293437958,
      "backward_entropy": 0.09892573526927403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.592378616333008,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04696403443813324,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10201181471347809,
      "backward_entropy": 0.09892774479729789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.69034767150879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047015462070703506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020115315914154,
      "backward_entropy": 0.005522850368704114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.87708854675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047067273408174515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201126337051392,
      "backward_entropy": 0.005508029567343848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.499065399169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047121986746788025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020110696554184,
      "backward_entropy": 0.023719885519572666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.67688751220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04717666283249855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201089084148407,
      "backward_entropy": 0.00547703674861363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.363567352294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047235261648893356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201078653335571,
      "backward_entropy": 0.023745079125676836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.231769561767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047294795513153076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201072692871094,
      "backward_entropy": 0.023757436445781162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.108211517333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04735519364476204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201069712638855,
      "backward_entropy": 0.02377154358795711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.968107223510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047417573630809784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201071202754974,
      "backward_entropy": 0.02378331550530025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.863121032714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04747893661260605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201073437929153,
      "backward_entropy": 0.005399913660117558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896608352661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047539595514535904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201074928045273,
      "backward_entropy": 0.023797165070261275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.26994323730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04759715870022774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201071202754974,
      "backward_entropy": 0.023813667041914805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.665376663208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04765937477350235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201077908277512,
      "backward_entropy": 0.023821217673165456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.730891227722168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04771953821182251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020108163356781,
      "backward_entropy": 0.005341040768793651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.160432815551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04777643457055092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201079398393631,
      "backward_entropy": 0.02384752460888454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.827749252319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04783433675765991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020108014345169,
      "backward_entropy": 0.023862464087350026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.66715431213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04789423197507858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201087594032288,
      "backward_entropy": 0.023871121662003652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.76548957824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047955870628356934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201101005077362,
      "backward_entropy": 0.0238730183669499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.904111862182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04801814258098602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201114416122437,
      "backward_entropy": 0.005269897835595267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.411396980285645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04807955026626587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201127827167511,
      "backward_entropy": 0.023892896515982493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.35434341430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04813762381672859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201133787631989,
      "backward_entropy": 0.00524471966283662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.946392059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04819636046886444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201144218444824,
      "backward_entropy": 0.005232044628688267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.10017967224121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048253245651721954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201151669025421,
      "backward_entropy": 0.0052200300352914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.38602066040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04831095412373543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201163589954376,
      "backward_entropy": 0.0052077727658408025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.718597412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048368245363235474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201172530651093,
      "backward_entropy": 0.005196551127093179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109134674072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04842384532094002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201181471347809,
      "backward_entropy": 0.023989149502345493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.576597213745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04847679287195206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201182961463928,
      "backward_entropy": 0.005178201411451612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.508217811584473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0485285259783268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201182961463928,
      "backward_entropy": 0.00517122820019722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.439493179321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04857916012406349,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201181471347809,
      "backward_entropy": 0.024105089051382884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.824207305908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04862873628735542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020117849111557,
      "backward_entropy": 0.02414945193699428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.877250671386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04867858439683914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020117849111557,
      "backward_entropy": 0.024193005902426585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.24553394317627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04872611537575722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201174765825272,
      "backward_entropy": 0.024236119219235013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.34811782836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04877287149429321,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201170295476913,
      "backward_entropy": 0.024280096803392683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382807731628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04882269352674484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201172530651093,
      "backward_entropy": 0.02432256724153246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.40134620666504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048868898302316666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201171040534973,
      "backward_entropy": 0.0051305485623223445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.348481178283691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04891563579440117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201169550418854,
      "backward_entropy": 0.005124308701072421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.08329772949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04895930364727974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201163589954376,
      "backward_entropy": 0.024451726249286106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3002824783325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04901123046875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201173275709152,
      "backward_entropy": 0.005114181233303887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.06690216064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04905937239527702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201176255941391,
      "backward_entropy": 0.0051087359232561925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.74220085144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049107812345027924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201182961463928,
      "backward_entropy": 0.024575552770069668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.681599617004395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0491553470492363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201187431812286,
      "backward_entropy": 0.005097334938389915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41795825958252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04920213297009468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201191902160645,
      "backward_entropy": 0.005092777843986239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.558327674865723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04924694821238518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201191902160645,
      "backward_entropy": 0.005088836486850466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.178987503051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929116740822792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201191902160645,
      "backward_entropy": 0.005084840314728873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304631233215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04933246970176697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201185941696167,
      "backward_entropy": 0.0050820596516132355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.520944595336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04937237128615379,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020117700099945,
      "backward_entropy": 0.02485883661678859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.34103012084961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049413375556468964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201174020767212,
      "backward_entropy": 0.024909370711871555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.103108882904053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945415258407593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201169550418854,
      "backward_entropy": 0.00507470007453646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.31118392944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04949219152331352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201162099838257,
      "backward_entropy": 0.02500660078866141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.243616104125977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04953144118189812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201157629489899,
      "backward_entropy": 0.025049786482538496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.132057189941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049571819603443146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201157629489899,
      "backward_entropy": 0.0050638408533164436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.056388854980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04961195960640907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201157629489899,
      "backward_entropy": 0.005059203399079186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.022750854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049650657922029495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201156884431839,
      "backward_entropy": 0.00505450793675014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.968812942504883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968807101249695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020115464925766,
      "backward_entropy": 0.005049906671047211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.956947326660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04972676560282707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020115539431572,
      "backward_entropy": 0.02523805626801082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.834577560424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049764230847358704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020115464925766,
      "backward_entropy": 0.02527542199407305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.888378620147705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049802932888269424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201156884431839,
      "backward_entropy": 0.005035819219691413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.855766296386719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04984033480286598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201157629489899,
      "backward_entropy": 0.025342951927866255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.636201858520508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049876581877470016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201157629489899,
      "backward_entropy": 0.025377081973212107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.460914611816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049914129078388214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201160609722137,
      "backward_entropy": 0.025406337210110257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.499703407287598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049954064190387726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201171040534973,
      "backward_entropy": 0.025430856006486074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.283266067504883,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04999493435025215,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10201183706521988,
      "backward_entropy": 0.09900261674608503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678129196166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05003790184855461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201200842857361,
      "backward_entropy": 0.004999519458838871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.91357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007903277873993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201217979192734,
      "backward_entropy": 0.004991653774465833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.403486251831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05012337490916252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201239585876465,
      "backward_entropy": 0.004982897745711463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.345670700073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016710236668587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201261192560196,
      "backward_entropy": 0.004975045365946633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.56578826904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05021028593182564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201281309127808,
      "backward_entropy": 0.004968136548995972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.225791931152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025649443268776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201308131217957,
      "backward_entropy": 0.004960699273007256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007034858223050833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050301846116781235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201331973075867,
      "backward_entropy": 0.025578962905066355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.21276092529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050342801958322525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.102013498544693,
      "backward_entropy": 0.02560229812349592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.41585350036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050386860966682434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201375186443329,
      "backward_entropy": 0.004940771098647799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.99170970916748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050432588905096054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201402008533478,
      "backward_entropy": 0.025634852903229848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.21550750732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05047744885087013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201428830623627,
      "backward_entropy": 0.025650950414793833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.490593910217285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052385851740837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201458632946014,
      "backward_entropy": 0.004918442240783146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.608180522918701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05057043209671974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201489925384521,
      "backward_entropy": 0.00491038230913026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.753641128540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05061372369527817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201515257358551,
      "backward_entropy": 0.025692179799079895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.946762084960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065644532442093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201539099216461,
      "backward_entropy": 0.0048978860889162335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.175411224365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050703201442956924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201570391654968,
      "backward_entropy": 0.004890843161514827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.092873573303223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050750087946653366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201601684093475,
      "backward_entropy": 0.004883685282298497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.51116943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05079708248376846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201634466648102,
      "backward_entropy": 0.025753498077392578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.930835723876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050843093544244766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020166426897049,
      "backward_entropy": 0.02576993831566402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.849015235900879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05088934302330017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201694816350937,
      "backward_entropy": 0.004864174340452466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.888235569000244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050935763865709305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201726108789444,
      "backward_entropy": 0.004858279334647315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4261980056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050980087369680405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201752930879593,
      "backward_entropy": 0.025826628719057356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.810756206512451,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051021281629800797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201774537563324,
      "backward_entropy": 0.004849628678389958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.709293365478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05106077343225479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201795399188995,
      "backward_entropy": 0.004845754908663886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.84055519104004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05110454186797142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201822221279144,
      "backward_entropy": 0.025887815015656606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.395075798034668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05114982649683952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201849043369293,
      "backward_entropy": 0.00483611279300281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.988639831542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05119534954428673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201877355575562,
      "backward_entropy": 0.02591546518462045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.54517364501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05123995617032051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020190417766571,
      "backward_entropy": 0.025932471667017256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.15706729888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05128594487905502,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201932489871979,
      "backward_entropy": 0.025947798575673784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.541495323181152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051332034170627594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201960057020187,
      "backward_entropy": 0.004818204258169446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.751633644104004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137597396969795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201984643936157,
      "backward_entropy": 0.004814408719539642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.15485382080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141907185316086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202008485794067,
      "backward_entropy": 0.00481080317071506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.05813980102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05146360024809837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202033817768097,
      "backward_entropy": 0.02601420453616551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.57864761352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05150940269231796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202060639858246,
      "backward_entropy": 0.026025346347263882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.691873550415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05155419558286667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202085226774216,
      "backward_entropy": 0.02603937472615923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.158169746398926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159918591380119,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202108323574066,
      "backward_entropy": 0.026054835745266507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.406900405883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05164102837443352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202128440141678,
      "backward_entropy": 0.004789532827479499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.236990451812744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051682207733392715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020214706659317,
      "backward_entropy": 0.004786854343754905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.400830268859863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051721662282943726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202162712812424,
      "backward_entropy": 0.004784660679953439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.416505813598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05176173150539398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202179849147797,
      "backward_entropy": 0.004781991243362427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.133492946624756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051803555339574814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202197730541229,
      "backward_entropy": 0.026164614728518894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0512380599975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05184362083673477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202212631702423,
      "backward_entropy": 0.004777492157050541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096525192260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051880959421396255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202226042747498,
      "backward_entropy": 0.02621769905090332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.065092086791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191801115870476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202237218618393,
      "backward_entropy": 0.004775214408125196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.996234893798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0519559420645237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202249884605408,
      "backward_entropy": 0.0047738440334796906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.96481466293335,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05199676752090454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202263295650482,
      "backward_entropy": 0.004771247506141663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897351264953613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05203578993678093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202275216579437,
      "backward_entropy": 0.0047686392707484105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.899375915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05207433924078941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202287137508392,
      "backward_entropy": 0.026330381631851196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.868082046508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05211135745048523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202296823263168,
      "backward_entropy": 0.026350545031683787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8372650146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05214701592922211,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202305018901825,
      "backward_entropy": 0.026372385876519338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9063282012939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0521814338862896,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202312469482422,
      "backward_entropy": 0.02639522509915488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.892289638519287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052213676273822784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020231768488884,
      "backward_entropy": 0.00476002533520971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.755289077758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052243947982788086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202322155237198,
      "backward_entropy": 0.004760068974324635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.45610523223877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052273526787757874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202325880527496,
      "backward_entropy": 0.004760417555059705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.853708267211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05230461061000824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202330350875854,
      "backward_entropy": 0.004760184990508216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.516578674316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05233383551239967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202333331108093,
      "backward_entropy": 0.02653824644429343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.303772926330566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05236352980136871,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202336311340332,
      "backward_entropy": 0.026568074311528887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.250630378723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05239470303058624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020234003663063,
      "backward_entropy": 0.026594391890934536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.801598310470581,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05242718756198883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202343016862869,
      "backward_entropy": 0.00475982523390225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.143592834472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052457667887210846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202344506978989,
      "backward_entropy": 0.004759706024612699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.632965087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0524895116686821,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202345252037048,
      "backward_entropy": 0.026665204337665012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.759589672088623,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052524715662002563,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10202346742153168,
      "backward_entropy": 0.09900920731680733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23177719116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05255761370062828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202346742153168,
      "backward_entropy": 0.004755696015698569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189716339111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05259060487151146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202346742153168,
      "backward_entropy": 0.02672666311264038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.290292739868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05262367054820061,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202345252037048,
      "backward_entropy": 0.026750485811914717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.49948501586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265989154577255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202343016862869,
      "backward_entropy": 0.0047514912273202625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.368441581726074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05269794166088104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202338546514511,
      "backward_entropy": 0.004748757928609848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.33721923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05273442715406418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202333331108093,
      "backward_entropy": 0.0047462401645524165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.613029479980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052769485861063004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202328860759735,
      "backward_entropy": 0.0047438134040151325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2773613929748535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05280537158250809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202321410179138,
      "backward_entropy": 0.004740968346595764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.116601943969727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05283990874886513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202313959598541,
      "backward_entropy": 0.026847898960113525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.03813648223877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287637561559677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202303528785706,
      "backward_entropy": 0.004735420324972698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775031089782715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291450396180153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020229160785675,
      "backward_entropy": 0.026869467326572964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.877605438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052952054888010025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202277451753616,
      "backward_entropy": 0.004727410418646676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.677365779876709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05299116298556328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202261060476303,
      "backward_entropy": 0.0047227857368333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.712749481201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05302958935499191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202242434024811,
      "backward_entropy": 0.02688546904495784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5272130966186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05306946486234665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020222157239914,
      "backward_entropy": 0.026888085263116018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.020669460296631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05310651287436485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202200710773468,
      "backward_entropy": 0.026893688099724904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.451309204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05314202606678009,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202178359031677,
      "backward_entropy": 0.02689998277596065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.432747840881348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05318327248096466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020214855670929,
      "backward_entropy": 0.02689701957362039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.921674728393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053223587572574615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202116519212723,
      "backward_entropy": 0.026894999401909963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.333800315856934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326204001903534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10202083736658096,
      "backward_entropy": 0.004688220896891185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.56818675994873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05329987406730652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020205020904541,
      "backward_entropy": 0.004683721278394971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.645503997802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053340137004852295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10202011466026306,
      "backward_entropy": 0.026897366557802473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.790109157562256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053380582481622696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201968252658844,
      "backward_entropy": 0.02689902697290693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1349663734436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053419169038534164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201926529407501,
      "backward_entropy": 0.026904355202402388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.087274074554443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345706641674042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201883316040039,
      "backward_entropy": 0.026911122458321706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.079029083251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05349433049559593,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201837122440338,
      "backward_entropy": 0.02691886680466788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.66172456741333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05353400483727455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020178571343422,
      "backward_entropy": 0.026922149317605153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.944363594055176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05357187241315842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201733559370041,
      "backward_entropy": 0.004656029599053519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.792884826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05360911786556244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201680660247803,
      "backward_entropy": 0.02693817445210048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.567103862762451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053648754954338074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201621055603027,
      "backward_entropy": 0.026946003947939192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.535129070281982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053686607629060745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201562196016312,
      "backward_entropy": 0.0046480510916028705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036078456323593855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0537228137254715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201504826545715,
      "backward_entropy": 0.026973394410950795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002533926162868738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053755614906549454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201454162597656,
      "backward_entropy": 0.004646426865032741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.131577491760254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0537853017449379,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201410949230194,
      "backward_entropy": 0.02702135912009648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.280198097229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05381704494357109,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201358795166016,
      "backward_entropy": 0.004647508263587952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798256874084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053851623088121414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10201296955347061,
      "backward_entropy": 0.027061973299298967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.109034538269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05388681963086128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201230645179749,
      "backward_entropy": 0.004645731832299914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.847487449645996,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053924474865198135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10201156139373779,
      "backward_entropy": 0.09900569915771484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.461313724517822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05396335572004318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10201073437929153,
      "backward_entropy": 0.00464177450963429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.277542591094971,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05400138348340988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10200989246368408,
      "backward_entropy": 0.004639664930956704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.371397018432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05403769388794899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10200907289981842,
      "backward_entropy": 0.0046381136136395594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.326773166656494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05407344549894333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200824588537216,
      "backward_entropy": 0.02715409653527396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.56563949584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054108627140522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020074188709259,
      "backward_entropy": 0.0046357523117746624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0811986923217773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414612963795662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020064428448677,
      "backward_entropy": 0.0046334708375590184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259974479675293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418099835515022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10200554132461548,
      "backward_entropy": 0.004632116960627692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.204596519470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054216280579566956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200457274913788,
      "backward_entropy": 0.027205309697559903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.038773536682129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0542520172894001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10200357437133789,
      "backward_entropy": 0.0272183290549687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.137606620788574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054285310208797455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10200265049934387,
      "backward_entropy": 0.004627798816987446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.042730331420898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432106927037239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020015999674797,
      "backward_entropy": 0.004626184169735227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.98204231262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435808002948761,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10200044512748718,
      "backward_entropy": 0.004623982523168836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021640716586261988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054394353181123734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199928283691406,
      "backward_entropy": 0.00462201184460095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9330902099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05442715063691139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199826210737228,
      "backward_entropy": 0.02729112548487527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9560225009918213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05445866659283638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019972562789917,
      "backward_entropy": 0.027308468307767595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8845901489257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054488152265548706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199634730815887,
      "backward_entropy": 0.02733025167669569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.722143173217773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05451667308807373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199545323848724,
      "backward_entropy": 0.027352277721677507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757353782653809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05454616621136665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199448466300964,
      "backward_entropy": 0.004621205053159169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.815300941467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05457561835646629,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199347883462906,
      "backward_entropy": 0.027390935591288974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.479315757751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054604094475507736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199250280857086,
      "backward_entropy": 0.027409913284438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.768721580505371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05463443323969841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10199140012264252,
      "backward_entropy": 0.02742519974708557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6176533699035645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05466369166970253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10199031233787537,
      "backward_entropy": 0.004619292914867401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7229669094085693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469289794564247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198920965194702,
      "backward_entropy": 0.004618461642946515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8511399030685425,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0547211617231369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10198812186717987,
      "backward_entropy": 0.02747428204332079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.19603157043457,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05474763736128807,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10198713839054108,
      "backward_entropy": 0.09900987999779838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.484550952911377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05477612093091011,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10198600590229034,
      "backward_entropy": 0.02750780539853232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021361629478633404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05480458587408066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10198482871055603,
      "backward_entropy": 0.027520716190338135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227598190307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05483035370707512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10198382288217545,
      "backward_entropy": 0.027538325105394636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185521602630615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0548572912812233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019827201962471,
      "backward_entropy": 0.027554595044681003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.356734752655029,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488528311252594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10198152810335159,
      "backward_entropy": 0.00461443726505552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3235039710998535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05491331219673157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1019803136587143,
      "backward_entropy": 0.004613555435623441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.054196357727051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05494134873151779,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019790768623352,
      "backward_entropy": 0.027600803545543125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.511683464050293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05497031658887863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197775810956955,
      "backward_entropy": 0.004611301102808544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698543548583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05500185489654541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10197622328996658,
      "backward_entropy": 0.027626403740474155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.086904525756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0550348237156868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10197454690933228,
      "backward_entropy": 0.027635174138205394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4264631271362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05507083982229233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197262465953827,
      "backward_entropy": 0.004602928246770587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.79758882522583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05510516092181206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197077691555023,
      "backward_entropy": 0.004600359925201961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6874123811721802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05513971298933029,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10196886956691742,
      "backward_entropy": 0.02765457970755441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.039765357971191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517183244228363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196711868047714,
      "backward_entropy": 0.004595973661967686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6409592628479,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05520610883831978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196514427661896,
      "backward_entropy": 0.004593351589781898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.940844535827637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05524059757590294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019631177186966,
      "backward_entropy": 0.027679541281291416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.902095317840576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055274371057748795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196108371019363,
      "backward_entropy": 0.004588076046534947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105107307434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530751869082451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10195907950401306,
      "backward_entropy": 0.004585684410163334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.861213684082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055341821163892746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10195693373680115,
      "backward_entropy": 0.027700698801449368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966649532318115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0553797110915184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019544005393982,
      "backward_entropy": 0.027701971786362783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.892918109893799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05541826784610748,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10195177793502808,
      "backward_entropy": 0.027704143098422458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1281230449676514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05545742064714432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019490510225296,
      "backward_entropy": 0.027707640613828386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.64910888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05549450218677521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10194643586874008,
      "backward_entropy": 0.004567559276308332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608002662658691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05553056672215462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10194388031959534,
      "backward_entropy": 0.004564836621284485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.567334175109863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05556569993495941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10194133967161179,
      "backward_entropy": 0.027730592659541538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025124300736933947,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05559993162751198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10193880647420883,
      "backward_entropy": 0.004559861229998725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.992683410644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055630914866924286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10193657875061035,
      "backward_entropy": 0.027752031173024858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4878783226013184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055662307888269424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019342839717865,
      "backward_entropy": 0.02776662153857095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.952528238296509,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05569153651595116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10193218290805817,
      "backward_entropy": 0.00455728971532413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.395486354827881,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05571967735886574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10193018615245819,
      "backward_entropy": 0.004557602107524872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.910435914993286,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05574760586023331,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192815959453583,
      "backward_entropy": 0.004557742072003228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.335463047027588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055774521082639694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192620754241943,
      "backward_entropy": 0.004558131630931582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.740154266357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055801376700401306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10192422568798065,
      "backward_entropy": 0.027867470468793596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4264464378356934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05582897737622261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192213952541351,
      "backward_entropy": 0.00455870692219053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.246615886688232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055854782462120056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019202396273613,
      "backward_entropy": 0.027909713132040843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.623355865478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055880580097436905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1019183024764061,
      "backward_entropy": 0.02793121337890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.189337253570557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590714141726494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10191619396209717,
      "backward_entropy": 0.004559296582426343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5464277267456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055933620780706406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10191407799720764,
      "backward_entropy": 0.027966882501329695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.754312038421631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05596083030104637,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10191182792186737,
      "backward_entropy": 0.027984040124075755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835145950317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055987074971199036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10190967470407486,
      "backward_entropy": 0.02800288370677403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.714611291885376,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05601486936211586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10190728306770325,
      "backward_entropy": 0.02802007326057979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.348354458808899,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05604160577058792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10190499573945999,
      "backward_entropy": 0.02803757573877062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.677086591720581,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05606657639145851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10190290957689285,
      "backward_entropy": 0.004556749016046524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.647247314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05609075352549553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10190089046955109,
      "backward_entropy": 0.02807401546410152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.599980354309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056116655468940735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10189861059188843,
      "backward_entropy": 0.028089489255632673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.240705490112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05614405870437622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10189607739448547,
      "backward_entropy": 0.004553460649081639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.200451850891113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05617200955748558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10189342498779297,
      "backward_entropy": 0.004551483584301812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8698697090148926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05620046332478523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10189065337181091,
      "backward_entropy": 0.004549448511430195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001202013110741973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05622856318950653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10188789665699005,
      "backward_entropy": 0.028137104851858958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.812164783477783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05625392496585846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10188548266887665,
      "backward_entropy": 0.028150424361228943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5234148502349854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05627921596169472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10188304632902145,
      "backward_entropy": 0.028163652334894453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.506686210632324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056303609162569046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10188069194555283,
      "backward_entropy": 0.004542822284357888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.733707904815674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056327253580093384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10187841206789017,
      "backward_entropy": 0.004541579633951187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.472715377807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056350983679294586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10187610983848572,
      "backward_entropy": 0.004540357206548963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.456317186355591,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056373998522758484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10187388956546783,
      "backward_entropy": 0.0282196934734072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.879438877105713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05639635771512985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10187172889709473,
      "backward_entropy": 0.02823494587625776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.05808687210083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056419651955366135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1018693596124649,
      "backward_entropy": 0.028247550129890442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.013341903686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05644458532333374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1018666997551918,
      "backward_entropy": 0.028258357729230608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.966906547546387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056470923125743866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10186372697353363,
      "backward_entropy": 0.02826471413884844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.185211420059204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05649854987859726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10186047852039337,
      "backward_entropy": 0.028269290924072266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.52407169342041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05652432143688202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185752809047699,
      "backward_entropy": 0.004526254854031971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3317692279815674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05654989928007126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10185457766056061,
      "backward_entropy": 0.028287461825779507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3146612644195557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05657452717423439,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185173153877258,
      "backward_entropy": 0.004521744591849191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.594262599945068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05659830942749977,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10184900462627411,
      "backward_entropy": 0.028307744434901645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.28090763092041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05662280321121216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184608399868011,
      "backward_entropy": 0.004517458379268646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.264007091522217,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05664645880460739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184329003095627,
      "backward_entropy": 0.004515369555779866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.248612403869629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056669313460588455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10184057056903839,
      "backward_entropy": 0.028335081679480418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.349259614944458,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0566914901137352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10183796286582947,
      "backward_entropy": 0.004511332937649318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.433523178100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05671381577849388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10183530300855637,
      "backward_entropy": 0.004509780555963516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2019877433776855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05673694238066673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10183242708444595,
      "backward_entropy": 0.004507269178118024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.370809555053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056759368628263474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1018296629190445,
      "backward_entropy": 0.02837656225476946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0857967138290405,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05678258463740349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10182669758796692,
      "backward_entropy": 0.004502910588468824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1551566123962402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05680431053042412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10182398557662964,
      "backward_entropy": 0.004500969712223325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280477523803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056825414299964905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10182134807109833,
      "backward_entropy": 0.02840569189616612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0639170408248901,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05684744939208031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1018184944987297,
      "backward_entropy": 0.004497012389557702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2221550941467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056868139654397964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10181592404842377,
      "backward_entropy": 0.004495684589658465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.383931159973145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05688977614045143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10181308537721634,
      "backward_entropy": 0.004494074199880872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012723541585728526,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056915149092674255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10180942714214325,
      "backward_entropy": 0.0044906096799033025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0952820777893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05693807080388069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10180622339248657,
      "backward_entropy": 0.00448786626969065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.119543075561523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05696093663573265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10180297493934631,
      "backward_entropy": 0.028457169021878923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0475363731384277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05698520690202713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10179933905601501,
      "backward_entropy": 0.028461000749043057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.052234172821045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057009290903806686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10179571807384491,
      "backward_entropy": 0.004478294934545245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9978018999099731,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057036060839891434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10179141163825989,
      "backward_entropy": 0.004474177956581116,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.618178667152534,
    "avg_log_Z": -0.05573531724512577,
    "success_rate": 1.0,
    "avg_reward": 48.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.01,
      "1": 0.51,
      "2": 0.48
    },
    "avg_forward_entropy": 0.10191658206284046,
    "avg_backward_entropy": 0.017387244515120984,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}