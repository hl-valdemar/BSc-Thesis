{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09901212794440133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09900460924421038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.92430114746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706821203231812,
      "backward_entropy": 0.09897938796452113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.46835327148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705909252166748,
      "backward_entropy": 0.09897570099149432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.15492248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020003801910206676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370498239994049,
      "backward_entropy": 0.09899940661021642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00029892390011809766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370404064655304,
      "backward_entropy": 0.09896785872323173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.0994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003983816131949425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703079521656036,
      "backward_entropy": 0.09899344614573888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.07180786132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004970793379470706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370210349559784,
      "backward_entropy": 0.09901962109974452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.28372192382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005953171639703214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701114058494568,
      "backward_entropy": 0.09902031932558332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.05396270751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006949162925593555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370009183883667,
      "backward_entropy": 0.09898318563188825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.25436401367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007897076429799199,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699063658714294,
      "backward_entropy": 0.09894594124385289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.48663330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0008857180364429951,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369800567626953,
      "backward_entropy": 0.09894124950681414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.61663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000983508420176804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136969193816185,
      "backward_entropy": 0.09893652370997838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.16098022460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001081700436770916,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695809245109558,
      "backward_entropy": 0.09893177236829485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.34837341308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011803065426647663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694678246974945,
      "backward_entropy": 0.09892700399671282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.69448852539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012768267188221216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693538308143616,
      "backward_entropy": 0.09901967218944005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.80059814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013725506141781807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692381978034973,
      "backward_entropy": 0.0989168541772025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.18878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014627119526267052,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691234588623047,
      "backward_entropy": 0.0990185056413923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.58163452148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015548778465017676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690057396888733,
      "backward_entropy": 0.09894519192831856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.88674926757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016486226813867688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368885040283203,
      "backward_entropy": 0.0989013739994594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.28184509277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017424634424969554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13687622547149658,
      "backward_entropy": 0.09901671750204903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.7576141357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001836283365264535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368637979030609,
      "backward_entropy": 0.09901619809014457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.456298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0019311733776703477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368512064218521,
      "backward_entropy": 0.09892618656158447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.49929809570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002027304843068123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683833181858063,
      "backward_entropy": 0.09901530402047294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.59017944335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021255072206258774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682511448860168,
      "backward_entropy": 0.09891654763902936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.00576782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022229382302612066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368117332458496,
      "backward_entropy": 0.09891160045351301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3928680419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023223611060529947,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679800927639008,
      "backward_entropy": 0.09886745895658221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.85089111328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0024233744479715824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678395748138428,
      "backward_entropy": 0.09890188489641462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.47055053710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002528366632759571,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676932454109192,
      "backward_entropy": 0.0990145036152431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.22726440429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002631481969729066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675463199615479,
      "backward_entropy": 0.09885479722704206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.25408935546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002734446432441473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673976063728333,
      "backward_entropy": 0.09888763087136405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.59757232666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002835510764271021,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367248147726059,
      "backward_entropy": 0.09884603534426008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.01629638671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002933426294475794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670986890792847,
      "backward_entropy": 0.09884117330823626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.1207275390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003032773034647107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669459521770477,
      "backward_entropy": 0.0990147420338222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.67628479003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031292636413127184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366792917251587,
      "backward_entropy": 0.09883104051862444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.86526489257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0032277109567075968,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13666361570358276,
      "backward_entropy": 0.0990147420338222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.02310180664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0033300286158919334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664735853672028,
      "backward_entropy": 0.09882073743002755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.92884826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003433350706472993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663075864315033,
      "backward_entropy": 0.09881561143057686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.37808227539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0035352003760635853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661406934261322,
      "backward_entropy": 0.09881016186305455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.55239868164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036322069354355335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659730553627014,
      "backward_entropy": 0.09883158547537667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67820739746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00372794340364635,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658039271831512,
      "backward_entropy": 0.09901487827301025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8468475341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003822817001491785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136563241481781,
      "backward_entropy": 0.09881579024451119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.53016662597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003920832183212042,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654547929763794,
      "backward_entropy": 0.09901465688432966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.49742126464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004020770080387592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652701675891876,
      "backward_entropy": 0.09879943302699498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.1334991455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004123485181480646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13650791347026825,
      "backward_entropy": 0.09879133531025477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1968536376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004227046389132738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648828864097595,
      "backward_entropy": 0.09878287996564593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.3582763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004328243434429169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13646849989891052,
      "backward_entropy": 0.09877360718590873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.04612731933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004433100577443838,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136447936296463,
      "backward_entropy": 0.09901443549564906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.23622131347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004541373811662197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364266723394394,
      "backward_entropy": 0.0987555810383388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.80772399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004648159723728895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640516996383667,
      "backward_entropy": 0.09874599320547921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.5540313720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004751145374029875,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13638374209403992,
      "backward_entropy": 0.099014299256461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.2743682861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004858387168496847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13636146485805511,
      "backward_entropy": 0.09871067319597517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.12984466552734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004964409861713648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363389492034912,
      "backward_entropy": 0.09901409489767891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.3855438232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005066489800810814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13631653785705566,
      "backward_entropy": 0.09869113990238734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.73306274414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005166888236999512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13629402220249176,
      "backward_entropy": 0.09868884086608887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.37110900878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005266950465738773,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362711787223816,
      "backward_entropy": 0.09866997173854283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.8417205810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005366213619709015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624806702136993,
      "backward_entropy": 0.09866188253675189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.14309692382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005469313357025385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13622412085533142,
      "backward_entropy": 0.09864842040198189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8264923095703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005573091097176075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361997425556183,
      "backward_entropy": 0.099011949130467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.30831909179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005675729364156723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13617511093616486,
      "backward_entropy": 0.09862032958439418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.90350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005778733175247908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136150062084198,
      "backward_entropy": 0.09861457347869873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4744415283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005880921613425016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13612475991249084,
      "backward_entropy": 0.09860263551984515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4686279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005985204130411148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360986977815628,
      "backward_entropy": 0.09857407638004848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.44557189941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0060873329639434814,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607257604599,
      "backward_entropy": 0.09900951385498047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.88760375976562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006190346088260412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360461413860321,
      "backward_entropy": 0.09900905404772077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.77252960205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00628984160721302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13602019846439362,
      "backward_entropy": 0.09852480888366699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.80410766601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0063844905234873295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359945833683014,
      "backward_entropy": 0.0985071233340672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.89383697509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006482250522822142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359681487083435,
      "backward_entropy": 0.09851866960525513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.47174072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006573128513991833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359422653913498,
      "backward_entropy": 0.0984703813280378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.39226531982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0066657778806984425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13591574132442474,
      "backward_entropy": 0.0984506436756679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.75042724609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006755384616553783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13588927686214447,
      "backward_entropy": 0.09900425161634173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.17068481445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00684449914842844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358625292778015,
      "backward_entropy": 0.0984489917755127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.87200927734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006935365032404661,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13583509624004364,
      "backward_entropy": 0.09900217396872384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.3571319580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007028182968497276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13580696284770966,
      "backward_entropy": 0.09841271809169225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.28834533691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007121278904378414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13577839732170105,
      "backward_entropy": 0.09900052206856864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.93324279785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007219001185148954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13574866950511932,
      "backward_entropy": 0.09837673391614642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.64234924316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007313564419746399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13571909070014954,
      "backward_entropy": 0.09835818835667201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.59783935546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007408069912344217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13568906486034393,
      "backward_entropy": 0.0989988020488194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.09063720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0075025297701358795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356586366891861,
      "backward_entropy": 0.09831978593553815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.16787719726562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007602928206324577,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13562677800655365,
      "backward_entropy": 0.09899794203894478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.66908264160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007707294542342424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13559380173683167,
      "backward_entropy": 0.09899805273328509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.3936004638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007813791744410992,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355600357055664,
      "backward_entropy": 0.09899833372661046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6853790283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007917258888483047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13552631437778473,
      "backward_entropy": 0.09824885640825544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.07469177246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00801854394376278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13549254834651947,
      "backward_entropy": 0.09822914430073329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.67893981933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008120914921164513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13545814156532288,
      "backward_entropy": 0.09820919377463204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.2164764404297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008220534771680832,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354237198829651,
      "backward_entropy": 0.09899767807551793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.52339935302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0083225779235363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353883594274521,
      "backward_entropy": 0.09808097566877093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.28041076660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008419214747846127,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13535358011722565,
      "backward_entropy": 0.09899675846099854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.98590087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0085173100233078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13531804084777832,
      "backward_entropy": 0.0980280978339059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008623705245554447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13528038561344147,
      "backward_entropy": 0.09809977667672294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.11184692382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008733107708394527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13524159789085388,
      "backward_entropy": 0.09798160621098109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.25830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00883836392313242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13520319759845734,
      "backward_entropy": 0.09805708272116524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.27518463134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008942704647779465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13516448438167572,
      "backward_entropy": 0.09793218544551305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.23458099365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00904299970716238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13512609899044037,
      "backward_entropy": 0.09800859008516584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9807891845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009139657951891422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350879818201065,
      "backward_entropy": 0.09798152106148857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.30230712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009234434925019741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135049507021904,
      "backward_entropy": 0.09795303855623518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.0933837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009329027496278286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13501004874706268,
      "backward_entropy": 0.0978124737739563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.6703338623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009428134188055992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349688470363617,
      "backward_entropy": 0.09778114727565221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.98091888427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009524822235107422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13492745161056519,
      "backward_entropy": 0.09774738550186157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.09365844726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009614512324333191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348869800567627,
      "backward_entropy": 0.09783170904432024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.65335083007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009704540483653545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13484574854373932,
      "backward_entropy": 0.09779793875558036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.91815185546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009799361228942871,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13480272889137268,
      "backward_entropy": 0.09898677894047328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.92721557617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00989463645964861,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347590535879135,
      "backward_entropy": 0.09898560387747628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.96324157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009993970394134521,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13471367955207825,
      "backward_entropy": 0.09769835642405919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.6722869873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010090974159538746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13466821610927582,
      "backward_entropy": 0.0976637601852417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.7193603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010186299681663513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13462257385253906,
      "backward_entropy": 0.09748506546020508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.05604553222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010278458707034588,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13457715511322021,
      "backward_entropy": 0.09898083550589425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.54009246826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010371226817369461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13453099131584167,
      "backward_entropy": 0.09740282808031354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.29782104492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01045602560043335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1344863623380661,
      "backward_entropy": 0.0989773188318525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.30929565429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010540138930082321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13444125652313232,
      "backward_entropy": 0.0973121268408639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.94142150878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010631167329847813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343936175107956,
      "backward_entropy": 0.09726846218109131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.16952514648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010726879350841045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13434365391731262,
      "backward_entropy": 0.09738825900214058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.6853790283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010825442150235176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134291872382164,
      "backward_entropy": 0.09735021420887538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.33969116210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01092666108161211,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13423851132392883,
      "backward_entropy": 0.09731281655175346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.88560485839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011028805747628212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341840624809265,
      "backward_entropy": 0.09710395336151123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.17820739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011127189733088017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13413000106811523,
      "backward_entropy": 0.09723447901862008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.19227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011224939487874508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13407529890537262,
      "backward_entropy": 0.097016555922372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.96788024902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011323331855237484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13401952385902405,
      "backward_entropy": 0.09696951934269496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.72195434570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011417925357818604,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13396412134170532,
      "backward_entropy": 0.09896855694907052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.39505004882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011518427170813084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13390609622001648,
      "backward_entropy": 0.09705885819026402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.67767333984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011613777838647366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13384902477264404,
      "backward_entropy": 0.0989666325705392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9725799560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011710401624441147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13379071652889252,
      "backward_entropy": 0.09677049091884068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.1546173095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011806825175881386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13373172283172607,
      "backward_entropy": 0.09691519396645683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.83145904541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011900744400918484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13367265462875366,
      "backward_entropy": 0.09686435971941267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.62638092041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011991581879556179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13361388444900513,
      "backward_entropy": 0.09660463673727852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.77826690673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012077374383807182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335560381412506,
      "backward_entropy": 0.09675383567810059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.0982208251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012160200625658035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334984004497528,
      "backward_entropy": 0.09647388117653984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.9969940185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012242212891578674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13344021141529083,
      "backward_entropy": 0.09663403034210205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.29295349121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01232546754181385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13338083028793335,
      "backward_entropy": 0.09633643286568778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.3288116455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012412849813699722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13331912457942963,
      "backward_entropy": 0.09626930100577218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.13385009765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012498827651143074,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13325710594654083,
      "backward_entropy": 0.09894381250653948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.96524047851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012588650919497013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13319283723831177,
      "backward_entropy": 0.0961317505155291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.12042236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012684913352131844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13312533497810364,
      "backward_entropy": 0.09606776918683733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.3649139404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012785309925675392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13305488228797913,
      "backward_entropy": 0.09600540569850377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.97064208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012885943986475468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1329827755689621,
      "backward_entropy": 0.09594007900782994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.42971801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012989044189453125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1329081952571869,
      "backward_entropy": 0.09587653194155012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.9756622314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013091148808598518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13283300399780273,
      "backward_entropy": 0.09581106049673897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.85226440429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013199479319155216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13275420665740967,
      "backward_entropy": 0.09608122280665807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.52255249023438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013302965089678764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.132676362991333,
      "backward_entropy": 0.09894258635384696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.12906646728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013406442478299141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13259738683700562,
      "backward_entropy": 0.09596754823412214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.24720001220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013505418784916401,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13251930475234985,
      "backward_entropy": 0.09894066197531563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.76605224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013597812503576279,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13244324922561646,
      "backward_entropy": 0.09583445957728795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.04449462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013690009713172913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323672980070114,
      "backward_entropy": 0.09576264449528285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.99000549316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013777574524283409,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13229264318943024,
      "backward_entropy": 0.09568585668291364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.63473510742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013860970735549927,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13221894204616547,
      "backward_entropy": 0.09892753192356654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.27244567871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013948805630207062,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13214224576950073,
      "backward_entropy": 0.0989241259438651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.92526245117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014036653563380241,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13206446170806885,
      "backward_entropy": 0.09544660363878522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.08547973632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014123416505753994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13198618590831757,
      "backward_entropy": 0.09492601667131696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.9239044189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01421101950109005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13190653920173645,
      "backward_entropy": 0.0952831506729126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.08589935302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014303559437394142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318235844373703,
      "backward_entropy": 0.09474674292973109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.84991455078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014392861165106297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13174156844615936,
      "backward_entropy": 0.098908645766122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.33393859863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014480514451861382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13165929913520813,
      "backward_entropy": 0.09504032135009766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.29298400878906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014562134630978107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13157919049263,
      "backward_entropy": 0.09890099082674299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.00650024414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014641483314335346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13149923086166382,
      "backward_entropy": 0.09485975333622523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.73619079589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014723855070769787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13141673803329468,
      "backward_entropy": 0.09476939269474574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.67129516601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014807136729359627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13133275508880615,
      "backward_entropy": 0.09467875105994088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.48863983154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014889701269567013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312481164932251,
      "backward_entropy": 0.09458621059145246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.27938842773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014965739101171494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311662793159485,
      "backward_entropy": 0.093904938016619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.85076904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015043795108795166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13108238577842712,
      "backward_entropy": 0.09379017353057861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.7132110595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01512154471129179,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1309976428747177,
      "backward_entropy": 0.09428465366363525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.48867797851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015207584947347641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13090747594833374,
      "backward_entropy": 0.09419200250080653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.08348083496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015292932279407978,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1308167576789856,
      "backward_entropy": 0.09886418070111956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.1606903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015375526621937752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13072651624679565,
      "backward_entropy": 0.09334099292755127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.05995178222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015465601347386837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13063108921051025,
      "backward_entropy": 0.09323370456695557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.1502914428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015553565695881844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13053569197654724,
      "backward_entropy": 0.09381341934204102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.09052276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015637235715985298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13044188916683197,
      "backward_entropy": 0.09299434082848686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.89886474609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015712784603238106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13035190105438232,
      "backward_entropy": 0.09359925985336304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.81048583984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01579027995467186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13025978207588196,
      "backward_entropy": 0.09272609438214983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.79615783691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01586952991783619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13016562163829803,
      "backward_entropy": 0.09259385722024101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.36131286621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01595146954059601,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13006870448589325,
      "backward_entropy": 0.09327154500143868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.7930145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016033319756388664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1299709677696228,
      "backward_entropy": 0.09232988527842931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.43426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016117891296744347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1298704892396927,
      "backward_entropy": 0.09219828673771449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.3002166748047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01620279625058174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12976861000061035,
      "backward_entropy": 0.09883250508989606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.57467651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01628689467906952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.129666268825531,
      "backward_entropy": 0.09192122731889997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.28628540039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016368264332413673,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12956468760967255,
      "backward_entropy": 0.09882635729653495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.19935607910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016446491703391075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12946420907974243,
      "backward_entropy": 0.0925875220979963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.95640563964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016519993543624878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12936615943908691,
      "backward_entropy": 0.0924548591886248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.87672424316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01659274660050869,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12926775217056274,
      "backward_entropy": 0.09232057843889509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.20420837402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01667150855064392,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1291644275188446,
      "backward_entropy": 0.09880469526563372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.62998962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016746962442994118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12906241416931152,
      "backward_entropy": 0.09101089409419469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.04059600830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016827434301376343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12895584106445312,
      "backward_entropy": 0.09086155891418457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.2385711669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01690632849931717,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12884947657585144,
      "backward_entropy": 0.09879395791462489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.1663360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01698850467801094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12873978912830353,
      "backward_entropy": 0.09167433636529106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.79302215576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017071785405278206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286282241344452,
      "backward_entropy": 0.09040422098977226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.21790313720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01715322583913803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12851686775684357,
      "backward_entropy": 0.09024604729243688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.133544921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01722905971109867,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12840776145458221,
      "backward_entropy": 0.09878243718828474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.2231674194336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017305104061961174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12829717993736267,
      "backward_entropy": 0.09111528737204415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.45755767822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01737830974161625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281876266002655,
      "backward_entropy": 0.09096133708953857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.93348693847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01745072565972805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12807762622833252,
      "backward_entropy": 0.09080445766448975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.75225830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017525169998407364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1279647946357727,
      "backward_entropy": 0.08935378279004778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.30928802490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017600012943148613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1278505027294159,
      "backward_entropy": 0.09049005167824882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.13034057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017672017216682434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12773741781711578,
      "backward_entropy": 0.0903256961277553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.54380798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017739230766892433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12762698531150818,
      "backward_entropy": 0.08876747744424003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.72026824951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017804229632019997,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12751725316047668,
      "backward_entropy": 0.0899753315108163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.77629089355469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017869021743535995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12740670144557953,
      "backward_entropy": 0.09871592691966466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.333740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017931705340743065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12729676067829132,
      "backward_entropy": 0.08812753643308367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.6201934814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017995601519942284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12718461453914642,
      "backward_entropy": 0.0879040105002267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.17987060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01806044951081276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1270706057548523,
      "backward_entropy": 0.08923645530428205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.88626861572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0181299839168787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1269521862268448,
      "backward_entropy": 0.08745096411023821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.842655181884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018199071288108826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12683334946632385,
      "backward_entropy": 0.08887087447302681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.36532592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018261026591062546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12672005593776703,
      "backward_entropy": 0.08867531163351876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.56346130371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018318217247724533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12661069631576538,
      "backward_entropy": 0.0884720938546317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.2132110595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01837771013379097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12649840116500854,
      "backward_entropy": 0.08827085154397148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.46221923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018444865942001343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12637901306152344,
      "backward_entropy": 0.08628473963056292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.79408264160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01851871982216835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12625323235988617,
      "backward_entropy": 0.08606981379645211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.0426483154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018587851896882057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12613056600093842,
      "backward_entropy": 0.08770808151790074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.65943908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018661759793758392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.126003235578537,
      "backward_entropy": 0.08752753053392683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.53672790527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01873422972857952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12587366998195648,
      "backward_entropy": 0.08734297752380371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.82516479492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018807653337717056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574145197868347,
      "backward_entropy": 0.08715736014502388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.01280212402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01887854002416134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1256084144115448,
      "backward_entropy": 0.0849153995513916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.1923370361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01894519105553627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1254773736000061,
      "backward_entropy": 0.086761474609375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.37642669677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0190134234726429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1253432333469391,
      "backward_entropy": 0.08441543579101562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.1395263671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019081151112914085,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12520796060562134,
      "backward_entropy": 0.09860182659966606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.50413513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019144823774695396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12507520616054535,
      "backward_entropy": 0.08613557474953788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.8425750732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01921509951353073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12493486702442169,
      "backward_entropy": 0.08593124151229858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.49346923828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01928616873919964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1247924268245697,
      "backward_entropy": 0.09858650820595878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.9219970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019359426572918892,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12464650720357895,
      "backward_entropy": 0.08552079541342598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.22604370117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019428906962275505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12450377643108368,
      "backward_entropy": 0.08530545234680176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.46670532226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01950022764503956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12435861676931381,
      "backward_entropy": 0.08509033918380737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.60620880126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019574826583266258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12420958280563354,
      "backward_entropy": 0.0823207071849278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.27961730957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019646087661385536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1240626722574234,
      "backward_entropy": 0.08465492725372314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.09078979492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01971529982984066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12391720712184906,
      "backward_entropy": 0.08442542382649013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.63616943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019786272197961807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1237693578004837,
      "backward_entropy": 0.08149000576564244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.77099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019863350316882133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12361449748277664,
      "backward_entropy": 0.08122050762176514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.36663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019935697317123413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12346384674310684,
      "backward_entropy": 0.08093758991786412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.29278564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020012270659208298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.123307965695858,
      "backward_entropy": 0.08352792263031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5707244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02008957415819168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12315071374177933,
      "backward_entropy": 0.08037716150283813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.49869537353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020171217620372772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12298861891031265,
      "backward_entropy": 0.08010577304022652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.37287902832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02025115303695202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12282755970954895,
      "backward_entropy": 0.08286641325269427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.73194122314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02032342366874218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12267481535673141,
      "backward_entropy": 0.07953740017754692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.39021301269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020392121747136116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12252558022737503,
      "backward_entropy": 0.08237045151846749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.446044921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02045990526676178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12237726151943207,
      "backward_entropy": 0.07894558565957206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.33490753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020522432401776314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12223414331674576,
      "backward_entropy": 0.07863959244319371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.92115783691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02058718539774418,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12208768725395203,
      "backward_entropy": 0.09851800543921334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.77621459960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020653637126088142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12193835526704788,
      "backward_entropy": 0.08130690029689244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.3860092163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020724203437566757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12178419530391693,
      "backward_entropy": 0.07772564888000488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.31536102294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020792236551642418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12163353711366653,
      "backward_entropy": 0.0807811873299735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.00835418701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02086050808429718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12148253619670868,
      "backward_entropy": 0.08051214899335589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.22406005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020930331200361252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12132905423641205,
      "backward_entropy": 0.07682468209947858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.78471374511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020994603633880615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12118132412433624,
      "backward_entropy": 0.07649854251316615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.47126770019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021054044365882874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12103864550590515,
      "backward_entropy": 0.07965317794254848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.57071304321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021110495552420616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12089855223894119,
      "backward_entropy": 0.07580803973334176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.62799835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021161213517189026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12076480686664581,
      "backward_entropy": 0.07902020215988159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.12782287597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021215656772255898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12062612175941467,
      "backward_entropy": 0.07870456150599889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.4321517944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02126813493669033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12048929929733276,
      "backward_entropy": 0.07471886702946254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.63972854614258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02131819911301136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12035444378852844,
      "backward_entropy": 0.0743372014590672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.71852111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021363038569688797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022547423839569,
      "backward_entropy": 0.07394235474722725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.29653930664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0214129239320755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12009043991565704,
      "backward_entropy": 0.07738854203905378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.4229621887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021468210965394974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1199483796954155,
      "backward_entropy": 0.07707300356456212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.58734893798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02151780016720295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1198129653930664,
      "backward_entropy": 0.07674112490245275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.07795715332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021565495058894157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11967919021844864,
      "backward_entropy": 0.07640166793550764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.78135681152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021613355726003647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1195446252822876,
      "backward_entropy": 0.07201498746871948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.82653045654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021665237843990326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11940489709377289,
      "backward_entropy": 0.07572192805153984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.7308349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02171739749610424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926481127738953,
      "backward_entropy": 0.07537986551012311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.51436614990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021769331768155098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11912466585636139,
      "backward_entropy": 0.07503020763397217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.41065979003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021817851811647415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11898868530988693,
      "backward_entropy": 0.07466653415134974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.4335174560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021872403100132942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11884531378746033,
      "backward_entropy": 0.07001625640051705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.92637634277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021934358403086662,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1186932623386383,
      "backward_entropy": 0.09818729332515172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.80870056152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022002149373292923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11853399872779846,
      "backward_entropy": 0.0692763158253261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.76582717895508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022065183147788048,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11838094890117645,
      "backward_entropy": 0.07334846258163452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.7429428100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022119691595435143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11823844909667969,
      "backward_entropy": 0.06848698002951485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3164291381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022172309458255768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11809812486171722,
      "backward_entropy": 0.06807571649551392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.20034790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022223906591534615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11795935034751892,
      "backward_entropy": 0.06766926390784127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.34756469726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02227410487830639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782220005989075,
      "backward_entropy": 0.0672576470034463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.3395004272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02232135459780693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11768878251314163,
      "backward_entropy": 0.07150790521076747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.88433837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02236800640821457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11755616962909698,
      "backward_entropy": 0.06642431020736694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.15776062011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02242405153810978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11741150915622711,
      "backward_entropy": 0.07077951942171369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.34351348876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022481203079223633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11726502329111099,
      "backward_entropy": 0.07042734112058367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.52207946777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022536655887961388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11712098121643066,
      "backward_entropy": 0.07006824868065971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.40276336669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02258838713169098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11698184162378311,
      "backward_entropy": 0.06969358239855085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.20701599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022638320922851562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11684487015008926,
      "backward_entropy": 0.06435602903366089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.03817749023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022699205204844475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11669456958770752,
      "backward_entropy": 0.06394746048109871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.11654663085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022766435518860817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11653735488653183,
      "backward_entropy": 0.06860720259802681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.18497467041016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0228288434445858,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11638687551021576,
      "backward_entropy": 0.09806113583700997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.70518493652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022894810885190964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1162324771285057,
      "backward_entropy": 0.06788787245750427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.84725189208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022964155301451683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1160745769739151,
      "backward_entropy": 0.06754021985190255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.29396057128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023036379367113113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11591383814811707,
      "backward_entropy": 0.06719917910439628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.14031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023110877722501755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11575087904930115,
      "backward_entropy": 0.06161935840334211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.04853820800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02318495139479637,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11558891832828522,
      "backward_entropy": 0.06651592254638672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.15423583984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023259153589606285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11542719602584839,
      "backward_entropy": 0.06617008788245064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.93804168701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02333662658929825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11526167392730713,
      "backward_entropy": 0.060472267014639716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.15721893310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023408550769090652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11510390043258667,
      "backward_entropy": 0.06546323640005929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.26097106933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023480528965592384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11494624614715576,
      "backward_entropy": 0.0650963272367205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.92381286621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02355106733739376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11479111760854721,
      "backward_entropy": 0.06472280195781163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.52044677734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02362365834414959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11463361978530884,
      "backward_entropy": 0.05884075164794922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.21234130859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023700080811977386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11447189748287201,
      "backward_entropy": 0.06398882184709821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.20675277709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023785434663295746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11430060863494873,
      "backward_entropy": 0.06365424394607544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.7574691772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023862699046730995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11414026468992233,
      "backward_entropy": 0.05766395585877555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.20941925048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02393605001270771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11398540437221527,
      "backward_entropy": 0.06290298700332642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.04798889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024005556479096413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11383555829524994,
      "backward_entropy": 0.06250226497650146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.5472869873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02407711185514927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11368358135223389,
      "backward_entropy": 0.056367882660457065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.94557189941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024162394925951958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11351613700389862,
      "backward_entropy": 0.06174988406045096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.69535827636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024247298017144203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11335049569606781,
      "backward_entropy": 0.05556634494236538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.73067474365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024329576641321182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11318900436162949,
      "backward_entropy": 0.06102547475269863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.11519622802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024411149322986603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11302924156188965,
      "backward_entropy": 0.06064826675823757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.10244750976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024491775780916214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11287127435207367,
      "backward_entropy": 0.060260542801448276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.908687591552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02457547001540661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11271059513092041,
      "backward_entropy": 0.05388656258583069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.54385375976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024651577696204185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11256013810634613,
      "backward_entropy": 0.05947946650641305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.1699447631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02472732774913311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1124105453491211,
      "backward_entropy": 0.0590762197971344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.84305191040039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024799475446343422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11226591467857361,
      "backward_entropy": 0.05866290841783796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.54518127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024867406114935875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1121276319026947,
      "backward_entropy": 0.0520962050982884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.07892608642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024939455091953278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11198469996452332,
      "backward_entropy": 0.05783345443861825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.5396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0250114593654871,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11184238642454147,
      "backward_entropy": 0.05741985355104719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.1561279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025085901841521263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11169805377721786,
      "backward_entropy": 0.0507508601461138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.0279541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025160424411296844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11155453324317932,
      "backward_entropy": 0.0566078211580004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.25173950195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025231750681996346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11141568422317505,
      "backward_entropy": 0.04984021186828613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.27388381958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025311730802059174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1112675592303276,
      "backward_entropy": 0.04940161108970642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.65174865722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025386687368154526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11112675070762634,
      "backward_entropy": 0.05538699882371085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.31310272216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02546156756579876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11098681390285492,
      "backward_entropy": 0.054970345326832364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.42190933227539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02553492784500122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11084951460361481,
      "backward_entropy": 0.04804966705186026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.32851791381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025603648275136948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11071871966123581,
      "backward_entropy": 0.04758595568793161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.27653503417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02566753886640072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11059419065713882,
      "backward_entropy": 0.047108475651059835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.1578369140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025732072070240974,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11047010868787766,
      "backward_entropy": 0.09813720839364189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.06715393066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02579587511718273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11034747958183289,
      "backward_entropy": 0.0528114778654916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.06599426269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02586476318538189,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1102200448513031,
      "backward_entropy": 0.05239512239183698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.67305374145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025933027267456055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11009429395198822,
      "backward_entropy": 0.045232964413506646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.81033706665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02599729783833027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10997408628463745,
      "backward_entropy": 0.05155321529933384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.21750259399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026058495044708252,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10985857248306274,
      "backward_entropy": 0.05112675258091518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.53289794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0261144507676363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10974997282028198,
      "backward_entropy": 0.04380170788083758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.766136169433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02617461234331131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10963691025972366,
      "backward_entropy": 0.043329903057643344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.77691650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02622985653579235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1095304936170578,
      "backward_entropy": 0.04284663711275373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.202184677124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026282018050551414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10942824184894562,
      "backward_entropy": 0.049385986157826016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.06439971923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026325413957238197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10933692753314972,
      "backward_entropy": 0.04183677690369742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.543752670288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026367291808128357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1092478334903717,
      "backward_entropy": 0.04132049424307687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.809051513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026404673233628273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.109164759516716,
      "backward_entropy": 0.04080580813544137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.72903442382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026439867913722992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10908487439155579,
      "backward_entropy": 0.04029686110360282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.01043701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026481235399842262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10899792611598969,
      "backward_entropy": 0.04705744130270822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.35592651367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026526540517807007,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1089068353176117,
      "backward_entropy": 0.09777448858533587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.2280502319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0265724528580904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10881580412387848,
      "backward_entropy": 0.04620605707168579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.93856811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026618942618370056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10872488468885422,
      "backward_entropy": 0.03839038951056344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.04943084716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026668613776564598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10863085091114044,
      "backward_entropy": 0.04538668053490775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.3076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026722494512796402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10853317379951477,
      "backward_entropy": 0.04500382287161691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.69771575927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02677985467016697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10843267291784286,
      "backward_entropy": 0.04463575993265424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.17668914794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026836760342121124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10833383351564407,
      "backward_entropy": 0.036689898797443936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.01641845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026894761249423027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10823473334312439,
      "backward_entropy": 0.043902039527893066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.48924255371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026953773573040962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10813556611537933,
      "backward_entropy": 0.03587759392602103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.12334442138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027012081816792488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1080387607216835,
      "backward_entropy": 0.035473529781614034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.76875305175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027076786383986473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10793645679950714,
      "backward_entropy": 0.04284295013972691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.86846923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0271446593105793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10783205181360245,
      "backward_entropy": 0.04251099058559963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.630680084228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027211995795369148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10772985219955444,
      "backward_entropy": 0.0343451201915741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.82176208496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02727624960243702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10763201117515564,
      "backward_entropy": 0.04186243670327323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.84809112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027341187000274658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10753452032804489,
      "backward_entropy": 0.041540018149784634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.92024993896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0274065975099802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10743752121925354,
      "backward_entropy": 0.041220401014600484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.89096069335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02747311070561409,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10734064877033234,
      "backward_entropy": 0.040912236486162455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.392276763916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027537861838936806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10724658519029617,
      "backward_entropy": 0.040592968463897705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.77632141113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027599576860666275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10715635120868683,
      "backward_entropy": 0.04026680759021214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.86192321777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02765989489853382,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10706830024719238,
      "backward_entropy": 0.03182162770203182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.10072326660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02772224135696888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1069788858294487,
      "backward_entropy": 0.03960313967296055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.39521789550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027780061587691307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10689502954483032,
      "backward_entropy": 0.031066892402512685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.3427505493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027838585898280144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10681117326021194,
      "backward_entropy": 0.030682976756777083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.17818450927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02789858728647232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10672692209482193,
      "backward_entropy": 0.03031050307410104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.01232147216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02795994281768799,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10664241015911102,
      "backward_entropy": 0.02994696795940399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.55490493774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028022542595863342,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10655773431062698,
      "backward_entropy": 0.029594583170754567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.670076370239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02808171696960926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10647769272327423,
      "backward_entropy": 0.029250513230051314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.8047103881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028136026114225388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10640360414981842,
      "backward_entropy": 0.037333088261740546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.53606033325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028193660080432892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10632705688476562,
      "backward_entropy": 0.028567118304116384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.54331970214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028249753639101982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10625293850898743,
      "backward_entropy": 0.028233672891344343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.2227783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028307422995567322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10617814213037491,
      "backward_entropy": 0.027902798993246897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.4975471496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02836669608950615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10610262304544449,
      "backward_entropy": 0.03612173880849566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.23844909667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02842254750430584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10603143274784088,
      "backward_entropy": 0.027255249874932424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.126399993896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028476981446146965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10596267879009247,
      "backward_entropy": 0.026934372527258738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.65612030029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028530165553092957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10589590668678284,
      "backward_entropy": 0.035230242780276706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.22752380371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02858404628932476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10582919418811798,
      "backward_entropy": 0.034943584884916036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.64704895019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02863890491425991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10576240718364716,
      "backward_entropy": 0.026009255221911838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.24757385253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028692716732621193,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1056973934173584,
      "backward_entropy": 0.09793753283364433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.30086898803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02874349057674408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10563603043556213,
      "backward_entropy": 0.034115884985242574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.54207611083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028791392222046852,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10557796061038971,
      "backward_entropy": 0.03382748365402222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.70237731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028843741863965988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10551624000072479,
      "backward_entropy": 0.024812794157436917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.02054977416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02889849618077278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10545291006565094,
      "backward_entropy": 0.033290162682533264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.19843673706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028950070962309837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10539320856332779,
      "backward_entropy": 0.024225424442972456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.95975685119629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028998488560318947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1053369790315628,
      "backward_entropy": 0.023918820278985158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.156843185424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02904309518635273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10528501868247986,
      "backward_entropy": 0.032456578952925544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.70906448364258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02908397652208805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10523709654808044,
      "backward_entropy": 0.03216882901532309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.67523193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029125457629561424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1051892340183258,
      "backward_entropy": 0.02301411543573652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.88752365112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029168501496315002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10514046251773834,
      "backward_entropy": 0.031624745045389445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.44703674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029212789610028267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1050914004445076,
      "backward_entropy": 0.022448612110955373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.67971801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029260685667395592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10503974556922913,
      "backward_entropy": 0.02218612177031381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.15953063964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029313627630472183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10498440265655518,
      "backward_entropy": 0.03092807105609349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.224239349365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029369354248046875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10492773354053497,
      "backward_entropy": 0.03072188581739153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.83342742919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029424207285046577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10487299412488937,
      "backward_entropy": 0.030516075236456736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.27423858642578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029484760016202927,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10481423884630203,
      "backward_entropy": 0.09796018259865898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.57868194580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02954661101102829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10475575923919678,
      "backward_entropy": 0.020989658577101573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.83712005615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029612502083182335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10469451546669006,
      "backward_entropy": 0.020766624382564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.534942626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02968141995370388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10463199764490128,
      "backward_entropy": 0.020545550755092075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.32851028442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02974841371178627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10457213222980499,
      "backward_entropy": 0.020325028470584323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.06108856201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029811765998601913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10451605916023254,
      "backward_entropy": 0.029397279024124146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.76780700683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029870079830288887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10446476936340332,
      "backward_entropy": 0.029205679893493652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.64812660217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029928740113973618,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10441387444734573,
      "backward_entropy": 0.029014306409018382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.05951499938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029981782659888268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10436779260635376,
      "backward_entropy": 0.02879174905163901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.084014892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030030574649572372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10432562232017517,
      "backward_entropy": 0.01914393901824951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.748051643371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03007734939455986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10428552329540253,
      "backward_entropy": 0.01889571121760777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.281349182128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030118925496935844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10424987226724625,
      "backward_entropy": 0.02809331246784755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.38870239257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03015841171145439,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10421647876501083,
      "backward_entropy": 0.027870361294065202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.754032135009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030203374102711678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10417932271957397,
      "backward_entropy": 0.01817289207662855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.78086853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030246825888752937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10414378345012665,
      "backward_entropy": 0.02744910546711513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.8192138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030292341485619545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10410714149475098,
      "backward_entropy": 0.027249168072428023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.8489761352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030342960730195045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1040673702955246,
      "backward_entropy": 0.027061939239501953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.05747604370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03039613738656044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10402622818946838,
      "backward_entropy": 0.026878399508340017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.51202392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030451089143753052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10398456454277039,
      "backward_entropy": 0.02671202165739877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.52599334716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030506610870361328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10394307971000671,
      "backward_entropy": 0.026540856276239668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.74318313598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03056894987821579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10389755666255951,
      "backward_entropy": 0.01666922335113798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.68340301513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030632056295871735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1038525402545929,
      "backward_entropy": 0.09817360128675189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.79130554199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030695725232362747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10380791127681732,
      "backward_entropy": 0.026137718132564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.00411987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03075656108558178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1037660613656044,
      "backward_entropy": 0.016149472977433885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.99404907226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030823135748505592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10372143983840942,
      "backward_entropy": 0.0159832558461598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.352542877197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030893148854374886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10367517173290253,
      "backward_entropy": 0.02577931114605495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.56710815429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030961353331804276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1036309152841568,
      "backward_entropy": 0.025668312396321977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.67977142333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031031711027026176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10358618199825287,
      "backward_entropy": 0.015507436224392481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.98077392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031103435903787613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1035413146018982,
      "backward_entropy": 0.015355317720345088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.9114761352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03117855079472065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10349543392658234,
      "backward_entropy": 0.015212151621069227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.36600112915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031256429851055145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10344825685024261,
      "backward_entropy": 0.025314262935093472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.81497192382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03133351355791092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10340264439582825,
      "backward_entropy": 0.01493443442242486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.5001449584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031411610543727875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1033572256565094,
      "backward_entropy": 0.014799403292792184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.185874938964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031490907073020935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10331197082996368,
      "backward_entropy": 0.025096016270773753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.20320892333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03156498447060585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10327036678791046,
      "backward_entropy": 0.014527373015880585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.925832748413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03164054453372955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10322887450456619,
      "backward_entropy": 0.014390611222812108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.0402717590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03171084448695183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10319115966558456,
      "backward_entropy": 0.014253669551440648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.24565124511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03177931159734726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10315509140491486,
      "backward_entropy": 0.024758926459721158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.80374526977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03184814751148224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10311943292617798,
      "backward_entropy": 0.024680356894220625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.57234191894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0319153256714344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10308524966239929,
      "backward_entropy": 0.024599432945251465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.57228088378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198131173849106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10305240005254745,
      "backward_entropy": 0.013707584568432398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.127769470214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032045960426330566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10302063822746277,
      "backward_entropy": 0.024438992142677307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.66771697998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03211025521159172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10298959910869598,
      "backward_entropy": 0.02437103646142142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.31493377685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032175127416849136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1029587984085083,
      "backward_entropy": 0.09866726398468018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.54233169555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03224589675664902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10292533040046692,
      "backward_entropy": 0.013200904641832625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.08684539794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03231620416045189,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10289259254932404,
      "backward_entropy": 0.024181246757507324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.5749626159668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03238692507147789,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10286019742488861,
      "backward_entropy": 0.012958823570183345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.33748626708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03245673328638077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282894968986511,
      "backward_entropy": 0.012849145701953344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.34917449951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03253000229597092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279639810323715,
      "backward_entropy": 0.012741530580180032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.59877014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032607924193143845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10276232659816742,
      "backward_entropy": 0.023994865162031993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.490665435791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03268525376915932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10272907465696335,
      "backward_entropy": 0.02395366770880563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.185413360595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03276192396879196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10269670188426971,
      "backward_entropy": 0.012422989521707808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.01636028289795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03283264487981796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10266801714897156,
      "backward_entropy": 0.012304640242031642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.845664978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03289645165205002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10264351218938828,
      "backward_entropy": 0.012180108044828688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8000876307487488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032959822565317154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10261955857276917,
      "backward_entropy": 0.012061939707824163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.83381652832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03301573172211647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10259999334812164,
      "backward_entropy": 0.023625339780535017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.54307556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0330730564892292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10257986932992935,
      "backward_entropy": 0.011818555848939078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.51608276367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033132195472717285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10255905985832214,
      "backward_entropy": 0.01170311655317034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.21512603759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03319414332509041,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10253699123859406,
      "backward_entropy": 0.023432416575295583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.80935668945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0332646481692791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10251098871231079,
      "backward_entropy": 0.023373637880597795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.28068923950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03334192559123039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10248236358165741,
      "backward_entropy": 0.01137496211699077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.93632507324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033418022096157074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10245509445667267,
      "backward_entropy": 0.02326453583581107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.373004913330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03349369764328003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10242857038974762,
      "backward_entropy": 0.01115357130765915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.94225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03356398642063141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10240501165390015,
      "backward_entropy": 0.023135227816445485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.51895523071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03363162279129028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10238300263881683,
      "backward_entropy": 0.0230756870337895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.07556915283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033699601888656616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10236118733882904,
      "backward_entropy": 0.02301484559263502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.569610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03376338258385658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10234171897172928,
      "backward_entropy": 0.010724274175507682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.50685119628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03382612764835358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10232299566268921,
      "backward_entropy": 0.022896059921809604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.2475700378418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389281406998634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10230283439159393,
      "backward_entropy": 0.010512842663696833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.36576461791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03395857289433479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10228341072797775,
      "backward_entropy": 0.01040973620755332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.24342346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034022457897663116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10226517170667648,
      "backward_entropy": 0.010315007397106715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.628177642822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03408891335129738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10224609076976776,
      "backward_entropy": 0.010222944830145155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.79909896850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03415177762508392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10222892463207245,
      "backward_entropy": 0.010136414851461138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.65645980834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03421414643526077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10221223533153534,
      "backward_entropy": 0.02263795052255903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.10191345214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03427973762154579,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10219442844390869,
      "backward_entropy": 0.022625201514789035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.39213562011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03434610739350319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10217656195163727,
      "backward_entropy": 0.0098934748343059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.51447296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03441200777888298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10215917229652405,
      "backward_entropy": 0.009819136134215764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.693946838378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034473590552806854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10214383900165558,
      "backward_entropy": 0.02258880010672978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.395273208618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03453637659549713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212822258472443,
      "backward_entropy": 0.022570839950016568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.76083755493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034595176577568054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211449861526489,
      "backward_entropy": 0.009578800627163478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.64860534667969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034657351672649384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209959745407104,
      "backward_entropy": 0.009501158126762934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.85042572021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03472233563661575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020837351679802,
      "backward_entropy": 0.022511009659085954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8824462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0347912535071373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020665317773819,
      "backward_entropy": 0.02249492491994585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.12882995605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03486566245555878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204742848873138,
      "backward_entropy": 0.009281281914029802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.29206657409668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034941647201776505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1020279973745346,
      "backward_entropy": 0.022482454776763916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.137882232666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0350138284265995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020103245973587,
      "backward_entropy": 0.00913778373173305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.99026107788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03508292883634567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1019941195845604,
      "backward_entropy": 0.009062553090708596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.22905731201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03514959663152695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10197912156581879,
      "backward_entropy": 0.008990648601736342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.1046257019043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03521723672747612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196392238140106,
      "backward_entropy": 0.008921984050955092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.26284790039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035285644233226776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10194863379001617,
      "backward_entropy": 0.02240896224975586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.83064270019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03535732999444008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10193228721618652,
      "backward_entropy": 0.022393126572881426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.6298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03543131798505783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10191533714532852,
      "backward_entropy": 0.02239091694355011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.415082931518555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03550372272729874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10189931094646454,
      "backward_entropy": 0.0223872001682009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.43341064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03557362034916878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10188449919223785,
      "backward_entropy": 0.02239405257361276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.23970603942871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03564051538705826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10187120735645294,
      "backward_entropy": 0.022391444870403836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.17045021057129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03570546209812164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185857862234116,
      "backward_entropy": 0.008476201444864273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.90106964111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035768553614616394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10184676945209503,
      "backward_entropy": 0.008419721254280635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.04664421081543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0358332060277462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10183463990688324,
      "backward_entropy": 0.008367190403597695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.6746711730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03589572384953499,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10182352364063263,
      "backward_entropy": 0.008313332285199846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.85457992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035959552973508835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10181192308664322,
      "backward_entropy": 0.022457735879080638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.420494079589844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03602154925465584,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10180114209651947,
      "backward_entropy": 0.09893851620810372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.76573371887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03608481213450432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10179002583026886,
      "backward_entropy": 0.022492906876972744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.35206604003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03614569455385208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10177986323833466,
      "backward_entropy": 0.00810032816869872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.30556106567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03620675951242447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10176976025104523,
      "backward_entropy": 0.022506337080683027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.91374588012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036267492920160294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10175984352827072,
      "backward_entropy": 0.022513227803366526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.41256332397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03632943704724312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10174958407878876,
      "backward_entropy": 0.007938449936253684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.651611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03639446571469307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10173830389976501,
      "backward_entropy": 0.02252365861620222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.543272018432617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03645576909184456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10172855854034424,
      "backward_entropy": 0.02253047696181706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.92883586883545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03651421517133713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10171987116336823,
      "backward_entropy": 0.007784181407519749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.24772644042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036568090319633484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10171288251876831,
      "backward_entropy": 0.00773495648588453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.65274429321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036623984575271606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10170520097017288,
      "backward_entropy": 0.022582537361553738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.373329162597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0366835780441761,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10169629752635956,
      "backward_entropy": 0.022601800305502757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.85527229309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03674011677503586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10168856382369995,
      "backward_entropy": 0.02262062898703984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.25089645385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036795224994421005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10168136656284332,
      "backward_entropy": 0.007541374968630927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.666696548461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03685364872217178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10167305171489716,
      "backward_entropy": 0.007490199059247971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.169288635253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03691084682941437,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10166521370410919,
      "backward_entropy": 0.022651169981275285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.94404602050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036965157836675644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10165846347808838,
      "backward_entropy": 0.022662130849702016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.01530456542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03702007234096527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10165152698755264,
      "backward_entropy": 0.0073448169444288525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.72499084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03708028420805931,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10164280235767365,
      "backward_entropy": 0.022691960845674788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.968103408813477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03714069724082947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10163408517837524,
      "backward_entropy": 0.0072569458612373895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.85873031616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03719775378704071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10162660479545593,
      "backward_entropy": 0.007211712854249137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.018184661865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03725655376911163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016184389591217,
      "backward_entropy": 0.022745613540921892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.009721755981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037318505346775055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016092449426651,
      "backward_entropy": 0.022757617490632192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.97639274597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03737935051321983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016005352139473,
      "backward_entropy": 0.02278771996498108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.902061462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03743849694728851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10159242153167725,
      "backward_entropy": 0.0070412371839795795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.845216751098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749603033065796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10158485174179077,
      "backward_entropy": 0.006999543734959194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.064090728759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03755177557468414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10157795250415802,
      "backward_entropy": 0.022840231657028198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.20864868164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037609584629535675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10157033056020737,
      "backward_entropy": 0.02285195674215044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.2736587524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03767246752977371,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10156102478504181,
      "backward_entropy": 0.022871673107147217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.06754302978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03774242103099823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10154943913221359,
      "backward_entropy": 0.022883743047714233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.493797302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0378204770386219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10153530538082123,
      "backward_entropy": 0.006787392177752086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.3151741027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037897929549217224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10152138769626617,
      "backward_entropy": 0.022899495703833445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.15682601928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037974998354911804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10150761902332306,
      "backward_entropy": 0.02289928070136479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.02421951293945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038049113005399704,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10149488598108292,
      "backward_entropy": 0.00665963494351932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.805667877197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038121793419122696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10148264467716217,
      "backward_entropy": 0.006618928696428027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.65874099731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03819497302174568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10147026926279068,
      "backward_entropy": 0.02293614617415837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.64344787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038268279284238815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10145781934261322,
      "backward_entropy": 0.006543817796877452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.32801818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03834007307887077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10144584625959396,
      "backward_entropy": 0.022968402930668423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.376853942871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03841244429349899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10143367946147919,
      "backward_entropy": 0.006469592984233584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.72684097290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03848371282219887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10142187774181366,
      "backward_entropy": 0.023022187607628957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.936883926391602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03855074569582939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1014116108417511,
      "backward_entropy": 0.00640169158577919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.03107833862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038612183183431625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10140325129032135,
      "backward_entropy": 0.023071310349873135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.551467895507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03867330029606819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10139456391334534,
      "backward_entropy": 0.023085975221225193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.1270637512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038731206208467484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.101387158036232,
      "backward_entropy": 0.0062906571796962196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.072059631347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03879229351878166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10137858986854553,
      "backward_entropy": 0.0062542696084295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.19538116455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03885164484381676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10137058794498444,
      "backward_entropy": 0.023133371557508196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.32472038269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03891265392303467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10136200487613678,
      "backward_entropy": 0.0061834438570908135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.725054740905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03897063434123993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1013544499874115,
      "backward_entropy": 0.023182754005704607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.333251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039023980498313904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10134841501712799,
      "backward_entropy": 0.02320169976779393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666837692260742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039081182330846786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10134103894233704,
      "backward_entropy": 0.02322668901511601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.59428596496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039133988320827484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10133516043424606,
      "backward_entropy": 0.023249085460390364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.527402877807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03918634355068207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10132940113544464,
      "backward_entropy": 0.006020699228559222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.451974868774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03923778980970383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10132388025522232,
      "backward_entropy": 0.005990403571299144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.61701583862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039288848638534546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10131843388080597,
      "backward_entropy": 0.005962761385100228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.46631622314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03934384509921074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10131160169839859,
      "backward_entropy": 0.005936197936534882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.867076873779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03940264880657196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10130336880683899,
      "backward_entropy": 0.023446964366095408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.813581466674805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03945846110582352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1012960821390152,
      "backward_entropy": 0.023492627910205295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.077346801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03951185196638107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10128966718912125,
      "backward_entropy": 0.005864127938236509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.58444595336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039564382284879684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10128343105316162,
      "backward_entropy": 0.005840029567480087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.72325897216797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039618898183107376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10127638280391693,
      "backward_entropy": 0.005813610340867724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370484352111816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03967737406492233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10126791894435883,
      "backward_entropy": 0.023679000990731374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.20418167114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0397317111492157,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10126090049743652,
      "backward_entropy": 0.023736393877438138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12704722583293915,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03978843614459038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.101252980530262,
      "backward_entropy": 0.023802059037344798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.96221160888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03983954340219498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10124704986810684,
      "backward_entropy": 0.005734829498188836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.69784164428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03989315405488014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1012401357293129,
      "backward_entropy": 0.023934119514056613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.35947608947754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0399475060403347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1012328565120697,
      "backward_entropy": 0.005700243370873588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.50497817993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03999975696206093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1012263223528862,
      "backward_entropy": 0.005685434809752873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.482391357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04005306214094162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1012193113565445,
      "backward_entropy": 0.005672185548714229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.35894012451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040108807384967804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10121133923530579,
      "backward_entropy": 0.02423915479864393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.205963134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04016636684536934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10120260715484619,
      "backward_entropy": 0.024314222591263906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.100196838378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04022417962551117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10119359195232391,
      "backward_entropy": 0.024384111166000366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.992971420288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04028346389532089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10118390619754791,
      "backward_entropy": 0.024441410388265337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.830631256103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040342994034290314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011740118265152,
      "backward_entropy": 0.0055960656276771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.856237411499023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04040393605828285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10116346925497055,
      "backward_entropy": 0.02455464005470276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.775074005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040463510900735855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10115333646535873,
      "backward_entropy": 0.02461383811065129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.694902420043945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04052167385816574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10114360600709915,
      "backward_entropy": 0.005544281963791166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.777767181396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04057862237095833,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10113421827554703,
      "backward_entropy": 0.02473278982298715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.912720680236816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040632858872413635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10112573951482773,
      "backward_entropy": 0.00551133815731321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.43226623535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04068309813737869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10111866891384125,
      "backward_entropy": 0.00549383567912238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.15880584716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074019938707352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10110889375209808,
      "backward_entropy": 0.005476131503071103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.31307029724121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079771041870117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10109885036945343,
      "backward_entropy": 0.005459631660154888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.38011169433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04085410386323929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10108909010887146,
      "backward_entropy": 0.025005570479801724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.52806091308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040913477540016174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10107801854610443,
      "backward_entropy": 0.025048466665404185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.38777160644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04097438231110573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10106620192527771,
      "backward_entropy": 0.025090732744761875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.612850189208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041036657989025116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10105369985103607,
      "backward_entropy": 0.005388307784284864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.70441436767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04109863564372063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10104114562273026,
      "backward_entropy": 0.005369585539613452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.378461837768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041163381189107895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10102736949920654,
      "backward_entropy": 0.02521230067525591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.715335845947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04122762009501457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10101361572742462,
      "backward_entropy": 0.005334066493170602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.628562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04128982499241829,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10100048780441284,
      "backward_entropy": 0.02529180475643703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5683746337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04135030135512352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10098789632320404,
      "backward_entropy": 0.005298197269439697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.466018676757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04140628129243851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10097701847553253,
      "backward_entropy": 0.0052807943097182685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.95157241821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04146130383014679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10096640884876251,
      "backward_entropy": 0.025409415364265442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.314748764038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04151378571987152,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10095669329166412,
      "backward_entropy": 0.02544997419629778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.63092803955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04156544432044029,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10094716399908066,
      "backward_entropy": 0.025488372359957014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.804495811462402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041617825627326965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10093715786933899,
      "backward_entropy": 0.025524748223168508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.09674835205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041668131947517395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1009279191493988,
      "backward_entropy": 0.025567878569875444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.708003997802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04171772673726082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10091880708932877,
      "backward_entropy": 0.025605868015970503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.847679138183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04176522046327591,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10091044008731842,
      "backward_entropy": 0.0990208727972848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.24564743041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041816599667072296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10090017318725586,
      "backward_entropy": 0.0051471936915602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.05112648010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04187420755624771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10088703781366348,
      "backward_entropy": 0.025681201900754656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.938270568847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04193216934800148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10087363421916962,
      "backward_entropy": 0.02570536094052451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.01786422729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04199010506272316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10086002945899963,
      "backward_entropy": 0.025726737720625743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.552927017211914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042049359530210495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10084560513496399,
      "backward_entropy": 0.025741526058741977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.472530364990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04210705682635307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10083167999982834,
      "backward_entropy": 0.02575650598321642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.60794448852539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04216354340314865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10081814229488373,
      "backward_entropy": 0.005030774644442967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.389814376831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04222172498703003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1008036732673645,
      "backward_entropy": 0.025802740028926303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.32844543457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042280081659555435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10078896582126617,
      "backward_entropy": 0.025832480617931912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.16689682006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0423397421836853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1007734090089798,
      "backward_entropy": 0.025856394852910723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.04227828979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042399514466524124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1007576435804367,
      "backward_entropy": 0.004964192530938557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.96732521057129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04246030002832413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10074108839035034,
      "backward_entropy": 0.025909896407808577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061766836792230606,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042519547045230865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10072508454322815,
      "backward_entropy": 0.025938044701303755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.884649276733398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04257315397262573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10071170330047607,
      "backward_entropy": 0.004916778632572719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.72737693786621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042624182999134064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10069932043552399,
      "backward_entropy": 0.026007801294326782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.922166347503662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042674362659454346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10068710148334503,
      "backward_entropy": 0.026035881468227932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.59108543395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042721010744571686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10067642480134964,
      "backward_entropy": 0.004869777177061353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.879842758178711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04276742786169052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10066571831703186,
      "backward_entropy": 0.004854775965213776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.06914520263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042810868471860886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1006564199924469,
      "backward_entropy": 0.02613661757537297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.615927696228027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04285736754536629,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10064545273780823,
      "backward_entropy": 0.026181731905256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.60762405395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290230944752693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10063519328832626,
      "backward_entropy": 0.004818660872323173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.72840881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04295143112540245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10062259435653687,
      "backward_entropy": 0.026281201413699558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.607337951660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043002765625715256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10060861706733704,
      "backward_entropy": 0.026324757507869175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.790430068969727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04305616766214371,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10059335827827454,
      "backward_entropy": 0.026366659573146274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.367141723632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04310988634824753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10057762265205383,
      "backward_entropy": 0.026402843849999563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.956769943237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04316110163927078,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10056297481060028,
      "backward_entropy": 0.026437078203473772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.271921157836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04321163892745972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10054849833250046,
      "backward_entropy": 0.02647513576916286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.162357330322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043260153383016586,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10053493827581406,
      "backward_entropy": 0.09902068546840123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.85741424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043313704431056976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10051846504211426,
      "backward_entropy": 0.0047219858637877875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.26141357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04336901754140854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10050079226493835,
      "backward_entropy": 0.02658677101135254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.567893981933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04342738911509514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10048122704029083,
      "backward_entropy": 0.0266202517918178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.965438842773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043484266847372055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10046225041151047,
      "backward_entropy": 0.026654341391154697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.11545181274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04354119300842285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10044294595718384,
      "backward_entropy": 0.026688305394990102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.312345504760742,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043604929000139236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10041970759630203,
      "backward_entropy": 0.09902073655809675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.220407485961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043666742742061615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10039728879928589,
      "backward_entropy": 0.026743009686470032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.137237548828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043726738542318344,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10037560015916824,
      "backward_entropy": 0.09902073655809675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.709092140197754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043785251677036285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10035456717014313,
      "backward_entropy": 0.02681868416922433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.659210205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043840717524290085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10033491998910904,
      "backward_entropy": 0.004612810377563749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.73854446411133,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04389359802007675,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10031656920909882,
      "backward_entropy": 0.09902086428233556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.81014633178711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04394962638616562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1002960354089737,
      "backward_entropy": 0.026936952556882585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.501904487609863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044004425406455994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10027600079774857,
      "backward_entropy": 0.026979331459317888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.654308319091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04405676946043968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10025723278522491,
      "backward_entropy": 0.004573473972933633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.578519821166992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04410823807120323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10023875534534454,
      "backward_entropy": 0.02707747689315251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.503925323486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044158872216939926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10022048652172089,
      "backward_entropy": 0.004557296101536069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.302078247070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04420871287584305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10020242631435394,
      "backward_entropy": 0.004549141441072736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.253604888916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044256534427404404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10018541663885117,
      "backward_entropy": 0.02723037770816258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.213383674621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044302456080913544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1001693457365036,
      "backward_entropy": 0.027282037905284336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.227659225463867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044346850365400314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10015407204627991,
      "backward_entropy": 0.027340467487062727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.38135528564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04439093917608261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10013873875141144,
      "backward_entropy": 0.004519745707511902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.092483520507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04444160312414169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1001187190413475,
      "backward_entropy": 0.027431752000536238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.029357433319092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0444914735853672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10009900480508804,
      "backward_entropy": 0.027472485389028276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.01237678527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044537853449583054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10008136183023453,
      "backward_entropy": 0.004491611250809261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.891088485717773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0445813424885273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10006557404994965,
      "backward_entropy": 0.027568131685256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.68273162841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04462487995624542,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10004957020282745,
      "backward_entropy": 0.02762681884425027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.662933349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446709580719471,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1000315248966217,
      "backward_entropy": 0.004471937460558755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.45665168762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04471795633435249,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10001254081726074,
      "backward_entropy": 0.027726526771272932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.473711013793945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044767167419195175,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09999170154333115,
      "backward_entropy": 0.09902021714619227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.379636764526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044816937297582626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09997010976076126,
      "backward_entropy": 0.027808014835630144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.46638298034668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0448673777282238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09994781017303467,
      "backward_entropy": 0.0278484331709998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.822976112365723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04491696134209633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09992578625679016,
      "backward_entropy": 0.0044298845210245675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.854326248168945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04496327415108681,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09990595281124115,
      "backward_entropy": 0.09902010645185198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.25240707397461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04501182213425636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09988419711589813,
      "backward_entropy": 0.004415351897478104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.900558471679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505964741110802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09986259043216705,
      "backward_entropy": 0.00440722331404686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.88386535644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04510823264718056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09984011948108673,
      "backward_entropy": 0.028063920991761342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.03125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04516143724322319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09981394559144974,
      "backward_entropy": 0.004389724028961999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.878536224365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045213472098112106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09978827089071274,
      "backward_entropy": 0.028129405208996365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.258346557617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045268453657627106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.099760040640831,
      "backward_entropy": 0.028157838753291538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.208553314208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0453207790851593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09973348677158356,
      "backward_entropy": 0.004360981551664216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.7204647064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04537080600857735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0997084230184555,
      "backward_entropy": 0.028225694383893694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.187599182128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04541999101638794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0996837168931961,
      "backward_entropy": 0.004344422370195389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.545732498168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045469775795936584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09965816140174866,
      "backward_entropy": 0.02830114109175546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.997398376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04551617056131363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09963510930538177,
      "backward_entropy": 0.02834581903048924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.965660095214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556342959403992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09961102902889252,
      "backward_entropy": 0.028390386274882724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.36858558654785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045608773827552795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09958815574645996,
      "backward_entropy": 0.004315805754491261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.874034881591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045653775334358215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995652973651886,
      "backward_entropy": 0.028482988476753235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.835139274597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04569698125123978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09954352676868439,
      "backward_entropy": 0.02852645516395569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.791004180908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04573876038193703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09952272474765778,
      "backward_entropy": 0.028574611459459578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.47673225402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045779116451740265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0995028167963028,
      "backward_entropy": 0.028621418135506765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.735198974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04582086205482483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09948135912418365,
      "backward_entropy": 0.028665936418942044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.303144454956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04586512967944145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09945742785930634,
      "backward_entropy": 0.004275766068271228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.81025505065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04591025412082672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0994323119521141,
      "backward_entropy": 0.004267217591404915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.390321731567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04595888406038284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09940383583307266,
      "backward_entropy": 0.028768283980233327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2749409675598145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04600932449102402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09937338531017303,
      "backward_entropy": 0.004249056535107749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.474411964416504,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04605627804994583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09934580326080322,
      "backward_entropy": 0.09902030229568481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.234453201293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04610133543610573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09931957721710205,
      "backward_entropy": 0.028866412384169444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.08997917175293,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04614976420998573,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0992898941040039,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.631074905395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04620128124952316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09925706684589386,
      "backward_entropy": 0.004215603428227561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.527061462402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04625296965241432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09922362864017487,
      "backward_entropy": 0.028944138969693865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.62347412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04630480706691742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09918959438800812,
      "backward_entropy": 0.028966731258801053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02427135966718197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046359408646821976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09915263950824738,
      "backward_entropy": 0.004186999052762985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.16486644744873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04640871286392212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0991203635931015,
      "backward_entropy": 0.004178285598754883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.118785858154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04645702987909317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09908853471279144,
      "backward_entropy": 0.02904094542775835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.021615028381348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046505920588970184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09905582666397095,
      "backward_entropy": 0.02906974298613412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.894502639770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046552687883377075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09902482479810715,
      "backward_entropy": 0.0291022104876382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.774072647094727,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046601176261901855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09899158030748367,
      "backward_entropy": 0.0990209664617266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.647850036621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04665132239460945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09895618259906769,
      "backward_entropy": 0.029144333941595896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.718490600585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04670301079750061,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0989188402891159,
      "backward_entropy": 0.029163765055792674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.64134407043457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046753499656915665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09888218343257904,
      "backward_entropy": 0.004113881715706417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.565837860107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04680290445685387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09884624183177948,
      "backward_entropy": 0.029204794338771274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.13934326171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04685132950544357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0988108292222023,
      "backward_entropy": 0.02922712905066354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.415898323059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046901457011699677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09877324104309082,
      "backward_entropy": 0.004086047144872802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.568318367004395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04695054888725281,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09873625636100769,
      "backward_entropy": 0.0040774185742650714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.27077865600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04699743911623955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09870122373104095,
      "backward_entropy": 0.029306667191641673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.648101806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04704366251826286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09866654872894287,
      "backward_entropy": 0.004061938662614141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.226844787597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04709167778491974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09862940013408661,
      "backward_entropy": 0.029370984860828946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37419605255127,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047142546623945236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09858860075473785,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.32551383972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471910759806633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09855002909898758,
      "backward_entropy": 0.004037562757730484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.78271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04723752662539482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09851342439651489,
      "backward_entropy": 0.02946617773600987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.225199699401855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047286972403526306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0984729528427124,
      "backward_entropy": 0.029500620705740794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04733411967754364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09843464195728302,
      "backward_entropy": 0.004016747166003499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.903446197509766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04737921804189682,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09839825332164764,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.19916534423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04742852598428726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09835629165172577,
      "backward_entropy": 0.02960103750228882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.536832809448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04748042672872543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09831078350543976,
      "backward_entropy": 0.02962304651737213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.87838363647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04753341153264046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09826330840587616,
      "backward_entropy": 0.003982919135263988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.25951385498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04758862033486366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0982125848531723,
      "backward_entropy": 0.02965648259435381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020920319482684135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04764452576637268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09816031157970428,
      "backward_entropy": 0.029667445591517856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808950424194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04769496992230415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09811428189277649,
      "backward_entropy": 0.00395206016089235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02240452915430069,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04774297773838043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09807072579860687,
      "backward_entropy": 0.029702080147606984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.41171646118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047786369919776917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09803271293640137,
      "backward_entropy": 0.003934157213994435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.99807357788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04783052206039429,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09799332916736603,
      "backward_entropy": 0.029757540140833174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.628266334533691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04787416011095047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09795418381690979,
      "backward_entropy": 0.00391924727175917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.301996231079102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04791608452796936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0979168638586998,
      "backward_entropy": 0.02983133281980242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.810379028320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795515164732933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09788291156291962,
      "backward_entropy": 0.0039067342877388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.748310089111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04799424856901169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09784860908985138,
      "backward_entropy": 0.029918596148490906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.689326286315918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048033252358436584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09781396389007568,
      "backward_entropy": 0.003896639815398625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.627645492553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04807216301560402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09777901321649551,
      "backward_entropy": 0.0300138635294778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.568924903869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04811086505651474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09774378687143326,
      "backward_entropy": 0.0038858351430722643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.51165771484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04814937338232994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09770818054676056,
      "backward_entropy": 0.03009351875100817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.455148696899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04818775877356529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09767226129770279,
      "backward_entropy": 0.03012905376298087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.272189140319824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048226114362478256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09763601422309875,
      "backward_entropy": 0.003865855612925121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.552358627319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04826326668262482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09760116040706635,
      "backward_entropy": 0.03020979038306645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.449949264526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04830286651849747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09756236523389816,
      "backward_entropy": 0.030250408819743564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.218063354492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04834457486867905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09751999378204346,
      "backward_entropy": 0.030284811343465532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.150437355041504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04838598147034645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09747771918773651,
      "backward_entropy": 0.0038412317101444516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.136600494384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04842691123485565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09743554890155792,
      "backward_entropy": 0.030362499611718313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.026390075683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048469867557287216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09738992154598236,
      "backward_entropy": 0.03039727679320744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.960186004638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04851347953081131,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.097342848777771,
      "backward_entropy": 0.030432920370783125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.850825309753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04855656996369362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09729619324207306,
      "backward_entropy": 0.003815766157848494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.891444683074951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04860030859708786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09724802523851395,
      "backward_entropy": 0.0038103575685194562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.67665958404541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04864225536584854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09720219671726227,
      "backward_entropy": 0.030564448663166592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.484100341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04868491366505623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09715479612350464,
      "backward_entropy": 0.003800537171108382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759519100189209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872943460941315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09710399806499481,
      "backward_entropy": 0.0037957637437752317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71425724029541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04877201095223427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09705569595098495,
      "backward_entropy": 0.003790984196322305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.330219268798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04881271347403526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09700976312160492,
      "backward_entropy": 0.03074585965701512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.053783416748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048854123800992966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09696201980113983,
      "backward_entropy": 0.0037789525730269296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.159366607666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889735206961632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09691073000431061,
      "backward_entropy": 0.0037719346582889557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.83487319946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04894107207655907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09685803949832916,
      "backward_entropy": 0.03084655318941389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.97712516784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048986468464136124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09680207818746567,
      "backward_entropy": 0.003757916124803679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.167773246765137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049032062292099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09674510359764099,
      "backward_entropy": 0.030909197671072825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019084982573986053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049076665192842484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09668909013271332,
      "backward_entropy": 0.03093615174293518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.03840446472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04911695420742035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09664000570774078,
      "backward_entropy": 0.03096771240234375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.633170127868652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04915676265954971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09659122675657272,
      "backward_entropy": 0.030996888875961304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6516146659851074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049197398126125336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0965404361486435,
      "backward_entropy": 0.031028253691537038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.310047149658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0492352657020092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09649406373500824,
      "backward_entropy": 0.0037137557353292194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.97735023498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04927731305360794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09643954783678055,
      "backward_entropy": 0.031082374708993093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.161805152893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932091012597084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09638147056102753,
      "backward_entropy": 0.0036948991141148974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.568552255630493,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049362752586603165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0963263213634491,
      "backward_entropy": 0.031121490257126943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.134947776794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04940175265073776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0962759405374527,
      "backward_entropy": 0.03115373636995043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.5451021194458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04944157600402832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09622348845005035,
      "backward_entropy": 0.03118663387639182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.99755334854126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049480970948934555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09617127478122711,
      "backward_entropy": 0.003665795549750328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.774444580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0495188944041729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0961214005947113,
      "backward_entropy": 0.031257999794823785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.362415313720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049562059342861176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09606099128723145,
      "backward_entropy": 0.003651384264230728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8710527420043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04960443824529648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09600142389535904,
      "backward_entropy": 0.03130921508584704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234996795654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04964495077729225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09594480693340302,
      "backward_entropy": 0.03133616277149746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.174930572509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968484118580818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09588871896266937,
      "backward_entropy": 0.003627475883279528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.75087833404541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04972419515252113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09583304822444916,
      "backward_entropy": 0.0036191464002643314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.711019515991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049762025475502014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0957799106836319,
      "backward_entropy": 0.003611448620046888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.64314079284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0497983954846859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09572906792163849,
      "backward_entropy": 0.0036036651581525803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.86112403869629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04984002560377121,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09566706418991089,
      "backward_entropy": 0.03145555938993182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.442087173461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988424479961395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09559918940067291,
      "backward_entropy": 0.0035843700170516968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.542175769805908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049929700791835785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09552808851003647,
      "backward_entropy": 0.0035743817154850277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.980350494384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04997297748923302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09546088427305222,
      "backward_entropy": 0.03149515816143581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.670546531677246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050016604363918304,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09539248049259186,
      "backward_entropy": 0.0315194981438773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413876056671143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0500592403113842,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09532530605792999,
      "backward_entropy": 0.03154196058000837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.545845031738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05010007694363594,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09526163339614868,
      "backward_entropy": 0.03157406832490649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.330336570739746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05014023929834366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09519865363836288,
      "backward_entropy": 0.031606278249195645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.426607131958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05017872527241707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09513872116804123,
      "backward_entropy": 0.0316413300377982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.369586944580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05021669715642929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09507916867733002,
      "backward_entropy": 0.0035185936306204113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.313785552978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025419965386391,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09501984715461731,
      "backward_entropy": 0.0035106856375932693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.33985710144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05029129981994629,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09496082365512848,
      "backward_entropy": 0.03173037937709263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.323420524597168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05032919719815254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09489943087100983,
      "backward_entropy": 0.0034949715648378643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.222990036010742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05036879703402519,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09483340382575989,
      "backward_entropy": 0.031788455588476996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.123302459716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05040985718369484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09476321935653687,
      "backward_entropy": 0.03180978127888271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.016189575195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05045238882303238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09468915313482285,
      "backward_entropy": 0.031835002558571954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.909212112426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05049510672688484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0946139246225357,
      "backward_entropy": 0.031861848064831326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.930860996246338,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05053907632827759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09453512728214264,
      "backward_entropy": 0.0034535513924700873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823701858520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050580937415361404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09446059167385101,
      "backward_entropy": 0.0034460784601313727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.675487518310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05062192678451538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09438742697238922,
      "backward_entropy": 0.03195562745843615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.917847156524658,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050663094967603683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09431293606758118,
      "backward_entropy": 0.031982836978776116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.518036842346191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05070159211754799,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09424474835395813,
      "backward_entropy": 0.003424620521920068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.441600799560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074051767587662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09417464584112167,
      "backward_entropy": 0.0034180733242205213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.528925895690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077984556555748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09410268068313599,
      "backward_entropy": 0.0034111086279153824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.104023933410645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05081856623291969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0940316915512085,
      "backward_entropy": 0.03214193880558014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41246223449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05085870251059532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09395614266395569,
      "backward_entropy": 0.03217500448226929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.574935436248779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05089816078543663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0938817709684372,
      "backward_entropy": 0.03221262352807181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.055033683776855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05093590170145035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09381154924631119,
      "backward_entropy": 0.0033836308866739273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.976971626281738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050974104553461075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09373937547206879,
      "backward_entropy": 0.0033764589045728955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.902660369873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05101259425282478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09366557002067566,
      "backward_entropy": 0.03231475608689444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7200307846069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05105147883296013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09358996152877808,
      "backward_entropy": 0.032340794801712036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.385035991668701,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05108761787414551,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0935211181640625,
      "backward_entropy": 0.09902082170758929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.016218185424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051122285425662994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09345553815364838,
      "backward_entropy": 0.0033423778201852527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.665919303894043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05115973949432373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09338188171386719,
      "backward_entropy": 0.0033334195613861084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9106926918029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05119458585977554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09331461787223816,
      "backward_entropy": 0.032451203891209195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.472715377807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05122920870780945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09324757754802704,
      "backward_entropy": 0.0033168611781937735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.400850296020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05126466602087021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0931776762008667,
      "backward_entropy": 0.0033096367759363992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.330902099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0513007789850235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09310531616210938,
      "backward_entropy": 0.03256122555051531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.935741424560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051337555050849915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09303051233291626,
      "backward_entropy": 0.003295786146606718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.09627103805542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051377877593040466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09294502437114716,
      "backward_entropy": 0.032645774739129205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.6234712600708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05141623318195343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09286431968212128,
      "backward_entropy": 0.03268419419016157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.519709348678589,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051455989480018616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09277902543544769,
      "backward_entropy": 0.00327493463243757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022002028301358223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05149291083216667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.092701256275177,
      "backward_entropy": 0.003268458481345858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.885427474975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05152647942304611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09263311326503754,
      "backward_entropy": 0.032829995666231425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.818305969238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05156079679727554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09256201982498169,
      "backward_entropy": 0.03288639443261283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.31718111038208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159574747085571,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09248821437358856,
      "backward_entropy": 0.03293837606906891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684362411499023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05163026601076126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09241491556167603,
      "backward_entropy": 0.0032472373651606695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.81496524810791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05166545882821083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09233894944190979,
      "backward_entropy": 0.003241309630019324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.93194580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05169910192489624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09226681292057037,
      "backward_entropy": 0.033079570957592556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.847050666809082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051734376698732376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09218884259462357,
      "backward_entropy": 0.0032267929720027106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.05994987487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051771193742752075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09210541844367981,
      "backward_entropy": 0.0032193075333322796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338377952575684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051807284355163574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09202335774898529,
      "backward_entropy": 0.0032111251992838724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.643421649932861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05184377357363701,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09193996340036392,
      "backward_entropy": 0.03321919909545353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.607517242431641,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051878731697797775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0918605849146843,
      "backward_entropy": 0.03325614546026502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01874309591948986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051912155002355576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09178478270769119,
      "backward_entropy": 0.0332891366311482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.810325622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051942404359579086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09171903133392334,
      "backward_entropy": 0.003179925893034254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.767300605773926,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05197254195809364,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09165208041667938,
      "backward_entropy": 0.09901989357812065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95938491821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05200262740254402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09158442914485931,
      "backward_entropy": 0.03339723178318569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.456899642944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052033647894859314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09151384234428406,
      "backward_entropy": 0.03343003562518528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.635457992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0520634725689888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09144638478755951,
      "backward_entropy": 0.033457521881376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.784088134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05209328606724739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09137830138206482,
      "backward_entropy": 0.033485740423202515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1939656734466553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05212406441569328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09130636602640152,
      "backward_entropy": 0.0031295628952128546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.668704986572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05215282738208771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0912407860159874,
      "backward_entropy": 0.03354669042995998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.463112831115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05218261107802391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0911710113286972,
      "backward_entropy": 0.03357835539749691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28428840637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052212391048669815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09110068529844284,
      "backward_entropy": 0.033612459897994995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.616472244262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05224110558629036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09103332459926605,
      "backward_entropy": 0.033642445291791646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.230260372161865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05227155610918999,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09095893800258636,
      "backward_entropy": 0.0030868944845029284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1082327365875244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05230109766125679,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0908874124288559,
      "backward_entropy": 0.03368825571877616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33041763305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05232873558998108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09082214534282684,
      "backward_entropy": 0.03372025489807129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.340078353881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05235748738050461,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09075231850147247,
      "backward_entropy": 0.03375369310379028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.118826389312744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052388157695531845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09067502617835999,
      "backward_entropy": 0.03378682477133615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.127264022827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052417904138565063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09060083329677582,
      "backward_entropy": 0.03383234569004604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.126138687133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05244779586791992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09052585065364838,
      "backward_entropy": 0.0030434190162590574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.030567646026611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05247944965958595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09044372290372849,
      "backward_entropy": 0.03394611392702375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.001582145690918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05250991880893707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09036539494991302,
      "backward_entropy": 0.034002559525626044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.88979721069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05253928154706955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09029035270214081,
      "backward_entropy": 0.034057834318705967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9435975551605225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05257127061486244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09020492434501648,
      "backward_entropy": 0.034105926752090454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.865248680114746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05260195955634117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09012353420257568,
      "backward_entropy": 0.0030159513865198407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.886730194091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052632465958595276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09004217386245728,
      "backward_entropy": 0.09901966367449079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.937348484992981,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05266186222434044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08996447920799255,
      "backward_entropy": 0.034245850784437995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.651731491088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0526893176138401,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08989359438419342,
      "backward_entropy": 0.03429340038980756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.702286243438721,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05271781235933304,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0898185670375824,
      "backward_entropy": 0.03434295952320099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.66229248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0527462475001812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08974223583936691,
      "backward_entropy": 0.03438978961535862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8860958814620972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052774593234062195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08966581523418427,
      "backward_entropy": 0.034432747534343174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.586902618408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05280125141143799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08959580212831497,
      "backward_entropy": 0.03448562962668283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8601983785629272,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052828118205070496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08952446281909943,
      "backward_entropy": 0.034541577100753784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.846026420593262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05285332351922989,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08945910632610321,
      "backward_entropy": 0.03459885077817099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.751402854919434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05288228020071983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0893782526254654,
      "backward_entropy": 0.03464598102228982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.428790092468262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05291445180773735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08928361535072327,
      "backward_entropy": 0.002949985276375498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.174607276916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05294610559940338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08919030427932739,
      "backward_entropy": 0.034701262201581685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.790030837059021,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05297819525003433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08909448981285095,
      "backward_entropy": 0.03472513386181423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5362305641174316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053008027374744415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08900725096464157,
      "backward_entropy": 0.0347502806356975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.259339332580566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053036563098430634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08892449736595154,
      "backward_entropy": 0.03476735098021371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218685626983643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05306505411863327,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08884145319461823,
      "backward_entropy": 0.034790792635508945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.179597854614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053093355149030685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08875849097967148,
      "backward_entropy": 0.0348126973424639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.140317440032959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05312151089310646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08867540210485458,
      "backward_entropy": 0.0028884190001658033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1022114753723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053149498999118805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08859240263700485,
      "backward_entropy": 0.034857132605143955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745986461639404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05317741259932518,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08850916475057602,
      "backward_entropy": 0.034882200615746636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36291217803955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053206056356430054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08842208236455917,
      "backward_entropy": 0.0028624763446194784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.982809066772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053236205130815506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08832799643278122,
      "backward_entropy": 0.034927702375820706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941582679748535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053266070783138275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08823446929454803,
      "backward_entropy": 0.0349553291286741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2715559005737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05329564958810806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08814159035682678,
      "backward_entropy": 0.03498644062450954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6302542686462402,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05332399532198906,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08805340528488159,
      "backward_entropy": 0.09902058328901019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6186988353729248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053350407630205154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08797318488359451,
      "backward_entropy": 0.03504302033356258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.161959648132324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053375132381916046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08789987117052078,
      "backward_entropy": 0.002814518553870065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1744422912597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05340327322483063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08781047910451889,
      "backward_entropy": 0.035097948142460415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41976547241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05343039333820343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0877252072095871,
      "backward_entropy": 0.03512465528079441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.569756269454956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05345990136265755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08762870728969574,
      "backward_entropy": 0.035149259226662774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5553345680236816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053487490862607956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08754034340381622,
      "backward_entropy": 0.03518265060016087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666233539581299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05351312458515167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08746018260717392,
      "backward_entropy": 0.0027743224054574966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.532994031906128,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05354044958949089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08737168461084366,
      "backward_entropy": 0.03523850440979004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5215333700180054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05356600880622864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.087290920317173,
      "backward_entropy": 0.03527235984802246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.998063564300537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05358997732400894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08721717447042465,
      "backward_entropy": 0.03531106880732945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4996968507766724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05361486226320267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08713828027248383,
      "backward_entropy": 0.03534488592829023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4902650117874146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053638212382793427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08706621080636978,
      "backward_entropy": 0.035382862601961405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.875207901000977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05366029217839241,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08699985593557358,
      "backward_entropy": 0.035432549459593635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9238104820251465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053683582693338394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08692736178636551,
      "backward_entropy": 0.0027274220649685177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9044156074523926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053706247359514236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08685719221830368,
      "backward_entropy": 0.03553469266210284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013517897576093674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05372839421033859,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08678900450468063,
      "backward_entropy": 0.03558609315327236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.294085502624512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05374839901924133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08673061430454254,
      "backward_entropy": 0.035636884825570245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.357608795166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05376886576414108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0866694301366806,
      "backward_entropy": 0.03568277188709804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.235080242156982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053793683648109436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0865866094827652,
      "backward_entropy": 0.03571552889687674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.599552154541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05381852388381958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08650316298007965,
      "backward_entropy": 0.0026909392327070236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.093677520751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053844284266233444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08641476929187775,
      "backward_entropy": 0.035787386553628106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.502992630004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053873803466558456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08630751073360443,
      "backward_entropy": 0.035813476358141215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.808691024780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05390378087759018,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0861976146697998,
      "backward_entropy": 0.035848404679979594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.741596221923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05393476039171219,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08608201891183853,
      "backward_entropy": 0.03587833046913147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6763670444488525,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05396667495369911,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08596116304397583,
      "backward_entropy": 0.09902036190032959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9690470695495605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05399695411324501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08584759384393692,
      "backward_entropy": 0.03593093156814575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.236448764801025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05402659252285957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08573649823665619,
      "backward_entropy": 0.03595343657902309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.89105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05405644699931145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08562375605106354,
      "backward_entropy": 0.03597506880760193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8547353744506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054085541516542435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08551372587680817,
      "backward_entropy": 0.035986202103751044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5497310161590576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054114196449518204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08540556579828262,
      "backward_entropy": 0.03600408349718366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.037841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414164811372757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08530295640230179,
      "backward_entropy": 0.002604652728353228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5026397705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054169461131095886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08519774675369263,
      "backward_entropy": 0.03604711379323687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7129275798797607,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05419617146253586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08509787917137146,
      "backward_entropy": 0.0025885733110564096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6793429851531982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05422266945242882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08499856293201447,
      "backward_entropy": 0.036107152700424194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48786735534668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05424897000193596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0848998874425888,
      "backward_entropy": 0.03614655562809536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.005231857299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05427799001336098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08478622138500214,
      "backward_entropy": 0.036181773458208354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756933212280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05430784448981285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0846673995256424,
      "backward_entropy": 0.03620885099683489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3602890968322754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054337743669748306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0845475047826767,
      "backward_entropy": 0.03623300790786743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4979028701782227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054366182535886765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08443519473075867,
      "backward_entropy": 0.002544511907867023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.761542797088623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439406633377075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08432459086179733,
      "backward_entropy": 0.002536425633089883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.151627779006958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054422806948423386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08420851826667786,
      "backward_entropy": 0.036295188324792046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.520491600036621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05444944277405739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08410357683897018,
      "backward_entropy": 0.0363119329724993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3597490787506104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05447649583220482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08399578928947449,
      "backward_entropy": 0.0363342889717647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.223221778869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054503072053194046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08388995379209518,
      "backward_entropy": 0.0025022484894309726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2964837551116943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05452859401702881,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08378952741622925,
      "backward_entropy": 0.036384829453059604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.097668170928955,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05455397069454193,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0836896300315857,
      "backward_entropy": 0.09902094091687884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2365224361419678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05457759276032448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08359900861978531,
      "backward_entropy": 0.036464307989392965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.272024154663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054601214826107025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08350799977779388,
      "backward_entropy": 0.002475776842662266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.069277048110962,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054625481367111206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08341269195079803,
      "backward_entropy": 0.036561548709869385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.105994939804077,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054648201912641525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0833258330821991,
      "backward_entropy": 0.036617049149104526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1613240242004395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0546702966094017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0832422524690628,
      "backward_entropy": 0.03668045997619629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125572681427002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05469295009970665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08315459638834,
      "backward_entropy": 0.002455521108848708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0512053966522217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05471615120768547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08306313306093216,
      "backward_entropy": 0.036773468766893656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.03363037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054738450795412064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08297623693943024,
      "backward_entropy": 0.03681085365159171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0151169300079346,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476002022624016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08289308845996857,
      "backward_entropy": 0.036850426878247945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.973767280578613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054780226200819016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0828174501657486,
      "backward_entropy": 0.03689265251159668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.967205047607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05480257794260979,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08272863179445267,
      "backward_entropy": 0.03692689112254551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9890038371086121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05482487007975578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08263957500457764,
      "backward_entropy": 0.036962232419422696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9160287380218506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05484563484787941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0825590118765831,
      "backward_entropy": 0.03699480635779245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.891240119934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05486645549535751,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08247759193181992,
      "backward_entropy": 0.03702756336757115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.719931602478027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488726496696472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08239556849002838,
      "backward_entropy": 0.0023929279829774585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8395586013793945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054909978061914444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08230152726173401,
      "backward_entropy": 0.03707195179803031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7460620403289795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05493250861763954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0822080448269844,
      "backward_entropy": 0.0023753206644739422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.861694574356079,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05495554581284523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08211088180541992,
      "backward_entropy": 0.03710222244262695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.674855947494507,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054977815598249435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08201806247234344,
      "backward_entropy": 0.0023589498762573513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01285521313548088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055000629276037216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08192138373851776,
      "backward_entropy": 0.0371553897857666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9116251468658447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0550212636590004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08183765411376953,
      "backward_entropy": 0.037186545985085626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.686396598815918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05504065752029419,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08176113665103912,
      "backward_entropy": 0.037224841969353814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.663841724395752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055060211569070816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08168315142393112,
      "backward_entropy": 0.03726463658469064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8890014290809631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0550798736512661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08160395920276642,
      "backward_entropy": 0.037303732974188666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.228626251220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055098410695791245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08153149485588074,
      "backward_entropy": 0.037350599254880636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.596412420272827,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05511917546391487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08144476264715195,
      "backward_entropy": 0.03739781039101737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.719657301902771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055139798671007156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08135823905467987,
      "backward_entropy": 0.037436600242342265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.550804615020752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0551597885787487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08127517998218536,
      "backward_entropy": 0.037479243108204434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5281968116760254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517985671758652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08119119703769684,
      "backward_entropy": 0.00229632348886558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.505551338195801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05519998446106911,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08110630512237549,
      "backward_entropy": 0.03757062554359436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.306612491607666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05522013083100319,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08102085441350937,
      "backward_entropy": 0.037617078849247525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2755956649780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055240824818611145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0809313952922821,
      "backward_entropy": 0.03765613266399929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2439823150634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055261947214603424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08083844929933548,
      "backward_entropy": 0.03768446615764073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6116007566452026,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055283524096012115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0807422548532486,
      "backward_entropy": 0.002264966389962605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8037495613098145,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055304303765296936,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08065054565668106,
      "backward_entropy": 0.09902083022253853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1519036293029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05532372370362282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08056709170341492,
      "backward_entropy": 0.037765519959586005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7889832854270935,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0553438700735569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08047834038734436,
      "backward_entropy": 0.002244774518268449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7820371389389038,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05536271631717682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08039780706167221,
      "backward_entropy": 0.03783656869615827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.775449275970459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05538041144609451,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08032427728176117,
      "backward_entropy": 0.037876865693501065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.286078453063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05539704114198685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0802573561668396,
      "backward_entropy": 0.037917758737291606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7633077502250671,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05541393160820007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08018825948238373,
      "backward_entropy": 0.0022211125386612757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.997037410736084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055429987609386444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08012434840202332,
      "backward_entropy": 0.03800767234393528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.97280216217041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055446892976760864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08005427569150925,
      "backward_entropy": 0.038049893719809394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.947281837463379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05546460300683975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07997840642929077,
      "backward_entropy": 0.03808718068259103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4655145406723022,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05548303201794624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07989721745252609,
      "backward_entropy": 0.03812095097133091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.616210460662842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05550094321370125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07981909066438675,
      "backward_entropy": 0.03815772703715733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010098293423652649,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05552016943693161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07973174750804901,
      "backward_entropy": 0.0021868139239294188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7180873155593872,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055537544190883636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07965630292892456,
      "backward_entropy": 0.09902056625911168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.117142915725708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05555378273129463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07958806306123734,
      "backward_entropy": 0.038259378501347134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0994014739990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05557038262486458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0795169547200203,
      "backward_entropy": 0.03829847489084516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7002465724945068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055587150156497955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07944419980049133,
      "backward_entropy": 0.03833333935056414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120489120483398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05560288578271866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07937795668840408,
      "backward_entropy": 0.03836791004453387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7248966693878174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05562073737382889,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07929724454879761,
      "backward_entropy": 0.00215049646794796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0436296463012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05563918501138687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07921179383993149,
      "backward_entropy": 0.03844256911958967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3396810293197632,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055659353733062744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07911433279514313,
      "backward_entropy": 0.0021372163402182715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3260304927825928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05567866191267967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07902199774980545,
      "backward_entropy": 0.038499798093523295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.616666078567505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05569728463888168,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07893387973308563,
      "backward_entropy": 0.03852925981794085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009009449742734432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055716414004564285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07884189486503601,
      "backward_entropy": 0.03855695043291364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5656473636627197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05573374778032303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07876189053058624,
      "backward_entropy": 0.03859192558697292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9077205657958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0557517446577549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07867689430713654,
      "backward_entropy": 0.03862813966614859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7692692279815674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055769797414541245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07859106361865997,
      "backward_entropy": 0.03866914340427944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6285089254379272,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0557895302772522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07849320769309998,
      "backward_entropy": 0.03870550223759243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.076897621154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05580783635377884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0784047320485115,
      "backward_entropy": 0.03873705438205174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2225444316864014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055827170610427856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0783085897564888,
      "backward_entropy": 0.0020762389259678976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6090971827507019,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055845800787210464,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07821697741746902,
      "backward_entropy": 0.038794943264552524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.982109785079956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05586324632167816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07813318818807602,
      "backward_entropy": 0.03883242607116699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.773689866065979,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055881746113300323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0780416876077652,
      "backward_entropy": 0.03886310117585318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.172731637954712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055900100618600845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07795048505067825,
      "backward_entropy": 0.038892158440181186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.466061592102051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055917806923389435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07786352932453156,
      "backward_entropy": 0.038923804249082296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8571724891662598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05593710392713547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0777648538351059,
      "backward_entropy": 0.03895249537059239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1341147422790527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05595724284648895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0776597410440445,
      "backward_entropy": 0.03897715466363089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3475522994995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055976517498493195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07756039500236511,
      "backward_entropy": 0.0020228555159909384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5576010942459106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05599711090326309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07745108008384705,
      "backward_entropy": 0.03902138131005423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0945574045181274,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056016165763139725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07735240459442139,
      "backward_entropy": 0.0020079846893038067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007831559516489506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056034404784440994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07725882530212402,
      "backward_entropy": 0.03905239275523594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6034172773361206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05605084449052811,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07717806845903397,
      "backward_entropy": 0.039069409881319316,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.695124657265842,
    "avg_log_Z": -0.05507894318550825,
    "success_rate": 1.0,
    "avg_reward": 25.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.76,
      "2": 0.2
    },
    "avg_forward_entropy": 0.08150122478604317,
    "avg_backward_entropy": 0.03290236531756818,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}