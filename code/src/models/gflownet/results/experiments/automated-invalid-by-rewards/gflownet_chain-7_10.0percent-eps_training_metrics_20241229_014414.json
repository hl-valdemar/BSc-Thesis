{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09899359089987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09900362151009696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.64381408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724590837955475,
      "backward_entropy": 0.09897900479180473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.6085205078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372479945421219,
      "backward_entropy": 0.09900527341025216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.46739196777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0001999999221879989,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372499167919159,
      "backward_entropy": 0.09900684016091484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.98301696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003002571174874902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725166022777557,
      "backward_entropy": 0.09899614538465228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.05914306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004007044481113553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725320994853973,
      "backward_entropy": 0.09899699687957764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.91275024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0004999589291401207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725462555885315,
      "backward_entropy": 0.09899774619511195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.31643676757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005991843063384295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725578784942627,
      "backward_entropy": 0.0989984359060015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 229.617919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006989625981077552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725674152374268,
      "backward_entropy": 0.09899910858699254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.5110626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007990080048330128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725757598876953,
      "backward_entropy": 0.0989997216633388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.36123657226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008958450052887201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725826144218445,
      "backward_entropy": 0.09900020701544625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.03004455566406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009912052191793919,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725882768630981,
      "backward_entropy": 0.09901590858186994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.58255004882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010830238461494446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725925981998444,
      "backward_entropy": 0.0989869236946106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.54698181152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011769250268116593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372595727443695,
      "backward_entropy": 0.09901713473456246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.64419555664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012724935077130795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725972175598145,
      "backward_entropy": 0.09898742607661656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5841522216797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013687503524124622,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725970685482025,
      "backward_entropy": 0.09901813098362514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.9932403564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014663689071312547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372595578432083,
      "backward_entropy": 0.09900166307176862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.54188537597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001565051730722189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372593641281128,
      "backward_entropy": 0.09900176525115967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.47381591796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016638728557154536,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725902140140533,
      "backward_entropy": 0.09901924644197736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.9527587890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001763628562912345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725852966308594,
      "backward_entropy": 0.09898791142872401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.6233673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018623339710757136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725793361663818,
      "backward_entropy": 0.09898778370448522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.3614959716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019593294709920883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725724816322327,
      "backward_entropy": 0.0990199361528669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.4773406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020575853995978832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725639879703522,
      "backward_entropy": 0.0990011181150164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.2860870361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0021561782341450453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725538551807404,
      "backward_entropy": 0.09900076048714775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.62896728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0022558055352419615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725422322750092,
      "backward_entropy": 0.0990003262247358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.70404052734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00235520931892097,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725292682647705,
      "backward_entropy": 0.09902033635548182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.94837951660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024545674677938223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725148141384125,
      "backward_entropy": 0.0990203789302281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.57701110839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00255460268817842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372498869895935,
      "backward_entropy": 0.09899844442095075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.6525115966797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0026554265059530735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724812865257263,
      "backward_entropy": 0.09902043001992362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.34646606445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027549900114536285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137246236205101,
      "backward_entropy": 0.09902044704982213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.2029571533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002852607984095812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724422454833984,
      "backward_entropy": 0.09898182324000768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.801513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00294833118095994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724209368228912,
      "backward_entropy": 0.09902043001992362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.82687377929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003046322613954544,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723976910114288,
      "backward_entropy": 0.0990204129900251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.53564453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003145343391224742,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723725080490112,
      "backward_entropy": 0.0990203959601266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.19064331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032469190191477537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723452389240265,
      "backward_entropy": 0.09899110453469413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.075927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033489512279629707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723161816596985,
      "backward_entropy": 0.09898978471755981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.03253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034523082431405783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722850382328033,
      "backward_entropy": 0.09902032784053258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.62521362304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0035568035673350096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372251957654953,
      "backward_entropy": 0.09902027675083705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.83038330078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003661414608359337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722169399261475,
      "backward_entropy": 0.09902022566114153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.38356018066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003766842884942889,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721801340579987,
      "backward_entropy": 0.099020174571446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.61611938476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038704441394656897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721419870853424,
      "backward_entropy": 0.09898248740604945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.45977783203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0039743902161717415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372101753950119,
      "backward_entropy": 0.09902003833225795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.06817626953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004078479018062353,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720598816871643,
      "backward_entropy": 0.09901995318276542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.30267333984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0041817473247647285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720163702964783,
      "backward_entropy": 0.09901988506317139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.36761474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004287681542336941,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719704747200012,
      "backward_entropy": 0.09901979991367885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 309.4410400390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004396029282361269,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719220459461212,
      "backward_entropy": 0.09901975733893258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.34951782226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004507874138653278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718704879283905,
      "backward_entropy": 0.09895799841199603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 294.75396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004617737140506506,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718175888061523,
      "backward_entropy": 0.0990196807043893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 325.59686279296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004729837644845247,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371762603521347,
      "backward_entropy": 0.09901964664459229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.3305358886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004845528397709131,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371704638004303,
      "backward_entropy": 0.09895406450544085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.37017822265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004961379803717136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371644288301468,
      "backward_entropy": 0.09896530423845563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.90234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005077873822301626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715815544128418,
      "backward_entropy": 0.09901966367449079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.1383361816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005193523596972227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715170323848724,
      "backward_entropy": 0.0990196807043893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.07891845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005310626234859228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714495301246643,
      "backward_entropy": 0.09894883632659912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.4593200683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005428948439657688,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713791966438293,
      "backward_entropy": 0.09901973179408483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.63671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005548224318772554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713061809539795,
      "backward_entropy": 0.09901975733893258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.5882568359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005668539088219404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371230036020279,
      "backward_entropy": 0.09895556313650948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.12356567382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005788745824247599,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711516559123993,
      "backward_entropy": 0.09901983397347587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.42906188964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005904655437916517,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710753619670868,
      "backward_entropy": 0.09901982545852661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.6778564453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006019328720867634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709977269172668,
      "backward_entropy": 0.09894970485142299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 308.9519348144531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006133738439530134,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709181547164917,
      "backward_entropy": 0.09901978288378034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.30206298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0062502361834049225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370835304260254,
      "backward_entropy": 0.09893717084612165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.6829833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006366936024278402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370750069618225,
      "backward_entropy": 0.09893543379647392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.56906127929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00648371409624815,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706614077091217,
      "backward_entropy": 0.09901973179408483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.51519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00659833662211895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705720007419586,
      "backward_entropy": 0.09893160206930977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.35093688964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006709280889481306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704822957515717,
      "backward_entropy": 0.0989352890423366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.70375061035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006818532478064299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703905045986176,
      "backward_entropy": 0.09893218108585902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.844482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006927307695150375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13702963292598724,
      "backward_entropy": 0.09892387049538749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 324.7100830078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007035278715193272,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701996207237244,
      "backward_entropy": 0.09901924644197736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.2560119628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007146797608584166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700979948043823,
      "backward_entropy": 0.09901915277753558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 340.398681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007258308585733175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699933886528015,
      "backward_entropy": 0.09891910212380546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.5401916503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007373695261776447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698837161064148,
      "backward_entropy": 0.09891623258590698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.00582885742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00749006774276495,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697701692581177,
      "backward_entropy": 0.09901905059814453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.9009704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007603958249092102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369655281305313,
      "backward_entropy": 0.09891039984566825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.4005584716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007717295084148645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695380091667175,
      "backward_entropy": 0.09890716416495186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.7178955078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00782661885023117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369420439004898,
      "backward_entropy": 0.09890340055738177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 292.089111328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007937503047287464,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13692989945411682,
      "backward_entropy": 0.09901884623936244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.43988037109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008049671538174152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369173526763916,
      "backward_entropy": 0.09889612027576991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.4107360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008159940131008625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690465688705444,
      "backward_entropy": 0.09889232260840279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 291.8907470703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008270901627838612,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689164817333221,
      "backward_entropy": 0.09901870148522514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.66876220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008383088745176792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687829673290253,
      "backward_entropy": 0.09888477836336408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 339.5703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00849196407943964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686488568782806,
      "backward_entropy": 0.09888044425419398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.48768615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008604845032095909,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685083389282227,
      "backward_entropy": 0.09887661252702985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.9674072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008715418167412281,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368366777896881,
      "backward_entropy": 0.09887819630759102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.9460754394531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00882639829069376,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368221640586853,
      "backward_entropy": 0.09901853970118932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.2734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008937150239944458,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136807382106781,
      "backward_entropy": 0.09901851415634155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.60003662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009048188105225563,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679197430610657,
      "backward_entropy": 0.09901848009654454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 290.4778137207031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009159887209534645,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13677601516246796,
      "backward_entropy": 0.09901845455169678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.3919677734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009272714145481586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367594599723816,
      "backward_entropy": 0.09885015657969884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 306.0994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009382165968418121,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674280047416687,
      "backward_entropy": 0.09901833534240723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.10923767089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009493871591985226,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672547042369843,
      "backward_entropy": 0.09901829276766096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.84759521484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009604002349078655,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367078721523285,
      "backward_entropy": 0.09901821613311768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 290.1164855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009709146805107594,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366903930902481,
      "backward_entropy": 0.09884450265339442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.8089294433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009816090576350689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667231798171997,
      "backward_entropy": 0.09883967467716762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.58953857421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009923039004206657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366538405418396,
      "backward_entropy": 0.09883470194680351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.32571411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010026459582149982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663539290428162,
      "backward_entropy": 0.0988088505608695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.39358520507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010128472931683064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661669194698334,
      "backward_entropy": 0.09882325785500663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 305.056640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010228080675005913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365978717803955,
      "backward_entropy": 0.0987937365259443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.37725830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010331092402338982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365782767534256,
      "backward_entropy": 0.098786575453622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.5260772705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010435097850859165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365581452846527,
      "backward_entropy": 0.09877929517201015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.99478149414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010537531226873398,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13653779029846191,
      "backward_entropy": 0.09901646205357142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.51634216308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010635768994688988,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13651758432388306,
      "backward_entropy": 0.0990161555153983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.4827880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010730313137173653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649748265743256,
      "backward_entropy": 0.09878582613808769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.1636047363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01082233153283596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13647732138633728,
      "backward_entropy": 0.09877809456416539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.08984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010916708037257195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364564448595047,
      "backward_entropy": 0.09877075467790876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.746337890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011012435890734196,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13643500208854675,
      "backward_entropy": 0.09901468242917742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.3824462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011107543483376503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13641326129436493,
      "backward_entropy": 0.09875641550336565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.7579803466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011204604990780354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136390820145607,
      "backward_entropy": 0.09874953542436872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 288.9333801269531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011301823891699314,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13636797666549683,
      "backward_entropy": 0.0990140438079834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 305.406982421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011401727795600891,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363442987203598,
      "backward_entropy": 0.09901395865849086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.01177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011504807509481907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13631971180438995,
      "backward_entropy": 0.09868374041148595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.77490234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011606546118855476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362949162721634,
      "backward_entropy": 0.09872349670955113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.7117462158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011708220466971397,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13626974821090698,
      "backward_entropy": 0.09901406935283116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 271.9968566894531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011809307150542736,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13624419271945953,
      "backward_entropy": 0.0990140608378819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.2461853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011911815963685513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621795177459717,
      "backward_entropy": 0.09870374202728271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.06939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012014619074761868,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361912190914154,
      "backward_entropy": 0.09901421410696847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.91259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01211431622505188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13616454601287842,
      "backward_entropy": 0.09868984563010079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.1576385498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012212779372930527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13613760471343994,
      "backward_entropy": 0.09868182454790388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.8924560546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012307949364185333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13611087203025818,
      "backward_entropy": 0.09861758777073451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 320.6265869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012404960580170155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13608330488204956,
      "backward_entropy": 0.09866433484213692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.21774291992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012506336905062199,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13605445623397827,
      "backward_entropy": 0.0986567565373012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.16062927246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012604656629264355,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13602571189403534,
      "backward_entropy": 0.09901360954557147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 287.7862854003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012700232677161694,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359969973564148,
      "backward_entropy": 0.09901338815689087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.33920288085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01279863715171814,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13596726953983307,
      "backward_entropy": 0.09901324340275355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.38424682617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01289459690451622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13593760132789612,
      "backward_entropy": 0.09855603320258004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.665771484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012989694252610207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13590756058692932,
      "backward_entropy": 0.09901273250579834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.24957275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0130852572619915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13587695360183716,
      "backward_entropy": 0.09859845467976161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.2853240966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013180003501474857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584600389003754,
      "backward_entropy": 0.098520142691476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.26283264160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013273237273097038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358148455619812,
      "backward_entropy": 0.09857605184827532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.84136962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013366060331463814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578319549560547,
      "backward_entropy": 0.09856421606881278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.5824432373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013460452668368816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357506662607193,
      "backward_entropy": 0.09848054817744664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.80831909179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013555171899497509,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357174813747406,
      "backward_entropy": 0.09901082515716553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.60244750976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013650494627654552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568368554115295,
      "backward_entropy": 0.09845409223011561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.88272094726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013740647584199905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13565051555633545,
      "backward_entropy": 0.09843913997922625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.12171936035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013828814961016178,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13561727106571198,
      "backward_entropy": 0.09900944573538643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.90740966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01391687709838152,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13558341562747955,
      "backward_entropy": 0.09848618507385254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.85699462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014002368785440922,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355496644973755,
      "backward_entropy": 0.09847044093268258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.48960876464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0140865258872509,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355157345533371,
      "backward_entropy": 0.09900703600474767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.5845947265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01417299173772335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13548067212104797,
      "backward_entropy": 0.09900633777890887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.947021484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01425787154585123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13544543087482452,
      "backward_entropy": 0.09900552885872978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.7029571533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01434125192463398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13540998101234436,
      "backward_entropy": 0.09831376586641584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.171142578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014425067231059074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13537383079528809,
      "backward_entropy": 0.09829371316092354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.24481201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01451126765459776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13533657789230347,
      "backward_entropy": 0.09827462264469691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 285.1045227050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014599762856960297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13529829680919647,
      "backward_entropy": 0.0982567582811628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.12176513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014692175202071667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13525839149951935,
      "backward_entropy": 0.09824236801692418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.03073120117188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014780299738049507,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135219007730484,
      "backward_entropy": 0.09900230169296265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.48590087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014869573526084423,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13517899811267853,
      "backward_entropy": 0.09831176485334124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.18572998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01496090367436409,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1351381242275238,
      "backward_entropy": 0.09829687220709664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.37039184570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015053368173539639,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13509684801101685,
      "backward_entropy": 0.09828228609902519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.72409057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015143580734729767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13505631685256958,
      "backward_entropy": 0.09826618432998657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.6294708251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01523322518914938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13501542806625366,
      "backward_entropy": 0.09824975899287633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.54788208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015323881059885025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13497324287891388,
      "backward_entropy": 0.0982335124697004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.88400268554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015415445901453495,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13492977619171143,
      "backward_entropy": 0.09900193555014473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.70176696777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015501406043767929,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348869800567627,
      "backward_entropy": 0.09900158643722534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.3766326904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015587005764245987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13484326004981995,
      "backward_entropy": 0.09807583263942174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.39195251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015675170347094536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13479742407798767,
      "backward_entropy": 0.09805845362799508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.5729217529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01576259545981884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13475072383880615,
      "backward_entropy": 0.0980399761881147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 267.8348083496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015848547220230103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13470354676246643,
      "backward_entropy": 0.09812782491956439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.51715087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015937838703393936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13465435802936554,
      "backward_entropy": 0.09811023303440639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.32525634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016025062650442123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346047967672348,
      "backward_entropy": 0.09809108291353498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.83177185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01610911637544632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13455554842948914,
      "backward_entropy": 0.09796028477805001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.66680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016192710027098656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13450545072555542,
      "backward_entropy": 0.09804749488830566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.45802307128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01627630554139614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13445457816123962,
      "backward_entropy": 0.0980245726449149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.62838745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01636088453233242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344025731086731,
      "backward_entropy": 0.09800141198294503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.40274047851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01644148863852024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13435085117816925,
      "backward_entropy": 0.0978631888117109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.790771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016518346965312958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13429877161979675,
      "backward_entropy": 0.09783451897757393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.8291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01659715548157692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1342446208000183,
      "backward_entropy": 0.09780490398406982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.27720642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016675416380167007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341896504163742,
      "backward_entropy": 0.09789509432656425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.50637817382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016756154596805573,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1341327279806137,
      "backward_entropy": 0.09899142810276576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.73553466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01683715358376503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13407470285892487,
      "backward_entropy": 0.0978410073689052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.03167724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01692117191851139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13401445746421814,
      "backward_entropy": 0.09781515598297119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.5493927001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017002301290631294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1339545100927353,
      "backward_entropy": 0.09898844787052699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.3877716064453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017080919817090034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13389478623867035,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.062255859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01715979352593422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1338338404893875,
      "backward_entropy": 0.09759855270385742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.7913818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0172421894967556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13377055525779724,
      "backward_entropy": 0.09756867374692645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.87464904785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017324548214673996,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1337062269449234,
      "backward_entropy": 0.0989842244556972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.83734130859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017407044768333435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13364088535308838,
      "backward_entropy": 0.09763838563646589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.0794677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017486577853560448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13357587158679962,
      "backward_entropy": 0.09760425771985735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.690185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017564963549375534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13351067900657654,
      "backward_entropy": 0.0974346569606236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.72808837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017641568556427956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.133445143699646,
      "backward_entropy": 0.09739587988172259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.9210662841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017718682065606117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13337823748588562,
      "backward_entropy": 0.09749361446925572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.12594604492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01779850572347641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13331003487110138,
      "backward_entropy": 0.09745740039008004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.14892578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017878606915473938,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13324102759361267,
      "backward_entropy": 0.09897552217755999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.9947967529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017960628494620323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13316990435123444,
      "backward_entropy": 0.09724338565553937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.14532470703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018044790253043175,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13309796154499054,
      "backward_entropy": 0.09897422790527344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 280.7486267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018127037212252617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13302616775035858,
      "backward_entropy": 0.09716823271342687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 232.2413787841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018214192241430283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.132951021194458,
      "backward_entropy": 0.09728310789380755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 264.7547607421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01830304227769375,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13287419080734253,
      "backward_entropy": 0.09897429602486747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.7026824951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01839512400329113,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13279473781585693,
      "backward_entropy": 0.09897501979555402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.70249938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018487321212887764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13271424174308777,
      "backward_entropy": 0.0970367533820016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 233.36558532714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018578466027975082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13263317942619324,
      "backward_entropy": 0.09715655871800014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.0758056640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018670570105314255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1325504332780838,
      "backward_entropy": 0.09897599049976893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.29481506347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01876171864569187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1324671357870102,
      "backward_entropy": 0.0970849905695234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.45278930664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018851011991500854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13238373398780823,
      "backward_entropy": 0.0970449447631836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.63116455078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0189371220767498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323014348745346,
      "backward_entropy": 0.09700163773127965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.9708709716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019021051004529,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322193145751953,
      "backward_entropy": 0.09676516056060791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 263.8729248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01910778135061264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13213443756103516,
      "backward_entropy": 0.09671276807785034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.89178466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019197922199964523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13204646110534668,
      "backward_entropy": 0.09666221482413155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.44357299804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01929037645459175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13195624947547913,
      "backward_entropy": 0.0968254464013236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.53182983398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019380178302526474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318666934967041,
      "backward_entropy": 0.09656098910740443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.04302978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01946641504764557,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13177821040153503,
      "backward_entropy": 0.0967315946306501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9549560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019549531862139702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316906213760376,
      "backward_entropy": 0.09667910848345075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.39013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019629843533039093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13160376250743866,
      "backward_entropy": 0.09637893949236188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.4317932128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019713276997208595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13151374459266663,
      "backward_entropy": 0.09656955514635358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.16427612304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0198005773127079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13142019510269165,
      "backward_entropy": 0.09625746522630964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.223388671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01988844759762287,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1313251554965973,
      "backward_entropy": 0.09896352461406163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.60562133789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01997658610343933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13122856616973877,
      "backward_entropy": 0.0961355481828962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.70419311523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020063454285264015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311318576335907,
      "backward_entropy": 0.09607164348874773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.1732940673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02014501392841339,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1310376077890396,
      "backward_entropy": 0.09630165781293597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.30343627929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02022581174969673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13094276189804077,
      "backward_entropy": 0.09592690638133458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.7808837890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02030770480632782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13084587454795837,
      "backward_entropy": 0.09617791857038226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.1472930908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020385650917887688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13075049221515656,
      "backward_entropy": 0.09611114433833531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.91322326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02046244591474533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13065510988235474,
      "backward_entropy": 0.09569103377205986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.33566284179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020540768280625343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305573433637619,
      "backward_entropy": 0.09560894966125488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.13674926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020617827773094177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13045960664749146,
      "backward_entropy": 0.09552490711212158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.12779998779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020692642778158188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13036245107650757,
      "backward_entropy": 0.09583113874707903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.45245361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020761266350746155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.130268856883049,
      "backward_entropy": 0.09575286933353969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.02297973632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020830227062106133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13017363846302032,
      "backward_entropy": 0.09525276081902641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.12452697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02090383879840374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13007408380508423,
      "backward_entropy": 0.09516585724694389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.61456298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020978659391403198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12997278571128845,
      "backward_entropy": 0.09552422591618129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.91029357910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021053967997431755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12986907362937927,
      "backward_entropy": 0.09499552420207433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.27723693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02113211527466774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12976102530956268,
      "backward_entropy": 0.09491159234728132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.39102172851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021208887919783592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12965244054794312,
      "backward_entropy": 0.09482322420392718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.66452026367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021284600719809532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12954336404800415,
      "backward_entropy": 0.09473216533660889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.72048950195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021359281614422798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1294337809085846,
      "backward_entropy": 0.09463913100106376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.21038818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021433906629681587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12932275235652924,
      "backward_entropy": 0.09454378059932164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.22312927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02150857262313366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12921036779880524,
      "backward_entropy": 0.09444619928087507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.46066284179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021586358547210693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12909424304962158,
      "backward_entropy": 0.09490652595247541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.8217010498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02166576124727726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12897539138793945,
      "backward_entropy": 0.09425936426435198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.87603759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021744735538959503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12885567545890808,
      "backward_entropy": 0.09474936553410121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.93846130371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02182038128376007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12873782217502594,
      "backward_entropy": 0.09466362851006645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.93927001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02189590409398079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286187767982483,
      "backward_entropy": 0.09395649603434972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.52813720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02197372354567051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284969598054886,
      "backward_entropy": 0.09385643686567034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.7653045654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022051464766263962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12837424874305725,
      "backward_entropy": 0.093754700251988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.90089416503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02213299088180065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12824705243110657,
      "backward_entropy": 0.09365651437214442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.1111297607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022212164476513863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281212568283081,
      "backward_entropy": 0.0942314692905971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.5258026123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02229396440088749,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12799187004566193,
      "backward_entropy": 0.09414550236293248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.7021942138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022372089326381683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278647631406784,
      "backward_entropy": 0.09334186145237514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.08660888671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02244883030653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1277376115322113,
      "backward_entropy": 0.09322214126586914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.41998291015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022527271881699562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12760743498802185,
      "backward_entropy": 0.09385723727090019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.60508728027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02260671928524971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12747561931610107,
      "backward_entropy": 0.09298041888645717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.19488525390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02268870919942856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1273401826620102,
      "backward_entropy": 0.0928605284009661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.7749481201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022768067196011543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1272062063217163,
      "backward_entropy": 0.09356244121279035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.87796020507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022845767438411713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12707237899303436,
      "backward_entropy": 0.09260299376079015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.81735229492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022927312180399895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12693384289741516,
      "backward_entropy": 0.09247655527932304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.5745086669922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02300627902150154,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1267969012260437,
      "backward_entropy": 0.09888928277151925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.980224609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023083185777068138,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12666143476963043,
      "backward_entropy": 0.09888662610735212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.59194946289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023155707865953445,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12652909755706787,
      "backward_entropy": 0.09888241972242083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.87884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023227617144584656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12639644742012024,
      "backward_entropy": 0.09287865672792707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.18890380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023302111774683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12626031041145325,
      "backward_entropy": 0.09175801277160645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.9024658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023374756798148155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12612512707710266,
      "backward_entropy": 0.09160477774483818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.35791015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023449840024113655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12598645687103271,
      "backward_entropy": 0.0925007632800511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.8004608154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023527201265096664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12584464251995087,
      "backward_entropy": 0.09237667492457799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.38551330566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0236024372279644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12570412456989288,
      "backward_entropy": 0.09224629402160645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.45445251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023676903918385506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12556365132331848,
      "backward_entropy": 0.09099098614283971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.5780029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0237538143992424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12541994452476501,
      "backward_entropy": 0.090835588318961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.40171813964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023831801488995552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12527424097061157,
      "backward_entropy": 0.09185118334633964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.45828247070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023906992748379707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12513133883476257,
      "backward_entropy": 0.0917130708694458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.28904724121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02398732677102089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1249818205833435,
      "backward_entropy": 0.09037697315216064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.19805145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02406647987663746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12483298778533936,
      "backward_entropy": 0.09022419793265206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.70396423339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02414115145802498,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12468799948692322,
      "backward_entropy": 0.09884522642408099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.87069702148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024217145517468452,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12454071640968323,
      "backward_entropy": 0.09884185450417655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.38449096679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02429528906941414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1243901401758194,
      "backward_entropy": 0.08972786154065814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.37346649169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024378038942813873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12423312664031982,
      "backward_entropy": 0.0908076422555106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.40524291992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024456046521663666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12408067286014557,
      "backward_entropy": 0.08939259392874581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.9261474609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024534709751605988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12392622232437134,
      "backward_entropy": 0.08921263899121966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.03985595703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02461221255362034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12377241998910904,
      "backward_entropy": 0.09882920128958565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.82706451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02468964084982872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12361791729927063,
      "backward_entropy": 0.08884177889142718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.06553649902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02476312778890133,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12346769869327545,
      "backward_entropy": 0.098820618220738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.18128204345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024832982569932938,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12332126498222351,
      "backward_entropy": 0.09881410428455897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.55552673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024900000542402267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12317844480276108,
      "backward_entropy": 0.08823534420558385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.20071411132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024966713041067123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12303449213504791,
      "backward_entropy": 0.08934041431971959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.06036376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025036746636033058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12288612127304077,
      "backward_entropy": 0.08913884844098773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.8575897216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025109512731432915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12273360788822174,
      "backward_entropy": 0.08894165924617223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.34231567382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025184737518429756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12257737666368484,
      "backward_entropy": 0.08740317821502686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.54107666015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025258224457502365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1224227100610733,
      "backward_entropy": 0.08854849849428449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.26837158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025330064818263054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12226828932762146,
      "backward_entropy": 0.08834196840013776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.6888198852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025402719154953957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12211232632398605,
      "backward_entropy": 0.08813471453530448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.4320831298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547168917953968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12195996940135956,
      "backward_entropy": 0.0865328311920166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.52249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025539396330714226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12180817872285843,
      "backward_entropy": 0.08629810810089111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.35792541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025609154254198074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12165307998657227,
      "backward_entropy": 0.08606678247451782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.97157287597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025676773861050606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1215001791715622,
      "backward_entropy": 0.08723994663783483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.11068725585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025743283331394196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12134777009487152,
      "backward_entropy": 0.0870049170085362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.35829162597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025807732716202736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12119707465171814,
      "backward_entropy": 0.08532982213156563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.89434814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025872470811009407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12104521691799164,
      "backward_entropy": 0.0865180322102138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.6869354248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025937044993042946,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12089197337627411,
      "backward_entropy": 0.09869604451315743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.81385803222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026002977043390274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12073676288127899,
      "backward_entropy": 0.0860224621636527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.50949096679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026069587096571922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12058126926422119,
      "backward_entropy": 0.08428546360560826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.90424346923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026142628863453865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12041749060153961,
      "backward_entropy": 0.08404459272112165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.3013153076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02621307782828808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025658786296844,
      "backward_entropy": 0.08379165615354266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.50820922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02628350630402565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12009565532207489,
      "backward_entropy": 0.08353877067565918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.78022003173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026357892900705338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11992941796779633,
      "backward_entropy": 0.08483432020459857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.52378845214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02642947994172573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11976616084575653,
      "backward_entropy": 0.08458966016769409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.46932220458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026500053703784943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11960455775260925,
      "backward_entropy": 0.08433926105499268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8630828857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0265682190656662,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11944540590047836,
      "backward_entropy": 0.08407805647168841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.83075714111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02663581073284149,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11928747594356537,
      "backward_entropy": 0.08381315640040807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.1968231201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026701390743255615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11913159489631653,
      "backward_entropy": 0.08353870255606514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.50851440429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026766497641801834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1189764142036438,
      "backward_entropy": 0.08165960652487618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.58648681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02683199942111969,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1188201904296875,
      "backward_entropy": 0.08137115410396031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.96469116210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026899652555584908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11866015940904617,
      "backward_entropy": 0.08108077730451312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.49034881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026963241398334503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850525438785553,
      "backward_entropy": 0.08077845403126307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.72023010253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02702299878001213,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11835479736328125,
      "backward_entropy": 0.0821326460157122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.24098205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027083074674010277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1182045191526413,
      "backward_entropy": 0.08184444052832467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.31930541992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027139678597450256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11805830895900726,
      "backward_entropy": 0.07983286040169853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.52227783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0271957665681839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11791317164897919,
      "backward_entropy": 0.08122880118233818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.43666076660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027252864092588425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11776559054851532,
      "backward_entropy": 0.08091577461787633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.51296997070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027312301099300385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11761471629142761,
      "backward_entropy": 0.07887098618916102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.34626770019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027370790019631386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11746525764465332,
      "backward_entropy": 0.08029108388083321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.22494506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027426348999142647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11732007563114166,
      "backward_entropy": 0.07996158940451485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.96327209472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027479276061058044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11717867851257324,
      "backward_entropy": 0.07785955497196742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.9971923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027533749118447304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11703447997570038,
      "backward_entropy": 0.07750809192657471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.99542236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027583347633481026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11689677834510803,
      "backward_entropy": 0.07713188443865095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.89151763916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027633847668766975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1167573407292366,
      "backward_entropy": 0.07675428901399885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.08526611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027682814747095108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11661909520626068,
      "backward_entropy": 0.07819010530199323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.910400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027735846117138863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11647473275661469,
      "backward_entropy": 0.07598003319331578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.08689880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027787024155259132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1163320243358612,
      "backward_entropy": 0.07746597698756627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.0615997314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027839334681630135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11618843674659729,
      "backward_entropy": 0.07710226093019758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.4395294189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02789350226521492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11604240536689758,
      "backward_entropy": 0.07480558327266149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.89315795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027948610484600067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11589595675468445,
      "backward_entropy": 0.07442637000765119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.58009338378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028000952675938606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11575321853160858,
      "backward_entropy": 0.0740330730165754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.26231384277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02805543877184391,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11560820043087006,
      "backward_entropy": 0.07364924464906965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.08708953857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028115835040807724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11545540392398834,
      "backward_entropy": 0.0732817564691816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.885009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02817506156861782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11530406773090363,
      "backward_entropy": 0.07290126596178327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.09397888183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028235506266355515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11515132337808609,
      "backward_entropy": 0.07252093723842076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.95417022705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02829805016517639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11499592661857605,
      "backward_entropy": 0.0721419027873448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.17352294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028356041759252548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11484670639038086,
      "backward_entropy": 0.07174046550478254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.13404846191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02841431461274624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11469738185405731,
      "backward_entropy": 0.07352284022739955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.5960235595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028470579534769058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11455069482326508,
      "backward_entropy": 0.07313988889966692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.88482666015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028531476855278015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439794301986694,
      "backward_entropy": 0.07052097576005119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.88267517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02859230525791645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1142454594373703,
      "backward_entropy": 0.07011101075581141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.78335571289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02865658327937126,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408938467502594,
      "backward_entropy": 0.09833684989384242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.30409240722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028724700212478638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11392860114574432,
      "backward_entropy": 0.0716919047491891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.33041381835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02878938987851143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11377401649951935,
      "backward_entropy": 0.07132669006075178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.18950653076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028849555179476738,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11362607777118683,
      "backward_entropy": 0.07093971116202218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.7198944091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028908586129546165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11347942054271698,
      "backward_entropy": 0.07054365532738822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.7725067138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02896852232515812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1133309006690979,
      "backward_entropy": 0.06768262386322021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.16143035888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029029197990894318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11318068206310272,
      "backward_entropy": 0.06724309069769722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.42929077148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029087800532579422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11303377151489258,
      "backward_entropy": 0.06932922771998815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.67486572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029145464301109314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11288800835609436,
      "backward_entropy": 0.06633074794496809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.6497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029200365766882896,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11274662613868713,
      "backward_entropy": 0.0982825585774013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.37010192871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029253799468278885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11260758340358734,
      "backward_entropy": 0.06538182497024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.76779174804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029310112819075584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11246497929096222,
      "backward_entropy": 0.06760088460786003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.41680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029365012422204018,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11232513934373856,
      "backward_entropy": 0.09823989016669137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.06869506835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02942517027258873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1121797114610672,
      "backward_entropy": 0.06399898443903242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.81809997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029485389590263367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.112034372985363,
      "backward_entropy": 0.06354710033961705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8118896484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02954467013478279,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11189061403274536,
      "backward_entropy": 0.06591354097638812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.30438232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029606718569993973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1117447018623352,
      "backward_entropy": 0.0626497311251504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.17062377929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0296703539788723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11159849911928177,
      "backward_entropy": 0.06222428594316755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.36407470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0297330841422081,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11145458370447159,
      "backward_entropy": 0.06179589884621756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.52576446533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029797179624438286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11131011694669724,
      "backward_entropy": 0.06425257240022932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.2709197998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029856806620955467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11117161810398102,
      "backward_entropy": 0.0638148444039481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.30801391601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029916701838374138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11103300750255585,
      "backward_entropy": 0.06047934293746948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.33413696289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02997676283121109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11089424043893814,
      "backward_entropy": 0.06293302774429321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.74666595458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030034977942705154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1107582375407219,
      "backward_entropy": 0.06248059443065098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.47918701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03009297512471676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11062382161617279,
      "backward_entropy": 0.06202828884124756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.65779876708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030152708292007446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11048802733421326,
      "backward_entropy": 0.06158431087221418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.76556396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030209161341190338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11035826802253723,
      "backward_entropy": 0.06113161359514509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.94258117675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030262237414717674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11023350059986115,
      "backward_entropy": 0.05772298574447632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.2948455810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03031439147889614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11011040955781937,
      "backward_entropy": 0.05725057635988508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.62674713134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030367739498615265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10998602956533432,
      "backward_entropy": 0.05972305365971157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.36012268066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030418317764997482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10986646264791489,
      "backward_entropy": 0.05924522025244577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.56246948242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030468838289380074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10974617302417755,
      "backward_entropy": 0.05876262698854719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.972412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03051646240055561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10962975025177002,
      "backward_entropy": 0.05531649078641619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.8152313232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030560387298464775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10951811075210571,
      "backward_entropy": 0.05480203032493591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.45539855957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030609583482146263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10940027236938477,
      "backward_entropy": 0.05727004153387887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.5399398803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03065807931125164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10928332060575485,
      "backward_entropy": 0.05677900995526995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.10009002685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030704107135534286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10917024314403534,
      "backward_entropy": 0.05628123453685215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.32820129394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030749285593628883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1090596467256546,
      "backward_entropy": 0.05280535135950361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.53153228759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030794810503721237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10895002633333206,
      "backward_entropy": 0.05529343230383737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.79956817626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03084014728665352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10884066671133041,
      "backward_entropy": 0.05182493584496634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.87357711791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03088676929473877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10873077064752579,
      "backward_entropy": 0.05134587628500802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.15005493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030929500237107277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10862743854522705,
      "backward_entropy": 0.05086358955928257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.2433624267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030976399779319763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10851854085922241,
      "backward_entropy": 0.05334643380982535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.37045288085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03102731704711914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1084049791097641,
      "backward_entropy": 0.05288803577423096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.03875732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031080516055226326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1082882285118103,
      "backward_entropy": 0.0524378206048693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.19216918945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031136207282543182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1081695705652237,
      "backward_entropy": 0.05200020756040301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.98016357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031190048903226852,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10805445909500122,
      "backward_entropy": 0.051557068313871114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.35435485839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03124617226421833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10793682187795639,
      "backward_entropy": 0.0481265698160444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.71640014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03130527585744858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10781614482402802,
      "backward_entropy": 0.0476897656917572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.84388732910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03136298060417175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10769768804311752,
      "backward_entropy": 0.04724431889397757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.52914428710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031421612948179245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10757894814014435,
      "backward_entropy": 0.09786479813711983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.4523696899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03147883340716362,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10746222734451294,
      "backward_entropy": 0.04941143308367048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.33541107177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031535886228084564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10734620690345764,
      "backward_entropy": 0.04897713661193848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.01185607910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031593888998031616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10722976177930832,
      "backward_entropy": 0.0454402140208653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.59085083007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03165167197585106,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10711424052715302,
      "backward_entropy": 0.09786522388458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.89253234863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03170935809612274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10699951648712158,
      "backward_entropy": 0.04768013954162598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.08718872070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031764961779117584,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1068880707025528,
      "backward_entropy": 0.09786146027701241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.16159057617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03181743994355202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10678061842918396,
      "backward_entropy": 0.04360268371445792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.07089233398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03186855465173721,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10667598247528076,
      "backward_entropy": 0.09784127984728132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.1887969970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03192337974905968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10656780749559402,
      "backward_entropy": 0.042681600366319926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.97266387939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198288381099701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10645589232444763,
      "backward_entropy": 0.042253507035119195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.85713958740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032041285187006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10634630173444748,
      "backward_entropy": 0.045073892389025004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.38829040527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03209610655903816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10624031722545624,
      "backward_entropy": 0.0446424058505467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.88816833496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03215248882770538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10613401234149933,
      "backward_entropy": 0.04093627418790545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.46305084228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03220628574490547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1060321033000946,
      "backward_entropy": 0.040501807417188375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.66537475585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032261524349451065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10592897236347198,
      "backward_entropy": 0.043380179575511386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.16001892089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032317325472831726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10582655668258667,
      "backward_entropy": 0.04297037635530744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.52032470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0323743112385273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10572317242622375,
      "backward_entropy": 0.039233156612941196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.58480834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032434530556201935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10561710596084595,
      "backward_entropy": 0.038823527949196954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.96622467041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03249311074614525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10551492869853973,
      "backward_entropy": 0.03842627150671823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.65420532226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03255189210176468,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10541346669197083,
      "backward_entropy": 0.09784565653119769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.85784149169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03261185809969902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10531168431043625,
      "backward_entropy": 0.037637685026441305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.07327270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032671745866537094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1052105650305748,
      "backward_entropy": 0.03724621023450579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.92034912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03272949904203415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10511218756437302,
      "backward_entropy": 0.03684772763933454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.46099853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03278949111700058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10501215606927872,
      "backward_entropy": 0.03985642961093357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.57164001464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032852496951818466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10490980744361877,
      "backward_entropy": 0.03948893291609628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.7889404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03291218727827072,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10481183975934982,
      "backward_entropy": 0.03911184413092477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.287841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03297097980976105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10471552610397339,
      "backward_entropy": 0.03529951614992959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.12759399414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033031709492206573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10461728274822235,
      "backward_entropy": 0.03836601546832493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.56893920898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033090222626924515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10452186316251755,
      "backward_entropy": 0.03452662059238979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.26261901855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03314998373389244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10442587733268738,
      "backward_entropy": 0.0341443589755467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.47645568847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03320574760437012,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10433465242385864,
      "backward_entropy": 0.03723394445010594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.86490631103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0332612469792366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10424493253231049,
      "backward_entropy": 0.03685729844229562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.31202697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03331964835524559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10415381193161011,
      "backward_entropy": 0.033003274883542745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.59748077392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033378954976797104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10406152904033661,
      "backward_entropy": 0.032631899629320414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.88361740112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03343784809112549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10397130250930786,
      "backward_entropy": 0.032273722546441216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.85675811767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03349332511425018,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10388588905334473,
      "backward_entropy": 0.035426823156220574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.57090759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03354640677571297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10380326956510544,
      "backward_entropy": 0.031556316784449985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.24070739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0335974283516407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10372330248355865,
      "backward_entropy": 0.03119478906903948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.07840728759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033650655299425125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10364184528589249,
      "backward_entropy": 0.030844977923801968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.231292724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03370390832424164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10356098413467407,
      "backward_entropy": 0.03401707325662885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.41989135742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03375381603837013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10348314046859741,
      "backward_entropy": 0.03015210373061044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.65908813476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03380303829908371,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10340654850006104,
      "backward_entropy": 0.03331954990114484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.1114273071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033852651715278625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10333013534545898,
      "backward_entropy": 0.032975733280181885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.34706497192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03390346094965935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10325271636247635,
      "backward_entropy": 0.03263586972440992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.931421279907227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03395148366689682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10317840427160263,
      "backward_entropy": 0.03229241073131561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.32749938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03399478271603584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10310844331979752,
      "backward_entropy": 0.028410813638142178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.87169647216797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03404470905661583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10303182899951935,
      "backward_entropy": 0.03160127145903451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.32393646240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03409207612276077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10295850038528442,
      "backward_entropy": 0.02772533893585205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.653076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034140780568122864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10288378596305847,
      "backward_entropy": 0.03093024662562779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.90252685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03418823331594467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10281169414520264,
      "backward_entropy": 0.030602410435676575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.8877944946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0342404730618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10273537039756775,
      "backward_entropy": 0.026734665036201477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.01499938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03429417684674263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10265938937664032,
      "backward_entropy": 0.02643509422029768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.68722534179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03434896841645241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.102582648396492,
      "backward_entropy": 0.0261404173714774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.041259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03440483659505844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10250580310821533,
      "backward_entropy": 0.025851922375815257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.57657623291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0344623439013958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10242756456136703,
      "backward_entropy": 0.029164586748395647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.97020721435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03452255204319954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10234782099723816,
      "backward_entropy": 0.025285271661622182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.89704132080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03458023816347122,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10227040946483612,
      "backward_entropy": 0.028629660606384277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.87516021728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03463868051767349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10219311714172363,
      "backward_entropy": 0.02473050355911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.82429504394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03469765931367874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10211566090583801,
      "backward_entropy": 0.024456224271229336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.49944305419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034755025058984756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10203956067562103,
      "backward_entropy": 0.024177661963871548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.7734603881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034813959151506424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10196229815483093,
      "backward_entropy": 0.027582413383892605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.5641326904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034871865063905716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10188716650009155,
      "backward_entropy": 0.023633262940815518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3328857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034933481365442276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10180949419736862,
      "backward_entropy": 0.023375536714281355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.08011627197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03499479964375496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1017332524061203,
      "backward_entropy": 0.02312684272016798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.52784729003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03505764529109001,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016564890742302,
      "backward_entropy": 0.026623985597065518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.34232330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0351238027215004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1015777736902237,
      "backward_entropy": 0.026406156165259227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.05574035644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0351887010037899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10150004178285599,
      "backward_entropy": 0.026182602558817183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.24080657958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035251736640930176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10142429172992706,
      "backward_entropy": 0.025957626955849782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.83442687988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03531520068645477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10134892165660858,
      "backward_entropy": 0.021930826561791555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.66500854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03537994623184204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10127345472574234,
      "backward_entropy": 0.02169919652598245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.91946411132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03544273227453232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1011991947889328,
      "backward_entropy": 0.021465263196400235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.79003143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035504959523677826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10112590342760086,
      "backward_entropy": 0.021234414407185147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.26079559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03556438162922859,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1010543629527092,
      "backward_entropy": 0.024875696216310774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.92340087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035626646131277084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10098174214363098,
      "backward_entropy": 0.02077228682381766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.0910186767578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03568724915385246,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10091038048267365,
      "backward_entropy": 0.09812194108963013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.81077575683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03575228154659271,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10083598643541336,
      "backward_entropy": 0.0242485659463065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.93826293945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03581717610359192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10076157748699188,
      "backward_entropy": 0.02009486300604684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.65959167480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035883065313100815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10068658739328384,
      "backward_entropy": 0.01986742445400783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.11164093017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03594602271914482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1006140485405922,
      "backward_entropy": 0.023621984890529087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.8796615600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03600716590881348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10054274648427963,
      "backward_entropy": 0.02341064385005406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.7345962524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03606816753745079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10047245025634766,
      "backward_entropy": 0.01918693312576839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.54932403564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03612758219242096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10040314495563507,
      "backward_entropy": 0.02299822441169194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.13132858276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03618558123707771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10033474862575531,
      "backward_entropy": 0.02278663856642587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.37972640991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03624121472239494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10026770830154419,
      "backward_entropy": 0.018497535160609653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.65119934082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03629406914114952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10020311176776886,
      "backward_entropy": 0.018265615616525923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.04752349853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03634944558143616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1001368910074234,
      "backward_entropy": 0.022147591624941145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.0061149597168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036408931016922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10006824135780334,
      "backward_entropy": 0.017830637948853627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.70866394042969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03646530583500862,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10000282526016235,
      "backward_entropy": 0.09819184030805315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.86370849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03651911020278931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09993864595890045,
      "backward_entropy": 0.017413309642246792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.99378967285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03657149896025658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09987583756446838,
      "backward_entropy": 0.021389116133962358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.36803436279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03662468492984772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09981334954500198,
      "backward_entropy": 0.017025459025587355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.63130950927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03667566180229187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09975287318229675,
      "backward_entropy": 0.016839482954570224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.85614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036727599799633026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09969213604927063,
      "backward_entropy": 0.02089621765272958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.49781036376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03678319230675697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09962905943393707,
      "backward_entropy": 0.02074744020189558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.05032348632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03684113547205925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956459701061249,
      "backward_entropy": 0.016323783567973545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.87504577636719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036898355931043625,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09950092434883118,
      "backward_entropy": 0.09823392118726458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.6675033569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03695595636963844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09943743050098419,
      "backward_entropy": 0.02033651513712747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.913835525512695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03701296076178551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09937465935945511,
      "backward_entropy": 0.015851948942456926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.51691436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03706507384777069,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09931474924087524,
      "backward_entropy": 0.020069445882524763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.81624603271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037115998566150665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09925563633441925,
      "backward_entropy": 0.015527927449771337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.24757385253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037169329822063446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09919591248035431,
      "backward_entropy": 0.01980689593723842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.84720611572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03722056373953819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09913777559995651,
      "backward_entropy": 0.015239150396415166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.09099578857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03727195784449577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09907981753349304,
      "backward_entropy": 0.019577835287366594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.46723175048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03732815384864807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09901879727840424,
      "backward_entropy": 0.014970841152327401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.62788200378418,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037385519593954086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09895644336938858,
      "backward_entropy": 0.09832660640989031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.16244506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03743710741400719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09889757633209229,
      "backward_entropy": 0.01924560112612588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.14080047607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749362379312515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09883579611778259,
      "backward_entropy": 0.014557747968605586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.90010070800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0375535748898983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09877195954322815,
      "backward_entropy": 0.01903775760105678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.18119049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0376165509223938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09870634227991104,
      "backward_entropy": 0.018941704716001238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.920692443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03768037632107735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09864035248756409,
      "backward_entropy": 0.014190303427832467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.897443771362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037742093205451965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09857574105262756,
      "backward_entropy": 0.014072097837924957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.03623580932617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037798892706632614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09851445257663727,
      "backward_entropy": 0.013949641159602575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.14578247070312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037853289395570755,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09845482558012009,
      "backward_entropy": 0.0984319874218532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.89500045776367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03790741786360741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09839531779289246,
      "backward_entropy": 0.013708799013069697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.24183654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037961505353450775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09833602607250214,
      "backward_entropy": 0.013593907867159163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.606998443603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0380144938826561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09827756136655807,
      "backward_entropy": 0.013481651033673967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.58736801147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03806550055742264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09822031110525131,
      "backward_entropy": 0.013370185026100703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.3359603881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03811648488044739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09816277027130127,
      "backward_entropy": 0.01325768870966775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.57553100585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038171324878931046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09810240566730499,
      "backward_entropy": 0.013146572879382543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.5529556274414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03822708874940872,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09804147481918335,
      "backward_entropy": 0.09849601984024048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.97697067260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038283318281173706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09797999262809753,
      "backward_entropy": 0.012935358498777663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.66184616088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038338977843523026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09791852533817291,
      "backward_entropy": 0.01781229781252997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.57738494873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0383944995701313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09785734117031097,
      "backward_entropy": 0.017736884100096568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.7309341430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0384497232735157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09779622405767441,
      "backward_entropy": 0.012619310191699437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.96847915649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0385056808590889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09773454070091248,
      "backward_entropy": 0.01758903477873121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.45291900634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03856031596660614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09767360985279083,
      "backward_entropy": 0.012416793831757136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.4601821899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03861551731824875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09761181473731995,
      "backward_entropy": 0.012314662337303162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.88469696044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03867234289646149,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09754876047372818,
      "backward_entropy": 0.017364276306969777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.268131256103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0387335941195488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09748265892267227,
      "backward_entropy": 0.012117960623332433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.09138107299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03879191726446152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09741830825805664,
      "backward_entropy": 0.012019310678754534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.61801147460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03884778916835785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09735564142465591,
      "backward_entropy": 0.011921223785196031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.28596496582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038905125111341476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09729161858558655,
      "backward_entropy": 0.011823303997516632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.733238220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038964126259088516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09722672402858734,
      "backward_entropy": 0.011731141379901342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.84275436401367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03902069106698036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09716334939002991,
      "backward_entropy": 0.016960797565323964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.5966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03907670080661774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09709979593753815,
      "backward_entropy": 0.011547488825661796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.43794250488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039130304008722305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09703809022903442,
      "backward_entropy": 0.011451910649027144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.34891891479492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039181917905807495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09697697311639786,
      "backward_entropy": 0.011358312198093959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.18199920654297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03923262655735016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09691649675369263,
      "backward_entropy": 0.09863339151654925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.20323371887207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03928351029753685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09685555100440979,
      "backward_entropy": 0.011169810380254473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.72940063476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933166712522507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09679622948169708,
      "backward_entropy": 0.011076055467128754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.38218688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03938217833638191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09673495590686798,
      "backward_entropy": 0.016485890107495443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.708343505859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03943594917654991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09667123854160309,
      "backward_entropy": 0.010898591152259282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.44390869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039488647133111954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09660794585943222,
      "backward_entropy": 0.0108119079044887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.25080108642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03954125568270683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09654437750577927,
      "backward_entropy": 0.01072438167674201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.690799713134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039593953639268875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09648048877716064,
      "backward_entropy": 0.010638788342475891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.47618103027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03964390978217125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09641849994659424,
      "backward_entropy": 0.01618954219988414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.59049224853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039696235209703445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09635461866855621,
      "backward_entropy": 0.016138346067496707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.07759857177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03974941372871399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09628961235284805,
      "backward_entropy": 0.0160833192723138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.43476867675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03980459272861481,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09622294455766678,
      "backward_entropy": 0.010317746017660414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.67775344848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039859838783741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09615616500377655,
      "backward_entropy": 0.01024484634399414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.4520034790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03991377726197243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0960899367928505,
      "backward_entropy": 0.010168383164065225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.353851318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03996960446238518,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09602201730012894,
      "backward_entropy": 0.01588804381234305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.41531372070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04002437740564346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09595473110675812,
      "backward_entropy": 0.01584333394254957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.24248504638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04008009657263756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09588651359081268,
      "backward_entropy": 0.009951619165284293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.50263977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04013657197356224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09581737220287323,
      "backward_entropy": 0.01576178627354758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.33209228515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04019281268119812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09574814885854721,
      "backward_entropy": 0.009816853063447135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.68617248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040248896926641464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09567879140377045,
      "backward_entropy": 0.009751953184604645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.49170684814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04030383378267288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09561007469892502,
      "backward_entropy": 0.009687589747565133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.74629974365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04035957157611847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09554031491279602,
      "backward_entropy": 0.009623887283461434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.66370391845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041694849729538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09546883404254913,
      "backward_entropy": 0.00956040301493236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.66790771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04047420620918274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0953972265124321,
      "backward_entropy": 0.009501362485545022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.61878967285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04053409397602081,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09532320499420166,
      "backward_entropy": 0.009445142533097948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.51630783081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04059164971113205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09525083750486374,
      "backward_entropy": 0.009390420147350855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.403167724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04064702242612839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09517998993396759,
      "backward_entropy": 0.015481482659067427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.8863410949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04070047289133072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09511047601699829,
      "backward_entropy": 0.009280941316059657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.43901062011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0407538115978241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09504054486751556,
      "backward_entropy": 0.009223468601703644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.55913543701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04080648347735405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09497088193893433,
      "backward_entropy": 0.009169632835047585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.20820617675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04085930064320564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09490065276622772,
      "backward_entropy": 0.009115920535155706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.88066864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04091621935367584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0948263630270958,
      "backward_entropy": 0.015361015285764421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.070899963378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040970999747514725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09475363790988922,
      "backward_entropy": 0.00901668518781662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.788612365722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04102584719657898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09468044340610504,
      "backward_entropy": 0.00896886842591422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.97708892822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04107976332306862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09460769593715668,
      "backward_entropy": 0.01530935721737998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.544952392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04113544896245003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09453271329402924,
      "backward_entropy": 0.01528823162828173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.331886291503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0411897636950016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09445846080780029,
      "backward_entropy": 0.00881801758493696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.275848388671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04124237969517708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09438545256853104,
      "backward_entropy": 0.008767396211624146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.13465118408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041295360773801804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0943116694688797,
      "backward_entropy": 0.008720777396644865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.048816680908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04134749621152878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09423821419477463,
      "backward_entropy": 0.015193109001432146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.83661651611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04139717295765877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09416680783033371,
      "backward_entropy": 0.008627355630908693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.5293960571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04144721105694771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09409445524215698,
      "backward_entropy": 0.00858022432242121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.5230827331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04149972274899483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0940190777182579,
      "backward_entropy": 0.008536096130098616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.12625122070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041552577167749405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09394286572933197,
      "backward_entropy": 0.01512226355927331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.60987091064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041607439517974854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09386397898197174,
      "backward_entropy": 0.008452047194753374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.39567565917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041666045784950256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09378065168857574,
      "backward_entropy": 0.008411027491092682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.874385833740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04172243922948837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09369919449090958,
      "backward_entropy": 0.008370678339685713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.709781646728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04177871346473694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09361729025840759,
      "backward_entropy": 0.008331284991332464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.80362319946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04183488339185715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0935349240899086,
      "backward_entropy": 0.015055718166487557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.38498306274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04189005494117737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09345310926437378,
      "backward_entropy": 0.008255768035139357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.53046417236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041945163160562515,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09337075799703598,
      "backward_entropy": 0.015036915029798235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.72507858276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04199957847595215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0932886153459549,
      "backward_entropy": 0.008185534604958125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.44451141357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042055003345012665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09320466220378876,
      "backward_entropy": 0.015033434544290816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.72754669189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0421140193939209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09311600029468536,
      "backward_entropy": 0.008119440504482814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.87411499023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042172711342573166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09302710741758347,
      "backward_entropy": 0.008087314133133208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.4748764038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042234715074300766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09293374419212341,
      "backward_entropy": 0.01503413702760424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.231201171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04229790344834328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09283839166164398,
      "backward_entropy": 0.008024474339825767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.53805923461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04236197471618652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09274137020111084,
      "backward_entropy": 0.007991430482694082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.74700164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04242239519953728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0926482230424881,
      "backward_entropy": 0.007958460599184036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.07670593261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04248402640223503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09255293011665344,
      "backward_entropy": 0.007924821227788925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.264493942260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04254579544067383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09245681017637253,
      "backward_entropy": 0.007889660873583384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.921695709228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04260414466261864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09236441552639008,
      "backward_entropy": 0.01501327965940748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.81298065185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04266133904457092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09227277338504791,
      "backward_entropy": 0.007824782814298357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.2142333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04272013157606125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09217840433120728,
      "backward_entropy": 0.007794100791215897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.19650650024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04278218373656273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09207922220230103,
      "backward_entropy": 0.007763777992555073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.84950637817383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042841628193855286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09198284894227982,
      "backward_entropy": 0.007733221564974103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.18754577636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04290148988366127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09188523888587952,
      "backward_entropy": 0.0077029503881931305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.24271774291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042959876358509064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09178894758224487,
      "backward_entropy": 0.007672239627156939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.558956146240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04301789402961731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0916924923658371,
      "backward_entropy": 0.007642356412751334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.04971694946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04307291656732559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09159953892230988,
      "backward_entropy": 0.007614723273686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.39035987854004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043128762394189835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09150472283363342,
      "backward_entropy": 0.007586645228522164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.49092102050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043181732296943665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0914134532213211,
      "backward_entropy": 0.014987735876015254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.61796569824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04323393478989601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09132259339094162,
      "backward_entropy": 0.007531369903257915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.18632507324219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04328904300928116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09122695028781891,
      "backward_entropy": 0.014979655189173562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.11927795410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04334232583642006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09113329648971558,
      "backward_entropy": 0.0074766650795936584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.95164108276367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04339743033051491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09103643894195557,
      "backward_entropy": 0.014970257878303528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.85934066772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04345161095261574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09094025194644928,
      "backward_entropy": 0.00742209968822343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.818389892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043504077941179276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0908460021018982,
      "backward_entropy": 0.007397271692752838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.651174545288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04355393350124359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09075526893138885,
      "backward_entropy": 0.007371752922024045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.95791625976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043602459132671356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09066601097583771,
      "backward_entropy": 0.007347364510808673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.590322494506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043654248118400574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09057110548019409,
      "backward_entropy": 0.014954298734664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.3458251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043703556060791016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09047958999872208,
      "backward_entropy": 0.01495038824422019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.86060333251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0437515527009964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09038960933685303,
      "backward_entropy": 0.007275277482611793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.367910385131836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04380016401410103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09029805660247803,
      "backward_entropy": 0.00725213172180312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.84545135498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04384666681289673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09020940959453583,
      "backward_entropy": 0.007230336644819805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.487489700317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0438966266810894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09011455625295639,
      "backward_entropy": 0.00720852826322828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.69491958618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043943483382463455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09002439677715302,
      "backward_entropy": 0.007188657564776284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.75594711303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04399290680885315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08992940187454224,
      "backward_entropy": 0.0071696144129548755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.655038833618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04404105246067047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.089835986495018,
      "backward_entropy": 0.0071519336530140466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.832557678222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044087979942560196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08974414318799973,
      "backward_entropy": 0.014950683074338096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.68447494506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04413564130663872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08965049684047699,
      "backward_entropy": 0.014953653727258955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.94871139526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044183917343616486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08955524861812592,
      "backward_entropy": 0.007098464029175895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.70000648498535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044231854379177094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08946017175912857,
      "backward_entropy": 0.007080565073660442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.24531173706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04427770525217056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08936833590269089,
      "backward_entropy": 0.007063096655266625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011469784192740917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04432431608438492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08927467465400696,
      "backward_entropy": 0.007045007177761623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.97382354736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04436632990837097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08918911963701248,
      "backward_entropy": 0.007028610046420779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.894710540771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044409558176994324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08910080790519714,
      "backward_entropy": 0.007013435874666486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.15570068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04445205628871918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08901333808898926,
      "backward_entropy": 0.006998381444386074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.13979721069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044496577233076096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08892165124416351,
      "backward_entropy": 0.006983132234641484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.621408462524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04454111307859421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08882950991392136,
      "backward_entropy": 0.014958641358784266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.911781311035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04458479955792427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08873850852251053,
      "backward_entropy": 0.006952810500349317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.080665588378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04462862387299538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0886467695236206,
      "backward_entropy": 0.006938397352184568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.351600646972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04467078298330307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08855777978897095,
      "backward_entropy": 0.006924631340163094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.20526885986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471235349774361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08846941590309143,
      "backward_entropy": 0.006911720548357282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.62928009033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044755980372428894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08837670087814331,
      "backward_entropy": 0.006898009883505958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.67288208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04480322450399399,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0882766991853714,
      "backward_entropy": 0.0149576621396201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.44536209106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04485457390546799,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08816854655742645,
      "backward_entropy": 0.00686714266027723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.64261245727539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044906146824359894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08805951476097107,
      "backward_entropy": 0.0068513282707759315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.127071380615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044955261051654816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08795499801635742,
      "backward_entropy": 0.01493623001234872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.29451370239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04500477761030197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08784931898117065,
      "backward_entropy": 0.014928046081747328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.94398498535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045056406408548355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0877390056848526,
      "backward_entropy": 0.006804821746689933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.428741455078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045109085738658905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0876261368393898,
      "backward_entropy": 0.0067890483353819165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.482147216796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04516005888581276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08751625567674637,
      "backward_entropy": 0.0067739273820604596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.26664352416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04521125927567482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08740544319152832,
      "backward_entropy": 0.01491247011082513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.10707664489746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045261774212121964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08729555457830429,
      "backward_entropy": 0.006744639149733952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.00355339050293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04531080648303032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08718834817409515,
      "backward_entropy": 0.006730959883758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.978340148925781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04535764455795288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08708520978689194,
      "backward_entropy": 0.006718529122216361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.76689147949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04540078341960907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.086989626288414,
      "backward_entropy": 0.006708086601325444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.721742630004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04544404521584511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08689314126968384,
      "backward_entropy": 0.006698964429753167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.539642333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04548653960227966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08679792284965515,
      "backward_entropy": 0.006692090736968177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.3111572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045529212802648544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08670181035995483,
      "backward_entropy": 0.006685488990374974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.171634674072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04557289928197861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08660298585891724,
      "backward_entropy": 0.006678781339100429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.191158294677734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045617491006851196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08650162816047668,
      "backward_entropy": 0.014907213194029672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.072601318359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045662034302949905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08640000224113464,
      "backward_entropy": 0.006664743913071496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.74406814575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04570653289556503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08629801869392395,
      "backward_entropy": 0.006658175161906651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.30014991760254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045751843601465225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08619378507137299,
      "backward_entropy": 0.006651543080806732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.71634292602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04579531401395798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08609326183795929,
      "backward_entropy": 0.006645868931497846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.91801452636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04583883658051491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08599207550287247,
      "backward_entropy": 0.006640425750187465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.16292190551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045887526124715805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08587893843650818,
      "backward_entropy": 0.00663322103875024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.670387268066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04593659192323685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08576447516679764,
      "backward_entropy": 0.006626099348068237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.568134307861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045984286814928055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08565261960029602,
      "backward_entropy": 0.006619693445307868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.468212127685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046030741184949875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08554323017597198,
      "backward_entropy": 0.006614067192588534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.778541564941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04607607424259186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08543600142002106,
      "backward_entropy": 0.014869606920651026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.98405456542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04611954838037491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08533274382352829,
      "backward_entropy": 0.00660507008433342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.26921081542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04616473615169525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08522488176822662,
      "backward_entropy": 0.014861378286566054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.60111999511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04621062055230141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08511481434106827,
      "backward_entropy": 0.006595746747085026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.487323760986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04625628516077995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08500489592552185,
      "backward_entropy": 0.006591566971370152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.944808006286621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046300046145915985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0848991870880127,
      "backward_entropy": 0.0065884095217500415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.79851722717285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04634123668074608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08479943871498108,
      "backward_entropy": 0.006586435117891857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.13818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04638179391622543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08470053970813751,
      "backward_entropy": 0.006584519254309791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.622297286987305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046422626823186874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08460065722465515,
      "backward_entropy": 0.014834030398300715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.384763717651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046462856233119965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08450175821781158,
      "backward_entropy": 0.014828684074538094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.45442008972168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046499982476234436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08441034704446793,
      "backward_entropy": 0.014824081744466509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.374385833740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046536870300769806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08431906998157501,
      "backward_entropy": 0.006577671106372561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.94047164916992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04657354950904846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08422785252332687,
      "backward_entropy": 0.006576780761991229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.51329803466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466117262840271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08413229882717133,
      "backward_entropy": 0.006575452429907662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.68841552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665040597319603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08403501659631729,
      "backward_entropy": 0.00657418104154723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.5572509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04669037461280823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08393390476703644,
      "backward_entropy": 0.014790937304496765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.65769958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046731509268283844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08382933586835861,
      "backward_entropy": 0.006570739937680108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.64110565185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046774499118328094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0837194174528122,
      "backward_entropy": 0.006567902863025665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.14352798461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04681578278541565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08361363410949707,
      "backward_entropy": 0.014757132955959864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.50383758544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04685806855559349,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08350472897291183,
      "backward_entropy": 0.014743618667125702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.86900329589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046898748725652695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08339974284172058,
      "backward_entropy": 0.0065604139651571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.97356414794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046940457075834274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08329156041145325,
      "backward_entropy": 0.0065576136112213135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.100846290588379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046984780579805374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08317588269710541,
      "backward_entropy": 0.006553867033549717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.300737380981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702559486031532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08306955546140671,
      "backward_entropy": 0.0065515243581363135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.36743927001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04706575348973274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08296459913253784,
      "backward_entropy": 0.01467015700680869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.17620086669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04710780829191208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08285395801067352,
      "backward_entropy": 0.006546244025230408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.019479751586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047150757163763046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08274037390947342,
      "backward_entropy": 0.006543051451444626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.93242835998535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719202220439911,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08263115584850311,
      "backward_entropy": 0.006541086626904351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.84271812438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04723256826400757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08252347260713577,
      "backward_entropy": 0.0065393176461969104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.816978454589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04727248474955559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08241716027259827,
      "backward_entropy": 0.014586444411958967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.49983215332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04731098189949989,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08231452107429504,
      "backward_entropy": 0.014570980199745722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.686933517456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0473506934940815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08220786601305008,
      "backward_entropy": 0.006536272487470082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.366559982299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04738901928067207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08210486173629761,
      "backward_entropy": 0.014539011887141637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.810752868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047427669167518616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08200047165155411,
      "backward_entropy": 0.006534186324902943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.31637954711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04746915027499199,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08188742399215698,
      "backward_entropy": 0.00653135244335447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.63825988769531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04750990495085716,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08177609741687775,
      "backward_entropy": 0.09900758096149989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.910966873168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04755242168903351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0816592201590538,
      "backward_entropy": 0.014456653169223241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.278167724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04759494215250015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08154180645942688,
      "backward_entropy": 0.006525106728076935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.94348907470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047635748982429504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.081429123878479,
      "backward_entropy": 0.006523811923606055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.854013442993164,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047675807029008865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08131830394268036,
      "backward_entropy": 0.099007214818682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.765541076660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047715239226818085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08120889961719513,
      "backward_entropy": 0.0065208471247128075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.67835235595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04775409400463104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08110080659389496,
      "backward_entropy": 0.0065200914229665485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.592300415039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047792427241802216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0809939056634903,
      "backward_entropy": 0.006519664078950882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.7559814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04783029481768608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08088795095682144,
      "backward_entropy": 0.006519772112369537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.62397766113281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04786939173936844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08077774941921234,
      "backward_entropy": 0.0065199993550777435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.48811721801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790959879755974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08066365122795105,
      "backward_entropy": 0.0065205565520695275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.23613929748535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04795077443122864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08054611086845398,
      "backward_entropy": 0.006520927484546389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.611568450927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799112305045128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08043080568313599,
      "backward_entropy": 0.006520409137010574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.545982360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04802999272942543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08031967282295227,
      "backward_entropy": 0.006521146212305341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.482452392578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04806745797395706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08021268993616104,
      "backward_entropy": 0.014192382139819009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.89097785949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04810374975204468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08010899275541306,
      "backward_entropy": 0.006523936454738889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.60763168334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048139773309230804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0800057128071785,
      "backward_entropy": 0.0065269917249679565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.721416473388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04817879572510719,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07989239692687988,
      "backward_entropy": 0.006529504699366433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.25712585449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0482172966003418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07978027313947678,
      "backward_entropy": 0.00653331247823579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.30665588378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04825851693749428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07965895533561707,
      "backward_entropy": 0.014108620584011078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.80595588684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04830048978328705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07953482866287231,
      "backward_entropy": 0.006537481078079769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.351755142211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834229126572609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07941097021102905,
      "backward_entropy": 0.006536701428038734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.5045166015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048383232206106186,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0792894959449768,
      "backward_entropy": 0.0990084069115775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.02094268798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04842656850814819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07915984094142914,
      "backward_entropy": 0.006535287946462631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.32026481628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048471223562955856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07902541756629944,
      "backward_entropy": 0.013981973486287253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.1939697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048515502363443375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0788918286561966,
      "backward_entropy": 0.013952197773115975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.436962127685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048559464514255524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0787588432431221,
      "backward_entropy": 0.01392402606351035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.577427864074707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04860071465373039,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0786345973610878,
      "backward_entropy": 0.013897471129894257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.00429344177246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04864032566547394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07851548492908478,
      "backward_entropy": 0.0065285515572343555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.72477912902832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04868082329630852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07839293777942657,
      "backward_entropy": 0.00652868886079107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.726633071899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04872129485011101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07826997339725494,
      "backward_entropy": 0.006528180624757495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.68195343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048762619495391846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07814361155033112,
      "backward_entropy": 0.013791978359222412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.50928497314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04880537465214729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07801197469234467,
      "backward_entropy": 0.006527184907879148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.063885688781738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048849526792764664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0778750330209732,
      "backward_entropy": 0.0065263914210455755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.17196273803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048890091478824615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07775036990642548,
      "backward_entropy": 0.006526167903627668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.007291793823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04893218353390694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07761994004249573,
      "backward_entropy": 0.006525134933846337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.914989471435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04897411912679672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07748952507972717,
      "backward_entropy": 0.0065250205142157415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.721906661987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04901505634188652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07736232876777649,
      "backward_entropy": 0.006524729409388134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.79965591430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049056679010391235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07723218202590942,
      "backward_entropy": 0.006524122719253812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.82735538482666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04909656569361687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07710786163806915,
      "backward_entropy": 0.006524168487106051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.549530029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04913412407040596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07699146866798401,
      "backward_entropy": 0.006525749606745583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.18494415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04917111620306969,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07687675952911377,
      "backward_entropy": 0.006527374897684369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.217702865600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04920925199985504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07675722241401672,
      "backward_entropy": 0.0065303923828261235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.472911834716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04924750700592995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0766368955373764,
      "backward_entropy": 0.006532421069485801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.59413528442383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928436130285263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07652127742767334,
      "backward_entropy": 0.006535201732601438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.569972038269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04932304471731186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07639852166175842,
      "backward_entropy": 0.00653722882270813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.54080581665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049359481781721115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07628372311592102,
      "backward_entropy": 0.006540143064090184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.486138343811035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04939696937799454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07616467773914337,
      "backward_entropy": 0.00654192002756255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.86676788330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04943230375647545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07605331391096115,
      "backward_entropy": 0.006544145622423717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.78860855102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0494672916829586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07594281435012817,
      "backward_entropy": 0.006547100841999054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.719627380371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04950188100337982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07583346962928772,
      "backward_entropy": 0.0065489645515169415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.624521255493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049538519233465195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07571595162153244,
      "backward_entropy": 0.006550970886434827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.910040855407715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049574606120586395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07560017704963684,
      "backward_entropy": 0.006552420556545258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.67861557006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049609508365392685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07548844814300537,
      "backward_entropy": 0.0065553901450974604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.787147521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04964558407664299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07537184655666351,
      "backward_entropy": 0.006557572100843702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.86602783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968049004673958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07525920122861862,
      "backward_entropy": 0.006561808288097382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.953128814697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04971577599644661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07514480501413345,
      "backward_entropy": 0.013081973152501243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.177467346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04975452274084091,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07501675188541412,
      "backward_entropy": 0.006567711276667458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.03893280029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04979404807090759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07488534599542618,
      "backward_entropy": 0.00657001936009952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.901334762573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983432963490486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07475054264068604,
      "backward_entropy": 0.006573336465018136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.760982513427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04987524077296257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07461293041706085,
      "backward_entropy": 0.012972704001835414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.322493553161621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04991668835282326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07447293400764465,
      "backward_entropy": 0.006579470953771046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.251934051513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04995633661746979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07433964312076569,
      "backward_entropy": 0.006582823182855334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.351112365722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04999442771077156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07421201467514038,
      "backward_entropy": 0.006588071584701538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.486377716064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05003328248858452,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07408109307289124,
      "backward_entropy": 0.012868598103523254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.086143493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500713512301445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07395291328430176,
      "backward_entropy": 0.00659643007176263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.63526725769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050110168755054474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07382143288850784,
      "backward_entropy": 0.006599566234009606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625998497009277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050148818641901016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07369047403335571,
      "backward_entropy": 0.006600106401102883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.864594459533691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050185151398181915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0735686868429184,
      "backward_entropy": 0.006601193653685706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.596336364746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0502200648188591,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07345245778560638,
      "backward_entropy": 0.012709113104002816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.964582443237305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0502590537071228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07331950217485428,
      "backward_entropy": 0.00659981369972229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.668155670166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05029725283384323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07318916916847229,
      "backward_entropy": 0.006600623684270042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.98653221130371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503339059650898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07306486368179321,
      "backward_entropy": 0.006601578422955104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.7147216796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050370655953884125,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07293982803821564,
      "backward_entropy": 0.09900690828050886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.770294189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05040665715932846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07281781733036041,
      "backward_entropy": 0.006600840815476009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.801271438598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050442952662706375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07269376516342163,
      "backward_entropy": 0.012495438967432295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24480152130127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05048007145524025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07256622612476349,
      "backward_entropy": 0.006602716233049121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.468597412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05051502212882042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07244730740785599,
      "backward_entropy": 0.006604115345648357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.36385154724121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05055011063814163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07232774794101715,
      "backward_entropy": 0.012385106512478419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.123614311218262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050585389137268066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07220713794231415,
      "backward_entropy": 0.006601216537611825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.16221046447754,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05061867833137512,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07209456712007523,
      "backward_entropy": 0.09900459221431188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.063690185546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0506523996591568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07197967171669006,
      "backward_entropy": 0.006601664636816297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.965227127075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05068653076887131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07186253368854523,
      "backward_entropy": 0.0066038040178162715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.835329055786133,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.050721023231744766,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07174339890480042,
      "backward_entropy": 0.09900426864624023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.767074584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050756506621837616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07161973416805267,
      "backward_entropy": 0.006610267928668431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.58930778503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05079212784767151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07149524241685867,
      "backward_entropy": 0.006612815495048251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.846662521362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050828609615564346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0713668167591095,
      "backward_entropy": 0.006614967648472104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8072991371154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050862912088632584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0712476372718811,
      "backward_entropy": 0.012072141681398665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.50430965423584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05089524760842323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07113678753376007,
      "backward_entropy": 0.006619093141385487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.581204414367676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050927210599184036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07102742046117783,
      "backward_entropy": 0.0066194747175489154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.013763427734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095814913511276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07092233002185822,
      "backward_entropy": 0.006619461945125035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.906700134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050990376621484756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07081128656864166,
      "backward_entropy": 0.006619370941604886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.576374053955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05102365463972092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07069559395313263,
      "backward_entropy": 0.006616869143077305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.128040313720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05105871334671974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07057176530361176,
      "backward_entropy": 0.006614708474704197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7900564670562744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109305679798126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07045121490955353,
      "backward_entropy": 0.006610191294125148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.97447681427002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051124706864356995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0703423023223877,
      "backward_entropy": 0.0066069141030311584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.90142822265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051155973225831985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07023507356643677,
      "backward_entropy": 0.09899930443082537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.823270797729492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05118688941001892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07012934982776642,
      "backward_entropy": 0.006594132099832807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.42244529724121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05121762678027153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07002408802509308,
      "backward_entropy": 0.006588232304368701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.676406860351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05124908685684204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0699148029088974,
      "backward_entropy": 0.006587486181940351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.961858749389648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05128035694360733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06980584561824799,
      "backward_entropy": 0.006588814514023917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.162023544311523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05131075531244278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06970040500164032,
      "backward_entropy": 0.00659255576985223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.467106819152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05134167894721031,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0695924460887909,
      "backward_entropy": 0.00659562594124249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.983078002929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05137234553694725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06948551535606384,
      "backward_entropy": 0.011404566466808319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.321995735168457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05140352621674538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06937602162361145,
      "backward_entropy": 0.0066003501415252686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.250579833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0514344684779644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06926732510328293,
      "backward_entropy": 0.011335021683147975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.250478744506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05146519094705582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06915923953056335,
      "backward_entropy": 0.011301543031420027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.590362548828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051497094333171844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06904581934213638,
      "backward_entropy": 0.006609436124563217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.537639617919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051527950912714005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06893689930438995,
      "backward_entropy": 0.01123318076133728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.965140342712402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05155918747186661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06882624328136444,
      "backward_entropy": 0.006613631333623614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.207862854003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051590096205472946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06871691346168518,
      "backward_entropy": 0.006614086351224354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.255638122558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05162417143583298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06859317421913147,
      "backward_entropy": 0.011114646281514848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.735715866088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05165836960077286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06846874207258224,
      "backward_entropy": 0.006610675581863948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.65450668334961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0516919307410717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06834712624549866,
      "backward_entropy": 0.006608877863202777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.351511001586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05172500014305115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06822740286588669,
      "backward_entropy": 0.006608766104493823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.874841690063477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05175889655947685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0681038647890091,
      "backward_entropy": 0.006607207868780408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.769489288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05179270729422569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06798101961612701,
      "backward_entropy": 0.006601561393056597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.66539192199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051826607435941696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.067857526242733,
      "backward_entropy": 0.006596253386565617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.87775230407715,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05186072736978531,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06773251295089722,
      "backward_entropy": 0.098993752683912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.18660831451416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189559608697891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06760390102863312,
      "backward_entropy": 0.006593271557773862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.105706214904785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05192975699901581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06747836619615555,
      "backward_entropy": 0.006592430706535067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.784253120422363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05196332931518555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06735528260469437,
      "backward_entropy": 0.006593412586620876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.18415069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05199563875794411,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06723795086145401,
      "backward_entropy": 0.006595212434019361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.922061920166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05202817544341087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06711934506893158,
      "backward_entropy": 0.006597413548401424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.988394737243652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052063748240470886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06698617339134216,
      "backward_entropy": 0.006601996719837189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.061683654785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052099235355854034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06685322523117065,
      "backward_entropy": 0.010566458106040955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.784976959228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052135176956653595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06671833246946335,
      "backward_entropy": 0.010533142302717482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.434035301208496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052170976996421814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06658373773097992,
      "backward_entropy": 0.00661343229668481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.368809700012207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0522051639854908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06645709276199341,
      "backward_entropy": 0.006615099098001208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.493718147277832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05223804712295532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06633628904819489,
      "backward_entropy": 0.0066186583467892236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.608558654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0522710345685482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06621481478214264,
      "backward_entropy": 0.006622213338102613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20165729522705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0523061640560627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0660829246044159,
      "backward_entropy": 0.006626291466610772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.143169403076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05233978480100632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.065958172082901,
      "backward_entropy": 0.0066298555050577435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.133283615112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05237207189202309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06583976000547409,
      "backward_entropy": 0.006633631352867399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.000076293945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052405945956707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06571321934461594,
      "backward_entropy": 0.006639829703739711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.915980339050293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052441757172346115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06557748466730118,
      "backward_entropy": 0.006644268653222493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.723772048950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05247735604643822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06544256210327148,
      "backward_entropy": 0.006649117384638105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.782794952392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05251404270529747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0653025358915329,
      "backward_entropy": 0.006653217864888055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.700959205627441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05254970118403435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0651673823595047,
      "backward_entropy": 0.006656687706708908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.633962631225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052584458142519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06503646820783615,
      "backward_entropy": 0.006660320929118565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.419487953186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05261819809675217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06491091847419739,
      "backward_entropy": 0.006659404507705143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.478509902954102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265188217163086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06478531658649445,
      "backward_entropy": 0.006659267204148429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.395145416259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052684709429740906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06466412544250488,
      "backward_entropy": 0.0066565168755395076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.328191757202148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052716922014951706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06454562395811081,
      "backward_entropy": 0.006655312010220119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.659313678741455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05274847522377968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06443028151988983,
      "backward_entropy": 0.006653197109699249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409847259521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05277809873223305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06432449817657471,
      "backward_entropy": 0.0066497741000992915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.13092041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052806612104177475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06422419846057892,
      "backward_entropy": 0.006644652890307563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.306316375732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05283472314476967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06412601470947266,
      "backward_entropy": 0.006636778690985271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.730992317199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052862007170915604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06403155624866486,
      "backward_entropy": 0.006631033761160714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.649168968200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052889831364154816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06393404304981232,
      "backward_entropy": 0.009680956602096558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7606778144836426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0529182031750679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0638333112001419,
      "backward_entropy": 0.006626216960804803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.810955047607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052944365888834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06374343484640121,
      "backward_entropy": 0.006625717239720481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.779834747314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052970509976148605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06365346163511276,
      "backward_entropy": 0.006626287209136146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.695895195007324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05299846827983856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06355445086956024,
      "backward_entropy": 0.006625474563666752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.339348316192627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05302608758211136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06345726549625397,
      "backward_entropy": 0.009477582361016954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.82745361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05305229127407074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06336675584316254,
      "backward_entropy": 0.006622230368001121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.501302719116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05307969078421593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06327017396688461,
      "backward_entropy": 0.006622010043689183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852284908294678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053107064217329025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06317316740751266,
      "backward_entropy": 0.006626262728657041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.384465217590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05313355475664139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06308053433895111,
      "backward_entropy": 0.006629397294351033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750132083892822,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316003039479256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06298772990703583,
      "backward_entropy": 0.006634937865393502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.494064331054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05318600311875343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06289659440517426,
      "backward_entropy": 0.009280573044504439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.214265823364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05321434140205383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06279394030570984,
      "backward_entropy": 0.006654869765043259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.152626991271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05324229225516319,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06269341707229614,
      "backward_entropy": 0.009226668093885695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.115196228027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532698854804039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06259468197822571,
      "backward_entropy": 0.006665012666157314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.49589729309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05329981446266174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06248413026332855,
      "backward_entropy": 0.006670542061328888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5302038192749023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053331125527620316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06236668676137924,
      "backward_entropy": 0.0066755616239139014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.968359470367432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05335994064807892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06226179003715515,
      "backward_entropy": 0.006680880806275776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.832504272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05338720977306366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0621643140912056,
      "backward_entropy": 0.006688299987997327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.48401641845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053414180874824524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06206841766834259,
      "backward_entropy": 0.006694097604070391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.527088165283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344341695308685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06196107342839241,
      "backward_entropy": 0.006699458828994206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64022445678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05347351357340813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06184925511479378,
      "backward_entropy": 0.00899766172681536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.950824737548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05350307747721672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061739999800920486,
      "backward_entropy": 0.006713064653532845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.519439697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05353284999728203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06162945181131363,
      "backward_entropy": 0.09900033473968506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.139338493347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053561966866254807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06152249127626419,
      "backward_entropy": 0.006726300077778953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.38471031188965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05359191447496414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061411287635564804,
      "backward_entropy": 0.006732249898569924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.884418487548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0536230131983757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0612945482134819,
      "backward_entropy": 0.006734474429062435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.54671859741211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05365651845932007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06116578355431557,
      "backward_entropy": 0.0067375334245818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.727426528930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053689584136009216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06103963777422905,
      "backward_entropy": 0.006737370576177325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.826755046844482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053722966462373734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06091197580099106,
      "backward_entropy": 0.00875999459198543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.037075996398926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0537550151348114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06079038232564926,
      "backward_entropy": 0.006742224097251892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970159530639648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053786154836416245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060673754662275314,
      "backward_entropy": 0.006744251187358584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4722137451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05381646752357483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060561686754226685,
      "backward_entropy": 0.006743530077593667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.448671340942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05384504795074463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06045793741941452,
      "backward_entropy": 0.008633252765451158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.325420379638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05387195944786072,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06036260724067688,
      "backward_entropy": 0.008601298821823937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.890567779541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053900204598903656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06026087701320648,
      "backward_entropy": 0.006747467177254813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.96211051940918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392845347523689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060159504413604736,
      "backward_entropy": 0.00674337734069143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.590266227722168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05395730957388878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06005518510937691,
      "backward_entropy": 0.0067371465265750885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.295558452606201,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053985707461833954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05995291471481323,
      "backward_entropy": 0.006733795361859458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.790956497192383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054012481123209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05985865741968155,
      "backward_entropy": 0.00673221583877291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.23695182800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05404062196612358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059757642447948456,
      "backward_entropy": 0.006729744374752045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1377146244049072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054067157208919525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0596645250916481,
      "backward_entropy": 0.006729323949132647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.44149112701416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05409161001443863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05958205461502075,
      "backward_entropy": 0.006729428257261004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.342217445373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05411692336201668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05949557200074196,
      "backward_entropy": 0.006725333631038666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.162264347076416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05414329841732979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059403225779533386,
      "backward_entropy": 0.0067250462515013555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.17902946472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05416879802942276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059315234422683716,
      "backward_entropy": 0.006726138825927462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.07681131362915,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054195284843444824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05922197550535202,
      "backward_entropy": 0.006729579929794584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.026260375976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05422024428844452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05913649499416351,
      "backward_entropy": 0.006732411150421415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.959465980529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05424560233950615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0590488463640213,
      "backward_entropy": 0.006736453090395246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922365665435791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054271310567855835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05895935744047165,
      "backward_entropy": 0.006741370473589216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.825167655944824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429680645465851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058870650827884674,
      "backward_entropy": 0.006748247359480176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757728576660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05432262271642685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05878021568059921,
      "backward_entropy": 0.008016777357884817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06000329926609993,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05434871464967728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05868830531835556,
      "backward_entropy": 0.006763036229780742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.88215970993042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054372236132621765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05860944837331772,
      "backward_entropy": 0.006771601736545563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6651458740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054394643753767014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05853601545095444,
      "backward_entropy": 0.006782788783311844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.837873697280884,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05441712960600853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.058461762964725494,
      "backward_entropy": 0.007927074496235167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.331008911132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054438553750514984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05839270353317261,
      "backward_entropy": 0.006808578968048096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7922351360321045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05446130037307739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05831659585237503,
      "backward_entropy": 0.006823400833777019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346964836120605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054482944309711456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058245949447155,
      "backward_entropy": 0.006838884204626083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.274113655090332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05450517684221268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058172378689050674,
      "backward_entropy": 0.006852085036890847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.06700611114502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452815070748329,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05809424817562103,
      "backward_entropy": 0.006868947829519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.976944923400879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054552096873521805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058011457324028015,
      "backward_entropy": 0.006882603679384504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.489810466766357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05457712709903717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0579226016998291,
      "backward_entropy": 0.006899091814245496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.841316223144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05460125580430031,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057838525623083115,
      "backward_entropy": 0.007797781910215106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191362380981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05462624132633209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05775023251771927,
      "backward_entropy": 0.0069241103317056385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6048622131347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05465095490217209,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057663168758153915,
      "backward_entropy": 0.007759360862629754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.109326362609863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054674241691827774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05758354067802429,
      "backward_entropy": 0.006944701075553894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.309968948364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054697226732969284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05750597268342972,
      "backward_entropy": 0.006948897881167275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.800066590309143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054719436913728714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057432565838098526,
      "backward_entropy": 0.006950215037379946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.96186637878418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473989248275757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05736824870109558,
      "backward_entropy": 0.006950076137270246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.624086380004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476045981049538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057303108274936676,
      "backward_entropy": 0.00761203042098454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.173124313354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478179454803467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057233408093452454,
      "backward_entropy": 0.0069532522133418494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.605733871459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054802585393190384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0571664460003376,
      "backward_entropy": 0.006955903023481369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7418862581253052,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054825637489557266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05708776414394379,
      "backward_entropy": 0.006959155201911926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.403803825378418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05484688654541969,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05701831728219986,
      "backward_entropy": 0.00696176290512085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.361977577209473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05486702919006348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056954603642225266,
      "backward_entropy": 0.006963405225958143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.660068511962891,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054887838661670685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05688732862472534,
      "backward_entropy": 0.00696534024817603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6900947093963623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054908689111471176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05681969225406647,
      "backward_entropy": 0.006967147546155112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.839303970336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05492806062102318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05675927922129631,
      "backward_entropy": 0.0069716327956744605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76217269897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05494867265224457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0566924586892128,
      "backward_entropy": 0.006975693362099784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6646151542663574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054970577359199524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05661828815937042,
      "backward_entropy": 0.00698427323784147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4589738845825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499081686139107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05655265226960182,
      "backward_entropy": 0.0069927578525883815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.837128162384033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05501105263829231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0564873069524765,
      "backward_entropy": 0.0069984761731965205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05346086248755455,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05503065884113312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056425806134939194,
      "backward_entropy": 0.006999128631183079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.774323463439941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05504831299185753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.056374065577983856,
      "backward_entropy": 0.007231817181621279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1875314712524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055065661668777466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056324124336242676,
      "backward_entropy": 0.007000034408909934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.276875019073486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05508219078183174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0562785342335701,
      "backward_entropy": 0.006996507623365947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.693171977996826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05509903281927109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.056231629103422165,
      "backward_entropy": 0.007126663944550923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.65669059753418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511568859219551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05618567019701004,
      "backward_entropy": 0.0069836947534765515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.225111961364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05513232201337814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05613920837640762,
      "backward_entropy": 0.0069805314498288295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.132170677185059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515037104487419,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05608546733856201,
      "backward_entropy": 0.006977078637906483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.100188255310059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055168651044368744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05603049695491791,
      "backward_entropy": 0.006973626890352794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0562615394592285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05518706887960434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05597502738237381,
      "backward_entropy": 0.006968333785023008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.531479358673096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05520464479923248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055923812091350555,
      "backward_entropy": 0.006963390324796949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95199966430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522196367383003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05587388575077057,
      "backward_entropy": 0.00695863738656044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.429590225219727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524064600467682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05581676959991455,
      "backward_entropy": 0.006955409688608987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.91331672668457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525991693139076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055756889283657074,
      "backward_entropy": 0.006950033562523978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.685851097106934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05527925863862038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05569671839475632,
      "backward_entropy": 0.006944441369601658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.380105972290039,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055300839245319366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05562476068735123,
      "backward_entropy": 0.09898349217006139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.219014644622803,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055321864783763885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05555541068315506,
      "backward_entropy": 0.006943918764591217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7377610206604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05534336715936661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05548346787691116,
      "backward_entropy": 0.006946798946176257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.704275608062744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05536487326025963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05541113018989563,
      "backward_entropy": 0.006953614630869457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8491125106811523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538623407483101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055339597165584564,
      "backward_entropy": 0.006960049803767886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.400798797607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0554065927863121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055272869765758514,
      "backward_entropy": 0.0069699473679065704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341322898864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055428050458431244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05520015209913254,
      "backward_entropy": 0.006982872528689248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.794194459915161,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0554504469037056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0551225021481514,
      "backward_entropy": 0.006997322397572654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.127749919891357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05547161027789116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05505127087235451,
      "backward_entropy": 0.007010999002626964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1031951904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055492278188467026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05498218536376953,
      "backward_entropy": 0.007027481283460345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.757501602172852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05551241710782051,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054915640503168106,
      "backward_entropy": 0.007044405809470585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.051017761230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05553309619426727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05484610050916672,
      "backward_entropy": 0.007062364369630814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.663658142089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055554624646902084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0547725111246109,
      "backward_entropy": 0.007077495966638837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9347100257873535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05557645857334137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05469737946987152,
      "backward_entropy": 0.007091454097202846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.649641752243042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05559892579913139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054619573056697845,
      "backward_entropy": 0.007100383618048259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3478994369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05562016740441322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05454779788851738,
      "backward_entropy": 0.0071101029004369464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.608438491821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05563968047499657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05448511615395546,
      "backward_entropy": 0.0071168871862547734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.139066696166992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055658284574747086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05442655831575394,
      "backward_entropy": 0.007125471319471087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3827643394470215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05567704141139984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054366886615753174,
      "backward_entropy": 0.007135640297617231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.100996494293213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05569624900817871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05430516600608826,
      "backward_entropy": 0.007142610315765653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.792292356491089,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05571513995528221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054246142506599426,
      "backward_entropy": 0.007139937686068671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7660627365112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055733561515808105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05418940633535385,
      "backward_entropy": 0.0071371447827134815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7260899543762207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055751558393239975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05413466691970825,
      "backward_entropy": 0.00713431675519262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.718353271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05576935037970543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05408014729619026,
      "backward_entropy": 0.00713682866522244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.340077877044678,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05578674003481865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0540277436375618,
      "backward_entropy": 0.09900006226130895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495112419128418,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05580514296889305,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05397047474980354,
      "backward_entropy": 0.09899946621486119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032283306121826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05582491308450699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053906604647636414,
      "backward_entropy": 0.007131382290806089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.799810886383057,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05584502965211868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053841207176446915,
      "backward_entropy": 0.007126360599483762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.767858028411865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055864956229925156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05377668887376785,
      "backward_entropy": 0.007120275071689061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059163570404053,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05588464066386223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05371386557817459,
      "backward_entropy": 0.0071119362754481176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2020570039749146,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05590515211224556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05364682525396347,
      "backward_entropy": 0.007105730473995209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.792516708374023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05592414736747742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05358714610338211,
      "backward_entropy": 0.007103543728590012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.476202964782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05594364553689957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05352456867694855,
      "backward_entropy": 0.00710490665265492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.70415735244751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055962517857551575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053465381264686584,
      "backward_entropy": 0.007105183920689991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.418203830718994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055981893092393875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05340331047773361,
      "backward_entropy": 0.0071088990994862145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.09135913848877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056000713258981705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053344033658504486,
      "backward_entropy": 0.007113381155899593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.685649394989014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056021660566329956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05327460169792175,
      "backward_entropy": 0.007114462022270475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.705464839935303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05604318156838417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05320265144109726,
      "backward_entropy": 0.007114446588924953,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.33605329439044,
    "avg_log_Z": -0.055044650919735434,
    "success_rate": 1.0,
    "avg_reward": 81.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.07,
      "2": 0.9
    },
    "avg_forward_entropy": 0.05642916079610586,
    "avg_backward_entropy": 0.009764713634337696,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}