{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13736608028411865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13750041723251344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 312.84442138671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13768308162689208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 296.2041320800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277964989344278,
      "backward_entropy": 0.1375080943107605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 296.13958740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019973141024820507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279472986857095,
      "backward_entropy": 0.13751530647277832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.50750732421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00029940472450107336,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280988931655884,
      "backward_entropy": 0.13774532079696655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.88323974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039863717393018305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282445271809897,
      "backward_entropy": 0.1375288724899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 295.94171142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004971098969690502,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18283861875534058,
      "backward_entropy": 0.13740859031677247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.76519775390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005960414418950677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285250663757324,
      "backward_entropy": 0.1378028631210327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.2577819824219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006943659391254187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286595741907755,
      "backward_entropy": 0.13754708766937257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.61810302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007927730912342668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287907044092813,
      "backward_entropy": 0.13743152618408203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.1319580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008912138873711228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289180596669516,
      "backward_entropy": 0.13755829334259034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.9146423339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0009897254640236497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829041838645935,
      "backward_entropy": 0.13756370544433594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 246.3526611328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010882229544222355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291616439819336,
      "backward_entropy": 0.13756880760192872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.91651916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011856473283842206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292768796284994,
      "backward_entropy": 0.1374600887298584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.75619506835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012816594680771232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829387148221334,
      "backward_entropy": 0.13746626377105714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.86773681640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013757487758994102,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829492449760437,
      "backward_entropy": 0.13747177124023438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.8141632080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014702518237754703,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829595367113749,
      "backward_entropy": 0.1379535675048828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.34315490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0015632073627784848,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829694906870524,
      "backward_entropy": 0.13796801567077638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 311.66473388671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016549109714105725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829790472984314,
      "backward_entropy": 0.13798182010650634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.4754943847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001749043702147901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298840522766113,
      "backward_entropy": 0.13759678602218628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 295.8570251464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018435403471812606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299738566080728,
      "backward_entropy": 0.1374964952468872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.58041381835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019394585397094488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830060879389445,
      "backward_entropy": 0.13802357912063598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 278.79559326171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020350106060504913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301417430241904,
      "backward_entropy": 0.1376094102859497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 245.31201171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0021313391625881195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302162488301596,
      "backward_entropy": 0.13751139640808105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 296.43170166015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022271531634032726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830286979675293,
      "backward_entropy": 0.13751528263092042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.86386108398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023241760209202766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303545316060385,
      "backward_entropy": 0.13751935958862305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.2112731933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002420022152364254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304173151652017,
      "backward_entropy": 0.13762519359588624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.82286071777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002516123466193676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304771184921265,
      "backward_entropy": 0.13752641677856445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026119048707187176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830532749493917,
      "backward_entropy": 0.1376330614089966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.29669189453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027060064021497965,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18305840094884238,
      "backward_entropy": 0.13812041282653809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 277.4483337402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002800470218062401,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306306997934976,
      "backward_entropy": 0.138131046295166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.92124938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028960672207176685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306724230448404,
      "backward_entropy": 0.13764281272888185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.29953002929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029898257926106453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307097752888998,
      "backward_entropy": 0.13764538764953613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.94004821777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0030814893543720245,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18307435512542725,
      "backward_entropy": 0.138161039352417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.8606719970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0031710444018244743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307729562123617,
      "backward_entropy": 0.1376490354537964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.7237854003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003261096077039838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18307989835739136,
      "backward_entropy": 0.13817932605743408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.29759216308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033530155196785927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308218320210776,
      "backward_entropy": 0.13818840980529784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.1185760498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034444283228367567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830841302871704,
      "backward_entropy": 0.137548565864563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035360967740416527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830856998761495,
      "backward_entropy": 0.13765554428100585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.72325134277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0036273100413382053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183086891969045,
      "backward_entropy": 0.137656831741333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.23541259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003718192921951413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308770656585693,
      "backward_entropy": 0.1376580238342285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.7262420654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0038100704550743103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830881436665853,
      "backward_entropy": 0.13755300045013427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.26318359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003899061819538474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308818340301514,
      "backward_entropy": 0.13755321502685547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.81497192382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003988601732999086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308784564336142,
      "backward_entropy": 0.13766138553619384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.9923553466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004076546523720026,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308715025583902,
      "backward_entropy": 0.13825222253799438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.0926513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0041650733910501,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308605750401816,
      "backward_entropy": 0.13825900554656984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 295.40155029296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004253394901752472,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308454751968384,
      "backward_entropy": 0.1382656216621399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.8936004638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004344412591308355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308260043462118,
      "backward_entropy": 0.13755537271499635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.09999084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00443349638953805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308027585347494,
      "backward_entropy": 0.13755608797073365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 309.93115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004521572031080723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307755390803018,
      "backward_entropy": 0.13755651712417602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.1612091064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004613413941115141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307437499364218,
      "backward_entropy": 0.1375575065612793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 292.96368408203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004704077262431383,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18307077884674072,
      "backward_entropy": 0.1382976531982422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.4580841064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004797537345439196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.183066725730896,
      "backward_entropy": 0.13755918741226197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.98240661621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0048904684372246265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306227525075278,
      "backward_entropy": 0.13766205310821533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.8474884033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004979644436389208,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18305768569310507,
      "backward_entropy": 0.13766170740127565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.4942321777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005065913777798414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830528179804484,
      "backward_entropy": 0.13766076564788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5006561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0051540592685341835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18304749329884848,
      "backward_entropy": 0.13766061067581176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.39285278320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00524209626019001,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304179112116495,
      "backward_entropy": 0.13833422660827638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.72190856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005329463630914688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303571144739786,
      "backward_entropy": 0.13755894899368287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.59158325195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005417104810476303,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302921454111734,
      "backward_entropy": 0.13834552764892577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.66285705566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005502982530742884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830223798751831,
      "backward_entropy": 0.13765783309936525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.24583435058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005588389001786709,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301514784495035,
      "backward_entropy": 0.13835604190826417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.12794494628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005672496277838945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300755818684897,
      "backward_entropy": 0.13836100101470947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.0134582519531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005757962353527546,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829995115598043,
      "backward_entropy": 0.13836597204208373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.04586791992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005845572333782911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829909086227417,
      "backward_entropy": 0.13755385875701903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.8274230957031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005932642612606287,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829822063446045,
      "backward_entropy": 0.13837604522705077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.06263732910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006022612564265728,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297292788823447,
      "backward_entropy": 0.1383812189102173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.6015319824219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0061134761199355125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829631725947062,
      "backward_entropy": 0.13838636875152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.8697204589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0062057930044829845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295286099116007,
      "backward_entropy": 0.1375516414642334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.37303161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006299674045294523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294199307759604,
      "backward_entropy": 0.13764820098876954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.4027862548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006392435636371374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293078740437826,
      "backward_entropy": 0.1375514030456543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.3450622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00648323493078351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291924397150675,
      "backward_entropy": 0.1376476526260376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.55517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006575532723218203,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829071044921875,
      "backward_entropy": 0.13755013942718505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.7987365722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006665704771876335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289450804392496,
      "backward_entropy": 0.13764650821685792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.51139831542969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006757534109055996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828810771306356,
      "backward_entropy": 0.13842053413391114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.61875915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0068438174203038216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828674872716268,
      "backward_entropy": 0.1375466465950012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.0783996582031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006930500268936157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18285328149795532,
      "backward_entropy": 0.13764313459396363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.74534606933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007020259276032448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283820152282715,
      "backward_entropy": 0.13843233585357667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.2722930908203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00710745295509696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828228235244751,
      "backward_entropy": 0.13843605518341065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.26284790039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007194827776402235,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280680974324545,
      "backward_entropy": 0.1384397029876709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.6068878173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007283490151166916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279008070627847,
      "backward_entropy": 0.1376331090927124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.01097106933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007371500600129366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827727953592936,
      "backward_entropy": 0.13762924671173096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007458231411874294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827551325162252,
      "backward_entropy": 0.13762505054473878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.1520233154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0075436001643538475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273703257242838,
      "backward_entropy": 0.137620210647583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.35464477539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007627757266163826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18271847565968832,
      "backward_entropy": 0.1376147985458374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.6730194091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007708483375608921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826998790105184,
      "backward_entropy": 0.13752322196960448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.0512237548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007790012750774622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826805075009664,
      "backward_entropy": 0.13751940727233886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.05735778808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00787335354834795,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18266026178995767,
      "backward_entropy": 0.13846476078033448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.8852996826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007957693189382553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18263928095499674,
      "backward_entropy": 0.13759250640869142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.90029907226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008040973916649818,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261786301930746,
      "backward_entropy": 0.13847017288208008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.6986541748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008121448568999767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825962464014689,
      "backward_entropy": 0.13750357627868653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2231903076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008203120902180672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257377545038858,
      "backward_entropy": 0.13757290840148925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3275909423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008282081224024296,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18255086739857992,
      "backward_entropy": 0.13847713470458983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.9879150390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008362657390534878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825269858042399,
      "backward_entropy": 0.13755967617034912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.61802673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00844634510576725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250183264414468,
      "backward_entropy": 0.13748738765716553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.8960418701172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008529909886419773,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18247528870900473,
      "backward_entropy": 0.1384835124015808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.9798889160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00861368328332901,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824477513631185,
      "backward_entropy": 0.13848572969436646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.46949768066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008701187558472157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824186642964681,
      "backward_entropy": 0.13753900527954102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.3258514404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008788995444774628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238898118336996,
      "backward_entropy": 0.13753417730331421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.6568603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008877462707459927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18235830465952554,
      "backward_entropy": 0.13752961158752441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.593017578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00896445382386446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18232699235280356,
      "backward_entropy": 0.13849581480026246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.9609832763672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009050128050148487,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18229504426320395,
      "backward_entropy": 0.1384982466697693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 274.9278259277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009137367829680443,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822618047396342,
      "backward_entropy": 0.1385008215904236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.82398986816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009227588772773743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18222691615422568,
      "backward_entropy": 0.13747166395187377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 289.2718811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009313192218542099,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821921467781067,
      "backward_entropy": 0.13746905326843262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 289.9980773925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009403186850249767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18215545018513998,
      "backward_entropy": 0.13746743202209472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.89202880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009496929123997688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821169058481852,
      "backward_entropy": 0.1374666929244995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.21304321289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009593229740858078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820767323176066,
      "backward_entropy": 0.1374664068222046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.80722045898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009690179489552975,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820354461669922,
      "backward_entropy": 0.13851673603057862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.87635803222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009785013273358345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18199376265207926,
      "backward_entropy": 0.13749446868896484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.16470336914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00987971667200327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18195112546284994,
      "backward_entropy": 0.1374921441078186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.83116149902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009971247985959053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18190828959147134,
      "backward_entropy": 0.1374614953994751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.07339477539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010060993954539299,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18186493714650473,
      "backward_entropy": 0.13748490810394287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 272.5983581542969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010150275193154812,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818207303682963,
      "backward_entropy": 0.1385287880897522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.2472381591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010242573916912079,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18177461624145508,
      "backward_entropy": 0.13745348453521727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.73497009277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010332267731428146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18172828356424967,
      "backward_entropy": 0.13747353553771974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.3466033935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010423130355775356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18168052037556967,
      "backward_entropy": 0.13746945858001708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8867645263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010516067035496235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18163100878397623,
      "backward_entropy": 0.13744441270828248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.70205688476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010603930801153183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158201376597086,
      "backward_entropy": 0.13745996952056885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.8761444091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01069251261651516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18153178691864014,
      "backward_entropy": 0.1374343991279602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.83755493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010783275589346886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18147969245910645,
      "backward_entropy": 0.1374495506286621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.35362243652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01087159849703312,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814273993174235,
      "backward_entropy": 0.13854403495788575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.0967559814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010959632694721222,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181374192237854,
      "backward_entropy": 0.13854556083679198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.69064331054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01104725617915392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181319793065389,
      "backward_entropy": 0.13741142749786378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.51864624023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01113236602395773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812643607457479,
      "backward_entropy": 0.137404465675354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.0840606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01121746189892292,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18120749791463217,
      "backward_entropy": 0.13739728927612305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.9268035888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011303619481623173,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18114892641703287,
      "backward_entropy": 0.13855056762695311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.51553344726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011392519809305668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18108793099721274,
      "backward_entropy": 0.13738341331481935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.7193603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011479360982775688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18102657794952393,
      "backward_entropy": 0.13737590312957765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.33177185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011565116234123707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1809644103050232,
      "backward_entropy": 0.13739268779754638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.94088745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011648129671812057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18090224266052246,
      "backward_entropy": 0.13735885620117189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.80459594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011729370802640915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18083953857421875,
      "backward_entropy": 0.13734909296035766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.10667419433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011813854798674583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18077407280604044,
      "backward_entropy": 0.13733994960784912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.16207885742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011901160702109337,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18070594469706217,
      "backward_entropy": 0.1385575771331787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.4679718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011990174651145935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18063567082087198,
      "backward_entropy": 0.13732300996780394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.9125213623047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012081612832844257,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18056287368138632,
      "backward_entropy": 0.13855962753295897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.2584991455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012169749476015568,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18049047390619913,
      "backward_entropy": 0.13730232715606688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.15525817871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012258452363312244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804161270459493,
      "backward_entropy": 0.1372898817062378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 251.35452270507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01234766747802496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18033987283706665,
      "backward_entropy": 0.1372770309448242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012439624406397343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18026085694630942,
      "backward_entropy": 0.1372896671295166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.20863342285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012529928237199783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1801812251408895,
      "backward_entropy": 0.13727725744247438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.72988891601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012615079060196877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18010266621907553,
      "backward_entropy": 0.13726334571838378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 284.8103332519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012701124884188175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18002204100290933,
      "backward_entropy": 0.1372491478919983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.81883239746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012791816145181656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799372434616089,
      "backward_entropy": 0.1372028946876526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.93617248535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012880987487733364,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17985141277313232,
      "backward_entropy": 0.13856585025787355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.95925903320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01296573132276535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17976613839467367,
      "backward_entropy": 0.1372058629989624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.76010131835938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013050500303506851,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17967901627222696,
      "backward_entropy": 0.13856632709503175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.302978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013134119100868702,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17959064245224,
      "backward_entropy": 0.1371300220489502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.84986877441406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013216190040111542,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17950169245402017,
      "backward_entropy": 0.13856632709503175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.46852111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013296540826559067,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17941204706827799,
      "backward_entropy": 0.13708775043487548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.39866638183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013376212678849697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17932099103927612,
      "backward_entropy": 0.13711297512054443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.26255798339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013449767604470253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792327562967936,
      "backward_entropy": 0.1370908498764038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.55262756347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013521946035325527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17914408445358276,
      "backward_entropy": 0.13706858158111573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.86581420898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01359463669359684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17905346552530924,
      "backward_entropy": 0.1370462417602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.8351821899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013667714782059193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17896093924840292,
      "backward_entropy": 0.1369610071182251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.0184783935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013734973967075348,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1788710355758667,
      "backward_entropy": 0.13693222999572754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.48110961914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013802312314510345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17877958218256632,
      "backward_entropy": 0.13696756362915039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.01353454589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013872437179088593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17868431409200033,
      "backward_entropy": 0.13687357902526856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.26864624023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013941316865384579,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1785884698232015,
      "backward_entropy": 0.13690840005874633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.954833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014014052227139473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17848811546961466,
      "backward_entropy": 0.13681404590606688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.99758911132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014090080745518208,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17838348944981894,
      "backward_entropy": 0.13678537607192992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.08639526367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014166047796607018,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17827709515889487,
      "backward_entropy": 0.13855571746826173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.97242736816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014244131743907928,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17816738287607828,
      "backward_entropy": 0.1385548949241638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.6140899658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0143213402479887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17805707454681396,
      "backward_entropy": 0.13669596910476683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.7244110107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014402355998754501,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17794179916381836,
      "backward_entropy": 0.13855364322662353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.6457977294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014484207145869732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17782431840896606,
      "backward_entropy": 0.13663630485534667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.0576171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014565606601536274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.177705446879069,
      "backward_entropy": 0.13855137825012206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9157257080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014643699862062931,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775877277056376,
      "backward_entropy": 0.1366466760635376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.57362365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014720058999955654,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17746996879577637,
      "backward_entropy": 0.1385478973388672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.53684997558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014795491471886635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17735111713409424,
      "backward_entropy": 0.13650431632995605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.6135711669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014869296923279762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17723204692204794,
      "backward_entropy": 0.13654618263244628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 279.64666748046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014944391325116158,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17710975805918375,
      "backward_entropy": 0.13854135274887086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.7628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015025898814201355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17697997887929282,
      "backward_entropy": 0.13639624118804933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.92323303222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015107821673154831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1768476366996765,
      "backward_entropy": 0.1364449977874756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.8151092529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01519125048071146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17671183745066324,
      "backward_entropy": 0.13641135692596434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.7100067138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015274290926754475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17657466729482016,
      "backward_entropy": 0.13637726306915282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.5051727294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015360105782747269,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17643354336420694,
      "backward_entropy": 0.13625612258911132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.68942260742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01544432993978262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17629235982894897,
      "backward_entropy": 0.13852987289428711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.4293212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015528799965977669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17614843448003134,
      "backward_entropy": 0.13627842664718628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.11962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01561058685183525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1760051647822062,
      "backward_entropy": 0.13624143600463867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.1038360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0156897883862257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1758622924486796,
      "backward_entropy": 0.13609640598297118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.92837524414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015770992264151573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1757153868675232,
      "backward_entropy": 0.13616299629211426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.60035705566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0158510934561491,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17556790510813394,
      "backward_entropy": 0.1361239194869995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.08448791503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015923617407679558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17542676130930582,
      "backward_entropy": 0.13595998287200928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.70797729492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015996815636754036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17528303464253744,
      "backward_entropy": 0.1359098434448242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.4153594970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016072401776909828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17513438065846762,
      "backward_entropy": 0.13597896099090576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.74818420410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01614801399409771,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1749833027521769,
      "backward_entropy": 0.13592878580093384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.30960083007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01622302643954754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17483113209406534,
      "backward_entropy": 0.13587751388549804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.91770935058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01629929430782795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1746753454208374,
      "backward_entropy": 0.1357055902481079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.6155776977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016377927735447884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1745150089263916,
      "backward_entropy": 0.13577457666397094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.6439971923828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016452696174383163,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17435785134633383,
      "backward_entropy": 0.1384918212890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.82362365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01653210073709488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1741934816042582,
      "backward_entropy": 0.1384892225265503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.09063720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016611352562904358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17402708530426025,
      "backward_entropy": 0.13562146425247193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.3068389892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016686055809259415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1738638679186503,
      "backward_entropy": 0.13556466102600098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.7122802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01675802655518055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17370212078094482,
      "backward_entropy": 0.13550411462783812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.10079956054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016831953078508377,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17353634039560953,
      "backward_entropy": 0.138474440574646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.52772521972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016903232783079147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17337199052174887,
      "backward_entropy": 0.13525514602661132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.893310546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016975127160549164,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17320466041564941,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.86131286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017044587060809135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17303860187530518,
      "backward_entropy": 0.13525184392929077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.554443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017114952206611633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1728692650794983,
      "backward_entropy": 0.135184907913208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.416259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017186405137181282,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1726969083150228,
      "backward_entropy": 0.13511946201324462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.64817810058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017261888831853867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.172517458597819,
      "backward_entropy": 0.1349266529083252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.1221466064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017336690798401833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.172337015469869,
      "backward_entropy": 0.13499497175216674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.1358184814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017412148416042328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1721540888150533,
      "backward_entropy": 0.13843920230865478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.56945037841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017487933859229088,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17196863889694214,
      "backward_entropy": 0.1384354591369629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.01931762695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017558440566062927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1717881957689921,
      "backward_entropy": 0.13843019008636476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.86087036132812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017626682296395302,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1716091831525167,
      "backward_entropy": 0.138424289226532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.79981994628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017694082111120224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17142979303995767,
      "backward_entropy": 0.13449770212173462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.9461669921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0177595354616642,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17125141620635986,
      "backward_entropy": 0.1344144344329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.42611694335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01782764308154583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17106767495473227,
      "backward_entropy": 0.1343334674835205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.52517700195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017894016578793526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1708852450052897,
      "backward_entropy": 0.1342495083808899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.68722534179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017959490418434143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17070206006368002,
      "backward_entropy": 0.1383918046951294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.0670166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018030807375907898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17050868272781372,
      "backward_entropy": 0.13421261310577393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.7710418701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018104027956724167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1703104774157206,
      "backward_entropy": 0.13413574695587158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4744415283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018176686018705368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17011098066965738,
      "backward_entropy": 0.13405485153198243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.71273803710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018248194828629494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16991204023361206,
      "backward_entropy": 0.1339715003967285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.94569396972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0183195061981678,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16971162954966226,
      "backward_entropy": 0.13375544548034668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.27548217773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018390556797385216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16950958967208862,
      "backward_entropy": 0.13379625082015992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.9396514892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018461741507053375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16930619875590006,
      "backward_entropy": 0.13357999324798583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2908935546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01853194646537304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16910314559936523,
      "backward_entropy": 0.1336151361465454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4248809814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018603216856718063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16889665524164835,
      "backward_entropy": 0.13352274894714355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.5818634033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018673328682780266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16869044303894043,
      "backward_entropy": 0.13330411911010742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.1465606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01874461956322193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16848077376683554,
      "backward_entropy": 0.13321038484573364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.25198364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018814759328961372,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16827134291330972,
      "backward_entropy": 0.1331130623817444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.61935424804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018884053453803062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1680621306101481,
      "backward_entropy": 0.13313727378845214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.349609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018952224403619766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16785279909769693,
      "backward_entropy": 0.13303349018096924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.66427612304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01901966519653797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1676433483759562,
      "backward_entropy": 0.1329275131225586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.00865173339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01908748224377632,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16743183135986328,
      "backward_entropy": 0.13830572366714478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.4020233154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01915527880191803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1672179102897644,
      "backward_entropy": 0.1325820803642273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.8531036376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019224543124437332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1670002539952596,
      "backward_entropy": 0.1324671983718872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.2342071533203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0192952249199152,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1667791207631429,
      "backward_entropy": 0.13828473091125487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.88951110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019363922998309135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.166560431321462,
      "backward_entropy": 0.13223482370376588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.0428924560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01943623460829258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1663344403107961,
      "backward_entropy": 0.13226326704025268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.89501953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01951279677450657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16609988609949747,
      "backward_entropy": 0.13202111721038817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.79592895507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019588757306337357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16586488485336304,
      "backward_entropy": 0.1319139003753662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3807373046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01966194063425064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16563314199447632,
      "backward_entropy": 0.13195106983184815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.7834930419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019736260175704956,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16539877653121948,
      "backward_entropy": 0.1316794276237488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.84776306152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01981096714735031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16516147057215372,
      "backward_entropy": 0.13156038522720337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.17971801757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019886210560798645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.164921502272288,
      "backward_entropy": 0.13160860538482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.4756622314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019963141530752182,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16467719276746115,
      "backward_entropy": 0.1313230276107788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.87342834472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020042784512043,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1644272804260254,
      "backward_entropy": 0.13824132680892945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.86614990234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02012256160378456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1641758382320404,
      "backward_entropy": 0.1310986042022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.26052856445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02020050399005413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16392706831296286,
      "backward_entropy": 0.13097734451293946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.52389526367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020277736708521843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1636784772078196,
      "backward_entropy": 0.1308504104614258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.90806579589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020353395491838455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16343210140864053,
      "backward_entropy": 0.13071610927581787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.1031951904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020432008430361748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16317975521087646,
      "backward_entropy": 0.13078689575195312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.8907012939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02051105722784996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16292593876520792,
      "backward_entropy": 0.130665922164917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.931884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02059050090610981,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16267070174217224,
      "backward_entropy": 0.13033424615859984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.1015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020669186487793922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.162416140238444,
      "backward_entropy": 0.13041794300079346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.6542510986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020742861554026604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16217068831125894,
      "backward_entropy": 0.13005151748657226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.20362854003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020820992067456245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1619169314702352,
      "backward_entropy": 0.12991502285003662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.52658081054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020897747948765755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16166595617930093,
      "backward_entropy": 0.12977163791656493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.64256286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02097158506512642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16141899426778158,
      "backward_entropy": 0.12986849546432494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.0389862060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02104298397898674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16117575764656067,
      "backward_entropy": 0.12944594621658326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.7383041381836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021117709577083588,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16092548767725626,
      "backward_entropy": 0.13817999362945557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.5243148803711,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02118668146431446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16068601608276367,
      "backward_entropy": 0.13816888332366944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.4628448486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021253611892461777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604493260383606,
      "backward_entropy": 0.12920944690704345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.34814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0213212538510561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16021116574605307,
      "backward_entropy": 0.12903087139129638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.95902252197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02138926275074482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15997129678726196,
      "backward_entropy": 0.12884926795959473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.96475219726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0214522797614336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15974120299021402,
      "backward_entropy": 0.12865055799484254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.62731170654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021516138687729836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15950838724772134,
      "backward_entropy": 0.12845070362091066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.51348114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021576477214694023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15928328037261963,
      "backward_entropy": 0.12789156436920165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.87693786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021635940298438072,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15906173984209696,
      "backward_entropy": 0.12766070365905763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3371124267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021693473681807518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15884369611740112,
      "backward_entropy": 0.13803682327270508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8078155517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02175365947186947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15861988067626953,
      "backward_entropy": 0.12757089138031005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.8040008544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021814335137605667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15839566787083945,
      "backward_entropy": 0.12735389471054076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.2934112548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021879617124795914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1581623156865438,
      "backward_entropy": 0.12715380191802977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.77180480957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0219456497579813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.157927006483078,
      "backward_entropy": 0.12652525901794434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.1489486694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02200949937105179,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15769716103871664,
      "backward_entropy": 0.12630071640014648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.45854187011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022070439532399178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15747104088465372,
      "backward_entropy": 0.1260583519935608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.9701690673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022127211093902588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15725380182266235,
      "backward_entropy": 0.12579679489135742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.01539611816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02218865230679512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1570261319478353,
      "backward_entropy": 0.12555172443389892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.4119873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02225106954574585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1567959984143575,
      "backward_entropy": 0.12530648708343506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.1190414428711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02231786772608757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15655752023061117,
      "backward_entropy": 0.12507843971252441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.16788482666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022378386929631233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15633110205332437,
      "backward_entropy": 0.12533583641052246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.41941833496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022436916828155518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15610897541046143,
      "backward_entropy": 0.12507405281066894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.0550079345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022498155012726784,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15588190158208212,
      "backward_entropy": 0.13780951499938965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.84252166748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022559454664587975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.155654639005661,
      "backward_entropy": 0.12456616163253784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.61048889160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02261744625866413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15543405214945474,
      "backward_entropy": 0.12373178005218506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.1179428100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022673429921269417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15521685282389322,
      "backward_entropy": 0.12400094270706177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.59767150878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022727705538272858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15500293175379434,
      "backward_entropy": 0.12369918823242188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.6405487060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022780831903219223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547922889391581,
      "backward_entropy": 0.1233928918838501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.53565979003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022835923358798027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15457743406295776,
      "backward_entropy": 0.12309072017669678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.29042053222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022888246923685074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15436768531799316,
      "backward_entropy": 0.12217085361480713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.34776306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022945886477828026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15414729714393616,
      "backward_entropy": 0.12247269153594971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.62267303466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023005245253443718,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1539243459701538,
      "backward_entropy": 0.12157400846481323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.95782470703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023063944652676582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15370357036590576,
      "backward_entropy": 0.12188901901245117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 220.97288513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023120112717151642,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15348966916402182,
      "backward_entropy": 0.12095918655395507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.6800537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02318360097706318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15326189994812012,
      "backward_entropy": 0.12132003307342529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.27230834960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023242346942424774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15304325024286905,
      "backward_entropy": 0.12102233171463013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.38552856445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023302722722291946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15282211701075235,
      "backward_entropy": 0.12007350921630859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.9127197265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023365341126918793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1525964935620626,
      "backward_entropy": 0.12044633626937866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0297622680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023425739258527756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15237581729888916,
      "backward_entropy": 0.1201441764831543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.91676330566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023485496640205383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15215774377187094,
      "backward_entropy": 0.11983568668365478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.66570281982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023543233051896095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1519437630971273,
      "backward_entropy": 0.11950769424438476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.5845718383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023600604385137558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1517319679260254,
      "backward_entropy": 0.11917735338211059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.08724212646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023655911907553673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15152319272359213,
      "backward_entropy": 0.11882387399673462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023709461092948914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15131727854410806,
      "backward_entropy": 0.11771317720413207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.58998107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023768484592437744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15110190709431967,
      "backward_entropy": 0.11811187267303466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.77017974853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023833470419049263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15087648232777914,
      "backward_entropy": 0.11780805587768554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.4384002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023894870653748512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15065880616505942,
      "backward_entropy": 0.1174776315689087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.09754943847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023957500234246254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15043973922729492,
      "backward_entropy": 0.11715023517608643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.2014617919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024020180106163025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15022167563438416,
      "backward_entropy": 0.11604033708572388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.0526580810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024082813411951065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1500044365723928,
      "backward_entropy": 0.1156917691230774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.33552551269531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024146759882569313,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14978760480880737,
      "backward_entropy": 0.1371798872947693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.4984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02420743554830551,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1495769222577413,
      "backward_entropy": 0.11578993797302246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.33233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02426799200475216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14936569333076477,
      "backward_entropy": 0.11461973190307617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.82755279541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02432902343571186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14915621280670166,
      "backward_entropy": 0.11425427198410035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.7083740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024388158693909645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1489515801270803,
      "backward_entropy": 0.11470280885696411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.07243347167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024444518610835075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14875356356302896,
      "backward_entropy": 0.11430869102478028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.15403747558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02450062520802021,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1485573649406433,
      "backward_entropy": 0.11304407119750977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.68757629394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024556122720241547,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14836225907007852,
      "backward_entropy": 0.1126145601272583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.70066452026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02460804581642151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1481749415397644,
      "backward_entropy": 0.11305222511291504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.46630096435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024655671790242195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14799676338831583,
      "backward_entropy": 0.11258392333984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.6971435546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02470286749303341,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14782071113586426,
      "backward_entropy": 0.13683167695999146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.75667572021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024754943326115608,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14763608574867249,
      "backward_entropy": 0.11166949272155761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.58185577392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024805964902043343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14745457967122397,
      "backward_entropy": 0.11024997234344483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.71915435791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024856043979525566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1472745736440023,
      "backward_entropy": 0.10977780818939209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.7615203857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024905184283852577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1470972498257955,
      "backward_entropy": 0.11028797626495361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.67535400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024956028908491135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1469185451666514,
      "backward_entropy": 0.10983090400695801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.80545806884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025005776435136795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14674200614293417,
      "backward_entropy": 0.10935609340667725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.12106323242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025053462013602257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1465694804986318,
      "backward_entropy": 0.10781989097595215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.20796203613281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025106234475970268,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1463895837465922,
      "backward_entropy": 0.13646095991134644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.94501495361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025158032774925232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14621283610661825,
      "backward_entropy": 0.10793143510818481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.85072326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025208666920661926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14603841304779053,
      "backward_entropy": 0.10744651556015014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.6855926513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025257276371121407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14586846033732095,
      "backward_entropy": 0.10694154500961303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.68914031982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025309747084975243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14569332202275595,
      "backward_entropy": 0.10537210702896119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.3688201904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02536090835928917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14552068710327148,
      "backward_entropy": 0.10596927404403686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.4475555419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02541685476899147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14534188310305277,
      "backward_entropy": 0.1055245041847229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.09526824951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025475746020674706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14515952269236246,
      "backward_entropy": 0.10398789644241332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.0436248779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025532707571983337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14498084783554077,
      "backward_entropy": 0.10462799072265624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.65879821777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025596091523766518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1447944442431132,
      "backward_entropy": 0.10421712398529052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.09166717529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02565954439342022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14460962017377219,
      "backward_entropy": 0.10379923582077026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.25003814697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025722287595272064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14442883928616843,
      "backward_entropy": 0.10337710380554199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.03797149658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025782734155654907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1442523698012034,
      "backward_entropy": 0.10292171239852906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.18144226074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02584111876785755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14407996336619058,
      "backward_entropy": 0.10243644714355468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.29517364501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025898534804582596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14391294121742249,
      "backward_entropy": 0.101958167552948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.69412994384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025951942428946495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14375221729278564,
      "backward_entropy": 0.1014352560043335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.9575653076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02600625529885292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14359054962793985,
      "backward_entropy": 0.10090956687927247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.37211608886719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02606304921209812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.143428236246109,
      "backward_entropy": 0.09928744435310363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.50831604003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02611641027033329,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14327280720074972,
      "backward_entropy": 0.1358954429626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.57992553710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026168551295995712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1431193153063456,
      "backward_entropy": 0.09936666488647461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.72604370117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026222921907901764,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14296332995096842,
      "backward_entropy": 0.09770983457565308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.61041259765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026279503479599953,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.142805943886439,
      "backward_entropy": 0.13578546047210693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.01961517333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02633240446448326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14265515406926474,
      "backward_entropy": 0.09783369302749634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.69251251220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026381798088550568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14250963926315308,
      "backward_entropy": 0.09725797176361084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.6419448852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026431085541844368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14236348867416382,
      "backward_entropy": 0.09551701545715333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.3455810546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02647871896624565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14222145080566406,
      "backward_entropy": 0.09491134881973266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.93760681152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02652565762400627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14208094278971353,
      "backward_entropy": 0.09429292678833008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.08524322509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02657638117671013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14193575580914816,
      "backward_entropy": 0.09370647072792053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.25316619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026628568768501282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14179019133249918,
      "backward_entropy": 0.09313462972640991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.15888977050781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026676587760448456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14165204763412476,
      "backward_entropy": 0.09363479018211365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.17713928222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026721548289060593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14151748021443686,
      "backward_entropy": 0.09188549518585205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.09695434570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026772474870085716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14137807488441467,
      "backward_entropy": 0.09241706728935242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.37132263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026819974184036255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14124276240666708,
      "backward_entropy": 0.0918041706085205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.15485382080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02686636708676815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14111170172691345,
      "backward_entropy": 0.09009668827056885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.99042510986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026913831010460854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14098123709360758,
      "backward_entropy": 0.08949989676475525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.55998992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026961876079440117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14085052410761514,
      "backward_entropy": 0.08890482187271118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.120662689208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027006130665540695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14072569211324057,
      "backward_entropy": 0.08827356100082398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.79154968261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027046091854572296,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14060826102892557,
      "backward_entropy": 0.08760870695114135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.01625061035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02708525024354458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14049214124679565,
      "backward_entropy": 0.08693925142288209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.02555084228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027127234265208244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.140373965104421,
      "backward_entropy": 0.08630546927452087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.88014602661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027171673253178596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14025392134984335,
      "backward_entropy": 0.08569221496582032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.60282135009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027212733402848244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14013883471488953,
      "backward_entropy": 0.08504377603530884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.63999938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027255384251475334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14002329111099243,
      "backward_entropy": 0.08552956581115723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.27165222167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02730162814259529,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13990485668182373,
      "backward_entropy": 0.08493001461029052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.3890838623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02734798938035965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13978836933771768,
      "backward_entropy": 0.08433641195297241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.28592681884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02739875763654709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13966854413350424,
      "backward_entropy": 0.08265345692634582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.529666900634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027447737753391266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1395514210065206,
      "backward_entropy": 0.08320521116256714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.14298248291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027493156492710114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13944000005722046,
      "backward_entropy": 0.08145971894264221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.42296600341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0275381188839674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13932826121648154,
      "backward_entropy": 0.0819606602191925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.013427734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02758454903960228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.139217346906662,
      "backward_entropy": 0.08022803068161011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.5772933959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02762986347079277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13910901546478271,
      "backward_entropy": 0.07961925864219666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.6392059326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02767428383231163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1390032966931661,
      "backward_entropy": 0.08014488220214844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.05809783935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027723176404833794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1388936440149943,
      "backward_entropy": 0.07844723463058471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.34668731689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02776966243982315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13878814379374185,
      "backward_entropy": 0.07899134159088135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.84149169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027816245332360268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1386840840180715,
      "backward_entropy": 0.07840391397476196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.79289245605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027862627059221268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13858050107955933,
      "backward_entropy": 0.07780495882034302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.91246795654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027912350371479988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13847487171490988,
      "backward_entropy": 0.07610548734664917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.130958557128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02796178124845028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13837074240048727,
      "backward_entropy": 0.07666057348251343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.58495330810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028007229790091515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1382702092329661,
      "backward_entropy": 0.07603783011436463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.16051483154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028049703687429428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1381744941075643,
      "backward_entropy": 0.07539764642715455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.85895538330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028094979003071785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13807790478070578,
      "backward_entropy": 0.07367310523986817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.07550048828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028139375150203705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13798330227533975,
      "backward_entropy": 0.07306069135665894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.03351593017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02818620577454567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13788723945617676,
      "backward_entropy": 0.07248290181159973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.35243225097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02823065221309662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13779338200887045,
      "backward_entropy": 0.07298410534858704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.7983627319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02827540971338749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1377002696196238,
      "backward_entropy": 0.07237556576728821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.16178894042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028317512944340706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1376075545946757,
      "backward_entropy": 0.07172194719314576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.25593566894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028361158445477486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13751419385274252,
      "backward_entropy": 0.07108598947525024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.40977478027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028407568112015724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13742026686668396,
      "backward_entropy": 0.06943620443344116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.90028381347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028456278145313263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13732539614041647,
      "backward_entropy": 0.06887518167495728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.95709991455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028507167473435402,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1372302770614624,
      "backward_entropy": 0.06937081813812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.40808868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028560321778059006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13713588317235312,
      "backward_entropy": 0.06886214017868042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.40309524536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028614161536097527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13704240322113037,
      "backward_entropy": 0.06835899353027344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.45482635498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028665030375123024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13695145646731058,
      "backward_entropy": 0.0678163468837738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.41168212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02871556766331196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13686148325602213,
      "backward_entropy": 0.0672637939453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.8131866455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0287647508084774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1367733379205068,
      "backward_entropy": 0.06573029160499573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.5162582397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02881862409412861,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13668412963549295,
      "backward_entropy": 0.06522835493087768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.9681396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028871994465589523,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1365963121255239,
      "backward_entropy": 0.06472538709640503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.22796630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02892366051673889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1365101933479309,
      "backward_entropy": 0.06514391303062439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.434776306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02897496335208416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13642477989196777,
      "backward_entropy": 0.06461198925971985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.92335510253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02902255766093731,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13634217778841654,
      "backward_entropy": 0.06313299536705017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.90442657470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02906925231218338,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362612247467041,
      "backward_entropy": 0.06346646547317505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.09796905517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029118625447154045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361804703871409,
      "backward_entropy": 0.06204354166984558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.24897766113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029166650027036667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13610035181045532,
      "backward_entropy": 0.06150074601173401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.132484436035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029215125367045403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602187236150107,
      "backward_entropy": 0.06183468103408814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.405540466308594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029260804876685143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359428366025289,
      "backward_entropy": 0.06040884256362915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.421287536621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029304776340723038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13586633404095969,
      "backward_entropy": 0.060662710666656496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.09785461425781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029347123578190804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13579206665356955,
      "backward_entropy": 0.060068929195404054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.68209075927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02939014323055744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1357168952624003,
      "backward_entropy": 0.059488892555236816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.19341278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029433881863951683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13564146558443704,
      "backward_entropy": 0.05815176367759704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.87651824951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029479138553142548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13556551933288574,
      "backward_entropy": 0.057617127895355225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.30067443847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029523860663175583,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13549107313156128,
      "backward_entropy": 0.13316380977630615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.91644287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02957022748887539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13541613022486368,
      "backward_entropy": 0.05726783275604248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.90340423583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029622960835695267,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13534017403920492,
      "backward_entropy": 0.056112867593765256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.9491958618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029678842052817345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352633833885193,
      "backward_entropy": 0.05637606978416443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.98217010498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02973383106291294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13518619537353516,
      "backward_entropy": 0.0559218168258667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.4485321044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029788419604301453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13510997096697488,
      "backward_entropy": 0.055463123321533206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.034568786621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02985125035047531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13503019014994302,
      "backward_entropy": 0.055072975158691403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.352439880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029910914599895477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13495361804962158,
      "backward_entropy": 0.05406197309494019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.92394256591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029965240508317947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13487964868545532,
      "backward_entropy": 0.05362435579299927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.33226013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030019253492355347,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13480662306149802,
      "backward_entropy": 0.05319113731384277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.95087814331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030073190107941628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1347353458404541,
      "backward_entropy": 0.05277045965194702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.91631317138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03012344054877758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1346657077471415,
      "backward_entropy": 0.052854859828948976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.99266815185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030175402760505676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13459283113479614,
      "backward_entropy": 0.05238598585128784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.552085876464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03022628277540207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1345211664835612,
      "backward_entropy": 0.051424461603164676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.182708740234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03027218021452427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13444975018501282,
      "backward_entropy": 0.05092332363128662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.48302459716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03031628578901291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13437900940577188,
      "backward_entropy": 0.05084185600280762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.69383239746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03035660646855831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13431010643641153,
      "backward_entropy": 0.05027182698249817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.54787063598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03039735183119774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13424309094746908,
      "backward_entropy": 0.049745112657547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.71628189086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030434485524892807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13417646288871765,
      "backward_entropy": 0.04880081117153168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.96156883239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030471254140138626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1341115434964498,
      "backward_entropy": 0.04863756000995636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.44639587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030504191294312477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13404913743336996,
      "backward_entropy": 0.047719717025756836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.54566192626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030539751052856445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.133984645207723,
      "backward_entropy": 0.04752588868141174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.919227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030580436810851097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13391842444737753,
      "backward_entropy": 0.0470449149608612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030618300661444664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13385480642318726,
      "backward_entropy": 0.04655592441558838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.81289672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030658725649118423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1337900161743164,
      "backward_entropy": 0.04609102606773376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.614994049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03069930709898472,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13372504711151123,
      "backward_entropy": 0.04536872506141663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.43349838256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030739299952983856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13366143902142844,
      "backward_entropy": 0.04493253827095032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.437528610229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030778096988797188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13359683752059937,
      "backward_entropy": 0.04471269547939301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.27788543701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03081359900534153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13353623946507773,
      "backward_entropy": 0.04424290657043457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.467437744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030846895650029182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13347750902175903,
      "backward_entropy": 0.043768087029457094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.32318878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03087867796421051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13341771562894186,
      "backward_entropy": 0.04308811128139496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.8121337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03091186285018921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13335804144541422,
      "backward_entropy": 0.04263579249382019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.65760803222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03094584494829178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13329676787058511,
      "backward_entropy": 0.0421923816204071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.6828498840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03098188526928425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1332345207532247,
      "backward_entropy": 0.041774234175682066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.16994094848633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031017731875181198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1331724226474762,
      "backward_entropy": 0.04136455059051514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.85608673095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03105239011347294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13311094045639038,
      "backward_entropy": 0.0410502016544342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.09308624267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03109104372560978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13304734230041504,
      "backward_entropy": 0.040589040517807005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.60400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031131155788898468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1329825520515442,
      "backward_entropy": 0.040282681584358215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.987998962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031175758689641953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13291501998901367,
      "backward_entropy": 0.03993895351886749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.98035430908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031216854229569435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1328479548295339,
      "backward_entropy": 0.03956256508827209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.139312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03125592693686485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13278049230575562,
      "backward_entropy": 0.03920626640319824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.41727828979492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03129377216100693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13271490732828775,
      "backward_entropy": 0.03885312974452972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.63845443725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03133136034011841,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1326494018236796,
      "backward_entropy": 0.03840233683586121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.866788864135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031369566917419434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13258315126101175,
      "backward_entropy": 0.03803159594535828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.0234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031405460089445114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13251853982607523,
      "backward_entropy": 0.037655597925186156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.762176513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03144459053874016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13245330254236856,
      "backward_entropy": 0.03731706440448761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.07026672363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031484514474868774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13238757848739624,
      "backward_entropy": 0.03722836673259735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.43193817138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03152894601225853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13231897354125977,
      "backward_entropy": 0.03669434189796448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.852420806884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03157772123813629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13224826256434122,
      "backward_entropy": 0.03642790615558624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.819114685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03162374719977379,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13217751185099283,
      "backward_entropy": 0.036133021116256714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.35649871826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03166908398270607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13210840026537576,
      "backward_entropy": 0.036224034428596494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.66512298583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03171877935528755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13203744093577066,
      "backward_entropy": 0.035603451728820804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.11719512939453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03176908567547798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1319655179977417,
      "backward_entropy": 0.132024884223938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.252532958984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03182022646069527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13189385334650675,
      "backward_entropy": 0.0351354718208313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.94293212890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03187092766165733,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1318221092224121,
      "backward_entropy": 0.13220092058181762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.68788146972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03192133083939552,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13175061345100403,
      "backward_entropy": 0.13228362798690796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.3681755065918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031972289085388184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13167845209439596,
      "backward_entropy": 0.03446363210678101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.83979606628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032020632177591324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1316065490245819,
      "backward_entropy": 0.03422331213951111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.1735610961914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03206460550427437,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13153600692749023,
      "backward_entropy": 0.13246943950653076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.301509857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032111261039972305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13146477937698364,
      "backward_entropy": 0.03371940851211548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.230438232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032157041132450104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13139426708221436,
      "backward_entropy": 0.034219032526016234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.25088119506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03220194950699806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1313239336013794,
      "backward_entropy": 0.03401829898357391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.08463287353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03224589303135872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1312522292137146,
      "backward_entropy": 0.033001890778541564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.914716720581055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03229108080267906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13117876648902893,
      "backward_entropy": 0.13271582126617432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.73426818847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03233171999454498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13110491633415222,
      "backward_entropy": 0.032477852702140805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.857309341430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032373856753110886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1310297648111979,
      "backward_entropy": 0.03312182426452637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.35660934448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03241315111517906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13095492124557495,
      "backward_entropy": 0.031905388832092284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.49701690673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03245218098163605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13087977965672812,
      "backward_entropy": 0.031613525748252866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.62377166748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03249390050768852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1308022936185201,
      "backward_entropy": 0.03133751749992371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.215885162353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032539043575525284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13072162866592407,
      "backward_entropy": 0.031082841753959655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.30738067626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03258437663316727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1306405464808146,
      "backward_entropy": 0.03083527386188507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.77645492553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032627981156110764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13056076566378275,
      "backward_entropy": 0.03058454394340515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.21756362915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032670676708221436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13048094511032104,
      "backward_entropy": 0.031510081887245175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.21893310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032713014632463455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1304014523824056,
      "backward_entropy": 0.030066388845443725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.903377532958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0327535942196846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13032125433286032,
      "backward_entropy": 0.029799169301986693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.40985870361328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0327940471470356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13024232784907022,
      "backward_entropy": 0.030840983986854552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.455049514770508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03283719718456268,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1301609675089518,
      "backward_entropy": 0.03063803315162659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.80620574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03287781774997711,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13008092840512595,
      "backward_entropy": 0.029054880142211914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.65973663330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032920144498348236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12999916076660156,
      "backward_entropy": 0.028817996382713318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.13207244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03296392783522606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12991603215535483,
      "backward_entropy": 0.028587070107460023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.4187126159668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03300623223185539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12983367840449014,
      "backward_entropy": 0.028355589509010314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.28491973876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03304668888449669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12975039084752402,
      "backward_entropy": 0.028107625246047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.76457977294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308549150824547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12966651717821756,
      "backward_entropy": 0.02784688174724579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.818721771240234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03312712535262108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1295802096525828,
      "backward_entropy": 0.0276063472032547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.12574005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0331672765314579,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1294940710067749,
      "backward_entropy": 0.028998643159866333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.26207733154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03320860490202904,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12940805157025656,
      "backward_entropy": 0.02713555097579956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.63850402832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03325056657195091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12932158509890238,
      "backward_entropy": 0.026915112137794496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.9167594909668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03329605236649513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12923183043797812,
      "backward_entropy": 0.026710319519042968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.8801040649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03334023803472519,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.129143754641215,
      "backward_entropy": 0.028311359882354736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64241790771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033387985080480576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12905155618985495,
      "backward_entropy": 0.026344755291938783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.990814208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03343885391950607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1289567748705546,
      "backward_entropy": 0.02619059383869171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.37749481201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03349040821194649,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1288603146870931,
      "backward_entropy": 0.026037323474884033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.994224548339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03354363888502121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1287616491317749,
      "backward_entropy": 0.0258902907371521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.644287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033595625311136246,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12866386771202087,
      "backward_entropy": 0.027741175889968873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.402259826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033644840121269226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12856598695119223,
      "backward_entropy": 0.027610626816749573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.98281860351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033693939447402954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12846765915552774,
      "backward_entropy": 0.02540183961391449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.14309310913086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03374537453055382,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12836859623591104,
      "backward_entropy": 0.13362417221069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.25896453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03379622846841812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1282685101032257,
      "backward_entropy": 0.025101348757743835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.12352180480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03384777531027794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12816670536994934,
      "backward_entropy": 0.024948461353778838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.076717376708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033896155655384064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12806691726048788,
      "backward_entropy": 0.024786949157714844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.67643737792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0339432992041111,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12796610593795776,
      "backward_entropy": 0.026894253492355347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.89289093017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03399288281798363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12786330779393515,
      "backward_entropy": 0.02678355574607849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.625450134277344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.034043945372104645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12776052951812744,
      "backward_entropy": 0.13398582935333253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.22103500366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03409488871693611,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12765596310297647,
      "backward_entropy": 0.026612821221351623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.94834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03414459899067879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1275527079900106,
      "backward_entropy": 0.024077415466308594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.80571746826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03419727832078934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12744692961374918,
      "backward_entropy": 0.02396143674850464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.78239059448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03424999490380287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12734110156695047,
      "backward_entropy": 0.026380833983421326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.46413040161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034301143139600754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12723459800084433,
      "backward_entropy": 0.023734769225120543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.79774475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03435111790895462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12712774674097696,
      "backward_entropy": 0.023607721924781798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.339168548583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034403860569000244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12701774636904398,
      "backward_entropy": 0.023487818241119385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.11351776123047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03445487841963768,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1269067128499349,
      "backward_entropy": 0.13454005718231202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.7103271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03450442850589752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12679482499758402,
      "backward_entropy": 0.02319801300764084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.57517623901367,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03455803543329239,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12667971849441528,
      "backward_entropy": 0.1346438407897949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.39517593383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03461023047566414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12656516830126444,
      "backward_entropy": 0.022943669557571413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.22598648071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03466115519404411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1264501412709554,
      "backward_entropy": 0.02281264215707779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.5302734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03471173346042633,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1263339320818583,
      "backward_entropy": 0.13479818105697633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.961624145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034765858203172684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12621297438939413,
      "backward_entropy": 0.0225498229265213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.69941329956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0348176546394825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12609407305717468,
      "backward_entropy": 0.022419764101505278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.244869232177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034868791699409485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12597358226776123,
      "backward_entropy": 0.022276060283184053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.4075927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03491979092359543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12585206826527914,
      "backward_entropy": 0.022135433554649354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.30402946472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03497326374053955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1257273554801941,
      "backward_entropy": 0.02200110852718353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.388826370239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035024628043174744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1256049076716105,
      "backward_entropy": 0.02187027931213379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.65935134887695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0350736528635025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12548316518465677,
      "backward_entropy": 0.021727386116981506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.1016616821289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03512223809957504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12535884976387024,
      "backward_entropy": 0.024740612506866454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.228307723999023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03517597168684006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12522889177004495,
      "backward_entropy": 0.021448975801467894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.96404266357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035226497799158096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1251029670238495,
      "backward_entropy": 0.021321457624435425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.249860763549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03528067097067833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12497176726659139,
      "backward_entropy": 0.021206901967525484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.50967025756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03533109277486801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12484268347422282,
      "backward_entropy": 0.0210703581571579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.437931060791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03538108617067337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12471153338750203,
      "backward_entropy": 0.020925961434841156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.06104278564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035428762435913086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12458193302154541,
      "backward_entropy": 0.020769190788269044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.85670852661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03547636419534683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12445096174875896,
      "backward_entropy": 0.02401621639728546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.651893615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035523902624845505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12431886792182922,
      "backward_entropy": 0.020455850660800932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.18898010253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03557138890028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12418505549430847,
      "backward_entropy": 0.020300281047821046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.171789169311523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03562208265066147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12404746810595195,
      "backward_entropy": 0.02366286963224411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.225494384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03567012771964073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12391394376754761,
      "backward_entropy": 0.020037755370140076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.10302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035719133913517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12377713123957317,
      "backward_entropy": 0.019912873208522797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.56088638305664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03576873615384102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12363680203755696,
      "backward_entropy": 0.019783155620098115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.298641204833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035818226635456085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12349605560302734,
      "backward_entropy": 0.01965455561876297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.0391845703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03586775064468384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12335472305615743,
      "backward_entropy": 0.019531817734241487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.06243133544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03591743856668472,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1232135792573293,
      "backward_entropy": 0.13545362949371337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.571584701538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03596896678209305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12306881944338481,
      "backward_entropy": 0.019315342605113982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.56052780151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0360184945166111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1229255199432373,
      "backward_entropy": 0.019211345911026002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.390771865844727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03607071191072464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12277576327323914,
      "backward_entropy": 0.022905221581459044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.1063346862793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03612060099840164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1226292351881663,
      "backward_entropy": 0.01900986135005951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.75603103637695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036170341074466705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1224816342194875,
      "backward_entropy": 0.018904176354408265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.90457534790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036220330744981766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12233375509579976,
      "backward_entropy": 0.02270742356777191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.541358947753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03626899793744087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12218572696050008,
      "backward_entropy": 0.02263765037059784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.828075408935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03631750866770744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12203717231750488,
      "backward_entropy": 0.022564637660980224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.89254379272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03636328876018524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12189197540283203,
      "backward_entropy": 0.018486909568309784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.599456787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641022741794586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12174274524052937,
      "backward_entropy": 0.018380460143089295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.021636962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036458391696214676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12159003814061482,
      "backward_entropy": 0.018283443152904512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.142093658447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036505550146102905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1214369535446167,
      "backward_entropy": 0.018181571364402772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.29975509643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03655390441417694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12128181258837382,
      "backward_entropy": 0.018087640404701233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.62879180908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03660493716597557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12112051248550415,
      "backward_entropy": 0.01799885183572769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.869483947753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03665688633918762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1209568480650584,
      "backward_entropy": 0.01792011857032776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.84601593017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036708518862724304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12079310417175293,
      "backward_entropy": 0.017843285202980043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.991188049316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036763597279787064,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1206222375233968,
      "backward_entropy": 0.1359713077545166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.20427322387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03681691363453865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12045301000277202,
      "backward_entropy": 0.017708057165145875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.58744430541992,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0368715301156044,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12028094132741292,
      "backward_entropy": 0.13605706691741942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.79010009765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036924537271261215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12010876337687175,
      "backward_entropy": 0.017560677230358125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.78608322143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03697708994150162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11993447939554851,
      "backward_entropy": 0.01748407483100891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.14976119995117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03703170642256737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11975543697675069,
      "backward_entropy": 0.017407578229904175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.937617301940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037084370851516724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11957784493764241,
      "backward_entropy": 0.02179282605648041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.378023147583008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03713290020823479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11940783262252808,
      "backward_entropy": 0.01721610575914383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.74716567993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03717963770031929,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1192409594853719,
      "backward_entropy": 0.01711660623550415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.366436004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03722652420401573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11907266577084859,
      "backward_entropy": 0.017020304501056672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.5016975402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037272557616233826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11890482902526855,
      "backward_entropy": 0.01692238450050354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.36867904663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037319835275411606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11873375376065572,
      "backward_entropy": 0.0168340802192688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.735336303710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037367917597293854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11855890353520711,
      "backward_entropy": 0.016744835674762724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.77629852294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03741420432925224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11838807662328084,
      "backward_entropy": 0.016653615236282348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.50436019897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03746066987514496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1182150940100352,
      "backward_entropy": 0.016566076874732973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.38083839416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03750539943575859,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11804445584615071,
      "backward_entropy": 0.02118380069732666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.249008178710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03754953667521477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11787418524424235,
      "backward_entropy": 0.016386018693447114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.107418060302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03759043291211128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11771005392074585,
      "backward_entropy": 0.016289891302585603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.033681869506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03763025254011154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11754830678304036,
      "backward_entropy": 0.016193403303623198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.538177490234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03766828402876854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11739025513331096,
      "backward_entropy": 0.01609719842672348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.754547119140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03770908713340759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11722381909688313,
      "backward_entropy": 0.016010087728500367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.887110710144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037748876959085464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11705964803695679,
      "backward_entropy": 0.02076658755540848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.2022819519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03778612241148949,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11690207322438557,
      "backward_entropy": 0.020704028010368348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.435630798339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03782448172569275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11674066384633382,
      "backward_entropy": 0.020647314190864564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.082508087158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037866607308387756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11656952897707622,
      "backward_entropy": 0.015694113075733186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.170358657836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03790849447250366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11639813582102458,
      "backward_entropy": 0.01563105434179306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.12172508239746,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03794935345649719,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11622846126556396,
      "backward_entropy": 0.1363568425178528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.361759185791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03798901289701462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11605981985727946,
      "backward_entropy": 0.0204891100525856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.22494125366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03802952542901039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11588773131370544,
      "backward_entropy": 0.015438397228717805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.33831787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0380706712603569,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11571290095647176,
      "backward_entropy": 0.02040778547525406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.286396026611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03811413422226906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11552995443344116,
      "backward_entropy": 0.015314307808876038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.360432624816895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03815694898366928,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11534726619720459,
      "backward_entropy": 0.020327728986740113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.901020050048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038196664303541183,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11517228682835896,
      "backward_entropy": 0.015177398920059204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.47800064086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03823427855968475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11500170826911926,
      "backward_entropy": 0.015095154941082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.19224739074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038274332880973816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11482105652491252,
      "backward_entropy": 0.015013891458511352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.56126594543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03831331431865692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11464301745096843,
      "backward_entropy": 0.020074015855789183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16658267378807068,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038352180272340775,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11446407437324524,
      "backward_entropy": 0.13643217086791992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.53969955444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838663175702095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11429786682128906,
      "backward_entropy": 0.014759142696857453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.94797134399414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038424186408519745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11412256956100464,
      "backward_entropy": 0.014682614803314209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.891589164733887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03846357390284538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11394067605336507,
      "backward_entropy": 0.014614078402519225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.91870880126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038500282913446426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1137664516766866,
      "backward_entropy": 0.01975591331720352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.13265037536621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03853977471590042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11358275016148885,
      "backward_entropy": 0.014477528631687164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.613420486450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03857727721333504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11340542634328206,
      "backward_entropy": 0.014406238496303559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.947611808776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03861485421657562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11322508255640666,
      "backward_entropy": 0.019593951106071473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.593460083007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0386507511138916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11304869254430135,
      "backward_entropy": 0.014263024926185608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.09812545776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038687750697135925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11286886533101399,
      "backward_entropy": 0.01947672665119171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.004024505615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038728274405002594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11267656087875366,
      "backward_entropy": 0.01413445770740509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.602567672729492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03877299651503563,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1124705970287323,
      "backward_entropy": 0.01408941149711609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.774280548095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038815367966890335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11227178573608398,
      "backward_entropy": 0.01404043436050415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.6126651763916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0388573482632637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11207381884256999,
      "backward_entropy": 0.013992489874362945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.48687744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03889906778931618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11187637845675151,
      "backward_entropy": 0.01394842118024826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.402196884155273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03894044831395149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11167877912521362,
      "backward_entropy": 0.013904768228530883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.207014083862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03898231312632561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11147874593734741,
      "backward_entropy": 0.013861896097660064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.086637496948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039023783057928085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11127920945485432,
      "backward_entropy": 0.013818074762821198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.905807495117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039065562188625336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.111076553662618,
      "backward_entropy": 0.013770692050457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.85463523864746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039107032120227814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1108745535214742,
      "backward_entropy": 0.013726195693016053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.74776268005371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03914722055196762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11067605018615723,
      "backward_entropy": 0.013678094744682312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.633737564086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039186228066682816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11048052708307902,
      "backward_entropy": 0.013626007735729218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.955867767333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03922419622540474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11028822263081868,
      "backward_entropy": 0.013571278750896454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.051883697509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03926454856991768,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1100847323735555,
      "backward_entropy": 0.013521121442317962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.883605003356934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03930552303791046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10987905661265056,
      "backward_entropy": 0.018958358466625212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.95827293395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03934284299612045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10968714952468872,
      "backward_entropy": 0.013424281775951386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.849149703979492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039380207657814026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1094948947429657,
      "backward_entropy": 0.018874666094779967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.5947380065918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03941747918725014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10930093129475911,
      "backward_entropy": 0.018831071257591248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.87126350402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039458129554986954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10909383495648702,
      "backward_entropy": 0.013284428417682648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.11306381225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03949759528040886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1088905930519104,
      "backward_entropy": 0.01324082463979721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.576560974121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953758254647255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10868336757024129,
      "backward_entropy": 0.013196413218975068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.76814079284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03957895562052727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1084703803062439,
      "backward_entropy": 0.01869136542081833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.423599243164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039620719850063324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10825499892234802,
      "backward_entropy": 0.013116666674613952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.192733764648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03966117650270462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10804414749145508,
      "backward_entropy": 0.01862289309501648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.211240768432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039698805660009384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10784435272216797,
      "backward_entropy": 0.013028080761432647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.12175941467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03973551094532013,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10764726996421814,
      "backward_entropy": 0.0185327410697937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.975902557373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03977306932210922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1074465016523997,
      "backward_entropy": 0.012935033440589905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.426444053649902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03981132432818413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10724159081776936,
      "backward_entropy": 0.012891671061515808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.786540985107422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039847876876592636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1070441206296285,
      "backward_entropy": 0.01284775733947754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.920272827148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03988368809223175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1068490743637085,
      "backward_entropy": 0.012804754078388214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.96841049194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03992122411727905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10664621988932292,
      "backward_entropy": 0.01276615411043167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.85053062438965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03995872288942337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10644332567850749,
      "backward_entropy": 0.012729121744632721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.72499084472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039996109902858734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10623995463053386,
      "backward_entropy": 0.01269141286611557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.51272964477539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04003579169511795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10602504014968872,
      "backward_entropy": 0.01265733540058136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.7235107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040077511221170425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10580054918924968,
      "backward_entropy": 0.012627188861370087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.808087348937988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04011949896812439,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10557399193445842,
      "backward_entropy": 0.01259775310754776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.265240669250488,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04015927389264107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10535631577173869,
      "backward_entropy": 0.012563149631023406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.452360153198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04019554704427719,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10515578587849934,
      "backward_entropy": 0.012523636221885681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.571133613586426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04023334011435509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10494589805603027,
      "backward_entropy": 0.012486094981431961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.08949851989746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04026934877038002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10474300384521484,
      "backward_entropy": 0.018008747696876527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.413653373718262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040306977927684784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10453276832898457,
      "backward_entropy": 0.012408873438835144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.45058822631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04034287855029106,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10433069864908855,
      "backward_entropy": 0.017927375435829163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.886802673339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04037793353199959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10413108269373576,
      "backward_entropy": 0.012330324202775956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.28886604309082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04041777551174164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1039083997408549,
      "backward_entropy": 0.012299198657274246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.25114440917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04045722261071205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10368696848551433,
      "backward_entropy": 0.012268256396055222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.01548194885254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04049943760037422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10345194737116496,
      "backward_entropy": 0.012243328988552094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.899237632751465,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04054175317287445,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10321545600891113,
      "backward_entropy": 0.13713583946228028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.681001663208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040582675486803055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10298633575439453,
      "backward_entropy": 0.01772805452346802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.43148422241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04062381386756897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10275536775588989,
      "backward_entropy": 0.017697617411613464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.572295188903809,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04066590219736099,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10251845916112264,
      "backward_entropy": 0.012142367660999298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.603920936584473,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.040706567466259,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.10228794813156128,
      "backward_entropy": 0.13721227645874023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.694918632507324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074518010020256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1020685335000356,
      "backward_entropy": 0.012088018655776977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.1252555847168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040781158953905106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10186262925465901,
      "backward_entropy": 0.012055996805429459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.375432014465332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04082085192203522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10163754224777222,
      "backward_entropy": 0.012031611800193787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.57493019104004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040858570486307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10142197211583455,
      "backward_entropy": 0.012003891170024872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4875288009643555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040896784514188766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10120372970898946,
      "backward_entropy": 0.01197752207517624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.99191665649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04093242436647415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10099983215332031,
      "backward_entropy": 0.011948269605636597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.450342178344727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04096948727965355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10078740119934082,
      "backward_entropy": 0.011921325325965881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.662941932678223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041006311774253845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10057564576466878,
      "backward_entropy": 0.011893811076879502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.48137092590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104219377040863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10036871830622356,
      "backward_entropy": 0.011865901201963425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.30769920349121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04107944667339325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10015432039896648,
      "backward_entropy": 0.011840078979730606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.194436073303223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04111793264746666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0999332070350647,
      "backward_entropy": 0.011816519498825073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.711492538452148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041153792291879654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09972692529360454,
      "backward_entropy": 0.01178957000374794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.18388557434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041188016533851624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09952878952026367,
      "backward_entropy": 0.01176021695137024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.61277198791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041221506893634796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09933408101399739,
      "backward_entropy": 0.011729780584573746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.99187660217285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041255079209804535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09913882613182068,
      "backward_entropy": 0.011699939519166947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.437349319458008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041290923953056335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09892962376276652,
      "backward_entropy": 0.016983018815517427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4683644771575928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04132512956857681,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0987291932106018,
      "backward_entropy": 0.011644946783781052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.595489501953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04135638475418091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09854542215665181,
      "backward_entropy": 0.016884568333625793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.059268951416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04138864949345589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09835406144460042,
      "backward_entropy": 0.011581405997276306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.9512882232666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041421081870794296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09816316763559978,
      "backward_entropy": 0.011551094055175782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.84393882751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041453663259744644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0979706843694051,
      "backward_entropy": 0.01673508882522583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.048666000366211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04148637130856514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09777797261873881,
      "backward_entropy": 0.01149209812283516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.984917640686035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041517727077007294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09759353597958882,
      "backward_entropy": 0.011461836844682693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.925278663635254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041547879576683044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09741624196370442,
      "backward_entropy": 0.01143115684390068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.149598121643066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041576940566301346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09724603096644084,
      "backward_entropy": 0.011400195956230163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.86846351623535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04160575196146965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0970760981241862,
      "backward_entropy": 0.01646882891654968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.23764419555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04163648188114166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09689392646153767,
      "backward_entropy": 0.01134384199976921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.03253173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04166749492287636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09671022494633992,
      "backward_entropy": 0.011318259686231614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.02362632751465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04170161113142967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09650758902231853,
      "backward_entropy": 0.01129700317978859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.27042007446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04173566401004791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09630535046259563,
      "backward_entropy": 0.011276085674762727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.484992980957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04177108779549599,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09609389305114746,
      "backward_entropy": 0.01125757247209549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41672420501709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041804876178503036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09589274724324544,
      "backward_entropy": 0.011237289011478423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.466829299926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04183720797300339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09569978713989258,
      "backward_entropy": 0.011215695738792419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.384839057922363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04186893254518509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09550982713699341,
      "backward_entropy": 0.011193936318159103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.306591987609863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04190010577440262,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09532282749811809,
      "backward_entropy": 0.01117200255393982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.223052978515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04193074628710747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09513940413792928,
      "backward_entropy": 0.016026994585990904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.182759284973145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0419609397649765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0949580470720927,
      "backward_entropy": 0.011127569526433945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.066908836364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041991375386714935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09477586547533672,
      "backward_entropy": 0.011106111854314805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.97498893737793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042021363973617554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09459663430849712,
      "backward_entropy": 0.011084742844104767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.861860275268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04205235093832016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09440942605336507,
      "backward_entropy": 0.01584736555814743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.875894546508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042084161192178726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09421813488006592,
      "backward_entropy": 0.011045878380537033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.616018295288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042114656418561935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0940354863802592,
      "backward_entropy": 0.011025810241699218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.406400680541992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042146049439907074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09384737412134807,
      "backward_entropy": 0.011008238047361374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.259838104248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04217894747853279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09364883104960124,
      "backward_entropy": 0.010993119329214096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.36759090423584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221317917108536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09344148635864258,
      "backward_entropy": 0.01097995787858963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.406843185424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042247213423252106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09323575099309285,
      "backward_entropy": 0.010966643691062927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.153806686401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0422804169356823,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09303432703018188,
      "backward_entropy": 0.010953132808208466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.854345321655273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042313508689403534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09283397595087688,
      "backward_entropy": 0.010939596593379975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.511754989624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042347174137830734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09262984991073608,
      "backward_entropy": 0.0154915452003479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.542253017425537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04238201305270195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09241857131322224,
      "backward_entropy": 0.010915754735469818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.985475540161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04241453483700752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09222279985745747,
      "backward_entropy": 0.010902183502912522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.178318977355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042446319013834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09203108151753743,
      "backward_entropy": 0.015375789999961854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7183356285095215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042476803064346313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0918465256690979,
      "backward_entropy": 0.01087295264005661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.80800437927246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04250474274158478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09167887767155965,
      "backward_entropy": 0.0108560711145401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.685638427734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042534422129392624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09149956703186035,
      "backward_entropy": 0.010843583196401597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.604384422302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04256359115242958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0913239320119222,
      "backward_entropy": 0.01082986444234848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.795369148254395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0425923652946949,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09115021427472432,
      "backward_entropy": 0.010816743969917298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.071998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04262206330895424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09097015857696533,
      "backward_entropy": 0.015139004588127137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.167070388793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042651932686567307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09078886111577351,
      "backward_entropy": 0.01079292893409729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.46581745147705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04268321767449379,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09059850374857585,
      "backward_entropy": 0.010781905055046082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6892876625061035,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.042715031653642654,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.09040621916453044,
      "backward_entropy": 0.13767015933990479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.627164363861084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04274534434080124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09022585550944011,
      "backward_entropy": 0.010752021521329879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.596829414367676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04277435317635536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09005530675252278,
      "backward_entropy": 0.010732819885015487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.507105827331543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04280354082584381,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0898828109105428,
      "backward_entropy": 0.010714484751224518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.41161823272705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0428328663110733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08970952033996582,
      "backward_entropy": 0.010696472972631455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4887115955352783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04286234453320503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08953483899434407,
      "backward_entropy": 0.010679684579372406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.125944137573242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04288928583264351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08937868475914001,
      "backward_entropy": 0.010659143328666687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.577216148376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04291784018278122,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08921136458714803,
      "backward_entropy": 0.01465584933757782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.458039283752441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042947184294462204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08903919657071431,
      "backward_entropy": 0.01062251180410385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.966925621032715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04297732561826706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08886021375656128,
      "backward_entropy": 0.014553534984588622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.973970413208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04300744831562042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08868123094240825,
      "backward_entropy": 0.0105923131108284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.76356315612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04303952679038048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08848836024602254,
      "backward_entropy": 0.010581153631210326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.665786743164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04307149723172188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08829524119695027,
      "backward_entropy": 0.010572611540555953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.263956069946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04310335963964462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08810191353162129,
      "backward_entropy": 0.010566388070583344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.48042106628418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043134428560733795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08791408936182658,
      "backward_entropy": 0.010560596734285355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.117561340332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04316539317369461,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08772653341293335,
      "backward_entropy": 0.010554712265729904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.046481132507324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04319559410214424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08754491806030273,
      "backward_entropy": 0.01054755300283432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.67542552947998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04322507977485657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08736888567606609,
      "backward_entropy": 0.010538749396800995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.560942649841309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04325583577156067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08718360463778178,
      "backward_entropy": 0.010532746464014054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.60573387145996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04328756779432297,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08699293931325276,
      "backward_entropy": 0.014156636595726014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555668354034424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043320950120687485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08679002523422241,
      "backward_entropy": 0.014118695259094238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.818909645080566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043352749198675156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08659801880518596,
      "backward_entropy": 0.01051393747329712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589436531066895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04338429495692253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08640817801157634,
      "backward_entropy": 0.010508929193019868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.508222579956055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04341495409607887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08622473478317261,
      "backward_entropy": 0.010502177476882934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.351724147796631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04344487935304642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08604568243026733,
      "backward_entropy": 0.010495659708976746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381429672241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043473366647958755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0858788788318634,
      "backward_entropy": 0.010484640300273896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.5836238861084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043501194566488266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08571780721346538,
      "backward_entropy": 0.01047140508890152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.294896125793457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04353087395429611,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08554331461588542,
      "backward_entropy": 0.010459590703248978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0692124366760254,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04356035217642784,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08537127574284871,
      "backward_entropy": 0.1378239154815674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.166702270507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04358730837702751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08521793286005656,
      "backward_entropy": 0.010430221259593964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.025670051574707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04361618310213089,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.085050235191981,
      "backward_entropy": 0.1378249406814575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.980401039123535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04364621266722679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08487403392791748,
      "backward_entropy": 0.010407066345214844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9351701736450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043674860149621964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08470835288365682,
      "backward_entropy": 0.010395979881286621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.658778190612793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043702200055122375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08455300331115723,
      "backward_entropy": 0.013504625856876373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.83034086227417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04373089224100113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0843854049841563,
      "backward_entropy": 0.013457962870597839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.685988426208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043758317828178406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08422801891962688,
      "backward_entropy": 0.013409338891506195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8323123455047607,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04378528520464897,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08407326539357503,
      "backward_entropy": 0.13783854246139526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.462157249450684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04381060227751732,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.083930770556132,
      "backward_entropy": 0.01034354642033577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.523560523986816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0438360869884491,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08378758033116658,
      "backward_entropy": 0.010332991182804108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.153904914855957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04386109113693237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0836489995320638,
      "backward_entropy": 0.010319682955741882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.91679859161377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388698935508728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08350327610969543,
      "backward_entropy": 0.010310408473014832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.808740615844727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043914102017879486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08334910869598389,
      "backward_entropy": 0.010300661623477935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8424475193023682,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04394226893782616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08318806687990825,
      "backward_entropy": 0.010289781540632249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992521286010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04396809637546539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08304463326931,
      "backward_entropy": 0.010278444737195969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5837385654449463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043994080275297165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08289951086044312,
      "backward_entropy": 0.010268184542655944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.849133491516113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04401855543255806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08276508748531342,
      "backward_entropy": 0.01025916039943695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.277127265930176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04404327645897865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08262829979260762,
      "backward_entropy": 0.010250245034694672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.236496448516846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044069286435842514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08248279492060344,
      "backward_entropy": 0.010241726040840149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.361615180969238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0440942719578743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08234486480553944,
      "backward_entropy": 0.010233262181282043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.85640287399292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044119853526353836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08220382034778595,
      "backward_entropy": 0.010223104804754257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.165918350219727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04414496198296547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08206679423650105,
      "backward_entropy": 0.0102127805352211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.402547836303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04417084902524948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08192237714926402,
      "backward_entropy": 0.010205602645874024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325713157653809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04419688507914543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08177645007769267,
      "backward_entropy": 0.012585650384426116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6871366500854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04422307759523392,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08162849148114522,
      "backward_entropy": 0.010200835764408112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.31139874458313,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0442470908164978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08149772882461548,
      "backward_entropy": 0.010198388993740082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6613799333572388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0442696139216423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08137894173463185,
      "backward_entropy": 0.01246759444475174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.470297336578369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044290319085121155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08127408226331075,
      "backward_entropy": 0.01018376722931862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.414439678192139,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431098699569702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08116963505744934,
      "backward_entropy": 0.010174299776554107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.376796245574951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044331714510917664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08106432358423869,
      "backward_entropy": 0.010166773945093155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.764410972595215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044352393597364426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08095974226792653,
      "backward_entropy": 0.010158352553844452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.733304500579834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04437243565917015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0808607538541158,
      "backward_entropy": 0.010147298872470855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.336766242980957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04439186677336693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0807672639687856,
      "backward_entropy": 0.010133052617311478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1243560314178467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04441245272755623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08066512644290924,
      "backward_entropy": 0.012130309641361237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.614912986755371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04443188011646271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0805722971757253,
      "backward_entropy": 0.010107220709323883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617802143096924,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04445095360279083,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08048136532306671,
      "backward_entropy": 0.1378530502319336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.570868492126465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044470712542533875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08038480579853058,
      "backward_entropy": 0.010088807344436646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50050687789917,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.044490985572338104,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08028474450111389,
      "backward_entropy": 0.13785181045532227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.968738079071045,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04451188072562218,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08017900586128235,
      "backward_entropy": 0.13785390853881835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.382442951202393,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044532716274261475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0800736943880717,
      "backward_entropy": 0.010072600096464157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.408890247344971,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04455413669347763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07996288438638051,
      "backward_entropy": 0.010073582082986832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.841722011566162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457501694560051,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0798554668823878,
      "backward_entropy": 0.010077083110809326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9105143547058105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044595688581466675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07975129783153534,
      "backward_entropy": 0.011756200343370438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.740151882171631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044615309685468674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07965498169263203,
      "backward_entropy": 0.011721470206975938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.112246990203857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044634997844696045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07955747346083324,
      "backward_entropy": 0.010076671838760376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.060367107391357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044655248522758484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0794548789660136,
      "backward_entropy": 0.010077641159296036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.628870487213135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04467596113681793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07934947808583577,
      "backward_entropy": 0.010078126937150956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.562098026275635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0446963794529438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07924798130989075,
      "backward_entropy": 0.0100726917386055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.512503623962402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471679404377937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07914593319098155,
      "backward_entropy": 0.010069604218006133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.920754432678223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04473727196455002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07904218137264252,
      "backward_entropy": 0.010070803761482238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7430717945098877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04475961625576019,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07892494897047679,
      "backward_entropy": 0.010072153061628342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.06272029876709,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04478061944246292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07881850997606914,
      "backward_entropy": 0.010071580111980439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9949493408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044800836592912674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07871927320957184,
      "backward_entropy": 0.01006748601794243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.927220821380615,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04482195898890495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07861295342445374,
      "backward_entropy": 0.1379150390625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.258166790008545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0448438823223114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07850042978922527,
      "backward_entropy": 0.010062091052532196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7853522300720215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04486547410488129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07839096585909526,
      "backward_entropy": 0.010058514028787612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5956971645355225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044887837022542953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07827526330947876,
      "backward_entropy": 0.01005641147494316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9182767868042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044908974319696426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07816850145657857,
      "backward_entropy": 0.010056249052286147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7947025299072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044931355863809586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07805225253105164,
      "backward_entropy": 0.010056167095899581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.017230033874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0449531264603138,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07793921232223511,
      "backward_entropy": 0.010061836242675782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.445785999298096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0449746809899807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07782760759194692,
      "backward_entropy": 0.010068713128566742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.945312976837158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04499691352248192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07771104574203491,
      "backward_entropy": 0.010074681043624878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.089834690093994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045018650591373444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07759960492451985,
      "backward_entropy": 0.010075308382511139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.631516695022583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04504065960645676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07748524347941081,
      "backward_entropy": 0.010078172385692596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.41365122795105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04506199061870575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07737544178962708,
      "backward_entropy": 0.0100843146443367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7463908195495605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045082200318574905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07727383077144623,
      "backward_entropy": 0.010092280805110931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.057927131652832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510236531496048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07717172304789226,
      "backward_entropy": 0.010102997720241546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6768479347229,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04512323811650276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07706499099731445,
      "backward_entropy": 0.010111421346664429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.206716537475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514383524656296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07696067293485005,
      "backward_entropy": 0.010118098556995391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.719913005828857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04516621679067612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07684160272280376,
      "backward_entropy": 0.01012844145298004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919922351837158,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04518869146704674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07672177751859029,
      "backward_entropy": 0.010138768702745438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.496647357940674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04521207883954048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07659545540809631,
      "backward_entropy": 0.010146832466125489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2378997802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045234937220811844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07647344470024109,
      "backward_entropy": 0.010154134780168533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5033392906188965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525651037693024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07636080185572307,
      "backward_entropy": 0.010163802653551102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3665289878845215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04527812823653221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07624833782513936,
      "backward_entropy": 0.010170912742614746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1746881008148193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045299362391233444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07613920172055562,
      "backward_entropy": 0.010176663845777511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4123759269714355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04531945288181305,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07603832085927327,
      "backward_entropy": 0.010768212378025055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1920571327209473,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04534011334180832,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07593350609143575,
      "backward_entropy": 0.1380842685699463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.20638370513916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04536004364490509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07583455244700114,
      "backward_entropy": 0.010192420333623886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1341910362243652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045379720628261566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07573766509691875,
      "backward_entropy": 0.010195407271385192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.225821495056152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04539875686168671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07564583420753479,
      "backward_entropy": 0.010198618471622466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.116554260253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04541989788413048,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07553692162036896,
      "backward_entropy": 0.13810269832611083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.057274341583252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045440927147865295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07543074587980907,
      "backward_entropy": 0.010200104862451553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.049011707305908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04546235874295235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07532222072283427,
      "backward_entropy": 0.010195361822843552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0416523218154907,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04548228159546852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07522702217102051,
      "backward_entropy": 0.010184228420257568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9245269298553467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045500487089157104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07514591018358867,
      "backward_entropy": 0.010170426219701767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8890414237976074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04551864042878151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07506471872329712,
      "backward_entropy": 0.010160122811794282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.920503854751587,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045536745339632034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07498335341612498,
      "backward_entropy": 0.010152720659971238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8986949920654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04555417597293854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07490789393583934,
      "backward_entropy": 0.010348998010158539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8812384605407715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04557095840573311,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0748384843269984,
      "backward_entropy": 0.010127320140600204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.630516529083252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04558707773685455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07477590441703796,
      "backward_entropy": 0.010107259452342986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8307852745056152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04560399428009987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07470751802126567,
      "backward_entropy": 0.010085929930210114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7882819175720215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562024027109146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07464563349882762,
      "backward_entropy": 0.010060404241085053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6552844047546387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04563608020544052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07458666960398357,
      "backward_entropy": 0.010036605596542358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6372263431549072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565213620662689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0745245764652888,
      "backward_entropy": 0.010019145905971527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7172558307647705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04566822946071625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07446213563283284,
      "backward_entropy": 0.010002952814102174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.322119235992432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568393900990486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07440248131752014,
      "backward_entropy": 0.009988121688365936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.404439449310303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045700740069150925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07433289289474487,
      "backward_entropy": 0.009980309009552001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0848846435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04571806639432907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07425809899965923,
      "backward_entropy": 0.009977765381336212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.620288848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04573679715394974,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07417103151480357,
      "backward_entropy": 0.009825018793344497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2978034019470215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045754872262477875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07408942778905232,
      "backward_entropy": 0.009988141059875489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.089511394500732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045773085206747055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07400708397229512,
      "backward_entropy": 0.009989563375711441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8887123465538025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04579189419746399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0739201009273529,
      "backward_entropy": 0.009990107268095016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.008816242218018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04580913856625557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07384662826855977,
      "backward_entropy": 0.009988254308700562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6843926906585693,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04582682251930237,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07377134760220845,
      "backward_entropy": 0.009979830682277679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.885998725891113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04584348946809769,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07370428244272868,
      "backward_entropy": 0.009971602261066437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.038800239562988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04586099460721016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07362981140613556,
      "backward_entropy": 0.009968238323926926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4130516052246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04587884619832039,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.0735519031683604,
      "backward_entropy": 0.009566645324230193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.971501588821411,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458962544798851,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07347655793031056,
      "backward_entropy": 0.009974615275859832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1566855907440186,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04591384157538414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07340024908383687,
      "backward_entropy": 0.009978820383548737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6614508628845215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045931193977594376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07332618037859599,
      "backward_entropy": 0.009981271624565125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5740987062454224,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04594910517334938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07324835161368053,
      "backward_entropy": 0.009981951862573623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0518829822540283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04596595838665962,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07317915558815002,
      "backward_entropy": 0.009428483992815017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2832272052764893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045982785522937775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07310910026232402,
      "backward_entropy": 0.009984136372804642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0115115642547607,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599912092089653,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07304266095161438,
      "backward_entropy": 0.009987610578536987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2522788047790527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04601523280143738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07297878464063008,
      "backward_entropy": 0.009986825287342072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.943737030029297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04603075608611107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07292050123214722,
      "backward_entropy": 0.009982500970363618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.630718946456909,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04604628309607506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07286179065704346,
      "backward_entropy": 0.009979701042175293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.88004732131958,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046062227338552475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07279928028583527,
      "backward_entropy": 0.009979436546564103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4514840841293335,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04607824608683586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0727351854244868,
      "backward_entropy": 0.009984160959720611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.226038932800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046093493700027466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07267675797144572,
      "backward_entropy": 0.009990306943655014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4393020868301392,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04610953852534294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.072611669699351,
      "backward_entropy": 0.00999748259782791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0985381603240967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04612460359930992,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07255520423253377,
      "backward_entropy": 0.010000407695770264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.399384617805481,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04613931104540825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07250136137008667,
      "backward_entropy": 0.009134398400783538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4111268520355225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04615336284041405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07245225707689922,
      "backward_entropy": 0.010010625422000884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.04922342300415,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046167805790901184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07240040103594463,
      "backward_entropy": 0.010015159845352173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9993832111358643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046182919293642044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07234381635983785,
      "backward_entropy": 0.009065299481153487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0102741718292236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04619878903031349,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0722806950410207,
      "backward_entropy": 0.01001954972743988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3390166759490967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04621411859989166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07222216327985127,
      "backward_entropy": 0.010021139681339265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9640742540359497,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04622867703437805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07216950257619222,
      "backward_entropy": 0.008992595970630646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7548298835754395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046242937445640564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07211873432000478,
      "backward_entropy": 0.010029634833335877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.556875705718994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046259038150310516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07205368081728618,
      "backward_entropy": 0.008949685096740722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9038134813308716,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04627499356865883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0719892183939616,
      "backward_entropy": 0.010040247440338134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2583943605422974,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04629053547978401,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07192730903625488,
      "backward_entropy": 0.13810427188873292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.481529474258423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04630549997091293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07186845938364665,
      "backward_entropy": 0.010064597427845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.463801622390747,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04632040485739708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0718097190062205,
      "backward_entropy": 0.010079541057348252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6401222944259644,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633517190814018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0717528760433197,
      "backward_entropy": 0.010090835392475128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0010483264923096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04634886980056763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07170415918032329,
      "backward_entropy": 0.010103462636470795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3963277339935303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04636299982666969,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07165188093980153,
      "backward_entropy": 0.010116568952798843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.367849111557007,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046377040445804596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07160082956155141,
      "backward_entropy": 0.010126423835754395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.345608949661255,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0463910736143589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07154975334803264,
      "backward_entropy": 0.010135409235954285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.152004718780518,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046405091881752014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07149872183799744,
      "backward_entropy": 0.010143543034791947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3018128871917725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04642104357481003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07143078247706096,
      "backward_entropy": 0.010157666355371475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1696418523788452,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04643673077225685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07136529684066772,
      "backward_entropy": 0.0101689413189888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6836153268814087,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04645141214132309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07130878667036693,
      "backward_entropy": 0.01017524152994156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1274964809417725,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04646584019064903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07125284274419148,
      "backward_entropy": 0.010186807066202164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1367415189743042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046479612588882446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07120135426521301,
      "backward_entropy": 0.010200092196464538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7270405292510986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0464925542473793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07115724682807922,
      "backward_entropy": 0.008712707459926606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.283167839050293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046505823731422424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07111074527104695,
      "backward_entropy": 0.010213053971529006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1450395584106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04652050510048866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07105280458927155,
      "backward_entropy": 0.010218682885169982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6488070487976074,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046535033732652664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07099611560503642,
      "backward_entropy": 0.01022290661931038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.182639122009277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04654967039823532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07093918820222218,
      "backward_entropy": 0.010223653912544251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.597177267074585,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04656612500548363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07086819410324097,
      "backward_entropy": 0.010222379863262177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0371735095977783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04658321291208267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07079225778579712,
      "backward_entropy": 0.010219916701316833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5384416580200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046600691974163055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07071215411027272,
      "backward_entropy": 0.010222000628709793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4853203296661377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046617262065410614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07064038515090942,
      "backward_entropy": 0.01021994948387146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.454164981842041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466337725520134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07056918740272522,
      "backward_entropy": 0.010217272490262986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9646446704864502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04665021970868111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07049839695294698,
      "backward_entropy": 0.010213632881641389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9750038385391235,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04666608199477196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07043378551801045,
      "backward_entropy": 0.010202937573194504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.299175977706909,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046681106090545654,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07037479678789775,
      "backward_entropy": 0.13819879293441772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4199179410934448,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466967411339283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07031160593032837,
      "backward_entropy": 0.010188224911689758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9475635290145874,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046711746603250504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0702534019947052,
      "backward_entropy": 0.010180362313985825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9338611960411072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046725913882255554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07020135720570882,
      "backward_entropy": 0.01017494797706604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1413676738739014,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0467393659055233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07015445331732433,
      "backward_entropy": 0.010172799229621887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0955681800842285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04675362631678581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07010110219319661,
      "backward_entropy": 0.010169928520917892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.191201686859131,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676872864365578,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0700405091047287,
      "backward_entropy": 0.010170486569404603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.439366579055786,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04678400605916977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06997786959012349,
      "backward_entropy": 0.010175654292106628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2880274057388306,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04680037871003151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06990494827429454,
      "backward_entropy": 0.010184945911169052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2779619693756104,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04681626334786415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06983484824498494,
      "backward_entropy": 0.010200934857130051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.910991907119751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04683161526918411,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06976836919784546,
      "backward_entropy": 0.008216229826211929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4793527126312256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04684754088521004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0696977178255717,
      "backward_entropy": 0.010237142443656921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2293646335601807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04686354845762253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0696275532245636,
      "backward_entropy": 0.010247905552387238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8525437116622925,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046878982335329056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06956113378206889,
      "backward_entropy": 0.010261933505535125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8212509751319885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046893227845430374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06950600941975911,
      "backward_entropy": 0.010267079621553422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.348578929901123,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046906642615795135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06945736209551494,
      "backward_entropy": 0.010272011160850525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.320518732070923,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04692046344280243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06940550108750661,
      "backward_entropy": 0.008138758689165115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5461393594741821,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693463817238808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06935089826583862,
      "backward_entropy": 0.010278172791004181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0037410259246826,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04694850742816925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06929878890514374,
      "backward_entropy": 0.010278979688882828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5075929164886475,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046963274478912354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06923994421958923,
      "backward_entropy": 0.010279529541730881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5724523067474365,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04697766527533531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06918417414029439,
      "backward_entropy": 0.010278838127851487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.830764651298523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04699251428246498,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06912536422411601,
      "backward_entropy": 0.010274767875671387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8096064329147339,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04700716212391853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06906904776891072,
      "backward_entropy": 0.1382385492324829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.090700626373291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702157899737358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0690154234568278,
      "backward_entropy": 0.010253528505563736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.062699556350708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047035276889801025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06896801789601643,
      "backward_entropy": 0.010237807035446167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3858011960983276,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04704849421977997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06892374157905579,
      "backward_entropy": 0.010226094722747802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.039349317550659,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04706154763698578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06888027985890706,
      "backward_entropy": 0.007873419672250748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6786470413208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04707491025328636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06883442401885986,
      "backward_entropy": 0.01020992249250412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6535227298736572,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04708835482597351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06878743569056193,
      "backward_entropy": 0.01020457074046135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.625284194946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047101911157369614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06873880823453267,
      "backward_entropy": 0.010203205049037933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9378128051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047115642577409744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06868769725163777,
      "backward_entropy": 0.010208334028720855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2185542583465576,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04712953791022301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06863608956336975,
      "backward_entropy": 0.010210464894771575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8779717683792114,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714387282729149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06858089566230774,
      "backward_entropy": 0.010210569202899932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2450753450393677,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471583716571331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06852450966835022,
      "backward_entropy": 0.010210619866847992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35985371470451355,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047172535210847855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06847047805786133,
      "backward_entropy": 0.010212743282318115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5141525268554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04718533158302307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06842877467473348,
      "backward_entropy": 0.010207489132881165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3321075439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719807952642441,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06838774681091309,
      "backward_entropy": 0.01020076870918274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4664760828018188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720985144376755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06835421919822693,
      "backward_entropy": 0.010196863114833832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.736161470413208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04722179099917412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06831881403923035,
      "backward_entropy": 0.01019584685564041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1669174432754517,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04723404347896576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06828108429908752,
      "backward_entropy": 0.010194293409585952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1309348344802856,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047245949506759644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06824689110120137,
      "backward_entropy": 0.010188601911067963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4084523916244507,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04725782945752144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06821181376775105,
      "backward_entropy": 0.010189232975244522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.637183427810669,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04726963862776756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06817824641863506,
      "backward_entropy": 0.010185050964355468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.403748035430908,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047281909734010696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06814003984133403,
      "backward_entropy": 0.010186196118593217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1115777492523193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047295354306697845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0680910050868988,
      "backward_entropy": 0.010192231833934784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8349231481552124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730955883860588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06803553303082784,
      "backward_entropy": 0.010201539844274521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5419002771377563,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04732402786612511,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06797825296719869,
      "backward_entropy": 0.010208678245544434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5282505750656128,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047337621450424194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06792762875556946,
      "backward_entropy": 0.010217945277690887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2642271518707275,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04735131561756134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06787622968355815,
      "backward_entropy": 0.010226528346538543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2452868223190308,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047364816069602966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0678265889485677,
      "backward_entropy": 0.010232684016227723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4569810628890991,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737813398241997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06777862707773845,
      "backward_entropy": 0.0102371484041214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7425975203514099,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04739158973097801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06772930920124054,
      "backward_entropy": 0.010243381559848785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1934031248092651,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740438982844353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06768533090750377,
      "backward_entropy": 0.010248921066522598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.73060142993927,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04741700366139412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06764327486356099,
      "backward_entropy": 0.010251405835151672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6072524785995483,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0474289134144783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06760764122009277,
      "backward_entropy": 0.01024920865893364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25392070412635803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04744111746549606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06757017970085144,
      "backward_entropy": 0.007275486737489701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9134621024131775,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04745245352387428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0675387183825175,
      "backward_entropy": 0.01024140566587448,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.022851847410202,
    "avg_log_Z": -0.0467651579529047,
    "success_rate": 1.0,
    "avg_reward": 80.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.03,
      "1": 0.09,
      "2": 0.88
    },
    "avg_forward_entropy": 0.0700771596034368,
    "avg_backward_entropy": 0.01386273992806673,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}