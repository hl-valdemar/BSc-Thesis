{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06276798248291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06284163214943626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.81253814697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144771099090576,
      "backward_entropy": 0.06269400770013983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.39753723144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144552548726399,
      "backward_entropy": 0.06269616430455988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.78453063964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00020007700368296355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144339958826701,
      "backward_entropy": 0.06284409219568426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.75336456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00030005862936377525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144122401873271,
      "backward_entropy": 0.06284531138160011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.34027862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00039447774179279804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143897891044617,
      "backward_entropy": 0.06284633549776944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.94172668457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00048622029135003686,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143676360448201,
      "backward_entropy": 0.06270424886183305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.31588745117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0005807606503367424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143460790316264,
      "backward_entropy": 0.06270616704767401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.08235168457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006728547741658986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143242239952087,
      "backward_entropy": 0.06284914233467796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.89283752441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007439444307237864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143014748891194,
      "backward_entropy": 0.06270909851247614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.87329864501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008168933563865721,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142796198527019,
      "backward_entropy": 0.06284997679970482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.87745666503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008828421123325825,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142579634984334,
      "backward_entropy": 0.06281295147809116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.86644744873047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0009566867956891656,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142365058263142,
      "backward_entropy": 0.06281667405908758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.45640563964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010380563326179981,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142143527666728,
      "backward_entropy": 0.06282061338424683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.23776245117188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0011258256854489446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141921003659566,
      "backward_entropy": 0.06271534616296942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.82566833496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001215552561916411,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141697486241658,
      "backward_entropy": 0.06271708011627197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.40602111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0013071347493678331,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141472975413005,
      "backward_entropy": 0.0628540190783414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.402587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001403308822773397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141246477762859,
      "backward_entropy": 0.06285511363636363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.39088439941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014964984729886055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141011039415996,
      "backward_entropy": 0.06285608898509633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.56359100341797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0015870971838012338,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140771627426147,
      "backward_entropy": 0.06272398341785777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.96955871582031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016813386464491487,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914052426815033,
      "backward_entropy": 0.06284885514866222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.71014404296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017731006955727935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914027492205302,
      "backward_entropy": 0.0628525668924505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.94617462158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001870814012363553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140018622080485,
      "backward_entropy": 0.06285987117073753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.87582397460938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019652803894132376,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139759341875713,
      "backward_entropy": 0.0628599687056108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.48621368408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002063620137050748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139485160509746,
      "backward_entropy": 0.06273201920769432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.10234832763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002163911936804652,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139207005500793,
      "backward_entropy": 0.06286289475180885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.18563842773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022597049828618765,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138920903205872,
      "backward_entropy": 0.06287065961144188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.76611328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023618522100150585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138619899749756,
      "backward_entropy": 0.06287428465756503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.02461242675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024691217113286257,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138311942418416,
      "backward_entropy": 0.06273938850923018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.57275390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002576498780399561,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138001004854839,
      "backward_entropy": 0.06274146925319325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.74252319335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00268548890016973,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913768212000529,
      "backward_entropy": 0.06274360960180109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.27609252929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027954005636274815,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137348333994548,
      "backward_entropy": 0.0628890178420327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.80146026611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0029093418270349503,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137008587519328,
      "backward_entropy": 0.06274822083386508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.01992797851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0030161801259964705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136658906936646,
      "backward_entropy": 0.06289619207382202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.85231018066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031273069325834513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136297305425008,
      "backward_entropy": 0.06275259906595404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.69320678710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003244639839977026,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135923782984416,
      "backward_entropy": 0.06275522708892822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.5487518310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003359259106218815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135548273722331,
      "backward_entropy": 0.06275769255378029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.69194793701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034763410221785307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135174751281738,
      "backward_entropy": 0.0627602447162975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.20362854003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035882066003978252,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134792288144429,
      "backward_entropy": 0.06287928061051802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.76412200927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0037000970914959908,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134411811828613,
      "backward_entropy": 0.06276475299488414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.9110565185547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003802636871114373,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913403332233429,
      "backward_entropy": 0.0629198442805897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.23960876464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00390799343585968,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133652846018474,
      "backward_entropy": 0.06276842680844394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.7012939453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00401737354695797,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133267402648926,
      "backward_entropy": 0.06292559883811256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.17852020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004126275423914194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913287103176117,
      "backward_entropy": 0.06288546865636652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.0491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004233928397297859,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132484594980876,
      "backward_entropy": 0.06293113665147261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.87782287597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004335145466029644,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913209617137909,
      "backward_entropy": 0.0629336183721369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.51055908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004442363977432251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131696820259094,
      "backward_entropy": 0.06277742710980502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.75318908691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004553063772618771,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131286541620891,
      "backward_entropy": 0.06277924234216864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.72225189208984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004665159620344639,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130870302518208,
      "backward_entropy": 0.06294138323176991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.9795684814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00477238604798913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130449096361797,
      "backward_entropy": 0.06289230693470348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.35232543945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004879661835730076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130024909973145,
      "backward_entropy": 0.06289334730668501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.49224090576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004986819811165333,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129592776298523,
      "backward_entropy": 0.06294832988218828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.5205078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0050900704227387905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129165609677632,
      "backward_entropy": 0.0627868500622836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.35653686523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005201457999646664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128692746162415,
      "backward_entropy": 0.06289623000405052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.51166534423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005309842061251402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912821094195048,
      "backward_entropy": 0.06289713491093028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.2049102783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0054115368984639645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127730131149292,
      "backward_entropy": 0.06289787725968794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.43516540527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005518933292478323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127235412597656,
      "backward_entropy": 0.0627920465035872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.76878356933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005626137834042311,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126734733581543,
      "backward_entropy": 0.0629599852995439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.95994567871094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005732265766710043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126212199529012,
      "backward_entropy": 0.06296171925284645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.4620819091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005837732460349798,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125671784083049,
      "backward_entropy": 0.06290112300352617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.5291290283203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005944849457591772,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125122427940369,
      "backward_entropy": 0.06296505711295387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.89593505859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006054944824427366,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124553203582764,
      "backward_entropy": 0.06290268898010254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.64544677734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006170618813484907,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123955170313518,
      "backward_entropy": 0.06296846541491422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.92790985107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006287651136517525,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912333329518636,
      "backward_entropy": 0.06297017769380049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.7176055908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006400417070835829,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122699499130249,
      "backward_entropy": 0.06290526823564009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.88166809082031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006513578817248344,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122053782145183,
      "backward_entropy": 0.06297330964695323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.60804748535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006622837856411934,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121398131052653,
      "backward_entropy": 0.06297474557703192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.99786376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006727251689881086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09120748440424602,
      "backward_entropy": 0.0628053058277477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.181884765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006836343090981245,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120076894760132,
      "backward_entropy": 0.06297737901861017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.11895751953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0069497027434408665,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119385480880737,
      "backward_entropy": 0.06297873908823187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.87522888183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007061759941279888,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118691086769104,
      "backward_entropy": 0.06280822103673761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.68899536132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007172353565692902,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117989738782246,
      "backward_entropy": 0.06280902299014005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.82647705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0072870757430791855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117267529169719,
      "backward_entropy": 0.06280990080399947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.28396606445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007404964417219162,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911652147769928,
      "backward_entropy": 0.06291168386285956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.97364807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007527386769652367,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09115743637084961,
      "backward_entropy": 0.06281191652471368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.39981079101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007652092259377241,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114943941434224,
      "backward_entropy": 0.06281298940831964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.83736419677734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0077753569930791855,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114132324854533,
      "backward_entropy": 0.06298705664548007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.5589141845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007893559522926807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911331574122111,
      "backward_entropy": 0.0629149241880937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.82763671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00801127403974533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112491210301717,
      "backward_entropy": 0.06291555274616588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.63786315917969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00812611822038889,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111649791399638,
      "backward_entropy": 0.06291604583913629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.38308715820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0082324193790555,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911081035931905,
      "backward_entropy": 0.06299076297066429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.0814666748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008337178267538548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910995602607727,
      "backward_entropy": 0.06291651725769043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.52294158935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008444593288004398,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09109083811442058,
      "backward_entropy": 0.06299221515655518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.54766845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008548934012651443,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108211596806844,
      "backward_entropy": 0.0628164139660922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.61624145507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008653836324810982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107343355814616,
      "backward_entropy": 0.06281631643121893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.57997131347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008762985467910767,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910645325978597,
      "backward_entropy": 0.06299414417960426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.59105682373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008875821717083454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105537335077922,
      "backward_entropy": 0.06291735172271729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.04766845703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008984491229057312,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09104614456494649,
      "backward_entropy": 0.06299538503993642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.23666381835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009094834327697754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103664755821228,
      "backward_entropy": 0.06291760097850453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.90737915039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009206905961036682,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102693200111389,
      "backward_entropy": 0.06299652836539528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.39105224609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009316359646618366,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09101703763008118,
      "backward_entropy": 0.06299704313278198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.90927124023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009427879005670547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100696444511414,
      "backward_entropy": 0.06281549280340021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.25831604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009537524543702602,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099682172139485,
      "backward_entropy": 0.06281510266390714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.44674682617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009648513048887253,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09098636110623677,
      "backward_entropy": 0.06281472878022627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.99945068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009760941378772259,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09097564220428467,
      "backward_entropy": 0.06291754679246382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.73950958251953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009877683594822884,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096446633338928,
      "backward_entropy": 0.06281408938494595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009989551268517971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095324079195659,
      "backward_entropy": 0.06291730837388472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010099681094288826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094201525052388,
      "backward_entropy": 0.06281300024552779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.87118530273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010214701294898987,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09093037247657776,
      "backward_entropy": 0.06300053813240745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.85245513916016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010330678895115852,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09091848134994507,
      "backward_entropy": 0.06300090659748424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.1470489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010442073456943035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09090654055277507,
      "backward_entropy": 0.06281113624572754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.94505310058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010556159541010857,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09089414278666179,
      "backward_entropy": 0.0629163221879439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.26556396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01067297626286745,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088140726089478,
      "backward_entropy": 0.06280971657146107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.53146362304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010798534378409386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908682147661845,
      "backward_entropy": 0.06291610544378107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.5808868408203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010920356959104538,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908550222714742,
      "backward_entropy": 0.06300262971357866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.88720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011043539270758629,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09084147214889526,
      "backward_entropy": 0.06280770085074684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.81515502929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011171086691319942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09082738558451335,
      "backward_entropy": 0.0629154226996682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.60478210449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011300469748675823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09081281224886577,
      "backward_entropy": 0.06291517344388095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.77352905273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011423619464039803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09079831838607788,
      "backward_entropy": 0.06291476162997159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.85556030273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011547649279236794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0907834271589915,
      "backward_entropy": 0.06280457973480225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.20584106445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011667368933558464,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09076843659083049,
      "backward_entropy": 0.0630044937133789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.01158905029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011785265989601612,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075328707695007,
      "backward_entropy": 0.0628022172234275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.19468688964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01189467404037714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073850512504578,
      "backward_entropy": 0.06291219321164218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.708251953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012006550095975399,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09072324633598328,
      "backward_entropy": 0.06300498138774525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.37606048583984,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012115316465497017,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09070781866709392,
      "backward_entropy": 0.06300508975982666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1578826904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012219852767884731,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09069241086641948,
      "backward_entropy": 0.06290919130498712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5808868408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012323722243309021,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09067665537198384,
      "backward_entropy": 0.06290798837488348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.95428466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012427532114088535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066068132718404,
      "backward_entropy": 0.06290674209594727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3938751220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012534407898783684,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09064419070879619,
      "backward_entropy": 0.06300529566678134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.4708709716797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012642384506762028,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906273623307546,
      "backward_entropy": 0.06290426037528297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.41567993164062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012753053568303585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09061043461163838,
      "backward_entropy": 0.06300540403886275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.78634643554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012862881645560265,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09059330821037292,
      "backward_entropy": 0.06300544738769531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.7025604248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012976090423762798,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09057543675104777,
      "backward_entropy": 0.06277987090024081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.39610290527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013091214001178741,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09055709838867188,
      "backward_entropy": 0.06300557743419301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.77215576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013210801407694817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905379851659139,
      "backward_entropy": 0.06277572566812689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.44100952148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013337559998035431,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09051796793937683,
      "backward_entropy": 0.0628968585621227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.14833068847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013462889939546585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09049804011980693,
      "backward_entropy": 0.06300594048066573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.81146240234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013585611246526241,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09047824144363403,
      "backward_entropy": 0.06276982480829413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.28855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013708838261663914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09045800566673279,
      "backward_entropy": 0.06289320642297919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.09127807617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01383095234632492,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09043747186660767,
      "backward_entropy": 0.06289185177196156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.81139373779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013952430337667465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09041674931844075,
      "backward_entropy": 0.06289044293490323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.30014038085938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01406813133507967,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09039617578188579,
      "backward_entropy": 0.06300631436434659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.80508422851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01418202556669712,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903754432996114,
      "backward_entropy": 0.06288719177246094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.65357971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014292677864432335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035468101501465,
      "backward_entropy": 0.06288539821451361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.98426818847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0144036328420043,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0903335412343343,
      "backward_entropy": 0.06274849718267267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.17092895507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014514719136059284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09031196435292561,
      "backward_entropy": 0.06288156726143578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.36253356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01462616678327322,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09029001990954082,
      "backward_entropy": 0.06274104118347168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.97552490234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014740877784788609,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09026734034220378,
      "backward_entropy": 0.06273730234666304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.55917358398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014852075837552547,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024463097254436,
      "backward_entropy": 0.0628748590295965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.81452178955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014969938434660435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09022093812624614,
      "backward_entropy": 0.0628726753321561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.8079376220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015080362558364868,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09019755323727925,
      "backward_entropy": 0.062725153836337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.93905639648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01519046351313591,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09017364184061687,
      "backward_entropy": 0.06272082979028876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.31919860839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015297063626348972,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09014956156412761,
      "backward_entropy": 0.06300573999231512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.4387969970703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015403863973915577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09012484550476074,
      "backward_entropy": 0.06286192482168024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.81504821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015513812191784382,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09009913603464763,
      "backward_entropy": 0.06270718574523926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.5299530029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015621993690729141,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09007312854131062,
      "backward_entropy": 0.06270252032713457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.10012817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015730049461126328,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09004656473795573,
      "backward_entropy": 0.06285301121798428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.38968658447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015841446816921234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09001915653546651,
      "backward_entropy": 0.06284994970668446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.73175811767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0159464068710804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0899922748406728,
      "backward_entropy": 0.06284664977680553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.44132232666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016045432537794113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08996581037839253,
      "backward_entropy": 0.06268221139907837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.86524963378906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0161406472325325,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08993947505950928,
      "backward_entropy": 0.06300449913198297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.07130432128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016237203031778336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991246422131856,
      "backward_entropy": 0.06267004121433604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.61929321289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016332775354385376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08988556265830994,
      "backward_entropy": 0.0628316727551547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.87918090820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016430040821433067,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08985801537831624,
      "backward_entropy": 0.06300360506231134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.36498260498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01653207093477249,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08982942501703899,
      "backward_entropy": 0.06265088644894687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.19023132324219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016629571095108986,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08980080485343933,
      "backward_entropy": 0.06300307403911244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.67996215820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016723401844501495,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08977224429448445,
      "backward_entropy": 0.06300273808566006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.92440795898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016817618161439896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08974329630533855,
      "backward_entropy": 0.06281154264103282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.42706298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01691068522632122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08971425890922546,
      "backward_entropy": 0.06262279640544545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.21563720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017012272030115128,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0896835724512736,
      "backward_entropy": 0.06261584975502708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.5899200439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017121683806180954,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08965146541595459,
      "backward_entropy": 0.06300165436484596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.9949951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017229396849870682,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08961900075276692,
      "backward_entropy": 0.06260251998901367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.34222412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017330579459667206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08958699305852254,
      "backward_entropy": 0.06259518319910223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.24380493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017438484355807304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955317735671997,
      "backward_entropy": 0.0627872185273604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.42298126220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017538296058773994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08952021598815918,
      "backward_entropy": 0.06258096478202126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.55044555664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01762857288122177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948815862337749,
      "backward_entropy": 0.06277761134234341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.66500091552734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017725953832268715,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08945457140604655,
      "backward_entropy": 0.06300015883012251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.49852752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01781819388270378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08942149082819621,
      "backward_entropy": 0.06276772238991478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.75396728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017905132845044136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08938864866892497,
      "backward_entropy": 0.06276221708817915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.6971893310547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01799275539815426,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08935519059499104,
      "backward_entropy": 0.06299890713258223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.38480377197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018080994486808777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08932111660639445,
      "backward_entropy": 0.06275097890333696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.19943237304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01816679909825325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0892871618270874,
      "backward_entropy": 0.06274512681094083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.79769897460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018256232142448425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08925178647041321,
      "backward_entropy": 0.0627393126487732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.5640411376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01834118738770485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08921674887339275,
      "backward_entropy": 0.0624998157674616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.75401306152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018430380150675774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08918005228042603,
      "backward_entropy": 0.0627271207896146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.99871826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018521254882216454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08914214372634888,
      "backward_entropy": 0.06272104653445157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.5963592529297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018611200153827667,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08910404642422994,
      "backward_entropy": 0.06299533627249977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.79178619384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018705109134316444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0890646477540334,
      "backward_entropy": 0.06270897388458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.99559783935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01879574917256832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08902536829312642,
      "backward_entropy": 0.06245181235400113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.63258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0188837181776762,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08898621797561646,
      "backward_entropy": 0.0624412785876881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.38203430175781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01897040195763111,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08894658088684082,
      "backward_entropy": 0.06243054975162853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.70301818847656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019054286181926727,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890682458877563,
      "backward_entropy": 0.06299255652861162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.53502655029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019138947129249573,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08886614441871643,
      "backward_entropy": 0.06299193338914351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.40989685058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019221289083361626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08882542451222737,
      "backward_entropy": 0.06239667805758389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.54220581054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01931159943342209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08878244956334432,
      "backward_entropy": 0.06266107884320346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.84005737304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019398611038923264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08873942494392395,
      "backward_entropy": 0.06265377998352051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.57845306396484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01948699727654457,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08869584401448567,
      "backward_entropy": 0.06298974969170311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.41201782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01957295648753643,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08865239222844441,
      "backward_entropy": 0.06263914975253018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.79888916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01965811848640442,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08860847353935242,
      "backward_entropy": 0.062338980761441315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.04916381835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019749391824007034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08856253822644551,
      "backward_entropy": 0.06232736869291826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.61441040039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019841080531477928,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08851586778958638,
      "backward_entropy": 0.06231559948487715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.77591705322266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019938159734010696,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08846728006998698,
      "backward_entropy": 0.06298764185471968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.0858154296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020031394436955452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08841885129610698,
      "backward_entropy": 0.06260230866345493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.4404296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02012103796005249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08837046225865682,
      "backward_entropy": 0.06259419701316139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.51499938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02021394670009613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08832022547721863,
      "backward_entropy": 0.06258605285124345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.99110412597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020308440551161766,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0882686972618103,
      "backward_entropy": 0.06298681280829689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.73467254638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02040085941553116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08821648359298706,
      "backward_entropy": 0.062243320725180885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.11476135253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020490173250436783,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08816447854042053,
      "backward_entropy": 0.06298632513393056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.67750549316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020578209310770035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08811201651891072,
      "backward_entropy": 0.0625506043434143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6660919189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020665235817432404,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08805916706720988,
      "backward_entropy": 0.06220178170637651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.05313110351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02075299620628357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0880053738753001,
      "backward_entropy": 0.06253100525249135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.05586242675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02084803394973278,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08794886867205302,
      "backward_entropy": 0.06217338822104714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.9266815185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020939836278557777,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08789277076721191,
      "backward_entropy": 0.06215837868777188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.29237365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02103295736014843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08783509333928426,
      "backward_entropy": 0.06298483501781117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.3135528564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021122904494404793,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08777774373690288,
      "backward_entropy": 0.06212764436548406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 231.48910522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021218063309788704,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08771794040997823,
      "backward_entropy": 0.06211238557642156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.55010986328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021321183070540428,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08765503764152527,
      "backward_entropy": 0.06209893660111861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.37222290039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02142440527677536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08759089310963948,
      "backward_entropy": 0.062462129376151344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.795166015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021524902433156967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08752681811650594,
      "backward_entropy": 0.0624516335400668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.96591186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0216266717761755,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08746188879013062,
      "backward_entropy": 0.06205624883825129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.39991760253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021723968908190727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08739739656448364,
      "backward_entropy": 0.0620402531190352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.77493286132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021819403395056725,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08733291427294414,
      "backward_entropy": 0.06202305446971546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.4917755126953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021919649094343185,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0872661570707957,
      "backward_entropy": 0.06298455866900357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.30733489990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022020790725946426,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08719821770985921,
      "backward_entropy": 0.0619884729385376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.63417053222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022117646411061287,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0871307651201884,
      "backward_entropy": 0.06196958368474787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.96500396728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022214412689208984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08706207076708476,
      "backward_entropy": 0.06236974759535356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.09059143066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02230541966855526,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08699405193328857,
      "backward_entropy": 0.06298355622725053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.54335021972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022395851090550423,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08692604303359985,
      "backward_entropy": 0.061906028877605095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.84587097167969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02248484455049038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08685742815335591,
      "backward_entropy": 0.06232806769284335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.89273071289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022571178153157234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08678903182347615,
      "backward_entropy": 0.06231332367116755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.94540405273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022658254951238632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08671896656354268,
      "backward_entropy": 0.062298460440202194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.92283630371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02274787612259388,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08664709329605103,
      "backward_entropy": 0.0618084885857322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.28184509277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022835886105895042,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08657447497049968,
      "backward_entropy": 0.06178306991403753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.18504333496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022917479276657104,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08650328715642293,
      "backward_entropy": 0.06297845190221613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.33103942871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022996896877884865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08643199006716411,
      "backward_entropy": 0.0622340820052407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.310791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023078182712197304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08635935187339783,
      "backward_entropy": 0.062216709960590706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.76258850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023157600313425064,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08628674348195393,
      "backward_entropy": 0.061667832461270417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.00167846679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023242125287652016,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08621130386988322,
      "backward_entropy": 0.06163797595284202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.63762664794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023331085219979286,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0861329436302185,
      "backward_entropy": 0.061608682979236946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.50193786621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023415617644786835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08605530858039856,
      "backward_entropy": 0.061577471819790924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.3206024169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023494219407439232,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0859790841738383,
      "backward_entropy": 0.06154412573034113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.82699584960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023573013022542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08590195576349895,
      "backward_entropy": 0.06210403008894487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.49659729003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02365019917488098,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08582466840744019,
      "backward_entropy": 0.06296730041503906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.6251678466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023727599531412125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08574633797009786,
      "backward_entropy": 0.06206123395399614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.56805419921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02381008490920067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08566461006800334,
      "backward_entropy": 0.06140368635004217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.55577087402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023896727710962296,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08557955423990886,
      "backward_entropy": 0.061369608749042855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.7705078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023978643119335175,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08549535274505615,
      "backward_entropy": 0.0629625753922896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.33938598632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024054624140262604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08541274070739746,
      "backward_entropy": 0.061972065405412155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.68310546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024134621024131775,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08532774448394775,
      "backward_entropy": 0.06125731901689009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.85713195800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024219172075390816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08523935079574585,
      "backward_entropy": 0.06192483143372969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.4105682373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02429780550301075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08515296379725139,
      "backward_entropy": 0.061180542815815316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.91067504882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024381134659051895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08506308992703755,
      "backward_entropy": 0.06295601346276024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.00230407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024467317387461662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08497096101442973,
      "backward_entropy": 0.06185055862773548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.1001739501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024558182805776596,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08487621943155925,
      "backward_entropy": 0.06106488813053478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.97942352294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024647608399391174,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0847811500231425,
      "backward_entropy": 0.06102532690221613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.52764892578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0247269868850708,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08469033241271973,
      "backward_entropy": 0.06177478486841375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.9525146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024813208729028702,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08459555109341939,
      "backward_entropy": 0.06094030900435014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.98406982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024900607764720917,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08449983596801758,
      "backward_entropy": 0.06089765917171131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.39535522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02499227225780487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08440128962198894,
      "backward_entropy": 0.060855849222703415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.7740020751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025089319795370102,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08429919679959615,
      "backward_entropy": 0.061670205809853294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.22884368896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025192707777023315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08419305086135864,
      "backward_entropy": 0.0616457462310791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.35981750488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02529009059071541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08408923943837483,
      "backward_entropy": 0.06161897832697088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.02711486816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025383438915014267,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08398632208506267,
      "backward_entropy": 0.06295017762617632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.8267364501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025478659197688103,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08388165632883708,
      "backward_entropy": 0.06294989585876465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.76307678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025575941428542137,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0837755799293518,
      "backward_entropy": 0.06153039498762651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.3390350341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02567148022353649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08366988102595012,
      "backward_entropy": 0.06149950894442471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.86566162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0257651899009943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08356423179308574,
      "backward_entropy": 0.0614672682502053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.53012084960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025857387110590935,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08345864216486613,
      "backward_entropy": 0.06045312231237238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.31724548339844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025949709117412567,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08335191011428833,
      "backward_entropy": 0.06294726783579047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.89724731445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026047026738524437,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08324125409126282,
      "backward_entropy": 0.0603506781838157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.33372497558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026144064962863922,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08312995235125224,
      "backward_entropy": 0.0613287633115595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.19820404052734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02624712511897087,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08301409085591634,
      "backward_entropy": 0.06294649297540839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.06925964355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026343800127506256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08290075262387593,
      "backward_entropy": 0.061254349621859466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.64592742919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02643688954412937,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08278890450795491,
      "backward_entropy": 0.06014039299704812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.85875701904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02652648650109768,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08267812927563985,
      "backward_entropy": 0.060081742026589134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.6722412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02660965919494629,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08257053295771281,
      "backward_entropy": 0.06294177878986705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.95381164550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02669410966336727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08246164520581563,
      "backward_entropy": 0.05995512008666992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.73191833496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026776069775223732,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0823534627755483,
      "backward_entropy": 0.05988899686119773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.68948364257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026859305799007416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08224379022916158,
      "backward_entropy": 0.06098027120937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.9649200439453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026941541582345963,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08213341732819875,
      "backward_entropy": 0.06293325532566417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.48393249511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02702822908759117,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08201947808265686,
      "backward_entropy": 0.05968650904568759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.01958465576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027112208306789398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08190655708312988,
      "backward_entropy": 0.06082557548176159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.6461639404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027193889021873474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0817946195602417,
      "backward_entropy": 0.06077063625509089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.15184020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027277017012238503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08168138563632965,
      "backward_entropy": 0.06071667237715288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.49790954589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02736157737672329,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08156702915827434,
      "backward_entropy": 0.05939707430926236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.04857635498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02744174376130104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08145453532536824,
      "backward_entropy": 0.06060489741238681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.91773986816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02751808986067772,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0813438097635905,
      "backward_entropy": 0.05923982641913674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.97879028320312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027591407299041748,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08123497168223064,
      "backward_entropy": 0.06291193311864679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.62090301513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02766324207186699,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08112616340319316,
      "backward_entropy": 0.05907074971632524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.80550384521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02773592621088028,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0810165802637736,
      "backward_entropy": 0.060353755950927734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.46456909179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02780964970588684,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08090650041898091,
      "backward_entropy": 0.0628989501432939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.91221618652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02789258398115635,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08079017698764801,
      "backward_entropy": 0.060229615731672806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.17433166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027968263253569603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08067859212557475,
      "backward_entropy": 0.05872799591584639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.82093048095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028037264943122864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08057110508282979,
      "backward_entropy": 0.058635408228093926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.20591735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028104528784751892,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08046549061934154,
      "backward_entropy": 0.06002818454395641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.67788696289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02817622758448124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08035588264465332,
      "backward_entropy": 0.05995925990017978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.5347900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028248393908143044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08024495343367259,
      "backward_entropy": 0.058352026072415436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.09812927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0283193476498127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08013411859671275,
      "backward_entropy": 0.05981594865972346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.52052307128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028387291356921196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08002439141273499,
      "backward_entropy": 0.059740174900401725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.77157592773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02845962531864643,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07991094887256622,
      "backward_entropy": 0.05966524644331499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.27888488769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028532516211271286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07979659239451091,
      "backward_entropy": 0.059588627381758255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.39244842529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028606455773115158,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07968188325564067,
      "backward_entropy": 0.05951235511086204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.477272033691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028675168752670288,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07956973214944203,
      "backward_entropy": 0.06285240975293246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.97355651855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028736243024468422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07946305970350902,
      "backward_entropy": 0.057654196565801445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.46937561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02879182994365692,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07935958604017894,
      "backward_entropy": 0.057540395043113014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.52970123291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028853101655840874,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0792514185110728,
      "backward_entropy": 0.05743002891540527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.47607421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028912629932165146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07914416988690694,
      "backward_entropy": 0.05908191745931452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.60617065429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02898082323372364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07903021574020386,
      "backward_entropy": 0.057209903543645683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.13113403320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029053546488285065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07891295353571574,
      "backward_entropy": 0.05891219052401456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.84724426269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029126951470971107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07879513502120972,
      "backward_entropy": 0.05882670662619851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.03822326660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029199063777923584,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07867789268493652,
      "backward_entropy": 0.056888948787342415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029269879683852196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856101294358571,
      "backward_entropy": 0.05864626711065119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.9495849609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029338572174310684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07844649751981099,
      "backward_entropy": 0.056660825555974785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.34022521972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029403144493699074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07833496729532878,
      "backward_entropy": 0.056539383801546966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.4456787109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02946883998811245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07822182774543762,
      "backward_entropy": 0.05641767111691562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.64961242675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029532384127378464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07811010380585988,
      "backward_entropy": 0.05825489217584783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.20643615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02959275059401989,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07800148924191792,
      "backward_entropy": 0.05616195635362105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.73712921142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029649978503584862,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07789537310600281,
      "backward_entropy": 0.05804265087301081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.29507446289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02970951236784458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07778733472029369,
      "backward_entropy": 0.057934934442693535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.8646240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029767392203211784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0776799867550532,
      "backward_entropy": 0.057824134826660156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.09221649169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02982434816658497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0775738259156545,
      "backward_entropy": 0.05771194804798473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.54012298583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029880758374929428,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07746900618076324,
      "backward_entropy": 0.05547011982310902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.91658020019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029937932267785072,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.077363520860672,
      "backward_entropy": 0.05532493374564431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.72056579589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029992179945111275,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07726006706555684,
      "backward_entropy": 0.05517446994781494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.751304626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03005101904273033,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07715322077274323,
      "backward_entropy": 0.05724766037680886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.18598175048828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030101431533694267,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07705274224281311,
      "backward_entropy": 0.06273682550950484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.35208129882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030155038461089134,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07694977521896362,
      "backward_entropy": 0.056996941566467285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.55305480957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030208053067326546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07684738437334697,
      "backward_entropy": 0.056868921626697884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.610572814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03026415966451168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07674290736516316,
      "backward_entropy": 0.056741248477589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.27474975585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03031310811638832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07664225498835246,
      "backward_entropy": 0.056604948910799896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.26295471191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03036138229072094,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0765412946542104,
      "backward_entropy": 0.05402459881522439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.14566040039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030410878360271454,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07643873989582062,
      "backward_entropy": 0.056322943080555306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.60697937011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030468402430415154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0763295590877533,
      "backward_entropy": 0.0561844598163258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.05522918701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03052498772740364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07622168958187103,
      "backward_entropy": 0.056043180552395905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.19766235351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030578630045056343,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761159857114156,
      "backward_entropy": 0.05333090912212025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.16181182861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03064180351793766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0760030746459961,
      "backward_entropy": 0.05316304618662054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.02559661865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030703065916895866,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07589153448740642,
      "backward_entropy": 0.05299027399583296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.12442016601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030764425173401833,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07577993969122569,
      "backward_entropy": 0.05281501466577703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.30892944335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030832890421152115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07566336790720622,
      "backward_entropy": 0.06266445463353937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.94487762451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030904458835721016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07554514209429423,
      "backward_entropy": 0.055177840319546784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.88258361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030973585322499275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07542932033538818,
      "backward_entropy": 0.05503076856786555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.64181518554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031045757234096527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0753118892510732,
      "backward_entropy": 0.054883480072021484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.90020751953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03111543506383896,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07519681255022685,
      "backward_entropy": 0.06266284530813043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.41246795654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031191783025860786,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07507797082265218,
      "backward_entropy": 0.051764374429529365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.32836151123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031262997537851334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07496260106563568,
      "backward_entropy": 0.051577849821610885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.46321105957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03133348375558853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07484816511472066,
      "backward_entropy": 0.054265146905725654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.05101013183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031403180211782455,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07473445932070415,
      "backward_entropy": 0.05119196935133501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.48405456542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03147779405117035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07461820542812347,
      "backward_entropy": 0.05394134738228538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.55160522460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0315471813082695,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07450498143831889,
      "backward_entropy": 0.05079502409154719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.11115264892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03162272647023201,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07438765962918599,
      "backward_entropy": 0.05059484460137107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.28268432617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03169726952910423,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07427197694778442,
      "backward_entropy": 0.06265375289050015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.63992309570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03177567943930626,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0741538405418396,
      "backward_entropy": 0.05326312238519842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.14838409423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03185565769672394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07403456171353658,
      "backward_entropy": 0.049978640946474945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.95075225830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031933918595314026,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07391707599163055,
      "backward_entropy": 0.05291158502752131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.75346374511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03201064094901085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07380127410093944,
      "backward_entropy": 0.052727276628667656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.35615539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03208598494529724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07368699212869008,
      "backward_entropy": 0.052539283579046074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.44945526123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032158587127923965,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07357558608055115,
      "backward_entropy": 0.05234661969271573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.53160858154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03223066031932831,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07346577445665996,
      "backward_entropy": 0.05215120315551758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.96839141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032302774488925934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07335544625918071,
      "backward_entropy": 0.04862260818481445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.06455993652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032374002039432526,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07324647903442383,
      "backward_entropy": 0.04837955669923262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.96070098876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032451365143060684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07313424348831177,
      "backward_entropy": 0.05154117670926181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.35572814941406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03252760320901871,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07302409907182057,
      "backward_entropy": 0.06264708258888939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.97565460205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03260255232453346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07291552424430847,
      "backward_entropy": 0.04765146428888494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.44215393066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03267139941453934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07281218965848286,
      "backward_entropy": 0.05090753598646684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.26710510253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03273749351501465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07271029551823933,
      "backward_entropy": 0.05068100582469593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.63854217529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032810408622026443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.072605033715566,
      "backward_entropy": 0.05045992136001587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.26638793945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03287593275308609,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07250627875328064,
      "backward_entropy": 0.046587234193628486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.7718963623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032942768186330795,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07240672409534454,
      "backward_entropy": 0.046312234618447044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.48773193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03301474452018738,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07230507334073384,
      "backward_entropy": 0.04604233394969593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.55360412597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033080827444791794,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0722079873085022,
      "backward_entropy": 0.04575934193351052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.76811981201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033147264271974564,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07211219767729442,
      "backward_entropy": 0.045473705638538704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.26736450195312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03321431949734688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0720180074373881,
      "backward_entropy": 0.04904664646495472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.04598999023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03327872231602669,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07192460695902507,
      "backward_entropy": 0.048799319700761276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.82066345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033344022929668427,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07182963192462921,
      "backward_entropy": 0.0485459024255926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.12289428710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0334041491150856,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07173886895179749,
      "backward_entropy": 0.04430081085725264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.96338653564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03346499800682068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07164869705835979,
      "backward_entropy": 0.0480229529467496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.0937728881836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03352278843522072,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0715609888235728,
      "backward_entropy": 0.06254471432078969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.57288360595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03357769176363945,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07147523760795593,
      "backward_entropy": 0.04337072914296931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.18242645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03362732753157616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07139107584953308,
      "backward_entropy": 0.04719668626785278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.69911193847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03367835283279419,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0713063379128774,
      "backward_entropy": 0.04272176460786299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.75222778320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03373079374432564,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07122141122817993,
      "backward_entropy": 0.04239913821220398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.048397064208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033780790865421295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07113811373710632,
      "backward_entropy": 0.04632799191908403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.04167175292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033825285732746124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07105860114097595,
      "backward_entropy": 0.04602728106758811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.94333267211914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03386889398097992,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07098108530044556,
      "backward_entropy": 0.04139315540140325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.00314331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03390992060303688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07090635597705841,
      "backward_entropy": 0.04542085528373718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.96671295166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03396026790142059,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07082659502824147,
      "backward_entropy": 0.04071604121815075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.87539672851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034012481570243835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07074689368406932,
      "backward_entropy": 0.04482991316101768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.65668487548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034064605832099915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0706682155529658,
      "backward_entropy": 0.04453326355327259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.98410034179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03412127122282982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07058757543563843,
      "backward_entropy": 0.03974559361284429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.19650268554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034186117351055145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07050250470638275,
      "backward_entropy": 0.043956249952316284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.6061248779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425583243370056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07041578491528828,
      "backward_entropy": 0.04367529262195934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.64849090576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03433007001876831,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0703273316224416,
      "backward_entropy": 0.04339471730318936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.87503051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03440384194254875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07024070123831432,
      "backward_entropy": 0.04310998591509732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.86869049072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034480709582567215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07015420993169148,
      "backward_entropy": 0.0382744317704981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.76925659179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03455862030386925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0700687865416209,
      "backward_entropy": 0.03798332539471713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.514381408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03464564308524132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06998029351234436,
      "backward_entropy": 0.037708401679992676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.58014678955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03472523018717766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06989593803882599,
      "backward_entropy": 0.03741682117635554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.05506896972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0348016582429409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06981369853019714,
      "backward_entropy": 0.037116557359695435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.53607177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034878458827733994,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06973157326380412,
      "backward_entropy": 0.0368144078688188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.26988220214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494857996702194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0696524977684021,
      "backward_entropy": 0.04110053994438865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.669227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03501928970217705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06957278152306874,
      "backward_entropy": 0.04078810865228826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.22496032714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035082779824733734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06949737668037415,
      "backward_entropy": 0.04046698050065474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.52375793457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035144925117492676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06942341725031535,
      "backward_entropy": 0.03551819920539856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.81730651855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03520558401942253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06935042142868042,
      "backward_entropy": 0.03982877189462835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.19230651855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03526462987065315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06927794218063354,
      "backward_entropy": 0.03949989513917403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.51768493652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035321664065122604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06920832395553589,
      "backward_entropy": 0.03917093439535661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.33800506591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03537997230887413,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06913924713929494,
      "backward_entropy": 0.038844959302382034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.48664855957031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03543608635663986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06907229622205098,
      "backward_entropy": 0.03851579536091198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.928466796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035492002964019775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06900653739770253,
      "backward_entropy": 0.03818553686141968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.316036224365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03554409369826317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06894299387931824,
      "backward_entropy": 0.03785047206011685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.62263488769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035593658685684204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06888267397880554,
      "backward_entropy": 0.03751804611899636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.259361267089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03564329445362091,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06882227460543315,
      "backward_entropy": 0.037183268503709274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.19041442871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03568610921502113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06876462697982788,
      "backward_entropy": 0.03204826604236256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.80770111083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03572911024093628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0687062640984853,
      "backward_entropy": 0.036487311124801636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.17234420776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035775553435087204,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06864747901757558,
      "backward_entropy": 0.031337350606918335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.69352722167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0358179435133934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06859162449836731,
      "backward_entropy": 0.030985317446968773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.07917022705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035855647176504135,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06853683789571126,
      "backward_entropy": 0.03062564405527982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.744041442871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03589983657002449,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.068479190270106,
      "backward_entropy": 0.03512071479450573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.014427185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035939671099185944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06842342515786488,
      "backward_entropy": 0.034778026017275726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.53530883789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03597782179713249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06836959719657898,
      "backward_entropy": 0.034436924891038376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.59135437011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03602232784032822,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06831355889638265,
      "backward_entropy": 0.029276622967286545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.94839477539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03607301041483879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06825642784436543,
      "backward_entropy": 0.033781989054246384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.07157135009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03612669184803963,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06820062796274821,
      "backward_entropy": 0.02866377071900801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.68341827392578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03618045896291733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06814425190289815,
      "backward_entropy": 0.033164227550679985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.09595489501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03623272851109505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06808879971504211,
      "backward_entropy": 0.028056461702693592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.66715240478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036289032548666,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06803297996520996,
      "backward_entropy": 0.027762009338899094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.57760620117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036345068365335464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06797730425993602,
      "backward_entropy": 0.03223703937097029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.66863250732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036404792219400406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06792143980662028,
      "backward_entropy": 0.03193760189143094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.49195098876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03646107763051987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0678677757581075,
      "backward_entropy": 0.03163362633098255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.56304168701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036518439650535583,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06781304876009624,
      "backward_entropy": 0.026601924137635666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.38296508789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0365779884159565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06775901714960735,
      "backward_entropy": 0.02631848779591647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.16679382324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03663719817996025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06770557165145874,
      "backward_entropy": 0.030725847591053356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.0836181640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03669612482190132,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06765183806419373,
      "backward_entropy": 0.030424210158261387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.13643455505371,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0367562398314476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06759826342264812,
      "backward_entropy": 0.06200484796003862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.19239807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03680969774723053,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06754777828852336,
      "backward_entropy": 0.02518473971973766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.71200561523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0368652306497097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0674968957901001,
      "backward_entropy": 0.029516878453168003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.76485443115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036921385675668716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06744683782259624,
      "backward_entropy": 0.024624521082097835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.83757781982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03698435053229332,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06739512085914612,
      "backward_entropy": 0.02893299948085438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.89305877685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037051744759082794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06734238068262736,
      "backward_entropy": 0.028652448545802723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.64899444580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03711661696434021,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06729091703891754,
      "backward_entropy": 0.02385130524635315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.85781478881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03718139976263046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.067240575949351,
      "backward_entropy": 0.02808734503659335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.33089256286621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037243157625198364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06719246506690979,
      "backward_entropy": 0.02781205556609414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.76970672607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03729831427335739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06714681784311931,
      "backward_entropy": 0.023075114596973766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.34970474243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03735380992293358,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06710125009218852,
      "backward_entropy": 0.02724517204544761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.88224792480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037406519055366516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0670569638411204,
      "backward_entropy": 0.026958387006412853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.96310424804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03746265918016434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06701108316580455,
      "backward_entropy": 0.022289636460217564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.91305541992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037519264966249466,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0669657935698827,
      "backward_entropy": 0.02203597534786571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.67277526855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03757815808057785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06692090630531311,
      "backward_entropy": 0.026115590875799007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.78234100341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037639129906892776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06687523424625397,
      "backward_entropy": 0.02584590424190868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.49498748779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03770168870687485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06682923932870229,
      "backward_entropy": 0.025578390468250622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.37245559692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03776276484131813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06678422788778941,
      "backward_entropy": 0.02531012079932473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.10094451904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03781866282224655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0667399416367213,
      "backward_entropy": 0.025032216852361507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.49747467041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03787193447351456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06669659912586212,
      "backward_entropy": 0.024753001603213223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.314571380615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037928882986307144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06665235261122386,
      "backward_entropy": 0.024477376179261642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.59959411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03798084706068039,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06660846869150798,
      "backward_entropy": 0.024192734198136764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.588966369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03803250566124916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06656519571940105,
      "backward_entropy": 0.023913944309408016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.66549301147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038083765655756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06652238965034485,
      "backward_entropy": 0.023637338118119675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.65266418457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038132697343826294,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06647993127504985,
      "backward_entropy": 0.01935473084449768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.202754974365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03818462789058685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06643624107042949,
      "backward_entropy": 0.023082641038027676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.80400085449219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03823437541723251,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06639327605565389,
      "backward_entropy": 0.018885489214550365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.687322616577148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038289833813905716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06634920835494995,
      "backward_entropy": 0.022542877630753952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.99361801147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03833803907036781,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06630674997965495,
      "backward_entropy": 0.018431332978335293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.90735626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838589787483215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06626428167025249,
      "backward_entropy": 0.02199912884018638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.34254455566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038437582552433014,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06622243920962016,
      "backward_entropy": 0.017982470718297092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.74263763427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03848893567919731,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06618061165014903,
      "backward_entropy": 0.02148551019755277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.40007019042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038541991263628006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06613871455192566,
      "backward_entropy": 0.02123674208467657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.00006103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038596753031015396,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06609724958737691,
      "backward_entropy": 0.01735884357582439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.409339904785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03864927962422371,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06605586409568787,
      "backward_entropy": 0.0207532061771913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.50126647949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03869921714067459,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06601412097613017,
      "backward_entropy": 0.01695335724137046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.70259857177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03875049576163292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06597208480040233,
      "backward_entropy": 0.020258936015042393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.591007232666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038802556693553925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06592950224876404,
      "backward_entropy": 0.020013431256467647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.15382385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03884987160563469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06588782866795857,
      "backward_entropy": 0.019768001003698868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.369617462158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038898568600416183,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06584506233533223,
      "backward_entropy": 0.019522875547409058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.13717651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038941700011491776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0658043920993805,
      "backward_entropy": 0.019280365922234276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.07299041748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038988642394542694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06576310594876607,
      "backward_entropy": 0.019044168970801613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.160404205322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039036475121974945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0657225747903188,
      "backward_entropy": 0.018816481937061657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.564279556274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039080146700143814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06568301717440288,
      "backward_entropy": 0.01858908479863947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.85519027709961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039119500666856766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06564351419607799,
      "backward_entropy": 0.01521982117132707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.671852111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03916028514504433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06560432414213817,
      "backward_entropy": 0.01813468878919428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.83809661865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03919907286763191,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06556549668312073,
      "backward_entropy": 0.01791204105723988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.15304946899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03924659639596939,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06552377343177795,
      "backward_entropy": 0.017698515545238148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.34628677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039292871952056885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06548202037811279,
      "backward_entropy": 0.017484160986813633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.03166198730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933669626712799,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06544065475463867,
      "backward_entropy": 0.01727093756198883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.056074142456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03938478231430054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06539906561374664,
      "backward_entropy": 0.014219536022706465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.84227752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039428193122148514,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06535753607749939,
      "backward_entropy": 0.016857300292361866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.113033294677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03948143497109413,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06531355778376262,
      "backward_entropy": 0.016655989668586037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.848060607910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03953135758638382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06526986261208852,
      "backward_entropy": 0.01645285432988947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.07864761352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03958337754011154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0652259886264801,
      "backward_entropy": 0.016256289048628372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.664730072021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039631959050893784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06518220901489258,
      "backward_entropy": 0.016056085174733944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.65109634399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03967791795730591,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06513882180054982,
      "backward_entropy": 0.013322370973500338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.09671401977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039721399545669556,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06509564320246379,
      "backward_entropy": 0.013174899599768898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.19068145751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03976772353053093,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06505203247070312,
      "backward_entropy": 0.013035835190252825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.64937210083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03981619328260422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06500730911890666,
      "backward_entropy": 0.01290102709423412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.357177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03986528888344765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0649624913930893,
      "backward_entropy": 0.01508945497599515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.00408172607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039917025715112686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06491805116335551,
      "backward_entropy": 0.014916176145726984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.89639663696289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03996600583195686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0648741324742635,
      "backward_entropy": 0.01474170522256331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.80348587036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040014300495386124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.064830482006073,
      "backward_entropy": 0.014571195298975164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.783164978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040065377950668335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06478659311930339,
      "backward_entropy": 0.014411015944047407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.41534423828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04011869430541992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0647420883178711,
      "backward_entropy": 0.014255472204901955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.38234519958496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04017110541462898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06469791134198506,
      "backward_entropy": 0.014102968302640047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.278926849365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0402209646999836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06465406219164531,
      "backward_entropy": 0.013951082121242176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.87929916381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04026854783296585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06461045145988464,
      "backward_entropy": 0.011905458840456877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.75000762939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0403161458671093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06456739703814189,
      "backward_entropy": 0.013654418966986916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.170265197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04036948084831238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06452334423859914,
      "backward_entropy": 0.013515987179496071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.79252624511719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040418509393930435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06447943051656087,
      "backward_entropy": 0.013373843648216942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.19426155090332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04046822711825371,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06443488597869873,
      "backward_entropy": 0.01154853809963573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.680397033691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040514957159757614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06438992420832317,
      "backward_entropy": 0.013083046132867987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.283329010009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040561046451330185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06434460481007893,
      "backward_entropy": 0.012933974916284735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.73133850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04060714319348335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06429942448933919,
      "backward_entropy": 0.011264234781265259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.13440704345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04065632075071335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0642533799012502,
      "backward_entropy": 0.011179541322317991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.45925521850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0407111831009388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06420644124348958,
      "backward_entropy": 0.012522877617315813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.63290786743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040763091295957565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06416003406047821,
      "backward_entropy": 0.01102262938564474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.06398582458496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04081568494439125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06411255399386089,
      "backward_entropy": 0.01225720616904172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.25792694091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.040866006165742874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06406574447949727,
      "backward_entropy": 0.062092602252960205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.63621139526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04091734439134598,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06401842832565308,
      "backward_entropy": 0.01079226556149396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.69010925292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04097133129835129,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06397077441215515,
      "backward_entropy": 0.011876812035387213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.07535171508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04103058576583862,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06392175952593486,
      "backward_entropy": 0.011760398745536804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.72634887695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041088834404945374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0638731022675832,
      "backward_entropy": 0.011648337949406017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.647830963134766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04115023836493492,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06382343173027039,
      "backward_entropy": 0.011538235978646711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.76175308227539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041211094707250595,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06377321481704712,
      "backward_entropy": 0.06221491640264338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.00968933105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04127343371510506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06372228264808655,
      "backward_entropy": 0.011311483654108915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.28565979003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041343823075294495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06367054581642151,
      "backward_entropy": 0.011211475188081915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.977581024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04141487553715706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06361859043439229,
      "backward_entropy": 0.011113556948575106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.758480072021484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04148199036717415,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.06356728076934814,
      "backward_entropy": 0.062322020530700684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.05936431884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04155036062002182,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06351561347643535,
      "backward_entropy": 0.010919754478064451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.33052444458008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04162077605724335,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06346299250920613,
      "backward_entropy": 0.010824540121988817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.24559783935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04169211909174919,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06341015795866649,
      "backward_entropy": 0.010159865699031136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.75056076049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04176392778754234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06335686643918355,
      "backward_entropy": 0.010640978813171387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.41806030273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041832830756902695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06330363949139912,
      "backward_entropy": 0.010543859817764976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.45589065551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041906535625457764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06324859460194905,
      "backward_entropy": 0.010445995086973364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.120250701904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04198084771633148,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06319394707679749,
      "backward_entropy": 0.009985340589826757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.12461853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04205074906349182,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06314004460970561,
      "backward_entropy": 0.009940182620828802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.970176696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04211798310279846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06308528780937195,
      "backward_entropy": 0.010156930847601458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.76152038574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04218752309679985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06303050617376964,
      "backward_entropy": 0.010059301148761402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.724395751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042256105691194534,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06297577420870464,
      "backward_entropy": 0.009794094345786354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.612070083618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042317964136600494,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0629221002260844,
      "backward_entropy": 0.00974151221188632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.44647979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04237648844718933,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06286867459615071,
      "backward_entropy": 0.009757076474753294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.472373962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042434487491846085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.062814195950826,
      "backward_entropy": 0.009648771448568865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.618553161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04248829558491707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06276015937328339,
      "backward_entropy": 0.009540723806077784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.725154876708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04254477098584175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06270629167556763,
      "backward_entropy": 0.009439668194814161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.31754684448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042601801455020905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06265196204185486,
      "backward_entropy": 0.009341275150125677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.199636459350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042661555111408234,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06259586413701375,
      "backward_entropy": 0.00938921557231383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.75434112548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042716920375823975,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06254062056541443,
      "backward_entropy": 0.009328429671851072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.024600982666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04277021065354347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06248586376508077,
      "backward_entropy": 0.009036307307806883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.930219650268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04281991720199585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06243181228637695,
      "backward_entropy": 0.008937623013149609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.11282730102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042866531759500504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06237827738126119,
      "backward_entropy": 0.008840214122425426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.22502136230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04291351139545441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06232452392578125,
      "backward_entropy": 0.008746865798126568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.945064544677734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042967528104782104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06226879358291626,
      "backward_entropy": 0.008654563941738823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.97662353515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04302087426185608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0622126559416453,
      "backward_entropy": 0.008564324541525408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.58420944213867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043076395988464355,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06215539574623108,
      "backward_entropy": 0.008957156403498217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.002254486083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313167184591293,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06209812064965566,
      "backward_entropy": 0.008390744978731329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.82265853881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04319097474217415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06203914682070414,
      "backward_entropy": 0.008876530961556868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.675575256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043253686279058456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061979313691457115,
      "backward_entropy": 0.008236895230683413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.27896881103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04331672936677933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061919202407201133,
      "backward_entropy": 0.008813276886940002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.61222076416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043392643332481384,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06185429294904073,
      "backward_entropy": 0.008787960491397163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.20548629760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04347090423107147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061788330475489296,
      "backward_entropy": 0.008756538006392393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.959129333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04354742541909218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061722775300343834,
      "backward_entropy": 0.007953506301749836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.668747901916504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0436226911842823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06165750324726105,
      "backward_entropy": 0.007881873710588976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.374977111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04369128867983818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06159438192844391,
      "backward_entropy": 0.0078123503110625525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626853942871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043757881969213486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061531633138656616,
      "backward_entropy": 0.007743075489997864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.907291412353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043818399310112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06147071719169617,
      "backward_entropy": 0.00767342746257782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.04936981201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04387648031115532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061410183707873024,
      "backward_entropy": 0.007605387405915694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.824092864990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04393557086586952,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06134941180547079,
      "backward_entropy": 0.00854436917738481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.630565643310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043993838131427765,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06128887335459391,
      "backward_entropy": 0.008522144772789696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.722904205322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044049832969903946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061228921016057335,
      "backward_entropy": 0.007420484315265308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.58021545410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04410793259739876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06116757790247599,
      "backward_entropy": 0.0073601440949873495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.303340911865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04417088255286217,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.061103890339533486,
      "backward_entropy": 0.008455869826403532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.19023895263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04423561319708824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.061039174596468605,
      "backward_entropy": 0.0072462592612613334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.00144577026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04429899528622627,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06097465753555298,
      "backward_entropy": 0.007192737676880576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.563941955566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04436250403523445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06090963383515676,
      "backward_entropy": 0.0071398907087065954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.882938385009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044430211186409,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.060842663049697876,
      "backward_entropy": 0.008390987461263483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.140791893005371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04449521377682686,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06077659626801809,
      "backward_entropy": 0.008379901674660769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.358421325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04455456882715225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06071274479230245,
      "backward_entropy": 0.006991808387366208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.76505661010742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04461437463760376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06064834197362264,
      "backward_entropy": 0.006942721253091639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.551485061645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04467741400003433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06058215101559957,
      "backward_entropy": 0.006894003261219372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.991884231567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04473762586712837,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06051689386367798,
      "backward_entropy": 0.006843961097977378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.030214309692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04479271173477173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06045383711655935,
      "backward_entropy": 0.00830752741206776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.55533218383789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044847529381513596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060390323400497437,
      "backward_entropy": 0.00674643570726568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.08924865722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044903844594955444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06032618383566538,
      "backward_entropy": 0.00828476995229721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.3311767578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04496242105960846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.060260385274887085,
      "backward_entropy": 0.006660428914156827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.551136016845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04502122849225998,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06019399563471476,
      "backward_entropy": 0.006615284491669048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.87807846069336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04507948458194733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.06012780467669169,
      "backward_entropy": 0.0065727437084371395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.87736511230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04513584449887276,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.06006231904029846,
      "backward_entropy": 0.00824755701151761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.232038497924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04519275575876236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05999612808227539,
      "backward_entropy": 0.0064897313714027405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.051536560058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045246049761772156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05993166069189707,
      "backward_entropy": 0.006445476954633539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.96525001525879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04530175402760506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059865549206733704,
      "backward_entropy": 0.006401055238463662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.606124401092529,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04535730183124542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05979921420415243,
      "backward_entropy": 0.006359529766169461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.537010192871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0454084575176239,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05973506967226664,
      "backward_entropy": 0.0063197958198460665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.38646697998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045462463051080704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05966902772585551,
      "backward_entropy": 0.006281467323953455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.53586959838867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045518744736909866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0596014658610026,
      "backward_entropy": 0.006242226470600475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.034400939941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045578733086586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059531440337498985,
      "backward_entropy": 0.006204166872934861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.83441925048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04564032703638077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05946028729279836,
      "backward_entropy": 0.006164833225987174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.397342681884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045703642070293427,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.059387664000193276,
      "backward_entropy": 0.00813560729677027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.801748275756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04576713591814041,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05931474765141805,
      "backward_entropy": 0.006088331341743469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.89735221862793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04582818225026131,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05924303332964579,
      "backward_entropy": 0.006051988764242692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.56886291503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0458882637321949,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05917163689931234,
      "backward_entropy": 0.008106839927760038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.515501022338867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045953813940286636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059096693992614746,
      "backward_entropy": 0.0059776428070935335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.981266021728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04601665586233139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.059023271004358925,
      "backward_entropy": 0.005940733985467391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.433265686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04608498513698578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.058946008483568825,
      "backward_entropy": 0.005903758785941384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.29642868041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04615303874015808,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0588686466217041,
      "backward_entropy": 0.005868237804282795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.09436798095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04622194170951843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05879045526186625,
      "backward_entropy": 0.0058321593837304545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.034811019897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046290382742881775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05871228873729706,
      "backward_entropy": 0.005796494131738489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.906402587890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04635479301214218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05863634248574575,
      "backward_entropy": 0.005764254792170091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.30522155761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04641644284129143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05856218934059143,
      "backward_entropy": 0.008016484027559107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.30982208251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046482235193252563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05848486224810282,
      "backward_entropy": 0.0056988149881362915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.111839294433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046549197286367416,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05840633809566498,
      "backward_entropy": 0.007997580549933693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.908607482910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661709815263748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05832700928052267,
      "backward_entropy": 0.007987629960883747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.400684356689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04668589308857918,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05824670195579529,
      "backward_entropy": 0.005600881847468289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.977943420410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046751562505960464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05816834171613058,
      "backward_entropy": 0.00796688212589784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.703853607177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046821024268865585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05808686216672262,
      "backward_entropy": 0.005537559362975034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.75187110900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046893928200006485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05800244708855947,
      "backward_entropy": 0.0079485299912366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.87648391723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046964775770902634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.057919194300969444,
      "backward_entropy": 0.00794243948026137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.470104217529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04703613370656967,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057835280895233154,
      "backward_entropy": 0.005449359051205895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.58858108520508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04710548371076584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05775254964828491,
      "backward_entropy": 0.005421077663248236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04717817157506943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05766684810320536,
      "backward_entropy": 0.005393071946772662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.038841247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047248754650354385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057582457860310875,
      "backward_entropy": 0.005366245454007929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.75032424926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04732003062963486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05749700963497162,
      "backward_entropy": 0.005340232090516524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.33798599243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047394488006830215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05740858614444733,
      "backward_entropy": 0.005315030501647429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.62300682067871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04746539890766144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.057322680950164795,
      "backward_entropy": 0.005291222171349959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.488040924072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047534357756376266,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05723799765110016,
      "backward_entropy": 0.005268265577879819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.354225158691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04760163649916649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05715423822402954,
      "backward_entropy": 0.005246755074370991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.639602661132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047667186707258224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05707176526387533,
      "backward_entropy": 0.005224938758394935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.102365493774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047728732228279114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0569924513498942,
      "backward_entropy": 0.007906506007367914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.217222213745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047788992524147034,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.056914145747820534,
      "backward_entropy": 0.005181675268845124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.658533096313477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04784940928220749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05683547258377075,
      "backward_entropy": 0.005158804357051849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.10157775878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790745675563812,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05675878624121348,
      "backward_entropy": 0.0051358694379979915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.481464385986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0479673370718956,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05667991439501444,
      "backward_entropy": 0.007888485762205992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.635210037231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048024944961071014,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05660297969977061,
      "backward_entropy": 0.007883376695893028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.759220123291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04808325693011284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05652479330698649,
      "backward_entropy": 0.00507116825743155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.45347213745117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048145826905965805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056442042191823326,
      "backward_entropy": 0.007877954027869484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.257381439208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048210956156253815,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0563569168249766,
      "backward_entropy": 0.007875601676377382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.020984649658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048279616981744766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05626774330933889,
      "backward_entropy": 0.0050108297304673624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.847017288208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834393411874771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05618259310722351,
      "backward_entropy": 0.004991744052280079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.686317443847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04840812459588051,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0560971995194753,
      "backward_entropy": 0.00786796821789308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.53271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04847203940153122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.056011974811553955,
      "backward_entropy": 0.00786417451771823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.37276268005371,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04853590950369835,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05592632790406545,
      "backward_entropy": 0.06297044320539995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.89497756958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859958216547966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055840318401654564,
      "backward_entropy": 0.004918076436627995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.249258041381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048665620386600494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05575023591518402,
      "backward_entropy": 0.00490034202283079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.672882080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04873010143637657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0556610773007075,
      "backward_entropy": 0.00785487483848225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.22165298461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048795659095048904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05556987722714742,
      "backward_entropy": 0.007854408838532188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019554274156689644,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04886331409215927,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055475781361262,
      "backward_entropy": 0.0048518719320947475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.05912971496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04892433062195778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05538889765739441,
      "backward_entropy": 0.004837715490297837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.57868957519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048983000218868256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055304110050201416,
      "backward_entropy": 0.004824188622561368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.881025314331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04904433712363243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.055215686559677124,
      "backward_entropy": 0.004809640347957611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.199437141418457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0491032637655735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05512987573941549,
      "backward_entropy": 0.007855361158197577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.845279693603516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04915875196456909,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05504791438579559,
      "backward_entropy": 0.00785487483848225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.62857437133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04921489208936691,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054964542388916016,
      "backward_entropy": 0.004769016395915638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.036520004272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049269143491983414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05488306780656179,
      "backward_entropy": 0.004756642336195166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.471101760864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0493205189704895,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05480467279752096,
      "backward_entropy": 0.007857685062018309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.396974563598633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04937043413519859,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054727847377459206,
      "backward_entropy": 0.00473433258858594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.20245361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04941903054714203,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054652392864227295,
      "backward_entropy": 0.004723495719107715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.07958221435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04946884512901306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05457507570584615,
      "backward_entropy": 0.004712374711578543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.73149108886719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04951976239681244,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05449596047401428,
      "backward_entropy": 0.0047011598944664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.094860076904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049574028700590134,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05441219607988993,
      "backward_entropy": 0.004689189520749179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.025997161865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04962658882141113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054330259561538696,
      "backward_entropy": 0.004678039388223128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.243194580078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0496811717748642,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.054245203733444214,
      "backward_entropy": 0.06298662315715443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.571727752685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049735113978385925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.054160818457603455,
      "backward_entropy": 0.004655478691512888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037863668985664845,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04978618025779724,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0540799746910731,
      "backward_entropy": 0.007852879437533293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.413816452026367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04983219504356384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05400614937146505,
      "backward_entropy": 0.004636042497374795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.057708740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988079145550728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05392845471700033,
      "backward_entropy": 0.0046261836859312925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.74811553955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04993049427866936,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.053849036494890846,
      "backward_entropy": 0.007848106324672699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.64938735961914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049980029463768005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053769578536351524,
      "backward_entropy": 0.004605636677958749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.276310920715332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05002940818667412,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053690205017725624,
      "backward_entropy": 0.004595470699397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.230012893676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007627606391907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05361430843671163,
      "backward_entropy": 0.004585792395201596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.55119514465332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05012091249227524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05354138215382894,
      "backward_entropy": 0.0078339238058437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.410139083862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016819015145302,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05346418420473734,
      "backward_entropy": 0.00456709550185637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.174253463745117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050217870622873306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.053383201360702515,
      "backward_entropy": 0.004556880078532479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.094331741333008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05026734992861748,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05330236256122589,
      "backward_entropy": 0.007816874168135902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.97449493408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05031783878803253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05321955680847168,
      "backward_entropy": 0.00453693148764697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.873558044433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503680519759655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05313690006732941,
      "backward_entropy": 0.004527560011907058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.887721061706543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05041798576712608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05305452148119608,
      "backward_entropy": 0.00451834499835968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.75931453704834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050465382635593414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05297570923964182,
      "backward_entropy": 0.004510071805932305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.793581008911133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05051162466406822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052898610631624855,
      "backward_entropy": 0.0045022415843876925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.875222682952881,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050555672496557236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05282476544380188,
      "backward_entropy": 0.004495135762474753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.416364669799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05059659108519554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05275571346282959,
      "backward_entropy": 0.007782918485728177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.166431427001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05063813924789429,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05268547932306925,
      "backward_entropy": 0.0044826038859107275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.435063362121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050681404769420624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05261220037937164,
      "backward_entropy": 0.0044759254563938485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.580961227416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050723910331726074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05254007379213969,
      "backward_entropy": 0.007770470597527244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.309981346130371,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05076457932591438,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.05247081319491068,
      "backward_entropy": 0.06298958171497691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.249490737915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0508047379553318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052402153611183167,
      "backward_entropy": 0.004458614371039651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.460046768188477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050844430923461914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.052333980798721313,
      "backward_entropy": 0.004453476857055317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.553483963012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05088255554437637,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05226828654607137,
      "backward_entropy": 0.007756720212372867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.762453079223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050922691822052,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05219887693723043,
      "backward_entropy": 0.004443807358091528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.680086135864258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05096350982785225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05212820569674174,
      "backward_entropy": 0.004438872703097083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.649847030639648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05100492388010025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0520562877257665,
      "backward_entropy": 0.004433919421651147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.51929473876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051043447107076645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05198939641316732,
      "backward_entropy": 0.004429774528199976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.83010482788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051082793623209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051920910676320396,
      "backward_entropy": 0.004425655711780895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.181458473205566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05112171918153763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05185296138127645,
      "backward_entropy": 0.004421664571220224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.141727447509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05115914344787598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05178770422935486,
      "backward_entropy": 0.00441821427507834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09918212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051203109323978424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05171060065428416,
      "backward_entropy": 0.004412980580871756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.11254119873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05124503746628761,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051637157797813416,
      "backward_entropy": 0.004408208483999426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.533287048339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05128739774227142,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.05156277120113373,
      "backward_entropy": 0.007709236307577653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.969964981079102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133127048611641,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.051485454042752586,
      "backward_entropy": 0.00439830869436264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.31669807434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05137309804558754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05141187707583109,
      "backward_entropy": 0.004393641921606931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88400650024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141647905111313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05133521556854248,
      "backward_entropy": 0.004388771273873069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.101757049560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051457855850458145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0512622594833374,
      "backward_entropy": 0.007679505104368383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.197040557861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05150076374411583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05118627846240997,
      "backward_entropy": 0.004379201680421829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.886674880981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05154282972216606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05111175775527954,
      "backward_entropy": 0.004374290731820193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.776365280151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051586370915174484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05103431145350138,
      "backward_entropy": 0.004369088533249768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.999095916748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05163125321269035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05095428228378296,
      "backward_entropy": 0.0043638003143397245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.241840362548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05167512223124504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05087601145108541,
      "backward_entropy": 0.004359012977643447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.439212799072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171917751431465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050797114769617714,
      "backward_entropy": 0.004354349252852527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.796741485595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051764458417892456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05071581403414408,
      "backward_entropy": 0.004349195821718736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.69536590576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0518086701631546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050636470317840576,
      "backward_entropy": 0.004344628277150067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.657241821289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05185629799962044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05055042107899984,
      "backward_entropy": 0.004339391534978693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.974088668823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051902610808610916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05046685039997101,
      "backward_entropy": 0.004334788092158057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.02389907836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051949892193078995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05038123329480489,
      "backward_entropy": 0.004329942844130776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.584760665893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051999133080244064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05029168725013733,
      "backward_entropy": 0.004324980757453225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24670696258545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052047938108444214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.050202876329422,
      "backward_entropy": 0.004320133138786663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.48862075805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052094217389822006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0501190721988678,
      "backward_entropy": 0.004316373304887252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.2968692779541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052141450345516205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.05003316203753153,
      "backward_entropy": 0.004312566735527732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.056406497955322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0521884523332119,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04994756976763407,
      "backward_entropy": 0.007517271421172402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.03506326675415,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052231933921575546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04986928900082906,
      "backward_entropy": 0.0043061365458098326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.020769119262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052272308617830276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04979734122753143,
      "backward_entropy": 0.0043043937872756614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.941364288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05231092497706413,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049728989601135254,
      "backward_entropy": 0.004303065890615637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.806142807006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052351150661706924,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04965710639953613,
      "backward_entropy": 0.0043010386553677645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.842848777770996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05239395424723625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04957965016365051,
      "backward_entropy": 0.004298601299524307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.395469665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052435752004384995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04950430989265442,
      "backward_entropy": 0.004295836118134585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.609294891357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05248204991221428,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04941935837268829,
      "backward_entropy": 0.004291822625832124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010967514477670193,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05252821743488312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04933454096317291,
      "backward_entropy": 0.004288754002614455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.28689193725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256977677345276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04925978680451711,
      "backward_entropy": 0.0042859417471018705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.17864227294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052612535655498505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04918244481086731,
      "backward_entropy": 0.0042822398245334625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634505271911621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265642702579498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04910252491633097,
      "backward_entropy": 0.004278203303163702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.382158279418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052698276937007904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.049026817083358765,
      "backward_entropy": 0.0042757070200009776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7821784019470215,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05273927003145218,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.048952837785085045,
      "backward_entropy": 0.06298953836614435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.262102127075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05277732014656067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04888532559076945,
      "backward_entropy": 0.007358118891716003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.843111038208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052819058299064636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0488095631202062,
      "backward_entropy": 0.004270351407202807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.24595832824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05286509543657303,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04872446755568186,
      "backward_entropy": 0.007330665534192865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.738631248474121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291295051574707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04863522450129191,
      "backward_entropy": 0.007315298373048956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.986196517944336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05296045169234276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04854653775691986,
      "backward_entropy": 0.004260352728041736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.916916847229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05300639569759369,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048461308081944786,
      "backward_entropy": 0.004257584160024469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.849501609802246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0530509315431118,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048379287123680115,
      "backward_entropy": 0.004254692657427354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.962486267089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05309431254863739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04829975962638855,
      "backward_entropy": 0.007259352640672164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5841658115386963,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05313870310783386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04821766416231791,
      "backward_entropy": 0.004250667989253998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.201997756958008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317975953221321,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04814321796099345,
      "backward_entropy": 0.004249105060642416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.068614482879639,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05322088301181793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.048068578044573464,
      "backward_entropy": 0.004246856678615917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.040410995483398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053260065615177155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04799837867418925,
      "backward_entropy": 0.004245160655541854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.475503921508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05329953506588936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04792742927869161,
      "backward_entropy": 0.004243309524926272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.951120853424072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05333823710680008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04785814881324768,
      "backward_entropy": 0.004241652109406211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4669671058654785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053375255316495895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04779268801212311,
      "backward_entropy": 0.004240722818808122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8797736167907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05340968072414398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047733316818873085,
      "backward_entropy": 0.004240325567397204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.26008129119873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344283953309059,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04767698049545288,
      "backward_entropy": 0.004240537570281463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.004592895507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053475890308618546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04762031634648641,
      "backward_entropy": 0.004240973090583628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.537450790405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053510796278715134,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04755928615729014,
      "backward_entropy": 0.007105466317046772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.466160774230957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053546417504549026,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04749638835589091,
      "backward_entropy": 0.004240584983067079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.73677635192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05358264595270157,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0474318265914917,
      "backward_entropy": 0.004240377721461383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.669193744659424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05362038314342499,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04736363887786865,
      "backward_entropy": 0.007062969559972937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.468168258666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053656529635190964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04729908208052317,
      "backward_entropy": 0.004239346493374218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.877941131591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05369729921221733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.047223264972368874,
      "backward_entropy": 0.004238823598081415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.083731651306152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053737133741378784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04714968800544739,
      "backward_entropy": 0.004238574003631418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.49333381652832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05377708002924919,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04707576831181844,
      "backward_entropy": 0.00423791767521338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.471011161804199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0538192093372345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04699637492497762,
      "backward_entropy": 0.004237298938361081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.450674057006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05385925620794296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046922008196512856,
      "backward_entropy": 0.004237295890396292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.57108211517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05390236899256706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0468402107556661,
      "backward_entropy": 0.0069635686549273405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.669669151306152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05394420772790909,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04676156242688497,
      "backward_entropy": 0.004235359755429355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3043036460876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053985871374607086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04668344557285309,
      "backward_entropy": 0.006930740042166276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.62667179107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054025571793317795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046609933177630104,
      "backward_entropy": 0.004233520816672932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.225327491760254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054066356271505356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04653356969356537,
      "backward_entropy": 0.004233161156827753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26652717590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410515516996384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04646212855974833,
      "backward_entropy": 0.004233384674245661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.272993087768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054143231362104416,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.046392242113749184,
      "backward_entropy": 0.006873995065689087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.067080497741699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05418148264288902,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046321903665860496,
      "backward_entropy": 0.00423528863625093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.101444244384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05421718582510948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04625770449638367,
      "backward_entropy": 0.004238105633042075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049131393432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054252348840236664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046194761991500854,
      "backward_entropy": 0.004240743815898895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.987932205200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05428704991936684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04613275329271952,
      "backward_entropy": 0.004243473776362159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.916556358337402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054322320967912674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046069140235582985,
      "backward_entropy": 0.004246180707758123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9838335514068604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435822904109955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.046003445982933044,
      "backward_entropy": 0.004250050268389962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.661714553833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439155921339989,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.045944611231486,
      "backward_entropy": 0.004253720356659455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.712519645690918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05442740023136139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04587933421134949,
      "backward_entropy": 0.004256049340421503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.541561126708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054463617503643036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.045812979340553284,
      "backward_entropy": 0.004258111796595834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9119699001312256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05450128763914108,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04574239253997803,
      "backward_entropy": 0.0042610205709934235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.631539344787598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05453632399439812,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04567858576774597,
      "backward_entropy": 0.006754404441876845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.280313491821289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05457080528140068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0456162691116333,
      "backward_entropy": 0.004268302158875899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.695887088775635,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460676550865173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04554980993270874,
      "backward_entropy": 0.004271490330045874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.295482635498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054641082882881165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04548789064089457,
      "backward_entropy": 0.006721664558757435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.226502418518066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05467575415968895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.045425196488698326,
      "backward_entropy": 0.004275687038898468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.718467712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05471076816320419,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0453617125749588,
      "backward_entropy": 0.004276064986532385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314952850341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0547480583190918,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04529213905334473,
      "backward_entropy": 0.004275850613008846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.01336669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478473752737045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04522358377774557,
      "backward_entropy": 0.004277337681163441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.483763694763184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05482145771384239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04515528678894043,
      "backward_entropy": 0.006642966107888656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.579217910766602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054856494069099426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04509139060974121,
      "backward_entropy": 0.004277689213102514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.489787101745605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05489274859428406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04502423604329427,
      "backward_entropy": 0.004276904192837802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.047727584838867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05493008717894554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04495429495970408,
      "backward_entropy": 0.004275349053469571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.68526029586792,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054966703057289124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044885843992233276,
      "backward_entropy": 0.004275082525881854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.591928482055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055000752210617065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04482415318489075,
      "backward_entropy": 0.004276035184209997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.13730525970459,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05503489077091217,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04476296901702881,
      "backward_entropy": 0.06298889897086403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.260353088378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05507039278745651,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04469778140385946,
      "backward_entropy": 0.004272657023234801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.956632614135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05510881170630455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044624850153923035,
      "backward_entropy": 0.004269830205223777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.728825569152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05514806881546974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04454952975114187,
      "backward_entropy": 0.004266856068914587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.763187408447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05518626421689987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044477115074793495,
      "backward_entropy": 0.004264571111310612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.14072036743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522541329264641,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044401745001475014,
      "backward_entropy": 0.0042631256986748085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.065293312072754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05526447296142578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044326325257619224,
      "backward_entropy": 0.004262366416779431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.987661361694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05530339851975441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04425101478894552,
      "backward_entropy": 0.004261906851421703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.85433578491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05534227564930916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.044175575176874794,
      "backward_entropy": 0.00636967271566391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3886637687683105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05538279563188553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04409560561180115,
      "backward_entropy": 0.004262564195828004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.89856481552124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542195588350296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.044019718964894615,
      "backward_entropy": 0.004261956973509355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.51398754119873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05545908212661743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0439495195945104,
      "backward_entropy": 0.0042617232962088155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.826264381408691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055497970432043076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04387434323628744,
      "backward_entropy": 0.004261193627660925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.788865089416504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05553479865193367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043805052836736046,
      "backward_entropy": 0.004260668023066087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.111805438995361,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0555698461830616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04374061028162638,
      "backward_entropy": 0.004260855642232028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063283920288086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05560428649187088,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04367780685424805,
      "backward_entropy": 0.06298285180872137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.341583251953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05563812702894211,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043615693847338356,
      "backward_entropy": 0.004264719784259796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.973204612731934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055672287940979004,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043552786111831665,
      "backward_entropy": 0.004267495464194904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.918127059936523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570556968450546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0434928834438324,
      "backward_entropy": 0.0042685456573963165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5944905281066895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05573834106326103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04343405365943909,
      "backward_entropy": 0.004270516335964203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.35533332824707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05576970428228378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04337919255097707,
      "backward_entropy": 0.00427295369180766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.27961540222168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05580240860581398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04332035779953003,
      "backward_entropy": 0.004275143823840402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.964529037475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05583622679114342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04325843850771586,
      "backward_entropy": 0.006127612834626978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897401809692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055870264768600464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043195645014444985,
      "backward_entropy": 0.004277596080845053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.027195930480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0559045746922493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04313170909881592,
      "backward_entropy": 0.004279801452701742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.58827543258667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055940136313438416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.043063730001449585,
      "backward_entropy": 0.004283963956616141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.697965621948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05597473308444023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04299823443094889,
      "backward_entropy": 0.00428701869466088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.069273948669434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05601456016302109,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04291824003060659,
      "backward_entropy": 0.004288749938661402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.418877601623535,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05605646222829819,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.04283250868320465,
      "backward_entropy": 0.06298424438996748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.68183422088623,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05609690770506859,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04275082548459371,
      "backward_entropy": 0.004291140220381997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397688865661621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05613870173692703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042664676904678345,
      "backward_entropy": 0.004293924028223211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.180721282958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056179679930210114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042581369479497276,
      "backward_entropy": 0.00429532609202645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.196246147155762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05621829256415367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0425050954023997,
      "backward_entropy": 0.004296612333167683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.375091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05625559389591217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04243289430936178,
      "backward_entropy": 0.004297475245865909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.124757766723633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05629761889576912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042347222566604614,
      "backward_entropy": 0.00429720397699963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0273213386535645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05634051188826561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042259146769841514,
      "backward_entropy": 0.004296446727080779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.971714973449707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05638158693909645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042176708579063416,
      "backward_entropy": 0.004295031455430118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.866650104522705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05642096698284149,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042099724213282265,
      "backward_entropy": 0.004292566329240799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.735739707946777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056459806859493256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.042024120688438416,
      "backward_entropy": 0.004290491342544556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.88692569732666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05649885535240173,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041948139667510986,
      "backward_entropy": 0.004287620498375459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7524285316467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05653563141822815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04187906285127004,
      "backward_entropy": 0.00428471104665236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470569610595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056571248918771744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04181326429049174,
      "backward_entropy": 0.004282262176275253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5206828117370605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05660754442214966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041745071609814964,
      "backward_entropy": 0.004280854016542435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.601781368255615,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05664355307817459,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04167757431666056,
      "backward_entropy": 0.004279889505017887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392107009887695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05667850375175476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041613017519315086,
      "backward_entropy": 0.004279632459987293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8663595914840698,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05671323090791702,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041549106438954674,
      "backward_entropy": 0.0042792636562477455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270098686218262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05674539878964424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041492934028307595,
      "backward_entropy": 0.004279753701253371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2099714279174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05677759647369385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041436282296975456,
      "backward_entropy": 0.004279865798625079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.374655723571777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056809861212968826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04137943685054779,
      "backward_entropy": 0.004280325363982807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8132057189941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0568414032459259,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041324528555075325,
      "backward_entropy": 0.004281434823166241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.289236068725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05687054619193077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041277180115381874,
      "backward_entropy": 0.004282049157402732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.250393867492676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056899357587099075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04123032589753469,
      "backward_entropy": 0.004284116693518378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.937507629394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056927863508462906,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.041183874011039734,
      "backward_entropy": 0.005581232634457675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.46897292137146,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056956805288791656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04113580038150152,
      "backward_entropy": 0.004291310229084708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.147768974304199,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05698445439338684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.041091784834861755,
      "backward_entropy": 0.00429484790021723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0452708937227726,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05701155215501785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04104994237422943,
      "backward_entropy": 0.004296499897133221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.746218204498291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057036060839891434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04101580878098806,
      "backward_entropy": 0.004299194636670026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.378512144088745,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05706131458282471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0409792015949885,
      "backward_entropy": 0.004301960156722503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.01825475692749,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05708552896976471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04094603657722473,
      "backward_entropy": 0.004303674128922549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.971922874450684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057109322398900986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04091509679953257,
      "backward_entropy": 0.004301969300616871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.099177360534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05713316425681114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04088375965754191,
      "backward_entropy": 0.004301106049255891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.621204376220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057160884141922,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04083987573782603,
      "backward_entropy": 0.00430018353191289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.473629951477051,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05719278007745743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04078329602877299,
      "backward_entropy": 0.004298660226843574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.224043130874634,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05722436681389809,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04072831322749456,
      "backward_entropy": 0.004295170984484933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.355912208557129,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05725451558828354,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.040677160024642944,
      "backward_entropy": 0.06296794522892345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.176966667175293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05728474631905556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040625604490439095,
      "backward_entropy": 0.004292354326356541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.150027275085449,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057313431054353714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040579020977020264,
      "backward_entropy": 0.0042906755750829525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.744643211364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05734076723456383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040536527832349144,
      "backward_entropy": 0.004289106211879037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.680389881134033,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057369083166122437,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04049114386240641,
      "backward_entropy": 0.0042867240580645475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.588398456573486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057398319244384766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04044290632009506,
      "backward_entropy": 0.0042840950191020966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.051301956176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057426873594522476,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.04039675990740458,
      "backward_entropy": 0.005216266959905624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0188100337982178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05745712295174599,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040345157186190285,
      "backward_entropy": 0.004279270429502834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.416593074798584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05748600512742996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04029737909634908,
      "backward_entropy": 0.0042787309397350655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815142631530762,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0575159452855587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040245696902275085,
      "backward_entropy": 0.0042800947346470575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4937405586242676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057547494769096375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0401887446641922,
      "backward_entropy": 0.004282410171898929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3491973876953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05757672339677811,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.040139044324556984,
      "backward_entropy": 0.0042853690683841705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.742249011993408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05760546773672104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04009028275807699,
      "backward_entropy": 0.004289980977773666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4566289186477661,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05763423442840576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.04004158079624176,
      "backward_entropy": 0.004293521019545468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4440007209777832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057660944759845734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03999923666318258,
      "backward_entropy": 0.004297468472610821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.434520959854126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05768584460020065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039962321519851685,
      "backward_entropy": 0.004302212799137289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.801292657852173,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05770906060934067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03993060439825058,
      "backward_entropy": 0.004307188093662262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265562057495117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05773159861564636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03990056117375692,
      "backward_entropy": 0.00431337681683627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21132755279541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05775635316967964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039863139390945435,
      "backward_entropy": 0.004319762980396097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.090256214141846,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05778280273079872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039820815126101174,
      "backward_entropy": 0.004323394122448834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.078123092651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057808876037597656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03977954884370168,
      "backward_entropy": 0.0043275403705510225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.329244613647461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05783652886748314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03973366320133209,
      "backward_entropy": 0.0043298547918146305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.615635395050049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05786651000380516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03968018293380737,
      "backward_entropy": 0.004992219534787265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6472630500793457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05789705738425255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03962501883506775,
      "backward_entropy": 0.004334599795666608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9075734615325928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057926006615161896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039574856559435524,
      "backward_entropy": 0.004336737096309662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.322951078414917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05795437842607498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039525941014289856,
      "backward_entropy": 0.004340260543606498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5683019161224365,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05798063054680824,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039483884970347084,
      "backward_entropy": 0.0043434521014040165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.069817066192627,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05800602212548256,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.039443512757619224,
      "backward_entropy": 0.06296779892661354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0294904708862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05803168937563896,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03940242528915405,
      "backward_entropy": 0.004918453029610894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.980005264282227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058057546615600586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039360697070757546,
      "backward_entropy": 0.004359625618566166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941826343536377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05808379873633385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03931728502114614,
      "backward_entropy": 0.004365257580171932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.897476673126221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058110252022743225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039273117979367576,
      "backward_entropy": 0.0043706392700021916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8590922355651855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058136917650699615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03922810157140096,
      "backward_entropy": 0.004877988587726246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.619540214538574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05816362053155899,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03918318450450897,
      "backward_entropy": 0.0043806139041077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5927343368530273,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05818977952003479,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03913984696070353,
      "backward_entropy": 0.06297279487956654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5553102493286133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058215297758579254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.039098853866259255,
      "backward_entropy": 0.004388282583518462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03950657323002815,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05824041739106178,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03905876229206721,
      "backward_entropy": 0.004392108795317737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1876699924468994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05826316773891449,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03902593503395716,
      "backward_entropy": 0.0048205561258576135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.624074459075928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05828457325696945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03899676104386648,
      "backward_entropy": 0.004403781484473835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582722187042236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05830642208456993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038966635862986244,
      "backward_entropy": 0.004408597268841483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.928319931030273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05832884833216667,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03893409172693888,
      "backward_entropy": 0.004413209855556488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.275573968887329,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058353763073682785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038893540700276695,
      "backward_entropy": 0.004417313093488867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1500420570373535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058377549052238464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038856628040472664,
      "backward_entropy": 0.004421190782026811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3406050205230713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05839962512254715,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03882530331611633,
      "backward_entropy": 0.004424664445898749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.120315432548523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058421432971954346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03879492481549581,
      "backward_entropy": 0.00442715666510842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.37717866897583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05844205245375633,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038767325381437935,
      "backward_entropy": 0.0044326335191726685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.188915729522705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05846307799220085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03873897592226664,
      "backward_entropy": 0.004720370200547305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2348742485046387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05848333239555359,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038713037967681885,
      "backward_entropy": 0.004438369788906791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2737016677856445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058503661304712296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038686384757359825,
      "backward_entropy": 0.004442002285610546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.345085144042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058524586260318756,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0386577844619751,
      "backward_entropy": 0.004445184360850941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.374772071838379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0585472472012043,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038623648385206856,
      "backward_entropy": 0.004446649077263745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2249064445495605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05857275053858757,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03858065108458201,
      "backward_entropy": 0.004446743564172225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.096454620361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05859969183802605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03853270411491394,
      "backward_entropy": 0.004447597332976081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.072618007659912,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05862605571746826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038486031194527946,
      "backward_entropy": 0.004450024528936906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.042609214782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058651700615882874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038441747426986694,
      "backward_entropy": 0.0044519765810533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0141255855560303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05867801234126091,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03839526573816935,
      "backward_entropy": 0.004453849724747918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.962007761001587,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05870316922664642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03835189839204153,
      "backward_entropy": 0.004457459531047128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9738106727600098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058728400617837906,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03830819328625997,
      "backward_entropy": 0.0045839073983105745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9258575439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05875261873006821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03826706359783808,
      "backward_entropy": 0.004466710104183717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.80753231048584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05877632647752762,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03822719802459081,
      "backward_entropy": 0.0044718770818276835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.757720470428467,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05880076810717583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03818485140800476,
      "backward_entropy": 0.004476020281965082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.645846366882324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05882595106959343,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03813981016476949,
      "backward_entropy": 0.004480165514079007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.594063758850098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05885237827897072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038090591629346214,
      "backward_entropy": 0.004483969035473737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.522256851196289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05887972190976143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.038038926819960274,
      "backward_entropy": 0.0044855113056573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.559746265411377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05890810489654541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037983680764834084,
      "backward_entropy": 0.00448745150457729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.60630464553833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058936674147844315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03792806466420492,
      "backward_entropy": 0.004488529806787317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5662612915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05896495282649994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03787291298309962,
      "backward_entropy": 0.0044905397702347145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7878285646438599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0589929074048996,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.037818667789300285,
      "backward_entropy": 0.0044814185662703085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7642325162887573,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05901920795440674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03777028123537699,
      "backward_entropy": 0.004493993791666898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5955045223236084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05904410406947136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037726372480392456,
      "backward_entropy": 0.0044951371171257715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7282301187515259,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059068404138088226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03768423448006312,
      "backward_entropy": 0.0044970644468610935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5479447841644287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059091486036777496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03764629364013672,
      "backward_entropy": 0.004498934881253676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5319952964782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059114035218954086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03761009623607,
      "backward_entropy": 0.004500375213948163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6917223930358887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05913590267300606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03757686416308085,
      "backward_entropy": 0.0044994110410863705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.29319429397583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05915648862719536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03754878292481104,
      "backward_entropy": 0.0044955563816157255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8387635350227356,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05917724221944809,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03752034902572632,
      "backward_entropy": 0.06297201460058038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4237704277038574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05919665843248367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03749575217564901,
      "backward_entropy": 0.004487767138264396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.418168783187866,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05921608582139015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03747019668420156,
      "backward_entropy": 0.004487261853434823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.387699604034424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05923512950539589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037446558475494385,
      "backward_entropy": 0.004484994506294077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.693863391876221,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05925407260656357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037422930200894676,
      "backward_entropy": 0.004483638500625437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.886815071105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05927471071481705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.037393078207969666,
      "backward_entropy": 0.004284442825750871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.366185665130615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059296127408742905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03736070295174917,
      "backward_entropy": 0.004270251501690258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5464533567428589,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05931951478123665,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03732141852378845,
      "backward_entropy": 0.004257729446346109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2734243869781494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059341706335544586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03728620211283366,
      "backward_entropy": 0.004485490308566527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5189497470855713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05936345085501671,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03725226720174154,
      "backward_entropy": 0.00448706949299032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2375080585479736,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0593840591609478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03722287714481354,
      "backward_entropy": 0.004487768492915414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.10144567489624,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059404127299785614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03719552357991537,
      "backward_entropy": 0.004486588930541819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.620823383331299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05942616984248161,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037160744269688926,
      "backward_entropy": 0.004485883834687146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5812647342681885,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0594487264752388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.037124832471211754,
      "backward_entropy": 0.004484447565945712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1345739364624023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0594717301428318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0370877260963122,
      "backward_entropy": 0.004482543603940444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1178383827209473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059494223445653915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03705184410015742,
      "backward_entropy": 0.004482157528400421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4543192386627197,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0595160573720932,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03701831897099813,
      "backward_entropy": 0.00448120114478198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3877530097961426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059538666158914566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03698149820168813,
      "backward_entropy": 0.004482657733288678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.051724433898926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05956026539206505,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036947632829348244,
      "backward_entropy": 0.004485632208260623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3605082035064697,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059581220149993896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036916342874368034,
      "backward_entropy": 0.004487171091816642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658494710922241,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05960126966238022,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03688783198595047,
      "backward_entropy": 0.06295764446258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.986512541770935,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05962156504392624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03685804704825083,
      "backward_entropy": 0.004492866722020236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3200404644012451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05964142456650734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03682990372180939,
      "backward_entropy": 0.00406870957125317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5830953121185303,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05966046825051308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03680423398812612,
      "backward_entropy": 0.004499087956818667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9219635725021362,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05967973172664642,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.03677780677874883,
      "backward_entropy": 0.004049446095119823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2953091859817505,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05969882756471634,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036751508712768555,
      "backward_entropy": 0.004506989974867214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.507331609725952,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059716787189245224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036729892094930015,
      "backward_entropy": 0.004508061165159399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.31813383102417,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059735093265771866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03670687476793925,
      "backward_entropy": 0.00450946255163713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2494051456451416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05975528806447983,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03667729596296946,
      "backward_entropy": 0.004511398347941312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.829782962799072,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05977446213364601,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036651228864987694,
      "backward_entropy": 0.0045126618986779995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2227898836135864,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05979584902524948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036617763340473175,
      "backward_entropy": 0.004513918337496844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.967106342315674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059816088527441025,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036588236689567566,
      "backward_entropy": 0.004514678635380485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7740880250930786,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059836797416210175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036557212471961975,
      "backward_entropy": 0.004514579068530689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1797047853469849,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.059856951236724854,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03652812292178472,
      "backward_entropy": 0.0629556720907038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.436886787414551,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05987616255879402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036502107977867126,
      "backward_entropy": 0.004514634609222412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5951501131057739,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05989639088511467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03647284706433614,
      "backward_entropy": 0.004514154385436665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.249711513519287,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05991514027118683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03644838432470957,
      "backward_entropy": 0.004514057527888905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1299302577972412,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05993407592177391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03642303744951884,
      "backward_entropy": 0.004514562812718478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1198420524597168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05995217710733414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036400253574053444,
      "backward_entropy": 0.004515643485567786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2619056701660156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05996948108077049,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.036380077401796974,
      "backward_entropy": 0.06295204162597656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.160644292831421,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05998783931136131,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03635677695274353,
      "backward_entropy": 0.004515943879430944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6126594543457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06000630185008049,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036333138744036354,
      "backward_entropy": 0.00451502644202926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5520541667938232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06002433970570564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03631114959716797,
      "backward_entropy": 0.004513824527913874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.090961456298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0600411631166935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036293099323908486,
      "backward_entropy": 0.004513719542460008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.070974111557007,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060058314353227615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03627277414004008,
      "backward_entropy": 0.00451429391449148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.049546718597412,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06007571145892143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03625175356864929,
      "backward_entropy": 0.00451478666879914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.030595064163208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06009332090616226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03623002767562866,
      "backward_entropy": 0.0045155740597031336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5107953548431396,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06011016666889191,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03621076544125875,
      "backward_entropy": 0.004516646943309091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029049916192889214,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060126904398202896,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03619140386581421,
      "backward_entropy": 0.004519214006987485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.514733076095581,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0601421482861042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03617658714453379,
      "backward_entropy": 0.004523398185318167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9873761534690857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0601564459502697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.036164735754330955,
      "backward_entropy": 0.004528269510377537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027912667021155357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06017046794295311,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03615321715672811,
      "backward_entropy": 0.004534949633208188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9203312397003174,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06018325686454773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03614551822344462,
      "backward_entropy": 0.004542739553885026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.495271235704422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06019670143723488,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.03613544007142385,
      "backward_entropy": 0.06295018846338446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031447745859622955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06020944565534592,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03612722953160604,
      "backward_entropy": 0.004559305242516778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9518728852272034,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06022089347243309,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03612357874711355,
      "backward_entropy": 0.004566962068731134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.408886194229126,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06023222208023071,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.03612027565638224,
      "backward_entropy": 0.004574854265559803,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.7243695801496504,
    "avg_log_Z": -0.05926794804632664,
    "success_rate": 1.0,
    "avg_reward": 76.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.1,
      "2": 0.84
    },
    "avg_forward_entropy": 0.037452678456902505,
    "avg_backward_entropy": 0.007988643727519295,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}