{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07694511943393284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07695154349009196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.8037872314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983428955078126,
      "backward_entropy": 0.07697870996263292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.77618408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983380079269409,
      "backward_entropy": 0.07694654994540745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.4534454345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00019999995129182935,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098332166671753,
      "backward_entropy": 0.07694795396592882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2821807861328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.000299229723168537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10983256101608277,
      "backward_entropy": 0.07696000734965007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.2556915283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00039890254265628755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098318338394165,
      "backward_entropy": 0.07695064279768202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1984405517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004988372675143182,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983098745346069,
      "backward_entropy": 0.07695198721355861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.91671752929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005994609091430902,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098300576210022,
      "backward_entropy": 0.07696790165371364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.58001708984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006991321570239961,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982903242111205,
      "backward_entropy": 0.07698591550191243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.70953369140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000799592409748584,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098279356956482,
      "backward_entropy": 0.07695594098832872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.52188110351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008999959682114422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982674360275269,
      "backward_entropy": 0.07698780298233032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.09524536132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010010366095229983,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982545614242553,
      "backward_entropy": 0.07695852385626899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.39968872070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011017796350643039,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098240852355957,
      "backward_entropy": 0.07698962423536512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.48109436035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0012001701397821307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982261896133423,
      "backward_entropy": 0.07699045870039198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.03829956054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012986883521080017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982108116149902,
      "backward_entropy": 0.07696218623055352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.98887634277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001395571161992848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981944799423218,
      "backward_entropy": 0.076992048157586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.48711395263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014929472235962749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098177194595337,
      "backward_entropy": 0.07699280314975315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.93646240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015871981158852577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981593132019044,
      "backward_entropy": 0.07699349853727552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.76569366455078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0016823811456561089,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981404781341553,
      "backward_entropy": 0.07699114746517605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.066162109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017743518110364676,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981211662292481,
      "backward_entropy": 0.07699271705415514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.235595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018665315583348274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981009006500245,
      "backward_entropy": 0.07699540588590834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.954345703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001961068483069539,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980794429779053,
      "backward_entropy": 0.0769956906636556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.31063842773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002056725090369582,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980567932128907,
      "backward_entropy": 0.07699661122428046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.84678649902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002151747466996312,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980327129364013,
      "backward_entropy": 0.07699844572279188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.99620056152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002246338175609708,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980075597763062,
      "backward_entropy": 0.07697201437420315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.20867919921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023428364656865597,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097981095314026,
      "backward_entropy": 0.07700095574061076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.09104919433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0024417995009571314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979529619216918,
      "backward_entropy": 0.07697392172283596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.66619873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002538757398724556,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979239940643311,
      "backward_entropy": 0.07697485552893744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.15672302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002636325778439641,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978938341140747,
      "backward_entropy": 0.07699978351593018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.89784240722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027329609729349613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978626012802124,
      "backward_entropy": 0.07700024710761176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.51815795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0028276192024350166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978306531906128,
      "backward_entropy": 0.07697739866044787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.46519470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002926292596384883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097797155380249,
      "backward_entropy": 0.07700108819537693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.17547607421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00302657438442111,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977625846862793,
      "backward_entropy": 0.07700799571143256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.14935302734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0031257260125130415,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097726821899414,
      "backward_entropy": 0.07700882355372111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.5634765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0032238815911114216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976903438568116,
      "backward_entropy": 0.0770022604200575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.12086486816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0033232697751373053,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976530313491821,
      "backward_entropy": 0.0770103136698405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.501708984375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034252216573804617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976144075393676,
      "backward_entropy": 0.07701100243462457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.49267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003527882741764188,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975749492645263,
      "backward_entropy": 0.07698255115085179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.1240234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036325594410300255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975339412689208,
      "backward_entropy": 0.07701223426394993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.4320068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003733998164534569,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974925756454468,
      "backward_entropy": 0.07700388961368138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.73519897460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0038339293096214533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097450613975525,
      "backward_entropy": 0.0770041545232137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.25637817382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003933846950531006,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974074602127075,
      "backward_entropy": 0.07701365815268622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.2686996459961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004032192286103964,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973635911941529,
      "backward_entropy": 0.07701404227150811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.8916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0041265725158154964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973196029663086,
      "backward_entropy": 0.07698551813761394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.7001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004220346454530954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972747802734376,
      "backward_entropy": 0.07700488964716594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.03695678710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004317313898354769,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972281694412231,
      "backward_entropy": 0.07698608769310845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.69064331054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004416134208440781,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097179651260376,
      "backward_entropy": 0.07700512144300672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.78746032714844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004513585940003395,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971305370330811,
      "backward_entropy": 0.07701534695095485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.8198699951172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0046161445789039135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970790386199951,
      "backward_entropy": 0.07701551914215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.9189910888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004719603341072798,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970261096954345,
      "backward_entropy": 0.07698702812194824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.31922912597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004822450689971447,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969719886779786,
      "backward_entropy": 0.07701579729715984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.5476837158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004926260560750961,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969161987304688,
      "backward_entropy": 0.07701590326097277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.91944885253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005029728170484304,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968589782714844,
      "backward_entropy": 0.07701599597930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.95811462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005130118224769831,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096801519393921,
      "backward_entropy": 0.07700532674789429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.59497833251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00523291015997529,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967420339584351,
      "backward_entropy": 0.07700526714324951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.99354553222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005329254548996687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096683382987976,
      "backward_entropy": 0.07698751820458306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.1127471923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005426177754998207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966230630874634,
      "backward_entropy": 0.07700505521562365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.65989685058594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005522109102457762,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965616703033447,
      "backward_entropy": 0.07701623439788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.21266174316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005619915202260017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964984893798828,
      "backward_entropy": 0.07700475719239977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.87744140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0057150498032569885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964349508285523,
      "backward_entropy": 0.07700457175572713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.0304718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005810917355120182,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963696241378784,
      "backward_entropy": 0.0769863592253791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.39707946777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005909462925046682,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963016748428345,
      "backward_entropy": 0.07700414127773708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.1373748779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006011834368109703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962311029434205,
      "backward_entropy": 0.07698567708333333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.1945037841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006111979950219393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961604118347168,
      "backward_entropy": 0.07698529296451145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.7439422607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00621213810518384,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096088171005249,
      "backward_entropy": 0.0770163271162245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.03829956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006313331890851259,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960139036178589,
      "backward_entropy": 0.07700310813056098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.07749938964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006411427166312933,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959395170211791,
      "backward_entropy": 0.07701634036170112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.94496154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006513209082186222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958619117736816,
      "backward_entropy": 0.07700253195232815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.86590576171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00661455886438489,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095782995223999,
      "backward_entropy": 0.0769829551378886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.80844116210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006718112621456385,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957016944885253,
      "backward_entropy": 0.07701634036170112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.66468811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006818022113293409,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956202745437622,
      "backward_entropy": 0.07698184251785278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.8817901611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006919180974364281,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955367088317872,
      "backward_entropy": 0.07698127958509657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.65960693359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007017174735665321,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095453143119812,
      "backward_entropy": 0.07700079017215306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.83798217773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007114889565855265,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953681468963623,
      "backward_entropy": 0.07701634036170112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.44610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007208778988569975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952832698822021,
      "backward_entropy": 0.07697947820027669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.1417236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0073072053492069244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951945781707764,
      "backward_entropy": 0.07697883579466078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.33070373535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007404445204883814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951049327850342,
      "backward_entropy": 0.07699906163745457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.32403564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007503004744648933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095012903213501,
      "backward_entropy": 0.07697746488783094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.48890686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007605536840856075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949169397354126,
      "backward_entropy": 0.07699813445409139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.64219665527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007710120175033808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948179960250855,
      "backward_entropy": 0.07697610060373943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.5255126953125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007812091615051031,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947189331054688,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.37051391601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007913525216281414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946183204650879,
      "backward_entropy": 0.076996644337972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.24083709716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008017128333449364,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945146083831787,
      "backward_entropy": 0.07701628737979466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.03296661376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008115454576909542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094412088394165,
      "backward_entropy": 0.07699554496341282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.30645751953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008209665305912495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943102836608887,
      "backward_entropy": 0.07699494891696507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.81398010253906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008302941918373108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094207763671875,
      "backward_entropy": 0.07701626088884142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.20004272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008393377996981144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941048860549926,
      "backward_entropy": 0.07699367735120985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.5742645263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008484276942908764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939996242523194,
      "backward_entropy": 0.0769930018319024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.4079132080078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008578472770750523,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938906669616699,
      "backward_entropy": 0.07701623439788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.59217834472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008675353601574898,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937782526016235,
      "backward_entropy": 0.07696757051679823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.60830688476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008770898915827274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936647653579712,
      "backward_entropy": 0.07699092229207356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.08251953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008862077258527279,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935523509979247,
      "backward_entropy": 0.0769655638270908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.68930053710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00894814170897007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934414863586425,
      "backward_entropy": 0.07698932621214125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.59739685058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00903551746159792,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933277606964112,
      "backward_entropy": 0.07696329222785102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.32842254638672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009122825227677822,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10932121276855469,
      "backward_entropy": 0.07701614167955187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.259033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009207253344357014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093096375465393,
      "backward_entropy": 0.07696085506015354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2514190673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009295781143009663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1092975378036499,
      "backward_entropy": 0.0769596364763048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.74229431152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009383627213537693,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10928529500961304,
      "backward_entropy": 0.07701606220669216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.57334899902344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009475327096879482,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092725396156311,
      "backward_entropy": 0.07701603571573894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.88589477539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00957020465284586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925924777984619,
      "backward_entropy": 0.07698310083813137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.32215881347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009665358811616898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924571752548218,
      "backward_entropy": 0.07698215378655328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.48892211914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009761865250766277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923182964324951,
      "backward_entropy": 0.07698120011223687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.17991638183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009855453856289387,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10921794176101685,
      "backward_entropy": 0.07701592312918769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.60887145996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009948087856173515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920389890670776,
      "backward_entropy": 0.07697914706336127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.96017456054688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010041003115475178,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10918959379196166,
      "backward_entropy": 0.07694973548253377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.23736572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010131505317986012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10917524099349976,
      "backward_entropy": 0.07694828510284424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.36643981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010219450108706951,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916087627410889,
      "backward_entropy": 0.07697584231694539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.99656677246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010312500409781933,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914583206176758,
      "backward_entropy": 0.07701570457882351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.81219482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010409233160316944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913023948669434,
      "backward_entropy": 0.0769736369450887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.2371368408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01050778478384018,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091141939163208,
      "backward_entropy": 0.07694245709313287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.59461975097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010603200644254684,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10909817218780518,
      "backward_entropy": 0.07701559861501057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.55474853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010699105449020863,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10908186435699463,
      "backward_entropy": 0.07693941063351101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.07867431640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010795448906719685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090652346611023,
      "backward_entropy": 0.07693784104453193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.02394104003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010882321745157242,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904927253723144,
      "backward_entropy": 0.07693611913257176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.10580444335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010973182506859303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10903264284133911,
      "backward_entropy": 0.07693443033430311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.36488342285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011067831888794899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10901541709899902,
      "backward_entropy": 0.07696539825863308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.44435119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011165475472807884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1089975357055664,
      "backward_entropy": 0.07696419292026097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.3831024169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011266019195318222,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10897910594940186,
      "backward_entropy": 0.07696300745010376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.01080322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011364327743649483,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10896060466766358,
      "backward_entropy": 0.07692779435051812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.096923828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011462274007499218,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10894186496734619,
      "backward_entropy": 0.07701528072357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.93376922607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011560150422155857,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892280340194702,
      "backward_entropy": 0.07692425780826145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.14100646972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011652307584881783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890409946441651,
      "backward_entropy": 0.07692231072319879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.10171508789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011745261959731579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10888501405715942,
      "backward_entropy": 0.07692031727896796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.67613983154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011842846870422363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1088651180267334,
      "backward_entropy": 0.07691842979855007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.01220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011935778893530369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10884543657302856,
      "backward_entropy": 0.07695341110229492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.35040283203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012029416859149933,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10882537364959717,
      "backward_entropy": 0.0770150555504693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.49473571777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012124806642532349,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10880479812622071,
      "backward_entropy": 0.07695041762457953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.54296112060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012211201712489128,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10878499746322631,
      "backward_entropy": 0.07690974076588948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.40731811523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012291103601455688,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10876626968383789,
      "backward_entropy": 0.07694707976447211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.23728942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012375977821648121,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874665975570678,
      "backward_entropy": 0.0769046147664388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.70327758789062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012462271377444267,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10872657299041748,
      "backward_entropy": 0.07701472441355388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.23822021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012548435479402542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10870654582977295,
      "backward_entropy": 0.07694252994325426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.06146240234375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012641578912734985,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1086854338645935,
      "backward_entropy": 0.07701461844974095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.62554168701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012733741663396358,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1086641788482666,
      "backward_entropy": 0.07689456144968669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.46043395996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012822308577597141,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1086430549621582,
      "backward_entropy": 0.07701451910866632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.45565795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012911783531308174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10862153768539429,
      "backward_entropy": 0.07688909106784397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.67147827148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013003591448068619,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10859941244125366,
      "backward_entropy": 0.07688637574513753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.93473815917969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01308957114815712,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10857775211334228,
      "backward_entropy": 0.07701434029473199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.62002563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013172445818781853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10855621099472046,
      "backward_entropy": 0.07693217198053996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.32989501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01325798686593771,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10853399038314819,
      "backward_entropy": 0.07693044344584148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.80256652832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013341924175620079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10851168632507324,
      "backward_entropy": 0.0769286486837599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.57977294921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013419735245406628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1084899663925171,
      "backward_entropy": 0.07701398266686334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.54119873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013497917912900448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846786499023438,
      "backward_entropy": 0.07692462868160671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.06752014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013576445169746876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844540596008301,
      "backward_entropy": 0.07692254914177789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.16275024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013655425980687141,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842257738113403,
      "backward_entropy": 0.07692045635647243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.94552612304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013736662454903126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839910507202148,
      "backward_entropy": 0.07685728205574884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.93792724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013812602497637272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.108376145362854,
      "backward_entropy": 0.07685367928610908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9087371826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013893969357013702,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10835204124450684,
      "backward_entropy": 0.07685024208492702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.85623168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013975519686937332,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10832754373550416,
      "backward_entropy": 0.07701313495635986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.53868103027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01405881717801094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10830246210098267,
      "backward_entropy": 0.07684327496422662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.39030456542969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014140930958092213,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10827722549438476,
      "backward_entropy": 0.07701295614242554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.41680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014220102690160275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10825214385986329,
      "backward_entropy": 0.07690512471728855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.38421630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014301702380180359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1082263469696045,
      "backward_entropy": 0.07690281338161892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.62721252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014386113733053207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10819969177246094,
      "backward_entropy": 0.0769005020459493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.1448516845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014472016133368015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10817246437072754,
      "backward_entropy": 0.07689820395575629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.92431640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014559394679963589,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10814462900161743,
      "backward_entropy": 0.07682055897182888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.91539001464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014649390242993832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10811595916748047,
      "backward_entropy": 0.07689366738001506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.380859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014740172773599625,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10808678865432739,
      "backward_entropy": 0.07701239983240764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.6196746826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014833349734544754,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10805680751800537,
      "backward_entropy": 0.07680905527538723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.1436004638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014924234710633755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10802685022354126,
      "backward_entropy": 0.0768867399957445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.77574157714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015013201162219048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1079968810081482,
      "backward_entropy": 0.07688423660066393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.52484130859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015101497061550617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10796661376953125,
      "backward_entropy": 0.07679617404937744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.37884521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015193884260952473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10793520212173462,
      "backward_entropy": 0.07679192225138347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.64173126220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015285657718777657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10790350437164306,
      "backward_entropy": 0.07687654097874959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.42315673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015370404347777367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10787274837493896,
      "backward_entropy": 0.07687359386020237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.15105438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01545807532966137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10784107446670532,
      "backward_entropy": 0.0768706931008233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.38668060302734,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015539262443780899,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10781035423278809,
      "backward_entropy": 0.07701171769036187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.71435546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015615170821547508,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10778080224990845,
      "backward_entropy": 0.07701148589452107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.20457458496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01569231040775776,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077506422996521,
      "backward_entropy": 0.0770112673441569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.71971130371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015768807381391525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10772024393081665,
      "backward_entropy": 0.07685693105061848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.47149658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0158492773771286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10768864154815674,
      "backward_entropy": 0.07674797375996907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.08177185058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015932131558656693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10765619277954101,
      "backward_entropy": 0.0768500632709927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.78997802734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016013778746128082,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10762357711791992,
      "backward_entropy": 0.07701048586103651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8746795654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016095688566565514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10759048461914063,
      "backward_entropy": 0.07684289084540473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.87831115722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01617811992764473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10755689144134521,
      "backward_entropy": 0.0767239597108629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.1169891357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016265645623207092,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10752179622650146,
      "backward_entropy": 0.07683576477898492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.76043701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016357310116291046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10748535394668579,
      "backward_entropy": 0.07683245340983073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.96669006347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016449397429823875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10744831562042237,
      "backward_entropy": 0.07670706510543823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.7874526977539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01654241420328617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10741057395935058,
      "backward_entropy": 0.07700988981458876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.54969787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01663130149245262,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10737330913543701,
      "backward_entropy": 0.07682175106472439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.97955322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01672186702489853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10733523368835449,
      "backward_entropy": 0.0766899585723877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.49830627441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016810040920972824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10729719400405884,
      "backward_entropy": 0.07681399583816528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.583251953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016896208748221397,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10725915431976318,
      "backward_entropy": 0.07680973079469469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.8830108642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016980860382318497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10722151994705201,
      "backward_entropy": 0.07680528693728977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.25424194335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01706869713962078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10718307495117188,
      "backward_entropy": 0.0766640305519104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.6259994506836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017159249633550644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10714325904846192,
      "backward_entropy": 0.07700909508599176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.33920288085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01724621281027794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10710313320159912,
      "backward_entropy": 0.07665104336208767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.3900909423828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01732843928039074,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10706348419189453,
      "backward_entropy": 0.07700876394907634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.86663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017412662506103516,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10702270269393921,
      "backward_entropy": 0.0770085785124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.98463439941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01749972440302372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10698051452636718,
      "backward_entropy": 0.07662935389412774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.31175231933594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017584627494215965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10693827867507935,
      "backward_entropy": 0.07700822088453504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.01536560058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017675457522273064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10689389705657959,
      "backward_entropy": 0.07661512162950304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.00474548339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01776711642742157,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10684866905212402,
      "backward_entropy": 0.07660822073618571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.27245330810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017858615145087242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10680291652679444,
      "backward_entropy": 0.07675598065058391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.29383850097656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017946438863873482,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10675761699676514,
      "backward_entropy": 0.07700773742463854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.56777954101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018032170832157135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10671229362487793,
      "backward_entropy": 0.07674437099032932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.51007080078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01811780221760273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1066664218902588,
      "backward_entropy": 0.07673816548453437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.038330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01820334792137146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10661996603012085,
      "backward_entropy": 0.0767317877875434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.73480987548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018284600228071213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10657422542572022,
      "backward_entropy": 0.0767249862353007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.81195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018361402675509453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10652928352355957,
      "backward_entropy": 0.07654745048946804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.24771118164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018444444984197617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10648183822631836,
      "backward_entropy": 0.07671160830391778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.7871856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01852646842598915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10643390417099,
      "backward_entropy": 0.07652755578358968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.8797149658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018608935177326202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10638514757156373,
      "backward_entropy": 0.07669846216837566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.3684539794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018693290650844574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10633511543273926,
      "backward_entropy": 0.07650818427403767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8961944580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01878282241523266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10628285408020019,
      "backward_entropy": 0.07649923695458306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.77027893066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01887040212750435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10623056888580322,
      "backward_entropy": 0.07667916350894505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.77938842773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01896410621702671,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10617568492889404,
      "backward_entropy": 0.07648095819685194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.6463165283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019055427983403206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10612092018127442,
      "backward_entropy": 0.07647152741750081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.31996154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019149174913764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10606467723846436,
      "backward_entropy": 0.07666044102774726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.21923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019243352115154266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10600758790969848,
      "backward_entropy": 0.07645290427737766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.83737182617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019339095801115036,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10594922304153442,
      "backward_entropy": 0.07700395584106445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.3155517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019431820139288902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10589120388031006,
      "backward_entropy": 0.07663994365268284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.32412719726562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019526822492480278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1058316707611084,
      "backward_entropy": 0.07663275135887994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.17636108398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01961781457066536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10577282905578614,
      "backward_entropy": 0.07662498288684422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.85020446777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019707420840859413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1057138442993164,
      "backward_entropy": 0.07661708196004231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.91615295410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019795207306742668,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10565481185913086,
      "backward_entropy": 0.0766085253821479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.08392333984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01988433487713337,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10559462308883667,
      "backward_entropy": 0.0763741135597229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.66159057617188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01997275836765766,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10553405284881592,
      "backward_entropy": 0.07700212796529134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.98967742919922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02005949057638645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1054734468460083,
      "backward_entropy": 0.07658052444458008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.06851196289062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02014305256307125,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10541335344314576,
      "backward_entropy": 0.07700112130906847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.67320251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020221499726176262,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1053545594215393,
      "backward_entropy": 0.07655882173114353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.61026000976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02030005306005478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10529494285583496,
      "backward_entropy": 0.07654707961612278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.52474975585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020382702350616455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10523302555084228,
      "backward_entropy": 0.0762818521923489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.56989288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020469019189476967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10516896247863769,
      "backward_entropy": 0.07652413845062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.91675567626953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020550398156046867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10510622262954712,
      "backward_entropy": 0.0765119194984436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.58824157714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020629744976758957,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10504369735717774,
      "backward_entropy": 0.07623208893669976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.15589141845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020708197727799416,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1049808144569397,
      "backward_entropy": 0.07699660460154216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.68316650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020781897008419037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10491923093795777,
      "backward_entropy": 0.07647260030110677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.88778686523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02085888758301735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10485556125640869,
      "backward_entropy": 0.07645905017852783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.00701141357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020932026207447052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1047929048538208,
      "backward_entropy": 0.07644467883639866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.78974914550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021000942215323448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10473135709762574,
      "backward_entropy": 0.07642918162875706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.10890197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021066810935735703,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10467051267623902,
      "backward_entropy": 0.07641296916537815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.65406799316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021136226132512093,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10460735559463501,
      "backward_entropy": 0.07639700836605495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8821563720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02120746113359928,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10454268455505371,
      "backward_entropy": 0.07638111379411486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.9907684326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021279891952872276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10447533130645752,
      "backward_entropy": 0.07698776986863878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.64071655273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021358797326683998,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10440397262573242,
      "backward_entropy": 0.0763499206966824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.73681640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021437348797917366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10433192253112793,
      "backward_entropy": 0.07698632611168756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.0399932861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021514838561415672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10425945520401,
      "backward_entropy": 0.07631886667675442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.8582763671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021594567224383354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10418498516082764,
      "backward_entropy": 0.07698482937282985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.7981185913086,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021673724055290222,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1041100025177002,
      "backward_entropy": 0.07698411411709255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.4828643798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021749477833509445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10403575897216796,
      "backward_entropy": 0.0762693617078993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.42332458496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021829908713698387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10395846366882325,
      "backward_entropy": 0.07625270552105373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 198.0041961669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02191704884171486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10387701988220215,
      "backward_entropy": 0.07587386502159967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.90902709960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022008845582604408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10379246473312378,
      "backward_entropy": 0.07622224754757351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.00823211669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02209869958460331,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10370779037475586,
      "backward_entropy": 0.07583298948076037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.1124267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022183449938893318,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10362387895584106,
      "backward_entropy": 0.07618971003426446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.88618469238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022262057289481163,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10354214906692505,
      "backward_entropy": 0.07578379578060573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.7919921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022336680442094803,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10346150398254395,
      "backward_entropy": 0.07575611935721503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.76602172851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022414295002818108,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10337830781936645,
      "backward_entropy": 0.07572880056169298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.56634521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022488027811050415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10329631567001343,
      "backward_entropy": 0.0756996406449212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.89964294433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02256561629474163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10321108102798462,
      "backward_entropy": 0.0760912232928806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.27340698242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02264680154621601,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10312309265136718,
      "backward_entropy": 0.07564410898420545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.21575164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022727137431502342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10303466320037842,
      "backward_entropy": 0.07604967885547215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.1892318725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022803789004683495,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10294758081436158,
      "backward_entropy": 0.07558560371398926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.51686096191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022876044735312462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10286219120025634,
      "backward_entropy": 0.07555367549260457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.69100952148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02294928953051567,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10277519226074219,
      "backward_entropy": 0.07597555054558648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.0306854248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02302403748035431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10268639326095581,
      "backward_entropy": 0.07548745473225911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.0953826904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023102115839719772,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10259478092193604,
      "backward_entropy": 0.07545430130428737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.4065399169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023182429373264313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10250086784362793,
      "backward_entropy": 0.075898011525472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.88009643554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023263538256287575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1024056077003479,
      "backward_entropy": 0.07696463664372762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.20350646972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02334657870233059,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10230824947357178,
      "backward_entropy": 0.07535436418321398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.5927276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0234312042593956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10220897197723389,
      "backward_entropy": 0.07581820752885607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.11701965332031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023513900116086006,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10211001634597779,
      "backward_entropy": 0.0769616961479187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.99952697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023592859506607056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10201280117034912,
      "backward_entropy": 0.07575943734910753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.45140075683594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023674137890338898,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1019134521484375,
      "backward_entropy": 0.07695868280198839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.1332244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023754138499498367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10181440114974975,
      "backward_entropy": 0.0756978988647461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.00582885742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0238348376005888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10171405076980591,
      "backward_entropy": 0.07566595077514648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.0455780029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02391122654080391,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1016158103942871,
      "backward_entropy": 0.0769526759783427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.3933868408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02398652769625187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1015174150466919,
      "backward_entropy": 0.07504632737901476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.2282485961914,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024063173681497574,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10141730308532715,
      "backward_entropy": 0.07694783475663927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.32054138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024135760962963104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10131921768188476,
      "backward_entropy": 0.07552221086290148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.95474243164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024210290983319283,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1012190341949463,
      "backward_entropy": 0.07548456059561835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.2818603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024285947903990746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10111722946166993,
      "backward_entropy": 0.0754464070002238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.06420135498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024361081421375275,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10101498365402221,
      "backward_entropy": 0.07481177647908528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.31878662109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024434037506580353,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10091350078582764,
      "backward_entropy": 0.0747611125310262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.35968780517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02451014518737793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10080897808074951,
      "backward_entropy": 0.07471125655704075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.4276580810547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02458241954445839,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10070652961730957,
      "backward_entropy": 0.07692851622899373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.4230728149414,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024656075984239578,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1006022572517395,
      "backward_entropy": 0.07692556911044651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.1443328857422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024728192016482353,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10049850940704345,
      "backward_entropy": 0.0769224034415351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.23690795898438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024800008162856102,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10039417743682862,
      "backward_entropy": 0.07691917154524061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.51470947265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024873584508895874,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1002878189086914,
      "backward_entropy": 0.0769162310494317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.94556427001953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02494688332080841,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10018092393875122,
      "backward_entropy": 0.07691323757171631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.72675323486328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025018375366926193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10007469654083252,
      "backward_entropy": 0.07690992620256212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.21832275390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.025087924674153328,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09996918439865113,
      "backward_entropy": 0.07690626382827759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.25047302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025157617405056953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09986280798912048,
      "backward_entropy": 0.07490887906816271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.26344299316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02522776462137699,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0997553825378418,
      "backward_entropy": 0.07485717535018921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.74234008789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025302065536379814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09964409470558167,
      "backward_entropy": 0.07407380474938287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.77033233642578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02537914179265499,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09952985048294068,
      "backward_entropy": 0.0768944223721822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.0085906982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025449486449360847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09942052364349366,
      "backward_entropy": 0.07394814491271973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.22418975830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025524871423840523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09930645227432251,
      "backward_entropy": 0.07465410232543945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.82183837890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02559826523065567,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0991932988166809,
      "backward_entropy": 0.07688573996225993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.08099365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02568093314766884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09907212853431702,
      "backward_entropy": 0.07375858889685737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.68511962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02576291188597679,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09895092248916626,
      "backward_entropy": 0.07449742158253987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.83216857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025849347934126854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.098825603723526,
      "backward_entropy": 0.07363609472910564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.03692626953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025939298793673515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09869680404663086,
      "backward_entropy": 0.0744024117787679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.619384765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026027340441942215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09856891632080078,
      "backward_entropy": 0.07351610395643446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.90196228027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026112116873264313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09844311475753784,
      "backward_entropy": 0.07345020771026611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.08233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026202715933322906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09831205606460572,
      "backward_entropy": 0.07338759634229872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.38067626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02629319205880165,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09818043708801269,
      "backward_entropy": 0.07332358095380995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.99085998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026383398100733757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0980483889579773,
      "backward_entropy": 0.07325780391693115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.04872131347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026477031409740448,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09791293740272522,
      "backward_entropy": 0.07319291432698567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.05389404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026567725464701653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09777923822402954,
      "backward_entropy": 0.07312371995713976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.3994369506836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026656102389097214,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.097646826505661,
      "backward_entropy": 0.0739794373512268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.87368774414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026738962158560753,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09751858711242675,
      "backward_entropy": 0.07297123803032769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.99300384521484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026823850348591805,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09738791584968567,
      "backward_entropy": 0.07688005765279134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.66399383544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02690316177904606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09726181030273437,
      "backward_entropy": 0.07280479537116157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.28086853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026980407536029816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0971369743347168,
      "backward_entropy": 0.07271410359276666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.23167419433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02705872803926468,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09701051712036132,
      "backward_entropy": 0.07262278927697076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.2499237060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027143070474267006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09687814712524415,
      "backward_entropy": 0.07253607114156087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.55499267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027229614555835724,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09674327969551086,
      "backward_entropy": 0.07244926028781468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.11013793945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027316775172948837,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09660741090774536,
      "backward_entropy": 0.07236062818103367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.37173461914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027397140860557556,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09647728204727173,
      "backward_entropy": 0.07226392957899305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.16896057128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027476390823721886,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09634757041931152,
      "backward_entropy": 0.07685681184132893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.98069763183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027561236172914505,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09621223211288452,
      "backward_entropy": 0.07685414950052898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.62141418457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02764686942100525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09607576131820679,
      "backward_entropy": 0.07309420903523763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.16981506347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027728261426091194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09594290256500244,
      "backward_entropy": 0.07301020622253418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.2150421142578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02781667560338974,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09580312967300415,
      "backward_entropy": 0.0768464141421848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.18434143066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027911989018321037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09565690755844117,
      "backward_entropy": 0.0716789960861206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.11864471435547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028011173009872437,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09550678730010986,
      "backward_entropy": 0.07158880763583714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.53823852539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028107812628149986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09535875916481018,
      "backward_entropy": 0.0714932812584771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.19309997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028202328830957413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09521242380142211,
      "backward_entropy": 0.07262004084057277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.50621032714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028296124190092087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09506640434265137,
      "backward_entropy": 0.07253171337975396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.66277313232422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028396043926477432,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09491453170776368,
      "backward_entropy": 0.07684323522779676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.26910400390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028493661433458328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09476462602615357,
      "backward_entropy": 0.07236116462283665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.67802429199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028592215850949287,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09461361169815063,
      "backward_entropy": 0.07097799248165554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.96210479736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02868625335395336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09446663856506347,
      "backward_entropy": 0.07217756907145183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.2011260986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02877536229789257,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09432423114776611,
      "backward_entropy": 0.07074139515558879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.16310119628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02886427566409111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09418161511421204,
      "backward_entropy": 0.07061756981743707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.43931579589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028957992792129517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403407573699951,
      "backward_entropy": 0.07186931371688843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.97714233398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029044263064861298,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0938936710357666,
      "backward_entropy": 0.0703665812810262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029139015823602676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09374499320983887,
      "backward_entropy": 0.07024578253428142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.1817169189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029238896444439888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09359120130538941,
      "backward_entropy": 0.07154823674096002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8739776611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029338272288441658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09343786239624023,
      "backward_entropy": 0.07000691360897487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.02983093261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029436862096190453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09328518509864807,
      "backward_entropy": 0.06988102859920925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.70590209960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029531072825193405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09313671588897705,
      "backward_entropy": 0.06974791155921088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.77944946289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029623186215758324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0929901659488678,
      "backward_entropy": 0.07110475831561619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.13247680664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0297105573117733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09284827709197999,
      "backward_entropy": 0.0709785024325053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.10653686523438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029799355193972588,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09270471334457397,
      "backward_entropy": 0.07680770423677233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.3204345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029883915558457375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09256537556648255,
      "backward_entropy": 0.06916356086730957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.47732543945312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029970357194542885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09242393374443054,
      "backward_entropy": 0.06901119152704875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.0553207397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03005177341401577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09228745698928834,
      "backward_entropy": 0.06884896755218506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.02276611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03012918308377266,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09215514659881592,
      "backward_entropy": 0.06867801480823094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.96925354003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030212517827749252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09201633930206299,
      "backward_entropy": 0.06851422786712646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.42306518554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030290648341178894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09188301563262939,
      "backward_entropy": 0.06834179825252956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.55441284179688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030369987711310387,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09174834489822388,
      "backward_entropy": 0.07676035828060573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.16057586669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03044990636408329,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09161291122436524,
      "backward_entropy": 0.06968163119422065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.77828979492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030526498332619667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09148093461990356,
      "backward_entropy": 0.06952187750074598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.28205108642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030604124069213867,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09134775400161743,
      "backward_entropy": 0.06763543023003472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.55752563476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03067862242460251,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09121780395507813,
      "backward_entropy": 0.076727913485633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.70022583007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030753038823604584,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09108771681785584,
      "backward_entropy": 0.06725769572787815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.03864288330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030826866626739502,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09095825552940369,
      "backward_entropy": 0.06883094045850965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.70295715332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030894415453076363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09083555936813355,
      "backward_entropy": 0.06685459613800049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.08386993408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03096107766032219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0907137632369995,
      "backward_entropy": 0.06845039791531032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.9458465576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03102881647646427,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09059076905250549,
      "backward_entropy": 0.07667246129777697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.4306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031103702262043953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0904603898525238,
      "backward_entropy": 0.06807616021898058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.79048156738281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031177328899502754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0903314471244812,
      "backward_entropy": 0.06788776318232219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.82477569580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031245902180671692,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0902079999446869,
      "backward_entropy": 0.06768856445948283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.4590072631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03131028264760971,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0900891125202179,
      "backward_entropy": 0.06559952762391832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.1207275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03137511759996414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08996970653533935,
      "backward_entropy": 0.06726886828740437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.79954528808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0314469039440155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08984307646751404,
      "backward_entropy": 0.06515979766845703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.45399475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031521763652563095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08971338272094727,
      "backward_entropy": 0.06685605314042833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.07421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031600259244441986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08958017826080322,
      "backward_entropy": 0.0647391743130154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.6961669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0316753014922142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08945097923278808,
      "backward_entropy": 0.06644778119193183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.18814086914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031752124428749084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0893201231956482,
      "backward_entropy": 0.06624095969729954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.8609848022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03182993084192276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08918845653533936,
      "backward_entropy": 0.06409307320912679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.39424133300781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031907036900520325,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08905789852142335,
      "backward_entropy": 0.07657384872436523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.10985565185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03198281303048134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08892888426780701,
      "backward_entropy": 0.06561730967627631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.59925842285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032057128846645355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0888015627861023,
      "backward_entropy": 0.06342469983630711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.32479858398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03213296830654144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08867306113243104,
      "backward_entropy": 0.0651800963613722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.78412628173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03220359981060028,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08855047225952148,
      "backward_entropy": 0.0629583133591546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.40485382080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03226972743868828,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08843298554420471,
      "backward_entropy": 0.06471043162875706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.35481262207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03233654052019119,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08831499814987183,
      "backward_entropy": 0.062458965513441295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.89679718017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032402824610471725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08819780349731446,
      "backward_entropy": 0.0642196536064148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.20640563964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03246792033314705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08808211088180543,
      "backward_entropy": 0.06396581729253133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.3013687133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032539039850234985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08796037435531616,
      "backward_entropy": 0.06372238530053033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.54550170898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03261055052280426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08783857822418213,
      "backward_entropy": 0.06144991848203871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.52583312988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03268223628401756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08771699666976929,
      "backward_entropy": 0.063222779168023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.9231948852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03275444731116295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08759545087814331,
      "backward_entropy": 0.06094013982348972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.42959594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03282393887639046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08747718334197999,
      "backward_entropy": 0.0606746408674452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.83145141601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03289305046200752,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08735912442207336,
      "backward_entropy": 0.07644923528035481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.45907592773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0329626090824604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08724104166030884,
      "backward_entropy": 0.06014149718814426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.32936096191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03303033486008644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08712553977966309,
      "backward_entropy": 0.059866898589664035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.03160095214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033102020621299744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08700632452964782,
      "backward_entropy": 0.059600651264190674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.29458618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033176321536302567,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08688475489616394,
      "backward_entropy": 0.0593393709924486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.6006965637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0332537405192852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0867605209350586,
      "backward_entropy": 0.05908020337422689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.77105712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033324386924505234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0866441011428833,
      "backward_entropy": 0.05880126025941637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.3556900024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03340037167072296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08652266263961791,
      "backward_entropy": 0.0585311386320326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.4695587158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03347577899694443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.086402428150177,
      "backward_entropy": 0.06028656827078925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.91024780273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03355235233902931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08628183603286743,
      "backward_entropy": 0.06000156535042657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.53179168701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03362603485584259,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0861647367477417,
      "backward_entropy": 0.05971123112572564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.83936309814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033699944615364075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0860476016998291,
      "backward_entropy": 0.05740189552307129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8345184326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.033770691603422165,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.085934317111969,
      "backward_entropy": 0.07636117935180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.33832550048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03384697809815407,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08581599593162537,
      "backward_entropy": 0.05681930647956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.9296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03392528370022774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08569614887237549,
      "backward_entropy": 0.058542331059773765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.8582305908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034003742039203644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08557681441307068,
      "backward_entropy": 0.058258771896362305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.94514083862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03408658504486084,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08545395135879516,
      "backward_entropy": 0.05598126517401801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.0115966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03416240215301514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08533916473388672,
      "backward_entropy": 0.05568465921613905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.91943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034236591309309006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08522637486457825,
      "backward_entropy": 0.05537917216618856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.44373321533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03430801257491112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08511669635772705,
      "backward_entropy": 0.05506025751431783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.871337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03437882289290428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08500810861587524,
      "backward_entropy": 0.05474050177468194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.29017639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034444600343704224,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08490543365478516,
      "backward_entropy": 0.05640077590942383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.1791000366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034516092389822006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08479750752449036,
      "backward_entropy": 0.05409161580933465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.74500274658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034589774906635284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08468787670135498,
      "backward_entropy": 0.053780721293555364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.16832733154297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034660980105400085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08458129167556763,
      "backward_entropy": 0.05346212784449259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.5167007446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03473088890314102,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08447664380073547,
      "backward_entropy": 0.053136467933654785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.67041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03480317443609238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08437016606330872,
      "backward_entropy": 0.054787635803222656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.75279998779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03487296402454376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08426679968833924,
      "backward_entropy": 0.05445176694128248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.76132202148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03494368493556976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08416317701339722,
      "backward_entropy": 0.05215080579121908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.36490249633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03501562774181366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08405851125717163,
      "backward_entropy": 0.053785373767217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.703495025634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03508065268397331,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08396169543266296,
      "backward_entropy": 0.051466935210757785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.27610778808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03514038398861885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08387095332145691,
      "backward_entropy": 0.053074042002360024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.56110382080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03519874066114426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08378206491470337,
      "backward_entropy": 0.05270853307512072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.16368865966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03525774925947189,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08369283080101013,
      "backward_entropy": 0.05037120978037516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.45039367675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03531379625201225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08360714316368104,
      "backward_entropy": 0.04999903175565931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.37158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035371143370866776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08352049589157104,
      "backward_entropy": 0.049632635381486684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.1923370361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035430196672677994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08343253135681153,
      "backward_entropy": 0.05122953653335571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.23208618164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03549744188785553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08333687782287598,
      "backward_entropy": 0.04892574085129632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.33248901367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03556115925312042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08324558734893799,
      "backward_entropy": 0.04857399728563097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.63269805908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035622622817754745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08315731883049012,
      "backward_entropy": 0.050131926933924355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.67211151123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03568689897656441,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08306689262390136,
      "backward_entropy": 0.047854956653383046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.53117370605469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03575056791305542,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08297778367996216,
      "backward_entropy": 0.04749288161595663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.19103240966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035811714828014374,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08289164304733276,
      "backward_entropy": 0.04712494876649645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.48658752441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03587612882256508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08280282020568848,
      "backward_entropy": 0.04676302274068197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.16669464111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035938289016485214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08271714448928832,
      "backward_entropy": 0.04639159970813327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.49526977539062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03600050136446953,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08263207674026489,
      "backward_entropy": 0.04602026277118259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.72052001953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03606355935335159,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08254626989364625,
      "backward_entropy": 0.04743540287017822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.1292724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03613198176026344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0824554443359375,
      "backward_entropy": 0.04530037773980035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.90505981445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036201536655426025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08236448764801026,
      "backward_entropy": 0.04494954148928324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3971710205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036267902702093124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08227723240852355,
      "backward_entropy": 0.04632506105634901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.137184143066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0363418310880661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08218333721160889,
      "backward_entropy": 0.04596491654713949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.5299072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03641049191355705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08209531307220459,
      "backward_entropy": 0.04559477170308431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.671142578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03648069500923157,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08200644254684449,
      "backward_entropy": 0.04355606105592516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.3527717590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03654750809073448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08192175626754761,
      "backward_entropy": 0.04486187961366442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.54125213623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03660813346505165,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08184387683868408,
      "backward_entropy": 0.04282861285739475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.84649658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03667134791612625,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08176347613334656,
      "backward_entropy": 0.04246635238329569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.89395141601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03672648221254349,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08169219493865967,
      "backward_entropy": 0.04371317558818393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.33496856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03678933531045914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08161338567733764,
      "backward_entropy": 0.04172643687989977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.79489135742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03685068339109421,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08153664469718933,
      "backward_entropy": 0.041365603605906166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.59724426269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03691651299595833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08145650625228881,
      "backward_entropy": 0.04101278384526571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.15888977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03698137030005455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08137791156768799,
      "backward_entropy": 0.040659974018732704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.0963363647461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03704437240958214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08130184412002564,
      "backward_entropy": 0.04029366042878893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.42196655273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037109825760126114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08122380971908569,
      "backward_entropy": 0.039937482939826116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.02522277832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03717953339219093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08114200830459595,
      "backward_entropy": 0.03960029946433173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.09849548339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03725024685263634,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08105994462966919,
      "backward_entropy": 0.03926249345143636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.03953552246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03731878474354744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08098083734512329,
      "backward_entropy": 0.04037162330415514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.7905387878418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037393368780612946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08089699149131775,
      "backward_entropy": 0.04001631670527988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.5452880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0374625138938427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0808193862438202,
      "backward_entropy": 0.03823360469606188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.26773834228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0375342033803463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08073986768722534,
      "backward_entropy": 0.0378835830423567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.90882110595703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037602029740810394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0806648850440979,
      "backward_entropy": 0.038863453600141734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.92787170410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037669893354177475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0805902361869812,
      "backward_entropy": 0.03715630703502231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.48489379882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037745922803878784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08050806522369384,
      "backward_entropy": 0.03811002439922757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.98129272460938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037822216749191284,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08042639493942261,
      "backward_entropy": 0.03774096237288581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.79070281982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037896912544965744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08034659624099731,
      "backward_entropy": 0.037378946940104164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.5285415649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03796793892979622,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0802710235118866,
      "backward_entropy": 0.03583427601390415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.3697509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0380389541387558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08019593954086304,
      "backward_entropy": 0.035504288143581815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.64917755126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038110580295324326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08012085556983947,
      "backward_entropy": 0.03628770179218716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.01301193237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038183391094207764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08004518747329711,
      "backward_entropy": 0.03486707144313388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.15849304199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038249097764492035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07997733354568481,
      "backward_entropy": 0.034524887800216675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.4176025390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03831355646252632,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07991124391555786,
      "backward_entropy": 0.034181810087627836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.1143341064453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.038380980491638184,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07984264492988587,
      "backward_entropy": 0.07586023542616102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.29981994628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03845788538455963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07976599931716918,
      "backward_entropy": 0.03446628318892585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.87796020507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03853267431259155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0796918272972107,
      "backward_entropy": 0.03326225280761719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.8687515258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038607195019721985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07961837053298951,
      "backward_entropy": 0.03296205070283678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.17865753173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03868067264556885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07954665422439575,
      "backward_entropy": 0.03343418571684095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.96257781982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03874713182449341,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07948269844055175,
      "backward_entropy": 0.032329297728008695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.87627410888672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03881299868226051,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07941950559616089,
      "backward_entropy": 0.03269763787587484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.12785339355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03887549787759781,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07936038374900818,
      "backward_entropy": 0.031679898500442505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.25691223144531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038935400545597076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07930445671081543,
      "backward_entropy": 0.03134295013215807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.97589874267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038992781192064285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07925159931182861,
      "backward_entropy": 0.031002263228098553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.80580139160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03905479237437248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07919458150863648,
      "backward_entropy": 0.03116349048084683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.484615325927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039115533232688904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07913954257965088,
      "backward_entropy": 0.03036070532268948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.04561996459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039173949509859085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07908734083175659,
      "backward_entropy": 0.030033674505021837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.77568054199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039230503141880035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07903772592544556,
      "backward_entropy": 0.03000820345348782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.1871452331543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03928801789879799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07898766994476318,
      "backward_entropy": 0.029386043548583984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.05630874633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03934422880411148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0789390742778778,
      "backward_entropy": 0.029066171911027696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.22474670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039396047592163086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07889525890350342,
      "backward_entropy": 0.02885921796162923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.44642639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0394461452960968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07885371446609497,
      "backward_entropy": 0.028467393583721586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.8630256652832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03949836641550064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07881052494049072,
      "backward_entropy": 0.028096967273288302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.4794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03954971209168434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07876853346824646,
      "backward_entropy": 0.027711677882406447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.65975952148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03960471227765083,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07872323989868164,
      "backward_entropy": 0.02749493055873447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.53871154785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0396646186709404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07867352962493897,
      "backward_entropy": 0.02721903721491496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.744239807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03973368927836418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07861539721488953,
      "backward_entropy": 0.02697209682729509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.90583801269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03979988768696785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0785606861114502,
      "backward_entropy": 0.026368934247228835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.32738494873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039865121245384216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07850746512413025,
      "backward_entropy": 0.02604254914654626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.237735748291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03993269056081772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07845242619514466,
      "backward_entropy": 0.02572148210472531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.37969207763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03999662399291992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07840136289596558,
      "backward_entropy": 0.02539811200565762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.387939453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04006347060203552,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07834780216217041,
      "backward_entropy": 0.07565111584133571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.75119400024414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04012736305594444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07829780578613281,
      "backward_entropy": 0.0254666441016727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.16394805908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04018903151154518,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07825061678886414,
      "backward_entropy": 0.025215238332748413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.21886444091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04025348648428917,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07820116877555847,
      "backward_entropy": 0.024977402554617986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.17914581298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031847417354584,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07815185189247131,
      "backward_entropy": 0.024741884734895494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.53470230102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0403829924762249,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07810336351394653,
      "backward_entropy": 0.024511966440412734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.1529312133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04044676944613457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.078055739402771,
      "backward_entropy": 0.02430157032277849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.21296691894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040510859340429306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07800811529159546,
      "backward_entropy": 0.024103027251031663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.18128967285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04057996720075607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07795600891113282,
      "backward_entropy": 0.023929897281858657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.93791961669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04064689576625824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07790648937225342,
      "backward_entropy": 0.02375455035103692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.45800018310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040714215487241745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07785718441009522,
      "backward_entropy": 0.023573926753467984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.10950469970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04078312963247299,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07780638933181763,
      "backward_entropy": 0.0757309463289049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.71709442138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040851105004549026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07775700092315674,
      "backward_entropy": 0.023236801226933796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.66702651977539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04091845452785492,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07770836353302002,
      "backward_entropy": 0.07575817902882893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.3326530456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04098211228847504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07766352891921997,
      "backward_entropy": 0.02288214862346649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.094356536865234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041042670607566833,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07762179374694825,
      "backward_entropy": 0.07576698727077907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.147233963012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04110204055905342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0775814712047577,
      "backward_entropy": 0.020608648657798767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.11674499511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04115583002567291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07754702568054199,
      "backward_entropy": 0.022325712773534987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.372285842895508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041212696582078934,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07750989198684692,
      "backward_entropy": 0.022157332963413663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.658077239990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041263870894908905,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07747875452041626,
      "backward_entropy": 0.021976606713400945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.10865020751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041313644498586655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07744979858398438,
      "backward_entropy": 0.021783883372942608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.29273223876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04136396199464798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07742097973823547,
      "backward_entropy": 0.01926838027106391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.61569213867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04141663759946823,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07738994359970093,
      "backward_entropy": 0.021419737074110243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.96434020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04147219657897949,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07735635638237,
      "backward_entropy": 0.018771999412112765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.4781723022461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041529759764671326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07732115983963013,
      "backward_entropy": 0.07574127780066596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.020023345947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041590698063373566,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07728308439254761,
      "backward_entropy": 0.020962178707122803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.18655776977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04165022447705269,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07724652290344239,
      "backward_entropy": 0.02081098821428087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.596500396728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04170931875705719,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0772104263305664,
      "backward_entropy": 0.02066969871520996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.31852722167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04176390543580055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.077179217338562,
      "backward_entropy": 0.02051311234633128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.97158813476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041821494698524475,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07714498043060303,
      "backward_entropy": 0.02037198179297977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.309898376464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041882000863552094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07710787057876586,
      "backward_entropy": 0.01714594993326399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.52294158935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0419391505420208,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07707428932189941,
      "backward_entropy": 0.020129541556040447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.50769805908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04199714586138725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07704000473022461,
      "backward_entropy": 0.016727055112520855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.522247314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04205382987856865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07700724601745605,
      "backward_entropy": 0.01990527245733473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.23748016357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04210604354739189,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07697928547859192,
      "backward_entropy": 0.019797871510187786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.65961456298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04216159135103226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07694803476333618,
      "backward_entropy": 0.019703340199258592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.98990631103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221935570240021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07691466808319092,
      "backward_entropy": 0.01595072282685174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.40800476074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04227898269891739,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07687971591949463,
      "backward_entropy": 0.015779458814197116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.562339782714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04233662039041519,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07684693336486817,
      "backward_entropy": 0.019451888071166143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.65250015258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04239422082901001,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07681456804275513,
      "backward_entropy": 0.019378304481506348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.21347427368164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04244871810078621,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07678554058074952,
      "backward_entropy": 0.019300775395499334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.28861236572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04250158369541168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07675833702087402,
      "backward_entropy": 0.0192180077234904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.12661361694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04255741462111473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07672823667526245,
      "backward_entropy": 0.01913886268933614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.99725341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042611315846443176,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07670034170150757,
      "backward_entropy": 0.01474658317036099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.77289581298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04266100749373436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07667697668075561,
      "backward_entropy": 0.014569976263576083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.26478958129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04271402582526207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07665036916732788,
      "backward_entropy": 0.014400031831529405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.17499542236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04276430606842041,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.076626718044281,
      "backward_entropy": 0.01880097223652734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.89511108398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04281407222151756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07660372257232666,
      "backward_entropy": 0.018725214733017817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.267879486083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042867787182331085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07657666206359863,
      "backward_entropy": 0.013911755548583137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.0650749206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04291992634534836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07655125856399536,
      "backward_entropy": 0.01861670944425795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.13450241088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04297294095158577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07652503252029419,
      "backward_entropy": 0.01857708560095893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.82772445678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043024640530347824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07650036215782166,
      "backward_entropy": 0.018530358870824177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.19252014160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04307727888226509,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07647467851638794,
      "backward_entropy": 0.018490925431251526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.071533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04313172027468681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07644717693328858,
      "backward_entropy": 0.013229105207655165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.998756408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043192893266677856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07641269564628601,
      "backward_entropy": 0.018410705857806735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.059364318847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04325483739376068,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0763775110244751,
      "backward_entropy": 0.018366480867067974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.37904357910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04331710562109947,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07634196281433106,
      "backward_entropy": 0.01831312643157111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.24456024169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04338213801383972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07630391716957093,
      "backward_entropy": 0.018271853526433308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.39368438720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04345414787530899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07625881433486939,
      "backward_entropy": 0.01258908874458737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.05845642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043531663715839386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07620789408683777,
      "backward_entropy": 0.0182359516620636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.712560653686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04360702261328697,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07615934610366822,
      "backward_entropy": 0.018213219112820096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.67350006103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04367800056934357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07611551284790039,
      "backward_entropy": 0.018188748094770644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.301456451416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04375029727816582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07607036828994751,
      "backward_entropy": 0.018162270387013752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.14276123046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043820224702358246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0760277807712555,
      "backward_entropy": 0.018140570984946355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.72875213623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04388933628797531,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07598605155944824,
      "backward_entropy": 0.01812298099199931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.150245666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043962933123111725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07593958377838135,
      "backward_entropy": 0.01183321906460656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.30689239501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044034797698259354,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07589493989944458,
      "backward_entropy": 0.01808663871553209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.104753494262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044110674411058426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07584604024887084,
      "backward_entropy": 0.018064330021540325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.32984161376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04418104141950607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07580315470695495,
      "backward_entropy": 0.01804396841261122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.25349044799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044245894998311996,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07576642036437989,
      "backward_entropy": 0.0180179625749588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.104406356811523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044311393052339554,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07572871446609497,
      "backward_entropy": 0.017992811070548162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.42256927490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0443720668554306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07569631338119506,
      "backward_entropy": 0.011191349890496995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.858646392822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044436417520046234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07565997242927551,
      "backward_entropy": 0.01793737378385332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.51129150390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044501300901174545,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07562307715415954,
      "backward_entropy": 0.017906732029385038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.27347183227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044567033648490906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07558515071868896,
      "backward_entropy": 0.01788032717174954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.00814437866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044630393385887146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07554981112480164,
      "backward_entropy": 0.01784831451045142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.98157501220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04469513148069382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07551286220550538,
      "backward_entropy": 0.017827168107032776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.49692153930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04476132616400719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07547423839569092,
      "backward_entropy": 0.010538316435284086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.070640563964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04482603445649147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07543717622756958,
      "backward_entropy": 0.017773937847879197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.98918914794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04488757252693176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07540355920791626,
      "backward_entropy": 0.01775307787789239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.367061614990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04495180398225784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07536698579788208,
      "backward_entropy": 0.01023906966050466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.38070297241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04501698911190033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0753291130065918,
      "backward_entropy": 0.017724762360254925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.05410766601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04508009925484657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07529346942901612,
      "backward_entropy": 0.017707435621155634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.79716491699219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045146677643060684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07525370121002198,
      "backward_entropy": 0.0176877843009101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.27257537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04521416872739792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07521274089813232,
      "backward_entropy": 0.009860007299317254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.14639663696289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.045283231884241104,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07516978979110718,
      "backward_entropy": 0.0765749282307095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.64277648925781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04535150155425072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0751275897026062,
      "backward_entropy": 0.017637891901863947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.341556549072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04541777819395065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07508765459060669,
      "backward_entropy": 0.017625153064727783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.71976089477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045484479516744614,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07504709362983704,
      "backward_entropy": 0.017610039975908067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.36553955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0455506406724453,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07500709295272827,
      "backward_entropy": 0.0175995495584276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.39567947387695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045616839081048965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07496685385704041,
      "backward_entropy": 0.017602342698309157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.51075744628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04568075016140938,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07492913007736206,
      "backward_entropy": 0.017596648799048528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.45999145507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04574389010667801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07489214539527893,
      "backward_entropy": 0.01758296125464969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.74767303466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045814305543899536,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07484648227691651,
      "backward_entropy": 0.00905719730589125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.061580657958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04588712379336357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07479766607284546,
      "backward_entropy": 0.017540994617674086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.71196365356445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045958295464515686,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07475073337554931,
      "backward_entropy": 0.017512026760313246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.74343872070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0460285060107708,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07470481395721436,
      "backward_entropy": 0.01748914685514238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.53532791137695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04610038921236992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07465669512748718,
      "backward_entropy": 0.008692485590775808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.438886642456055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0461694672703743,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07461183071136475,
      "backward_entropy": 0.01744648151927524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.248252868652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04623458907008171,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07457170486450196,
      "backward_entropy": 0.008510476185215844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.27423095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04630030319094658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07453083992004395,
      "backward_entropy": 0.017387302385436162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.1413516998291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04636840894818306,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07448662519454956,
      "backward_entropy": 0.01734350124994914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.70439529418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046431589871644974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07444859147071839,
      "backward_entropy": 0.01730153626865811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.924869537353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04649356007575989,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.074411940574646,
      "backward_entropy": 0.017272477348645527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.524635314941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04655344411730766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07437779903411865,
      "backward_entropy": 0.017235159873962402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.83948516845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04661322757601738,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07434358596801757,
      "backward_entropy": 0.01719968020915985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.52232360839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667703062295914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07430393695831299,
      "backward_entropy": 0.00786293794711431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.805686950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046738773584365845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07426668405532837,
      "backward_entropy": 0.017135906550619338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.31798553466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046801842749118805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07422752380371093,
      "backward_entropy": 0.01710793375968933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.637332916259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046862345188856125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07419164180755615,
      "backward_entropy": 0.007609179450405968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.183753967285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04692338407039642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07415494322776794,
      "backward_entropy": 0.017084997561242845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.46489334106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04698632284998894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0741155743598938,
      "backward_entropy": 0.01709494325849745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.61066436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04704923555254936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07407611608505249,
      "backward_entropy": 0.017109124196900263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.75788879394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04711103439331055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07403790354728698,
      "backward_entropy": 0.017130199405882094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.15267562866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04717449098825455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07399722337722778,
      "backward_entropy": 0.017159124215443928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.819599151611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04723754897713661,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07395675182342529,
      "backward_entropy": 0.0171825024816725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.88711166381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047297749668359756,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07391980290412903,
      "backward_entropy": 0.01720267865392897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.179813385009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04735787957906723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07388263940811157,
      "backward_entropy": 0.017218573225869074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.780261993408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04741967096924782,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07384305596351623,
      "backward_entropy": 0.01724035044511159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.1190299987793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047477949410676956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07380801439285278,
      "backward_entropy": 0.007002299858464135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.844539642333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04753713309764862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07377138137817382,
      "backward_entropy": 0.017239171597692702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.982398986816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047595273703336716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07373592853546143,
      "backward_entropy": 0.017236416538556416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.66923904418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04765667766332626,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07369568347930908,
      "backward_entropy": 0.01724378102355533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.501049995422363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047716669738292694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07365727424621582,
      "backward_entropy": 0.017250491513146296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.1500129699707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04777103662490845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07362666726112366,
      "backward_entropy": 0.017247259616851807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.07417297363281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047827497124671936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07359298467636108,
      "backward_entropy": 0.017248713307910495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.88348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04788554087281227,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0735565960407257,
      "backward_entropy": 0.01724902954366472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.01233673095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04794144630432129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07352306842803955,
      "backward_entropy": 0.006505875951713986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.67652893066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0479971319437027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07348964214324952,
      "backward_entropy": 0.0064528874225086635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.78907012939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0480598583817482,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07344594001770019,
      "backward_entropy": 0.017291646864679124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.196311950683594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04812689870595932,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07339600920677185,
      "backward_entropy": 0.01732428206337823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.81818771362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04819491133093834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07334438562393189,
      "backward_entropy": 0.017360306448406644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.8900146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04826256260275841,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07329296469688415,
      "backward_entropy": 0.01740005115667979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.43753433227539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04833096265792847,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07324008941650391,
      "backward_entropy": 0.0768238968319363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.51901626586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04839939996600151,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07318693399429321,
      "backward_entropy": 0.017491522762510512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.48141098022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846682399511337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07313485145568847,
      "backward_entropy": 0.00615897277990977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.07492446899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04853621870279312,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07307947874069214,
      "backward_entropy": 0.01757572591304779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.12620544433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04860523343086243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07302438616752624,
      "backward_entropy": 0.017624280518955655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.05911636352539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04867725074291229,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0729644775390625,
      "backward_entropy": 0.017668949233161077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.49952697753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04874987527728081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07290295958518982,
      "backward_entropy": 0.0060028330319457585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.58879089355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882810264825821,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07283310890197754,
      "backward_entropy": 0.0059627075162198805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.399147033691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048904452472925186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07276561260223388,
      "backward_entropy": 0.01774507098727756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.047855377197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048979248851537704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07269991636276245,
      "backward_entropy": 0.017768906222449407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.22239303588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04905428737401962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07263354063034058,
      "backward_entropy": 0.01780009600851271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.653221130371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04912668466567993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0725705862045288,
      "backward_entropy": 0.017830260925822787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.39041519165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04919968917965889,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07250627875328064,
      "backward_entropy": 0.01786998411019643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.37308120727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049273863434791565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07243959903717041,
      "backward_entropy": 0.01790345377392239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.52686309814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04934801906347275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07237237691879272,
      "backward_entropy": 0.0056872715552647906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.46697425842285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04942052438855171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07230708599090577,
      "backward_entropy": 0.017960006992022198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.88426208496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04949133098125458,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07224414348602295,
      "backward_entropy": 0.01800034112400479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.310283660888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04956215247511864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07218064665794373,
      "backward_entropy": 0.018033403489324782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.273393630981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04963101074099541,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07211978435516357,
      "backward_entropy": 0.01807119283411238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.36479949951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049697671085596085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07206184864044189,
      "backward_entropy": 0.005503977338473002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.51548767089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04976474493741989,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07200275659561158,
      "backward_entropy": 0.005464959889650345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.496768951416016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04983155056834221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07194353342056274,
      "backward_entropy": 0.07693983448876275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.725284576416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0499003529548645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07188053131103515,
      "backward_entropy": 0.01819208926624722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.60148239135742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049970030784606934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0718156099319458,
      "backward_entropy": 0.005361092587312062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.9874267578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05004020780324936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07174934148788452,
      "backward_entropy": 0.018274966213438246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.02496337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010950192809105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07168389558792114,
      "backward_entropy": 0.005297164122263591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.26546478271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05018222704529762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0716123878955841,
      "backward_entropy": 0.00526918512251642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.90694808959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050258781760931015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07153410911560058,
      "backward_entropy": 0.018414997392230563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.69357681274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05033496394753456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07145580649375916,
      "backward_entropy": 0.018459604846106634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.89040756225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05041093751788139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0713773250579834,
      "backward_entropy": 0.005183267096678416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.5718994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05048747360706329,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07129723429679871,
      "backward_entropy": 0.01853728128804101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.8240737915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050565049052238464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07121487855911254,
      "backward_entropy": 0.018573368589083355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.77250289916992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05064599961042404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07112634778022767,
      "backward_entropy": 0.0186109377278222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.352569580078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05072464048862457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07104098796844482,
      "backward_entropy": 0.0050588415728675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.35626220703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080042779445648,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07095990180969239,
      "backward_entropy": 0.005028083092636532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.393402099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05087494105100632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07088044881820679,
      "backward_entropy": 0.004999138414859772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.765453338623047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050949059426784515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07080087065696716,
      "backward_entropy": 0.018747127718395658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.707659721374512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05101855471730232,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07072908878326416,
      "backward_entropy": 0.018790592749913532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.83344650268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0510823093354702,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07066716551780701,
      "backward_entropy": 0.018835935327741835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.7789421081543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051145557314157486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07060556411743164,
      "backward_entropy": 0.018875386979844835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.553930282592773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05120910704135895,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07054263949394227,
      "backward_entropy": 0.01889712280697293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.429222106933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05127113685011864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07048196196556092,
      "backward_entropy": 0.01892155408859253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.0610237121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133282020688057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0704212248325348,
      "backward_entropy": 0.00478188114033805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.647159576416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05139715597033501,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07035512924194336,
      "backward_entropy": 0.018972727987501357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.19365119934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05146642029285431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07027958631515503,
      "backward_entropy": 0.019015747639867995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.828216552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0515330508351326,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07020821571350097,
      "backward_entropy": 0.019045546650886536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.943269729614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159911513328552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0701372742652893,
      "backward_entropy": 0.01907751460870107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.731592178344727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05166298896074295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.070069819688797,
      "backward_entropy": 0.019100626309712727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.078747749328613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051725536584854126,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07000434994697571,
      "backward_entropy": 0.019131696886486478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.56133460998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051784589886665344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06994524002075195,
      "backward_entropy": 0.019174171818627253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.87070083618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05184252932667732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0698876678943634,
      "backward_entropy": 0.01921525928709242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.396568298339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05190201476216316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06982651948928834,
      "backward_entropy": 0.019257790512508817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.600624084472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05196008086204529,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06976748704910278,
      "backward_entropy": 0.019292367829216853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.140972137451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052015844732522964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06971243023872375,
      "backward_entropy": 0.004468666182623969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.100292205810547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05207093805074692,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06965823173522949,
      "backward_entropy": 0.01936443977885776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.3581657409668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05212504416704178,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0696054995059967,
      "backward_entropy": 0.01939837634563446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.48430633544922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05218331888318062,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06954399347305298,
      "backward_entropy": 0.0769891341527303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.223894119262695,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05224142223596573,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0694823443889618,
      "backward_entropy": 0.07698901494344075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.302127838134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05229721590876579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06942474842071533,
      "backward_entropy": 0.019485471977127924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.07261276245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235535278916359,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06936182975769042,
      "backward_entropy": 0.0042974137597613865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.005348205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052415963262319565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0692935049533844,
      "backward_entropy": 0.019518357184198167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.906736373901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052475910633802414,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06922593116760253,
      "backward_entropy": 0.019523599081569247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.07881164550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05253336578607559,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06916303634643554,
      "backward_entropy": 0.01953165398703681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.97109603881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05259234458208084,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06909657120704651,
      "backward_entropy": 0.01954742603831821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.20960998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05265231803059578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0690274953842163,
      "backward_entropy": 0.0041396332283814745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.973289489746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052714183926582336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06895399689674378,
      "backward_entropy": 0.004106956637567944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.122474670410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05277810990810394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0688757061958313,
      "backward_entropy": 0.004075133138232761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.997270584106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05284164473414421,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06879777908325195,
      "backward_entropy": 0.004045451680819194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.752572536468506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052904702723026276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06872047781944275,
      "backward_entropy": 0.019596611460049946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.4963321685791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05296296253800392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0686529278755188,
      "backward_entropy": 0.01962537235683865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.60509490966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05302002280950546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06858731508255005,
      "backward_entropy": 0.003964504020081626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.46587562561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05307723581790924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06852084994316102,
      "backward_entropy": 0.019679801331626043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.125577926635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053134702146053314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06845333576202392,
      "backward_entropy": 0.019711761011017695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.3408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053191639482975006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06838654279708863,
      "backward_entropy": 0.01975941989156935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.950254440307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05325019359588623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06831576228141785,
      "backward_entropy": 0.019812999500168696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.863025665283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053307853639125824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06824647784233093,
      "backward_entropy": 0.019872537917561002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.855621337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0533645823597908,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06817864775657653,
      "backward_entropy": 0.019933917456203036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.719629287719727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05342145264148712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06810991168022155,
      "backward_entropy": 0.0038212305969662136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.548280715942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053478557616472244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0680400550365448,
      "backward_entropy": 0.02005042963557773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.51568603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053533535450696945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06797443032264709,
      "backward_entropy": 0.02011021806134118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.37936782836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05358857288956642,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06790797710418701,
      "backward_entropy": 0.020159792568948533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.419169902801514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053644753992557526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06783834099769592,
      "backward_entropy": 0.020198434591293335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.24463653564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05369655787944794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06777818202972412,
      "backward_entropy": 0.020240787002775405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.09105110168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05374738201498985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06771968603134156,
      "backward_entropy": 0.020271536376741197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.281101703643799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053797900676727295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06766139268875122,
      "backward_entropy": 0.02030858728620741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.917163848876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053845182061195374,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06761029958724976,
      "backward_entropy": 0.020364253057373896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.71215057373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053892504423856735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06755859255790711,
      "backward_entropy": 0.020420567856894598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.942626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053940724581480026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06750417947769165,
      "backward_entropy": 0.02046996686193678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.594566345214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05399412661790848,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06743743419647216,
      "backward_entropy": 0.020505249500274658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.594404220581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05404750630259514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06737018823623657,
      "backward_entropy": 0.020559431778060064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.68897819519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054099954664707184,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06730449795722962,
      "backward_entropy": 0.020604716406928167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.655397415161133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05415091663599014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06724177598953247,
      "backward_entropy": 0.003549435486396154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.4268684387207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0542001947760582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06718249320983886,
      "backward_entropy": 0.02070724798573388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.932971954345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05425287410616875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06711490154266357,
      "backward_entropy": 0.0035153875748316445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.070112228393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05430576205253601,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06704627871513366,
      "backward_entropy": 0.020807297693358526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.60362243652344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054358404129743576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06697777509689332,
      "backward_entropy": 0.02086341381072998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.787052154541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054415155202150345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0668993592262268,
      "backward_entropy": 0.0034666930635770163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.4637565612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054474394768476486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06681467890739441,
      "backward_entropy": 0.0034525489641560447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.11742401123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054538752883672714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06671777367591858,
      "backward_entropy": 0.0210265318552653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.941164970397949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054600268602371216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0666269063949585,
      "backward_entropy": 0.0034197980744971167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.57149124145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054656948894262314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06654701232910157,
      "backward_entropy": 0.02112673885292477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.4232177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05471454933285713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06646432280540467,
      "backward_entropy": 0.02116892735163371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.7313117980957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054770708084106445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0663845419883728,
      "backward_entropy": 0.003367957141664293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.6644344329834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05482910946011543,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06629884243011475,
      "backward_entropy": 0.02123601734638214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.268256187438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054887156933546066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06621336936950684,
      "backward_entropy": 0.021263228522406682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.20647048950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05494145303964615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06613644361495971,
      "backward_entropy": 0.021286196178860135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.186579704284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05499814450740814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06605308055877686,
      "backward_entropy": 0.02130787240134345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.1909122467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05505099892616272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06597853302955628,
      "backward_entropy": 0.021318692300054762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.390869140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05510381981730461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06590359210968018,
      "backward_entropy": 0.021320437391599018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.300939559936523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05515458807349205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06583321690559388,
      "backward_entropy": 0.02132208479775323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.942269325256348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05520372465252876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06576647758483886,
      "backward_entropy": 0.0031897674004236856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.17789077758789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05525032803416252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06570566296577454,
      "backward_entropy": 0.0031672175973653793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.625028610229492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055295608937740326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06564775109291077,
      "backward_entropy": 0.0031449536068571936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.494184494018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05534171685576439,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06558719873428345,
      "backward_entropy": 0.02136714259783427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.1617374420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055388882756233215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06552350521087646,
      "backward_entropy": 0.003100086831384235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.526595592498779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0554361492395401,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06545931100845337,
      "backward_entropy": 0.021406299538082547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.014358520507812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05548012629151344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06540333032608033,
      "backward_entropy": 0.021444891889890034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.94317054748535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0555243082344532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06534628868103028,
      "backward_entropy": 0.021487633387247723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.97996711730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05556856840848923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06528866887092591,
      "backward_entropy": 0.0030312289794286094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.677962303161621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05561415106058121,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06522713899612427,
      "backward_entropy": 0.021576465831862554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.625250816345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055658504366874695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06516823768615723,
      "backward_entropy": 0.02162090606159634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.70750617980957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05570164695382118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06511189937591552,
      "backward_entropy": 0.0029841415170166227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.545698165893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05574589967727661,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06505214571952819,
      "backward_entropy": 0.0029672053125169543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.429304122924805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05579020082950592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0649918794631958,
      "backward_entropy": 0.0029505110449261135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.369161605834961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0558350495994091,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06492983102798462,
      "backward_entropy": 0.002936763068040212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.332807540893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05587882921099663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06487013101577759,
      "backward_entropy": 0.002923249370521969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.211091995239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05592437461018562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06480495929718018,
      "backward_entropy": 0.0029067014240556294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.092931747436523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05597076565027237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0647370994091034,
      "backward_entropy": 0.002889681193563673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.070547103881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05601810663938522,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06466624736785889,
      "backward_entropy": 0.021944241391287908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.78497314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05606496334075928,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06459618806838989,
      "backward_entropy": 0.021972709231906466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.57607650756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05611395090818405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06452012062072754,
      "backward_entropy": 0.002840497013595369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.791217803955078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056165486574172974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06443696022033692,
      "backward_entropy": 0.0028239917010068893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.536867141723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056216299533843994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0643552839756012,
      "backward_entropy": 0.022070103221469455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.7515754699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056267689913511276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06427156329154968,
      "backward_entropy": 0.0027930852439668444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.526451110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05632340908050537,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06417576670646667,
      "backward_entropy": 0.02213214834531148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.428041458129883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056377679109573364,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06408331394195557,
      "backward_entropy": 0.002758530072040028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.5403413772583,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0564306378364563,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06399382352828979,
      "backward_entropy": 0.07700420750512017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.9419002532959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056481972336769104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0639083981513977,
      "backward_entropy": 0.022187928358713787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.838050842285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05653379112482071,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06382118463516236,
      "backward_entropy": 0.022220833433998957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.649687767028809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05658584460616112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0637327790260315,
      "backward_entropy": 0.022252877553304035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.964126586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05663523077964783,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06365140676498413,
      "backward_entropy": 0.022297903895378113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.148242950439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05668376758694649,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06357188820838929,
      "backward_entropy": 0.0223342047797309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.131183624267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056733857840299606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0634875774383545,
      "backward_entropy": 0.02236751053068373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.08231258392334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05678257718682289,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06340672969818115,
      "backward_entropy": 0.022412872976726957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.754728317260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05682976916432381,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06332971453666687,
      "backward_entropy": 0.0026254095137119293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.495643615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056878712028265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06324725747108459,
      "backward_entropy": 0.022506347960895963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.8933687210083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056927390396595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06316503882408142,
      "backward_entropy": 0.022562121351559956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.378210067749023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05697442963719368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0630869746208191,
      "backward_entropy": 0.022616131438149348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.26036834716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05702310800552368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06300369501113892,
      "backward_entropy": 0.022664818498823378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.105335235595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05707306042313576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06291608214378357,
      "backward_entropy": 0.02270229657491048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.170477867126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05712452530860901,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06282373666763305,
      "backward_entropy": 0.02274166378710005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.004615783691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05717314034700394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06273913383483887,
      "backward_entropy": 0.02278466522693634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.677792072296143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057220909744501114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06265636682510375,
      "backward_entropy": 0.02281775739457872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.443341255187988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05726509541273117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06258363127708436,
      "backward_entropy": 0.02285449869102902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.72081756591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05730795860290527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06251434683799743,
      "backward_entropy": 0.02288876473903656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.952533721923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05735127627849579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.062443393468856814,
      "backward_entropy": 0.022939410474565294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9147367477417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05739272013306618,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06237772703170776,
      "backward_entropy": 0.022999909189012315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.516267776489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057432472705841064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0623166024684906,
      "backward_entropy": 0.023068384991751775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.873590469360352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05747268721461296,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.062253701686859134,
      "backward_entropy": 0.02313962909910414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.103217124938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05751076713204384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06219650506973266,
      "backward_entropy": 0.02319844729370541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783120155334473,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05754828453063965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.06214045882225037,
      "backward_entropy": 0.0770124461915758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.734305381774902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05758429318666458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06208854913711548,
      "backward_entropy": 0.0024278368800878525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.197446823120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057619210332632065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06203952431678772,
      "backward_entropy": 0.023383771379788715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.80864906311035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05765485018491745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06198761463165283,
      "backward_entropy": 0.02344796558221181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.6572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05769410729408264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06192441582679749,
      "backward_entropy": 0.02350133326318529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.75741958618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057737138122320175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06184972524642944,
      "backward_entropy": 0.002389877206749386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.091257095336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0577838271856308,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06176350116729736,
      "backward_entropy": 0.023606960972150166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.093433380126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05783075466752052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06167600154876709,
      "backward_entropy": 0.023637274901072185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.61398696899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057879578322172165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.061582434177398684,
      "backward_entropy": 0.002354502263996336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.52517032623291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05792662501335144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.06149381399154663,
      "backward_entropy": 0.002342941032515632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.73420524597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0579725056886673,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06140826344490051,
      "backward_entropy": 0.023768790894084506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.603792190551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05802008509635925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06131714582443237,
      "backward_entropy": 0.02382030751970079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.44554901123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05806926637887955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.061220806837081906,
      "backward_entropy": 0.023874145415094163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.331697463989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05811864137649536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0611233651638031,
      "backward_entropy": 0.023922645383410983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.20441246032715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05816826596856117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06102464199066162,
      "backward_entropy": 0.023969057533476088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.092559814453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05822038650512695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06091794967651367,
      "backward_entropy": 0.024021622207429674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.958471298217773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05827333405613899,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060808217525482176,
      "backward_entropy": 0.024065716399086848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.109256744384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058326926082372665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06069608330726624,
      "backward_entropy": 0.024098124768998887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016064643859863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05837688222527504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06059471368789673,
      "backward_entropy": 0.024118138684166804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.331787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058424342423677444,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0605007529258728,
      "backward_entropy": 0.002239631281958686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.561758041381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.058474957942962646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060396552085876465,
      "backward_entropy": 0.0022277331186665427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.787845611572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05852535739541054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.060292601585388184,
      "backward_entropy": 0.002214759588241577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.302757263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05858004465699196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.060175031423568726,
      "backward_entropy": 0.024230910672081843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.579362869262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05863451585173607,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.06005771160125732,
      "backward_entropy": 0.024264474709828694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.389307022094727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05869153514504433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0599323034286499,
      "backward_entropy": 0.024294546908802457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.476944923400879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05875065177679062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05980006456375122,
      "backward_entropy": 0.002169485307402081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634422302246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05880649387836456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05967758893966675,
      "backward_entropy": 0.02432249155309465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.687376022338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058859214186668396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.059564518928527835,
      "backward_entropy": 0.02434742616282569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.95318603515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05891185253858566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05945129990577698,
      "backward_entropy": 0.07701279057396783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.53715705871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.058968979865312576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05932380557060242,
      "backward_entropy": 0.024402573704719543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.33477020263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05902206897735596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.059208571910858154,
      "backward_entropy": 0.0021084874040550655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.24359893798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05907491222023964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05909380316734314,
      "backward_entropy": 0.02443293399280972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.68871307373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.059127096086740494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058980661630630496,
      "backward_entropy": 0.0020827090160714257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.90069580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059179943054914474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0588650107383728,
      "backward_entropy": 0.024451745880974665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.738833427429199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05923017859458923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0587571382522583,
      "backward_entropy": 0.02445192469490899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.78636932373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05927663668990135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05866125226020813,
      "backward_entropy": 0.02446370157930586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.197635650634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05932321026921272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058564549684524535,
      "backward_entropy": 0.02447303632895152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21853528916835785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059368789196014404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058470416069030764,
      "backward_entropy": 0.024475981791814167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.103799819946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05940980091691017,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05839095115661621,
      "backward_entropy": 0.02448134786552853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.829912185668945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05944904685020447,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05831700563430786,
      "backward_entropy": 0.07700681686401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.300052642822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05949026718735695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058236217498779295,
      "backward_entropy": 0.024530044860310025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5948004722595215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059532344341278076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.058152186870574954,
      "backward_entropy": 0.024560795889960393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.899877548217773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05957154557108879,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.058077335357666016,
      "backward_entropy": 0.0019565742048952314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.043289184570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05961351841688156,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057992970943450926,
      "backward_entropy": 0.024641659524705675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.600159645080566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059655994176864624,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05790640711784363,
      "backward_entropy": 0.024674392408794828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.854381561279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059698011726140976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05782094597816467,
      "backward_entropy": 0.024704014261563618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.164323806762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059740595519542694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057733154296875,
      "backward_entropy": 0.024732218848334417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.090065956115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05978121981024742,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0576513946056366,
      "backward_entropy": 0.024738437599605985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.036453247070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05982049182057381,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057573717832565305,
      "backward_entropy": 0.02474159002304077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.477684020996094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.059858545660972595,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05749964714050293,
      "backward_entropy": 0.02474140789773729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.162790298461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05989803001284599,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.057420605421066286,
      "backward_entropy": 0.024764367275767855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4264447689056396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0599374957382679,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05734132528305054,
      "backward_entropy": 0.02479396594895257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.611227512359619,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05997385457158089,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0572722852230072,
      "backward_entropy": 0.02481949163807763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.570389270782471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06000854820013046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05720849633216858,
      "backward_entropy": 0.02484875751866235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.7229642868042,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06004198640584946,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.057148689031600954,
      "backward_entropy": 0.07700363132688734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.01665496826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06007517874240875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05708932876586914,
      "backward_entropy": 0.024939434395896062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.799315452575684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06010992079973221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.057024359703063965,
      "backward_entropy": 0.0018041431903839111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.013935089111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06014484167098999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05695837140083313,
      "backward_entropy": 0.025038002265824214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.432332992553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060181766748428345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05688504576683044,
      "backward_entropy": 0.025076443950335186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.920167922973633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060216717422008514,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0568181037902832,
      "backward_entropy": 0.0251065989335378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.731706619262695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06025492399930954,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05673969984054565,
      "backward_entropy": 0.025144494242138334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.322144985198975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06029462441802025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05665579438209534,
      "backward_entropy": 0.025169973572095234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.50959587097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06033230572938919,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056578391790390016,
      "backward_entropy": 0.025197962919871014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.250349521636963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06037205830216408,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05649372935295105,
      "backward_entropy": 0.025235517157448664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.321552276611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06040985882282257,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05641546845436096,
      "backward_entropy": 0.02527717583709293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.181820869445801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06044930964708328,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05633118748664856,
      "backward_entropy": 0.025312425361739263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.10911750793457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06048683077096939,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0562533974647522,
      "backward_entropy": 0.025353716479407415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.120799541473389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06052703037858009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.056166046857833864,
      "backward_entropy": 0.025392621755599976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.071722507476807,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06056498363614082,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05608614683151245,
      "backward_entropy": 0.07700681686401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.70787811279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0606013722717762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05601133108139038,
      "backward_entropy": 0.0016862215060326788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.722131729125977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06064137443900108,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055923736095428465,
      "backward_entropy": 0.025520796577135723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.786479949951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060682736337184906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05583099126815796,
      "backward_entropy": 0.025558561086654663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.718124389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06072389706969261,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055738747119903564,
      "backward_entropy": 0.0016623417743378216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.401958465576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06076478958129883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05564714670181274,
      "backward_entropy": 0.02565791706244151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.285730361938477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060806989669799805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05555078387260437,
      "backward_entropy": 0.02570476796891954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.349669456481934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06085057556629181,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.055449163913726805,
      "backward_entropy": 0.0016412302437755796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.964728593826294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06089416891336441,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.055347269773483275,
      "backward_entropy": 0.025795916716257732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.156448364257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.060934729874134064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05525572299957275,
      "backward_entropy": 0.025851176844702825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.295465469360352,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.060975946485996246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05516164302825928,
      "backward_entropy": 0.0016211833183964093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.690131187438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061016593128442764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05506913065910339,
      "backward_entropy": 0.02596457302570343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.91042709350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061055026948451996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.054984104633331296,
      "backward_entropy": 0.0016077831387519836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8757095336914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06109406054019928,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054896587133407594,
      "backward_entropy": 0.026063924034436543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.748230934143066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06113048642873764,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054818129539489745,
      "backward_entropy": 0.02612492276562585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.268538475036621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06116776540875435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054736316204071045,
      "backward_entropy": 0.02618344955974155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.22548770904541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06120390072464943,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05465821027755737,
      "backward_entropy": 0.0015818019294076497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.519318580627441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06123892217874527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05458371043205261,
      "backward_entropy": 0.026275272170702618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.785462379455566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06127490475773811,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05450543761253357,
      "backward_entropy": 0.026315766904089186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.712007522583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06131083518266678,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05442700386047363,
      "backward_entropy": 0.026355612609121535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.55443572998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06134700030088425,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05434739589691162,
      "backward_entropy": 0.026406011647648282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.372015953063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061385564506053925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05425890684127808,
      "backward_entropy": 0.026446875598695543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.131448745727539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061422061175107956,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.054177528619766234,
      "backward_entropy": 0.026485739482773676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.885718822479248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061459317803382874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05409313440322876,
      "backward_entropy": 0.026523104972309537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14368554949760437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061495598405599594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05401188731193542,
      "backward_entropy": 0.026562223831812542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.901056289672852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06152830645442009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0539432168006897,
      "backward_entropy": 0.026601541373464797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763513088226318,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06156226247549057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05386984348297119,
      "backward_entropy": 0.0015086893820100361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71514892578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061595335602760315,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05379928350448608,
      "backward_entropy": 0.02668440341949463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.190295219421387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06162775307893753,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05373082160949707,
      "backward_entropy": 0.0267228020562066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.12905502319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061660319566726685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0536615252494812,
      "backward_entropy": 0.001486235298216343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.535634994506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06169315427541733,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05359086990356445,
      "backward_entropy": 0.026791916953192815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.956345558166504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061728592962026596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0535105288028717,
      "backward_entropy": 0.026818431086010404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.768604278564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06176562234759331,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05342432260513306,
      "backward_entropy": 0.026843511395984225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.440176486968994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06180582940578461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053326350450515744,
      "backward_entropy": 0.026868462562561035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.393661975860596,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.061844777315855026,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05323273539543152,
      "backward_entropy": 0.0014478079974651337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.154561996459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.061882514506578445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053143280744552615,
      "backward_entropy": 0.026935216453340318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.306259632110596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0619208998978138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.053051155805587766,
      "backward_entropy": 0.02697417140007019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.76027488708496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06195790320634842,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05296388864517212,
      "backward_entropy": 0.027005175749460857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.561102867126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06199691817164421,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05286905765533447,
      "backward_entropy": 0.02702492144372728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.161261081695557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06203548237681389,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05277578234672546,
      "backward_entropy": 0.02704776989089118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.7645263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06207263097167015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05268731713294983,
      "backward_entropy": 0.02706767453087701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.367667198181152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06211021915078163,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05259703397750855,
      "backward_entropy": 0.027086739738782246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024656295776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06214754655957222,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0525075614452362,
      "backward_entropy": 0.02711314128504859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.526432037353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06218342110514641,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05242320895195007,
      "backward_entropy": 0.001379756774339411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.913957595825195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062219973653554916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052336156368255615,
      "backward_entropy": 0.027146579490767583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.373147010803223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062255628407001495,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05225212574005127,
      "backward_entropy": 0.02717525429195828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.30835247039795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062292031943798065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05216508507728577,
      "backward_entropy": 0.027209086550606623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.665194511413574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062328822910785675,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.052076411247253415,
      "backward_entropy": 0.02723601957162221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737118721008301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06236777827143669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051979660987854004,
      "backward_entropy": 0.027264571852154203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.258841514587402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062405362725257874,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05188778042793274,
      "backward_entropy": 0.02729319367143843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.972710609436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.062444090843200684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05179151296615601,
      "backward_entropy": 0.027319752507739596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.583128452301025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06248347461223602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051692640781402587,
      "backward_entropy": 0.027363760603798762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.982016563415527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06252168864011765,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051597923040390015,
      "backward_entropy": 0.027418378326627944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.36662483215332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06256072968244553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05150001049041748,
      "backward_entropy": 0.001314218363000287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.566657066345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06259771436452866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051409471035003665,
      "backward_entropy": 0.02750401861137814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.691195487976074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06263422966003418,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05132050514221191,
      "backward_entropy": 0.027546730306413438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.602219581604004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06267210096120834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05122634172439575,
      "backward_entropy": 0.027594104409217834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.313417434692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06271111220121384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.051127827167510985,
      "backward_entropy": 0.027642034822040133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.36520767211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06274872273206711,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05103424787521362,
      "backward_entropy": 0.0012876737034983104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.331624984741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06278670579195023,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05093915462493896,
      "backward_entropy": 0.027739859289593168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.163390636444092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06282562762498856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05084043741226196,
      "backward_entropy": 0.027783244848251343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.121057033538818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06286217272281647,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05075041055679321,
      "backward_entropy": 0.02782027588950263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.078011512756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06289684027433395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05066714286804199,
      "backward_entropy": 0.02786433696746826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.053551197052002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06293130666017532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050584417581558225,
      "backward_entropy": 0.001260588876903057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.944622993469238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06296462565660477,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05050570964813232,
      "backward_entropy": 0.027948730521731906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13486769795417786,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06299839168787003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050425213575363156,
      "backward_entropy": 0.02797800302505493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.919264316558838,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.06302843987941742,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.05035854578018188,
      "backward_entropy": 0.07701614830229017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.880070209503174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06305810809135437,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05029304623603821,
      "backward_entropy": 0.02801590495639377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.780014514923096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06308749318122864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.050228238105773926,
      "backward_entropy": 0.028057737482918635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9221107959747314,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06311695277690887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.05016305446624756,
      "backward_entropy": 0.001222311415606075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7931742668151855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0631449967622757,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.05010291337966919,
      "backward_entropy": 0.02812291185061137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.633975028991699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06317250430583954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.050044548511505124,
      "backward_entropy": 0.001209399559431606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.455588340759277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0632004514336586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0499842643737793,
      "backward_entropy": 0.028179119030634563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.10778522491455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06322964280843735,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04991905987262726,
      "backward_entropy": 0.02821471956041124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7919793128967285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06326166540384293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04984289705753327,
      "backward_entropy": 0.0282639827993181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598222255706787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06329227238893509,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04977181553840637,
      "backward_entropy": 0.02831968002849155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.044144630432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06332243978977203,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04970209002494812,
      "backward_entropy": 0.0283851424853007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.166593551635742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0633542388677597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049626097083091736,
      "backward_entropy": 0.0011808837039603128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.299973964691162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06338657438755035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04954791367053986,
      "backward_entropy": 0.02849877542919583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.61349868774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06341873109340668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04947028756141662,
      "backward_entropy": 0.028546075026194256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.418087482452393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06345285475254059,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04938509464263916,
      "backward_entropy": 0.028582364320755005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.385525226593018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06348595023155212,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04930362105369568,
      "backward_entropy": 0.028620233138402302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5886359214782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0635179802775383,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.049226009845733644,
      "backward_entropy": 0.0011557996686961916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.514853477478027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06354852765798569,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04915371835231781,
      "backward_entropy": 0.028696248928705852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.718240737915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06358055770397186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04907571077346802,
      "backward_entropy": 0.0011459385148353046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.668066024780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06361314654350281,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048995491862297055,
      "backward_entropy": 0.028773711787329778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.380093574523926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06364595890045166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04891443550586701,
      "backward_entropy": 0.028797156280941434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.465799570083618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06368222087621689,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04882057905197144,
      "backward_entropy": 0.028821696837743122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.111398696899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06371641904115677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04873438775539398,
      "backward_entropy": 0.028847889767752752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.392027854919434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06374944746494293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04865243434906006,
      "backward_entropy": 0.028873711824417114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.027039051055908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06378280371427536,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04856924414634704,
      "backward_entropy": 0.028895209232966106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.989317893981934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06381519138813019,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04848945140838623,
      "backward_entropy": 0.02892104122373793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.829468727111816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06384669244289398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04841271936893463,
      "backward_entropy": 0.028952545589870878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.305147647857666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06387926638126373,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04833188951015473,
      "backward_entropy": 0.02897443373998006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.463798522949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06391023844480515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04825693368911743,
      "backward_entropy": 0.001090838366912471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.273869514465332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06394138187170029,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04818103313446045,
      "backward_entropy": 0.029048562049865723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6660579442977905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06397072970867157,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04811180830001831,
      "backward_entropy": 0.02908261948161655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.340153217315674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06399796903133392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.048050296306610105,
      "backward_entropy": 0.029118223322762385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.537334442138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06402553617954254,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047987356781959534,
      "backward_entropy": 0.029158916738298204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1723074913024902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06405571103096008,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04791474938392639,
      "backward_entropy": 0.029179314772288006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.760602951049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06408441811800003,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04784749448299408,
      "backward_entropy": 0.001061417783300082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.140395164489746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0641135722398758,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04777858257293701,
      "backward_entropy": 0.029214892122480605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6289567947387695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06414110213518143,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04771568775177002,
      "backward_entropy": 0.02922006116973029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.590073108673096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06416962295770645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04764887094497681,
      "backward_entropy": 0.029236263699001737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.047512531280518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06419737637042999,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0475848376750946,
      "backward_entropy": 0.029251515865325928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.522731781005859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06422509998083115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04752079844474792,
      "backward_entropy": 0.0292639070087009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5684819221496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06425219029188156,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047459131479263304,
      "backward_entropy": 0.029277112748887803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.468079090118408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06427707523107529,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04740566611289978,
      "backward_entropy": 0.029279569784800213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7733793258667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06430148333311081,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.047353869676589964,
      "backward_entropy": 0.029278980361090765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.292139053344727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06432779878377914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04729469418525696,
      "backward_entropy": 0.029287728998396132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.234889507293701,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06435474753379822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04723304510116577,
      "backward_entropy": 0.029286626312467787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.33741569519043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06438237428665161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04716885387897492,
      "backward_entropy": 0.0009927038724223773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4874237775802612,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06440942734479904,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04710657000541687,
      "backward_entropy": 0.0009864492134915458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274994373321533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06443466246128082,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04705095887184143,
      "backward_entropy": 0.029300666517681546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.030799865722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06445961445569992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.046996194124221805,
      "backward_entropy": 0.0009754993435409334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.973051071166992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06448554247617722,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046937686204910276,
      "backward_entropy": 0.029343436161677044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.18961763381958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06451258063316345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04687473177909851,
      "backward_entropy": 0.0293760167227851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.796037435531616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06453908234834671,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0468137264251709,
      "backward_entropy": 0.029410762919320002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.844317436218262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06456451117992401,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046756574511528017,
      "backward_entropy": 0.029451946417490642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.79398775100708,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.06459064781665802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.04669674932956695,
      "backward_entropy": 0.0009530016945468055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0777459144592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06461747735738754,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046634232997894286,
      "backward_entropy": 0.029507464832729764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6939849853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06464364379644394,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.04657405018806458,
      "backward_entropy": 0.029528578122456867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.633230209350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.06467054039239883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.046511095762252805,
      "backward_entropy": 0.029547774129443698,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.773900196552277,
    "avg_log_Z": -0.06316631224006414,
    "success_rate": 1.0,
    "avg_reward": 24.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.01,
      "1": 0.81,
      "2": 0.18
    },
    "avg_forward_entropy": 0.05005908831954002,
    "avg_backward_entropy": 0.02380205737116436,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}