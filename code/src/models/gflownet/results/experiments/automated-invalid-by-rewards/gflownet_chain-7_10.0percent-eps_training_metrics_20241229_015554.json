{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09897931132997785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09894824028015137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.5242462158203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372450739145279,
      "backward_entropy": 0.09900898592812675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.64491271972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372435837984085,
      "backward_entropy": 0.09897950717381068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.44471740722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00019961562065873295,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724195957183838,
      "backward_entropy": 0.09901087624686104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5704803466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00029952044133096933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372402012348175,
      "backward_entropy": 0.09897996698107038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.8641357421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00039913563523441553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372382789850235,
      "backward_entropy": 0.09901254517691475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.48065185546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004993662587366998,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723623752593994,
      "backward_entropy": 0.09901332003729683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.01451110839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006003014277666807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723400235176086,
      "backward_entropy": 0.09898076738630023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.181640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0007003225036896765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723166286945343,
      "backward_entropy": 0.098945038659232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.6955261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008006943389773369,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722917437553406,
      "backward_entropy": 0.09894454479217529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.72198486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009013616945594549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722652196884155,
      "backward_entropy": 0.09898135491779872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.6878662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010017046006396413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372237652540207,
      "backward_entropy": 0.09901649611336845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.64019775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011030480964109302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372208297252655,
      "backward_entropy": 0.09894263744354248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 276.7812194824219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0012051776284351945,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721764087677002,
      "backward_entropy": 0.09901744978768486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.3707580566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001307549886405468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372143179178238,
      "backward_entropy": 0.09894120693206787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.43362426757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014096156228333712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721086084842682,
      "backward_entropy": 0.0989404661314828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5655975341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001508809975348413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720734417438507,
      "backward_entropy": 0.09901854821613856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.9153137207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016069768462330103,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720373809337616,
      "backward_entropy": 0.09898136343274798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 260.2029113769531,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0017056947108358145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719996809959412,
      "backward_entropy": 0.09901900802339826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.65902709960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018047323683276772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719606399536133,
      "backward_entropy": 0.0989358765738351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.88343811035156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0019020898034796119,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719207048416138,
      "backward_entropy": 0.09901934010641915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.6854705810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001999465050175786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371879279613495,
      "backward_entropy": 0.0989325898034232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.69140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002094531897455454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718368113040924,
      "backward_entropy": 0.09901948486055646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.2096405029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002189846243709326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717932999134064,
      "backward_entropy": 0.09897778715406146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 293.07781982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002285442780703306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371748149394989,
      "backward_entropy": 0.09897685050964355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.89553833007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0023830782156437635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717009127140045,
      "backward_entropy": 0.0989239045551845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.4259948730469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024791420437395573,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716527819633484,
      "backward_entropy": 0.09901957852499825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.82498168945312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025760603602975607,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371602714061737,
      "backward_entropy": 0.09901957852499825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.90570068359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002671488095074892,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371552050113678,
      "backward_entropy": 0.09897249937057495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.74029541015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0027657400351017714,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715003430843353,
      "backward_entropy": 0.09901949337550572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.4884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002861080225557089,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714468479156494,
      "backward_entropy": 0.09896978310176305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.44729614257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0029576628003269434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713909685611725,
      "backward_entropy": 0.0989072152546474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.0858154296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003054447937756777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713335990905762,
      "backward_entropy": 0.09890421799251012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.807861328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031506672967225313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712748885154724,
      "backward_entropy": 0.09896550859723773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.25238037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0032470901496708393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712148368358612,
      "backward_entropy": 0.0989639333316258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.77500915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003342272248119116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711518049240112,
      "backward_entropy": 0.09896227291652135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.12562561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003436428727582097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.0989605188369751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.26177978515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003531011752784252,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710203766822815,
      "backward_entropy": 0.09901899099349976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.85443115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0036247153766453266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13709521293640137,
      "backward_entropy": 0.09895683186394828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.44558715820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003718262305483222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708820939064026,
      "backward_entropy": 0.0989548989704677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.77647399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003810284659266472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370811015367508,
      "backward_entropy": 0.09895288092749459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.40322875976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0039023691788315773,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370738297700882,
      "backward_entropy": 0.09895079476492745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.0208740234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003991986159235239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706651329994202,
      "backward_entropy": 0.0989485468183245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.34146118164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004081757739186287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370590627193451,
      "backward_entropy": 0.09894622223717826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.03106689453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004169312305748463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370515525341034,
      "backward_entropy": 0.09885709626334054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.7021484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0042584906332194805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370437890291214,
      "backward_entropy": 0.09894132614135742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.36807250976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004348276183009148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370358169078827,
      "backward_entropy": 0.09893891641071864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.18460083007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0044360077008605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370278000831604,
      "backward_entropy": 0.09884236540113177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.74588012695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004524618852883577,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137019544839859,
      "backward_entropy": 0.09901738166809082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.43792724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004614671226590872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701105117797852,
      "backward_entropy": 0.09893146583012172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.5080108642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004701620899140835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370026022195816,
      "backward_entropy": 0.09892879213605608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.63673400878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004789508879184723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369939148426056,
      "backward_entropy": 0.09882211685180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.62164306640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0048772725276649,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698506355285645,
      "backward_entropy": 0.09901680265154157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.88418579101562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004963143263012171,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697616755962372,
      "backward_entropy": 0.099016615322658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5919189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005046430509537458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136967271566391,
      "backward_entropy": 0.09880478041512626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.21157836914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005126396659761667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695845007896423,
      "backward_entropy": 0.09879818984440394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.09703063964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005205556284636259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694950938224792,
      "backward_entropy": 0.09879156521388463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.72523498535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005287663079798222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694018125534058,
      "backward_entropy": 0.0987853833607265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.99920654296875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005369498860090971,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693073391914368,
      "backward_entropy": 0.09901547431945801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.27850341796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0054502058774232864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136921226978302,
      "backward_entropy": 0.0989008971623012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.938720703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005528988316655159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691173493862152,
      "backward_entropy": 0.09876572234289986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.2794952392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005606988910585642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13690225780010223,
      "backward_entropy": 0.0988936253956386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.51356506347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005686141084879637,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689252734184265,
      "backward_entropy": 0.09901452916009086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.33216857910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005762604530900717,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13688282668590546,
      "backward_entropy": 0.09901424816676549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.61209106445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00584059813991189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687285780906677,
      "backward_entropy": 0.09873659270150321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.34957885742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005919729825109243,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368626058101654,
      "backward_entropy": 0.09887845175606864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.64678955078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005998207721859217,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685226440429688,
      "backward_entropy": 0.09887456893920898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.08148193359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006075158715248108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13684183359146118,
      "backward_entropy": 0.09887053285326276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.46649169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0061528380028903484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683117926120758,
      "backward_entropy": 0.09870610918317523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.7806854248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006228920072317123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368204653263092,
      "backward_entropy": 0.09901297092437744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.3764953613281,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00630764989182353,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368093490600586,
      "backward_entropy": 0.09901281765529088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.47499084472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006390316411852837,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367977261543274,
      "backward_entropy": 0.09901274953569685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.3477325439453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0064717805944383144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678601384162903,
      "backward_entropy": 0.09885049717766899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.2700958251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006553487852215767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677407801151276,
      "backward_entropy": 0.09866694041660853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.92547607421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0066382125951349735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13676178455352783,
      "backward_entropy": 0.09901254517691475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.05316162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00672379694879055,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13674919307231903,
      "backward_entropy": 0.09883888278688703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.4537811279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00681183161213994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367361843585968,
      "backward_entropy": 0.09901268141610282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.0369110107422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006899796426296234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367228627204895,
      "backward_entropy": 0.09901283468518939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.44805145263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006987190805375576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670925796031952,
      "backward_entropy": 0.09863083703177315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.959228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00707015348598361,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13669578731060028,
      "backward_entropy": 0.09882427964891706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.50531005859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007153089623898268,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13668209314346313,
      "backward_entropy": 0.09901303904397148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.25233459472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007239106576889753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666768372058868,
      "backward_entropy": 0.09881673540387835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.59312438964844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007323822472244501,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665319979190826,
      "backward_entropy": 0.09901327746255058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.68511962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007409493438899517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136638343334198,
      "backward_entropy": 0.09880920818873815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.26983642578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007493108976632357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662341237068176,
      "backward_entropy": 0.09880516358784266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.36224365234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007575880270451307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366083025932312,
      "backward_entropy": 0.09880095720291138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.9374542236328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007658087182790041,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365930140018463,
      "backward_entropy": 0.09901344776153564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.98416137695312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007740786299109459,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657736778259277,
      "backward_entropy": 0.09901349033628191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.559814453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00782569870352745,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656121492385864,
      "backward_entropy": 0.09901354994092669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.58199310302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007908024825155735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654504716396332,
      "backward_entropy": 0.09878320353371757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.9723663330078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007986346259713173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365290731191635,
      "backward_entropy": 0.0987778902053833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.2274932861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008067579008638859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651247322559357,
      "backward_entropy": 0.09852245024272374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.5350341796875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008151154965162277,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13649532198905945,
      "backward_entropy": 0.09901315825326103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.58447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008234057575464249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13647794723510742,
      "backward_entropy": 0.09850272110530309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.94500732421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008319941349327564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13645990192890167,
      "backward_entropy": 0.09901305607386998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.32083129882812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008407525718212128,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13644133508205414,
      "backward_entropy": 0.09901300498417445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.3949737548828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008498887531459332,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13642200827598572,
      "backward_entropy": 0.09901303052902222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.90512084960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008590572513639927,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640236854553223,
      "backward_entropy": 0.09874198266438075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.179931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00868175271898508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13638241589069366,
      "backward_entropy": 0.09873656715665545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 254.64578247070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008768809027969837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363627165555954,
      "backward_entropy": 0.09844002553394862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.9405059814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008859822526574135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363421082496643,
      "backward_entropy": 0.0987246036529541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.14462280273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008948125876486301,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363215297460556,
      "backward_entropy": 0.09871828556060791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.51239013671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009037102572619915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363004744052887,
      "backward_entropy": 0.09840529305594307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.6181869506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009127491153776646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13627885282039642,
      "backward_entropy": 0.09870517253875732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.91946411132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009211059659719467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13625794649124146,
      "backward_entropy": 0.09869802849633354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.6236572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009292867965996265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362370103597641,
      "backward_entropy": 0.09869068009512764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.13616943359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00937724020332098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621535897254944,
      "backward_entropy": 0.09868354456765312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.8094940185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009459499269723892,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361936628818512,
      "backward_entropy": 0.09834088597978864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.65280151367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009544027037918568,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617123663425446,
      "backward_entropy": 0.0990106293133327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.07369995117188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009629501961171627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614828884601593,
      "backward_entropy": 0.09831380844116211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.0224151611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009718355722725391,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13612446188926697,
      "backward_entropy": 0.0983010104724339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.8123321533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009806702844798565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13610029220581055,
      "backward_entropy": 0.09864437580108643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.60906982421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00989795196801424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607528805732727,
      "backward_entropy": 0.09901001623698644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.1501007080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009991608560085297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13604950904846191,
      "backward_entropy": 0.09826162031718663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.94236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010084631852805614,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13602344691753387,
      "backward_entropy": 0.09901002475193568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.18024444580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010174870491027832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13599742949008942,
      "backward_entropy": 0.09823507922036308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.71353149414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010260227136313915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597185909748077,
      "backward_entropy": 0.0982199055807931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.67230224609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010345458984375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359458863735199,
      "backward_entropy": 0.09859233243124825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.6298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010428517125546932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13591992855072021,
      "backward_entropy": 0.09858172280447823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 285.485595703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010509628802537918,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13589389622211456,
      "backward_entropy": 0.099008389881679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.41920471191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010597708635032177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358662098646164,
      "backward_entropy": 0.09856058870043073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.37374877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010686319321393967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583797216415405,
      "backward_entropy": 0.09855003867830549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.68331909179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010779116302728653,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135808527469635,
      "backward_entropy": 0.09853993143354144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.48829650878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01087448000907898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13577821850776672,
      "backward_entropy": 0.09853005409240723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.03781127929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010968874208629131,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357475221157074,
      "backward_entropy": 0.0990082962172372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.74982452392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011059311218559742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357172578573227,
      "backward_entropy": 0.09850861345018659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.8682861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011142496019601822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568800687789917,
      "backward_entropy": 0.09806452478681292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.81964111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011224945075809956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13565844297409058,
      "backward_entropy": 0.09848262582506452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.7698516845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011306743137538433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13562767207622528,
      "backward_entropy": 0.09802781684058053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.03114318847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011387966573238373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13559624552726746,
      "backward_entropy": 0.09800840275628227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.22947692871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011470664292573929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355637013912201,
      "backward_entropy": 0.09844086851392474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.89279174804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011551659554243088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13553085923194885,
      "backward_entropy": 0.09796832289014544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.99298095703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011631898581981659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13549746572971344,
      "backward_entropy": 0.09794678006853376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.08792114257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011712807230651379,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13546331226825714,
      "backward_entropy": 0.09839627572468349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.17408752441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01178987417370081,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354295313358307,
      "backward_entropy": 0.0979019148009164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.4456558227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011862985789775848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1353965699672699,
      "backward_entropy": 0.09836358683449882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.7971954345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011931738816201687,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13536444306373596,
      "backward_entropy": 0.09900062424795968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9219207763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012000047601759434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13533297181129456,
      "backward_entropy": 0.09832724503108434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.70193481445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012066979892551899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353013515472412,
      "backward_entropy": 0.09899827412196568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.7640380859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012140153907239437,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352677047252655,
      "backward_entropy": 0.09899747371673584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.3445281982422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012215000577270985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13523297011852264,
      "backward_entropy": 0.09899687767028809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.3319549560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012289118021726608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13519783318042755,
      "backward_entropy": 0.09772122757775444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.28981018066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012361403554677963,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13516271114349365,
      "backward_entropy": 0.09899582181658063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 268.8670654296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01243204902857542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13512752950191498,
      "backward_entropy": 0.09766953332083565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.75279235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012509847991168499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13508987426757812,
      "backward_entropy": 0.09819993802479335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.84739685058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012588598765432835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13505148887634277,
      "backward_entropy": 0.09762053830283028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.84393310546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012668409384787083,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13501228392124176,
      "backward_entropy": 0.09899497032165527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.211181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012748010456562042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349731832742691,
      "backward_entropy": 0.09814577443259102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.31353759765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012827334925532341,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13493399322032928,
      "backward_entropy": 0.09899504695619855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.4500732421875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012910955585539341,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13489310443401337,
      "backward_entropy": 0.09899541309901647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.84283447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012994969263672829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348515748977661,
      "backward_entropy": 0.09749476398740496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.76736450195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013079920783638954,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13480910658836365,
      "backward_entropy": 0.09899614538465228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.52218627929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013168208301067352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347651183605194,
      "backward_entropy": 0.09805182899747576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.62274169921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013256128877401352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13472062349319458,
      "backward_entropy": 0.09741154738834926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.60867309570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013340680859982967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13467654585838318,
      "backward_entropy": 0.09738097872052874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.75540161132812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013426817953586578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13463161885738373,
      "backward_entropy": 0.0973508528300694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.35736083984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01351657509803772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13458481431007385,
      "backward_entropy": 0.09732237883976527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.3060760498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013608522713184357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13453690707683563,
      "backward_entropy": 0.09794721433094569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.38262939453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01369788870215416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13448919355869293,
      "backward_entropy": 0.09792497328349523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.43560028076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013791661709547043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13443955779075623,
      "backward_entropy": 0.09723404475620814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.713134765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013880287297070026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13439098000526428,
      "backward_entropy": 0.09719982317515782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.7869415283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013968819752335548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343417763710022,
      "backward_entropy": 0.0978548356464931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.6930389404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014054028317332268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13429304957389832,
      "backward_entropy": 0.09782809870583671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 267.03692626953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014140380546450615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13424327969551086,
      "backward_entropy": 0.09780069759913854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3250732421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01423233188688755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13419094681739807,
      "backward_entropy": 0.09777418204716273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.32144165039062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014322981238365173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13413846492767334,
      "backward_entropy": 0.09774655955178398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.44798278808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014411784708499908,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13408616185188293,
      "backward_entropy": 0.09899912561689105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.29827880859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014499318785965443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13403357565402985,
      "backward_entropy": 0.096929703439985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.13331604003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014583435840904713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13398151099681854,
      "backward_entropy": 0.09765713555472237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 217.7137908935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014669322408735752,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13392916321754456,
      "backward_entropy": 0.09899801015853882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.9495391845703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014757763594388962,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13387559354305267,
      "backward_entropy": 0.09899778025490898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.98828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014843900687992573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13382217288017273,
      "backward_entropy": 0.09756382874080113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.8821563720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014931119978427887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13376760482788086,
      "backward_entropy": 0.09670730999537877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.31280517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015017055906355381,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13371261954307556,
      "backward_entropy": 0.09749654361179896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.49468994140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015102447010576725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336573213338852,
      "backward_entropy": 0.09899553230830602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.81576538085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015187053009867668,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13360163569450378,
      "backward_entropy": 0.09742403030395508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 249.09939575195312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015267654322087765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13354679942131042,
      "backward_entropy": 0.09738506589617048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.42495727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015353639610111713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13348917663097382,
      "backward_entropy": 0.09645119735172816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.2622528076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015441248193383217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13343027234077454,
      "backward_entropy": 0.09639949457986015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.57025146484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01552556175738573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333717554807663,
      "backward_entropy": 0.09727065052304949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.0743408203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01561000570654869,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13331204652786255,
      "backward_entropy": 0.09899049145834786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2494659423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0156937837600708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13325174152851105,
      "backward_entropy": 0.09622980867113386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.6748809814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01577576994895935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13319131731987,
      "backward_entropy": 0.09616962500980922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.8550262451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015858549624681473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13312973082065582,
      "backward_entropy": 0.0961090156010219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.46011352539062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015940852463245392,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1330675184726715,
      "backward_entropy": 0.09898599556514195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.2303009033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016021426767110825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13300517201423645,
      "backward_entropy": 0.09701944249016899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.64266204833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016102369874715805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13294215500354767,
      "backward_entropy": 0.09592393466404506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.941162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016179600730538368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1328800469636917,
      "backward_entropy": 0.09585985115596227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.24789428710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016260236501693726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13281536102294922,
      "backward_entropy": 0.09579593794686454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.74864196777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01634095050394535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13274990022182465,
      "backward_entropy": 0.09898046936307635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.82733917236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016424719244241714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326821893453598,
      "backward_entropy": 0.09566714082445417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.7609405517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016504403203725815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326155960559845,
      "backward_entropy": 0.09559861251286098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 278.7763977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01658497378230095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13254763185977936,
      "backward_entropy": 0.09668408121381487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.85113525390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016673395410180092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13247527182102203,
      "backward_entropy": 0.09663682324545723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.6820526123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01676308736205101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13240134716033936,
      "backward_entropy": 0.09658893517085484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.97479248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01685636304318905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323249191045761,
      "backward_entropy": 0.09654246057782855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.6089630126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016952738165855408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13224613666534424,
      "backward_entropy": 0.09527005468096052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.4245147705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017050622031092644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13216572999954224,
      "backward_entropy": 0.09520636286054339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.59898376464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017147209495306015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1320846974849701,
      "backward_entropy": 0.09640353066580636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 214.4517364501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017240852117538452,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13200438022613525,
      "backward_entropy": 0.09897883449281965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.87118530273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017336489632725716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13192220032215118,
      "backward_entropy": 0.09630331822804042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.8020782470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017430271953344345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13183991611003876,
      "backward_entropy": 0.0949265616280692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.12188720703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01752348430454731,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13175690174102783,
      "backward_entropy": 0.09619631937571935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.98458862304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01761980541050434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1316714584827423,
      "backward_entropy": 0.09477622168404716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.90359497070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017711902037262917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13158726692199707,
      "backward_entropy": 0.0946966324533735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.41514587402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0178024061024189,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13150295615196228,
      "backward_entropy": 0.0960284982408796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.36941528320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017890483140945435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13141915202140808,
      "backward_entropy": 0.09596715654645648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.20265197753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01797475665807724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13133633136749268,
      "backward_entropy": 0.09590251105172294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.48275756835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018058855086565018,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312534064054489,
      "backward_entropy": 0.09583769525800433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.71890258789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018143799155950546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13116943836212158,
      "backward_entropy": 0.09577302421842303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.75086975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018225882202386856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1310863196849823,
      "backward_entropy": 0.09416546140398298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.72988891601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018307315185666084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13100247085094452,
      "backward_entropy": 0.09563604422977992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.28704833984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018391083925962448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13091649115085602,
      "backward_entropy": 0.09397606338773455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.5424041748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018475957214832306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13082918524742126,
      "backward_entropy": 0.0954979317528861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018558798357844353,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13074198365211487,
      "backward_entropy": 0.09542581013270787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.46131896972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018636438995599747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1306571513414383,
      "backward_entropy": 0.0936833279473441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.69236755371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018712179735302925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13057266175746918,
      "backward_entropy": 0.09896526166370936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.29193115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018791571259498596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1304846853017807,
      "backward_entropy": 0.09519173417772565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.6280975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018870826810598373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13039574027061462,
      "backward_entropy": 0.09336497953959874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.405517578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018955951556563377,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13030223548412323,
      "backward_entropy": 0.09896080834524972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.79916381835938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019045041874051094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13020522892475128,
      "backward_entropy": 0.09495776891708374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.74391174316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0191333144903183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13010792434215546,
      "backward_entropy": 0.09895968437194824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.14031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019221656024456024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13000942766666412,
      "backward_entropy": 0.09479946749550956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.71391296386719,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019308052957057953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12991151213645935,
      "backward_entropy": 0.09895798138209752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.56808471679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019389020279049873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1298162341117859,
      "backward_entropy": 0.09462802750723702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.7844467163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019475985318422318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1297161877155304,
      "backward_entropy": 0.0945429972239903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.9530792236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01955685205757618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296200156211853,
      "backward_entropy": 0.09248835699898857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.28079223632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019635412842035294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295243799686432,
      "backward_entropy": 0.09436157771519252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.18450164794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01971735805273056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12942098081111908,
      "backward_entropy": 0.09427079132625035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.94818878173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01979328691959381,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1293187439441681,
      "backward_entropy": 0.0941744361604963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.78077697753906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019865460693836212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12921752035617828,
      "backward_entropy": 0.09407480273927961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.33367919921875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01993590220808983,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12911540269851685,
      "backward_entropy": 0.09894270556313652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.01185607910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020012004300951958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290072202682495,
      "backward_entropy": 0.09387247903006417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.39100646972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02008454129099846,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12889999151229858,
      "backward_entropy": 0.09893798828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.27976989746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020163722336292267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1287861168384552,
      "backward_entropy": 0.09893655776977539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.53033447265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02023945190012455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286737620830536,
      "backward_entropy": 0.09134135927472796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.5377197265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020313318818807602,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12856151163578033,
      "backward_entropy": 0.09893216405596052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.22767639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02038653939962387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128448024392128,
      "backward_entropy": 0.09106014456067767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.85389709472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02046133205294609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12833157181739807,
      "backward_entropy": 0.09091596943991524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.5223846435547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020536836236715317,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12821337580680847,
      "backward_entropy": 0.09892564160483223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.5353240966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020610418170690536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280956268310547,
      "backward_entropy": 0.09301086834498815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.72987365722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020689498633146286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12797217071056366,
      "backward_entropy": 0.09892221859523229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8629608154297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020765691995620728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278509944677353,
      "backward_entropy": 0.09032896586826869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.36798095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02084103785455227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12772905826568604,
      "backward_entropy": 0.09266583408628191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.50767517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02091960981488228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12760323286056519,
      "backward_entropy": 0.09003092561449323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.60191345214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020993482321500778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1274808794260025,
      "backward_entropy": 0.08987438678741455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.3939971923828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021069318056106567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12735554575920105,
      "backward_entropy": 0.09891494682856969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.63187408447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021144362166523933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12722957134246826,
      "backward_entropy": 0.09217589242117745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.6373748779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021214962005615234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12710654735565186,
      "backward_entropy": 0.09204316139221191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.3787841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021285727620124817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1269824355840683,
      "backward_entropy": 0.08921912738255092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.04049682617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021359723061323166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12685394287109375,
      "backward_entropy": 0.09177585159029279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.62254333496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021435396745800972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12672272324562073,
      "backward_entropy": 0.08887416975838798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.858154296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02150908298790455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12659229338169098,
      "backward_entropy": 0.09150295598166329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.91067504882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02158500999212265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12645873427391052,
      "backward_entropy": 0.09136615480695452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.17308044433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021666396409273148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12631942331790924,
      "backward_entropy": 0.08835076434271676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.28018188476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021747808903455734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12617917358875275,
      "backward_entropy": 0.08817904336111886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.26055908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02182791382074356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12603922188282013,
      "backward_entropy": 0.0909628016608102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.8922882080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02190808206796646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12589812278747559,
      "backward_entropy": 0.08781824793134417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.3227996826172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021987389773130417,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12575718760490417,
      "backward_entropy": 0.09890399660382952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.79734802246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022071726620197296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12561051547527313,
      "backward_entropy": 0.08745289700371879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.48191833496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02214738354086876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1254723072052002,
      "backward_entropy": 0.08725988013403756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.37232971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022224584594368935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125331312417984,
      "backward_entropy": 0.08706314223153251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.96402740478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022298431023955345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1251927614212036,
      "backward_entropy": 0.09006680761064802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.66229248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022367792204022408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12505778670310974,
      "backward_entropy": 0.08663855280194964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.22195434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022435421124100685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12492350488901138,
      "backward_entropy": 0.08972464288984026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.46519470214844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022505339235067368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12478543817996979,
      "backward_entropy": 0.08618252617972237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.71356201171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022573070600628853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12464921176433563,
      "backward_entropy": 0.08937452520642962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.02890014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022641241550445557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12451182305812836,
      "backward_entropy": 0.08572397061756679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.8197479248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022710641846060753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12437200546264648,
      "backward_entropy": 0.08902046510151454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.7257537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022783629596233368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12422738969326019,
      "backward_entropy": 0.0852655257497515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.20599365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02285737171769142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1240810751914978,
      "backward_entropy": 0.08503452369144984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.04879760742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0229319017380476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12393312156200409,
      "backward_entropy": 0.08849249567304339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.1754608154297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023007148876786232,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12378384917974472,
      "backward_entropy": 0.09887196336473737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.1818389892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023085100576281548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1236305758357048,
      "backward_entropy": 0.08432989461081368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.52589416503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023162085562944412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12347757071256638,
      "backward_entropy": 0.08795067242213658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3652114868164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02323591522872448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12332756817340851,
      "backward_entropy": 0.08775969914027623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.76205444335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0233041662722826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12318313121795654,
      "backward_entropy": 0.08755836316517421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.66844177246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023368142545223236,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12304367125034332,
      "backward_entropy": 0.08734958512442452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.8227081298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02343164198100567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1229042187333107,
      "backward_entropy": 0.08713884013039726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.40982818603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023500647395849228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12275777757167816,
      "backward_entropy": 0.08276390177862984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.56385803222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023568686097860336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12261202931404114,
      "backward_entropy": 0.09884626524788993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.84890747070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023638777434825897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12246277928352356,
      "backward_entropy": 0.08222086088997978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.78713989257812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023707596585154533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12231434881687164,
      "backward_entropy": 0.08630232300077166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.61038208007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023778824135661125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12216228991746902,
      "backward_entropy": 0.08166038990020752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.66001892089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0238465778529644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1220143586397171,
      "backward_entropy": 0.08137587138584682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.04023742675781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023915614932775497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12186410278081894,
      "backward_entropy": 0.08108805758612496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.89114379882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023979710415005684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12171845138072968,
      "backward_entropy": 0.08542515550340925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.19117736816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02404148317873478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12157584726810455,
      "backward_entropy": 0.08519217797688075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 230.54959106445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02410663478076458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12142837047576904,
      "backward_entropy": 0.08496247019086565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.03214263916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024179568514227867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12127120792865753,
      "backward_entropy": 0.07991195576531547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.66375732421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024249734356999397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12111678719520569,
      "backward_entropy": 0.07961867536817278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.07688903808594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02432212233543396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1209588274359703,
      "backward_entropy": 0.08429231813975743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.59832000732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024392019957304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12080363929271698,
      "backward_entropy": 0.0790172815322876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.09136962890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024460947141051292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12064946442842484,
      "backward_entropy": 0.07871127128601074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.072998046875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02453026734292507,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12049469351768494,
      "backward_entropy": 0.09880430357796806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.6215057373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0245958361774683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12034399062395096,
      "backward_entropy": 0.07809509549822126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.28045654296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024665592238307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018774449825287,
      "backward_entropy": 0.07778209447860718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.85599517822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0247354693710804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12003105878829956,
      "backward_entropy": 0.08282903262547084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.64682006835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024804413318634033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1198764443397522,
      "backward_entropy": 0.07714406933103289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.43272399902344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02487732656300068,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1197168380022049,
      "backward_entropy": 0.08232463257653373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.04011917114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024950481951236725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11955728381872177,
      "backward_entropy": 0.08207465069634574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.72021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025015924125909805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1194072738289833,
      "backward_entropy": 0.07618602684565953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.10513305664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02507963590323925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925926804542542,
      "backward_entropy": 0.08153506687709264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 212.5576934814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0251452699303627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11910831928253174,
      "backward_entropy": 0.098775999886649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.06861877441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025217415764927864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1189487874507904,
      "backward_entropy": 0.0809998767716544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.71208953857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025290850549936295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1187877207994461,
      "backward_entropy": 0.07484361955097743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.88204956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02536083199083805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11863142251968384,
      "backward_entropy": 0.07450630835124425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.64688873291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02543441392481327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1184701919555664,
      "backward_entropy": 0.07416865655354091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.18032836914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025506962090730667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11831071972846985,
      "backward_entropy": 0.07992569037846156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.449462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025574151426553726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1181575357913971,
      "backward_entropy": 0.07963713577815465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.14815521240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025637049227952957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1180100068449974,
      "backward_entropy": 0.07933832066399711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.166595458984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0256989523768425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11786428093910217,
      "backward_entropy": 0.07275591577802386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.2718963623047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025754645466804504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11772681772708893,
      "backward_entropy": 0.07238221168518066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.99236297607422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02581482008099556,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11758367717266083,
      "backward_entropy": 0.09873494080134801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.13015747070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025872493162751198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11744348704814911,
      "backward_entropy": 0.0716477462223598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.05967712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025927498936653137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11730588972568512,
      "backward_entropy": 0.07125742946352277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.61580657958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025983192026615143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11716732382774353,
      "backward_entropy": 0.07745564835412162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.64448547363281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026036858558654785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11703113466501236,
      "backward_entropy": 0.07046807663781303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.12220764160156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026087960228323936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11689881980419159,
      "backward_entropy": 0.07678839138575963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.83473205566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026144081726670265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1167602390050888,
      "backward_entropy": 0.0764627116067069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.00306701660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02620103396475315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11662086844444275,
      "backward_entropy": 0.07613905838557652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.52667236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02625351957976818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11648743599653244,
      "backward_entropy": 0.07580232620239258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.1631317138672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.026309235021471977,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11634937673807144,
      "backward_entropy": 0.09865543672016688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.51927185058594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026368921622633934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11620566248893738,
      "backward_entropy": 0.0751442653792245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.46969604492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026429016143083572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11606182157993317,
      "backward_entropy": 0.0677273188318525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.59195709228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026488110423088074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11591941118240356,
      "backward_entropy": 0.06733095645904541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.55787658691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026547903195023537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11577679216861725,
      "backward_entropy": 0.07415579046521868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.46121978759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026604291051626205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1156388372182846,
      "backward_entropy": 0.06653588158743722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.94268798828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026661250740289688,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1155000552535057,
      "backward_entropy": 0.07346837861197335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.42098236083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026720531284809113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11535913497209549,
      "backward_entropy": 0.0657396742275783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.12786102294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026780011132359505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11521779000759125,
      "backward_entropy": 0.06534131935664586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.69651794433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026839368045330048,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11507600545883179,
      "backward_entropy": 0.07244021551949638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.02345275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02690073288977146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11493262648582458,
      "backward_entropy": 0.06452699218477521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.89691162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026964660733938217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1147860735654831,
      "backward_entropy": 0.06412830523082189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.90188598632812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027029946446418762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11463829129934311,
      "backward_entropy": 0.07142836281231471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.100830078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02709254063665867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11449432373046875,
      "backward_entropy": 0.06332943269184657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.70826721191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027158968150615692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143459901213646,
      "backward_entropy": 0.07074116809027535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.01919555664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02722978964447975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1141924113035202,
      "backward_entropy": 0.07040628365107945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.69293212890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027297185733914375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11404338479042053,
      "backward_entropy": 0.062135321753365655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.6138916015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02736658602952957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11389237642288208,
      "backward_entropy": 0.09860845123018537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.75594711303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02744227834045887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11373381316661835,
      "backward_entropy": 0.06937795877456665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.73452758789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027512265369296074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11358395218849182,
      "backward_entropy": 0.06093066930770874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.55201721191406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02758127637207508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11343535780906677,
      "backward_entropy": 0.06866220491273063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.06092834472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0276485662907362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11328970640897751,
      "backward_entropy": 0.06009321553366525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.20254516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027715276926755905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11314500868320465,
      "backward_entropy": 0.059663431985037665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.01791381835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02778889238834381,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11299265921115875,
      "backward_entropy": 0.0592501163482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.7154541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027860352769494057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11284385621547699,
      "backward_entropy": 0.0588279834815434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.81353759765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027930734679102898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11269661784172058,
      "backward_entropy": 0.05839431285858154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.73995971679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027996866032481194,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11255554109811783,
      "backward_entropy": 0.09860069411141532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.57676696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0280615147203207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11241686344146729,
      "backward_entropy": 0.057504083429064067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.12559509277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028120912611484528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11228492110967636,
      "backward_entropy": 0.05703866481781006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.18836975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028179626911878586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11215441673994064,
      "backward_entropy": 0.05657182846750532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.03852844238281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028238803148269653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11202371120452881,
      "backward_entropy": 0.056105222020830424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.27249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028297241777181625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11189444363117218,
      "backward_entropy": 0.05563653792653765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.95228576660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028352169319987297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11176934838294983,
      "backward_entropy": 0.06399451409067426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.86750030517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02841010130941868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11164051294326782,
      "backward_entropy": 0.05466787304197039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.3431396484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028466185554862022,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11151457577943802,
      "backward_entropy": 0.06315244947160993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.76817321777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028524532914161682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11138695478439331,
      "backward_entropy": 0.06273625578199114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.11349868774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02858356200158596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11125929653644562,
      "backward_entropy": 0.053233053003038676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.47236633300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028637047857046127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11113913357257843,
      "backward_entropy": 0.061886451074055264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.5150604248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028689082711935043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11102098971605301,
      "backward_entropy": 0.061453282833099365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.66480255126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02874961495399475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11089359223842621,
      "backward_entropy": 0.0610433646610805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.78560638427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028808224946260452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1107693612575531,
      "backward_entropy": 0.0513301534312112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.05730438232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028867552056908607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11064518988132477,
      "backward_entropy": 0.05086726801736014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.18865203857422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028927335515618324,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1105208694934845,
      "backward_entropy": 0.09842922006334577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.64183044433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02898678369820118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11039839684963226,
      "backward_entropy": 0.04994894777025495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.93449401855469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02904670313000679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11027591675519943,
      "backward_entropy": 0.049490698746272495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.02374267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02910376340150833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11015786975622177,
      "backward_entropy": 0.0490309510912214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.25459289550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029158160090446472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11004383862018585,
      "backward_entropy": 0.05812890189034598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.59741973876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029213478788733482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1099289208650589,
      "backward_entropy": 0.05770063826016018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.66191864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02926984243094921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10981343686580658,
      "backward_entropy": 0.05727805410112653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.82792663574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02932802215218544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10969604551792145,
      "backward_entropy": 0.05685843314443316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.86978149414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029385725036263466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10957992821931839,
      "backward_entropy": 0.09836372307368688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.41349029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029445739462971687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10946250706911087,
      "backward_entropy": 0.04626983829907009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.73533630371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02950608730316162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10934537649154663,
      "backward_entropy": 0.055604904890060425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.84007263183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029564620926976204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10923101007938385,
      "backward_entropy": 0.04535170112337385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.54190826416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029622800648212433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1091177761554718,
      "backward_entropy": 0.054766522986548286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.29951477050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029681643471121788,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10900409519672394,
      "backward_entropy": 0.054344398634774346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.46365356445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029738398268818855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10889525711536407,
      "backward_entropy": 0.09832819870540074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.45630645751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02979356050491333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10878848284482956,
      "backward_entropy": 0.0435460593019213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.69451904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02984408661723137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10868792235851288,
      "backward_entropy": 0.04309205498014178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.41058349609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0298952367156744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10858745872974396,
      "backward_entropy": 0.052620070321219306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.95046615600586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029950547963380814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10848337411880493,
      "backward_entropy": 0.05220117739268711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.74568939208984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030001360923051834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10838537663221359,
      "backward_entropy": 0.05177483814103263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.25511169433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03005252033472061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1082872822880745,
      "backward_entropy": 0.04133269616535732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.35874938964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030102841556072235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10819045454263687,
      "backward_entropy": 0.05092241082872663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.9897689819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0301562137901783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10809122025966644,
      "backward_entropy": 0.050505025046212335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.36679077148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030209826305508614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10799240320920944,
      "backward_entropy": 0.05008851630347116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.20037841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030262606218457222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10789543390274048,
      "backward_entropy": 0.03959335173879351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.075347900390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030314654111862183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10779999196529388,
      "backward_entropy": 0.04925216095788138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.24375915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0303640179336071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10770867764949799,
      "backward_entropy": 0.0488322377204895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.07906341552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0304128285497427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1076182872056961,
      "backward_entropy": 0.03831495131765093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.0265655517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030461160466074944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10752883553504944,
      "backward_entropy": 0.037886594023023336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.13434600830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03051450103521347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10743603110313416,
      "backward_entropy": 0.047587884323937554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.9962158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030567819252610207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10734524577856064,
      "backward_entropy": 0.047198048659733365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.39962005615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030626626685261726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10725029557943344,
      "backward_entropy": 0.03673204353877476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.68321228027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030684025958180428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10715712606906891,
      "backward_entropy": 0.03635785409382412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.84626007080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030744029209017754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10706248879432678,
      "backward_entropy": 0.04607856273651123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.20369720458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030801471322774887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10697101056575775,
      "backward_entropy": 0.035619727202824185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.33444213867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030861541628837585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1068781316280365,
      "backward_entropy": 0.035254712615694316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.54935455322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030921489000320435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10678618401288986,
      "backward_entropy": 0.044961243867874146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.76471710205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030983934178948402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10669322311878204,
      "backward_entropy": 0.03453094192913601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.4902572631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031046144664287567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10660150647163391,
      "backward_entropy": 0.03417438907282693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.56900024414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031107097864151,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10651223361492157,
      "backward_entropy": 0.04388009650366647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.8396987915039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03116895630955696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10642257332801819,
      "backward_entropy": 0.03346322476863861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.75782775878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031230872496962547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10633423179388046,
      "backward_entropy": 0.04315769672393799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.25753784179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031290069222450256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10624906420707703,
      "backward_entropy": 0.04279244797570365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.71450805664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031348083168268204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1061653271317482,
      "backward_entropy": 0.03239805570670536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.7496337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031406302005052567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10608194768428802,
      "backward_entropy": 0.04206551398549761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.05709075927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03146356716752052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10600028932094574,
      "backward_entropy": 0.04170319863728115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.14009857177734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03152229264378548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10591819882392883,
      "backward_entropy": 0.041342237165996006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.40652465820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03157957270741463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1058373898267746,
      "backward_entropy": 0.030962069119725908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.04410552978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03163432329893112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10575862973928452,
      "backward_entropy": 0.0405894262450082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.22293853759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03168853372335434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10568124055862427,
      "backward_entropy": 0.04021173715591431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.52532196044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031741123646497726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10560602694749832,
      "backward_entropy": 0.029843168599264964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.322750091552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031796008348464966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10553015768527985,
      "backward_entropy": 0.029490006821496145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.68033599853516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03184808790683746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10545746237039566,
      "backward_entropy": 0.03910147292273385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.91095733642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031903691589832306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10538308322429657,
      "backward_entropy": 0.03874664221491132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.67340850830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03195894882082939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10531005263328552,
      "backward_entropy": 0.02846312735761915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.47313690185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03201477974653244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1052372008562088,
      "backward_entropy": 0.028129730905805315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.14139556884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03207114711403847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10516460239887238,
      "backward_entropy": 0.03769750254494803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.9400405883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03212810680270195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10509222000837326,
      "backward_entropy": 0.037353847708020894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.48481750488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032185617834329605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10502016544342041,
      "backward_entropy": 0.037016102245875766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.96115112304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032243821769952774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10494882613420486,
      "backward_entropy": 0.03668503676142011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.93515014648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03230861574411392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1048741340637207,
      "backward_entropy": 0.026536856378827776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.86296081542969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03237207978963852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10480131208896637,
      "backward_entropy": 0.02623824349471501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.103271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03243568167090416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10472945868968964,
      "backward_entropy": 0.03575928722109113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.74490356445312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03250046819448471,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10465772449970245,
      "backward_entropy": 0.025657383458954946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.0669937133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03256642445921898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10458627343177795,
      "backward_entropy": 0.03516419444765363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.42031860351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03263108432292938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10451671481132507,
      "backward_entropy": 0.034869990178516934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.13656616210938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032699473202228546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10444609820842743,
      "backward_entropy": 0.024827652743884494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.46814727783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03276730328798294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10437645018100739,
      "backward_entropy": 0.03430636440004621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.52837371826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03283500298857689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10430820286273956,
      "backward_entropy": 0.024290065680231367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.81893920898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03290363401174545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1042402982711792,
      "backward_entropy": 0.033753744193485806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.92369842529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03297225385904312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10417383909225464,
      "backward_entropy": 0.03348719435078757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.89883422851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033039391040802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1041092574596405,
      "backward_entropy": 0.02352918897356306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.54493713378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033107463270425797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10404452681541443,
      "backward_entropy": 0.032955459186009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.50994873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03317413479089737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10398156940937042,
      "backward_entropy": 0.03269103595188686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.97158813476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033237114548683167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10392145067453384,
      "backward_entropy": 0.022783243230410984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.24288558959961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03330389782786369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10385993123054504,
      "backward_entropy": 0.032160588673182895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.08655548095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033367011696100235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10380111634731293,
      "backward_entropy": 0.022291351641927446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.4696273803711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033431172370910645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10374179482460022,
      "backward_entropy": 0.03162742725440434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.30419158935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03349766880273819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10368163138628006,
      "backward_entropy": 0.03136468359402248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.05345153808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033565156161785126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10362155735492706,
      "backward_entropy": 0.021541912640844072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.12021255493164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03363354876637459,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1035616546869278,
      "backward_entropy": 0.030849388667515347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.96095275878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033699579536914825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10350407660007477,
      "backward_entropy": 0.030593269637652805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.294185638427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033763498067855835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10344859212636948,
      "backward_entropy": 0.02081624524933951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.16828918457031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03382414951920509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10339534282684326,
      "backward_entropy": 0.030079847999981472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.58748245239258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03388635814189911,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1033417284488678,
      "backward_entropy": 0.020338524665151323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.14156341552734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033946797251701355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10328970849514008,
      "backward_entropy": 0.020103718553270613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.86734008789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034010209143161774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10323658585548401,
      "backward_entropy": 0.019877625363213674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.01148223876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03407296538352966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10318468511104584,
      "backward_entropy": 0.019656624112810408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.5009994506836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03413480520248413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10313349962234497,
      "backward_entropy": 0.028854825666972568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.03038024902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03419865295290947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10308244824409485,
      "backward_entropy": 0.01921630757195609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.17487335205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034257981926202774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1030336543917656,
      "backward_entropy": 0.02839002013206482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.51615524291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034317731857299805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10298453271389008,
      "backward_entropy": 0.018770394580704824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.87782287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03437606245279312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1029367595911026,
      "backward_entropy": 0.01855019586426871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.75430297851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0344342477619648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10288965702056885,
      "backward_entropy": 0.02768996145044054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.50132751464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034493930637836456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284313559532166,
      "backward_entropy": 0.018134153314999173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.05644989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03455762192606926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279484838247299,
      "backward_entropy": 0.027269278253827776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.83468627929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034619398415088654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1027478501200676,
      "backward_entropy": 0.027058809995651245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.98379516601562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034683115780353546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10270066559314728,
      "backward_entropy": 0.017540869968278066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.41124725341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03474621847271919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10265430808067322,
      "backward_entropy": 0.017350693898541585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.95743560791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03480955958366394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10260793566703796,
      "backward_entropy": 0.01715895107814244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.03890609741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03487666696310043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10256034135818481,
      "backward_entropy": 0.026263641459601268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.4288330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03494040295481682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10251444578170776,
      "backward_entropy": 0.016780386013644084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.12979507446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03500332683324814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1024690493941307,
      "backward_entropy": 0.01659019504274641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.26128387451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035064272582530975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1024245172739029,
      "backward_entropy": 0.025669161762510027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.10713195800781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03512856736779213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10237964242696762,
      "backward_entropy": 0.09861489704677037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.41600799560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03519438952207565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10233443975448608,
      "backward_entropy": 0.025302124874932424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.3780517578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03525830805301666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10229054093360901,
      "backward_entropy": 0.025123683469636098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.94119644165039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03532162681221962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10224717855453491,
      "backward_entropy": 0.01568485583577837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.93936157226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03538355231285095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10220520198345184,
      "backward_entropy": 0.024783496345792497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.811214447021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03544876351952553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10216283798217773,
      "backward_entropy": 0.015360902462686812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.88191604614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03551100939512253,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10212188959121704,
      "backward_entropy": 0.024474676166261946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.249786376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03556918352842331,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10208232700824738,
      "backward_entropy": 0.02430883688586099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.1727523803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03562667965888977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10204379260540009,
      "backward_entropy": 0.014884937022413527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.424394607543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03568856418132782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1020035445690155,
      "backward_entropy": 0.014733330479690008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.299346923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03574574738740921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10196548700332642,
      "backward_entropy": 0.014582846845899309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.238182067871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03580067679286003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10192815959453583,
      "backward_entropy": 0.014429977961948939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.11088562011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03585438430309296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10189071297645569,
      "backward_entropy": 0.023545020392962863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.127952575683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03590613603591919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185402631759644,
      "backward_entropy": 0.01410677284002304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.6052360534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03595512732863426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10181830823421478,
      "backward_entropy": 0.013946290527071272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.352928161621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03600391373038292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1017824336886406,
      "backward_entropy": 0.013788188142435891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.02075958251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03605275973677635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10174688696861267,
      "backward_entropy": 0.01363604941538402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.44165802001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03610268607735634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10171128064393997,
      "backward_entropy": 0.022764340043067932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.02208709716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03615134581923485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016763299703598,
      "backward_entropy": 0.022623621991702487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.75048065185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0362035296857357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10164062678813934,
      "backward_entropy": 0.013205566576548986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.42777633666992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036252282559871674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1016065925359726,
      "backward_entropy": 0.022372130836759294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.663047790527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03629890829324722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10157346725463867,
      "backward_entropy": 0.012944666402680534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.4740104675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036345742642879486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10154031217098236,
      "backward_entropy": 0.02213566643851144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.82477569580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036392923444509506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10150729864835739,
      "backward_entropy": 0.022024991256850108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.1865348815918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0364391952753067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10147465765476227,
      "backward_entropy": 0.02191619575023651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.69294738769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03648349642753601,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10144268721342087,
      "backward_entropy": 0.012451004769120897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.06409454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036527059972286224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10141079127788544,
      "backward_entropy": 0.012329129236085075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.90003204345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657351806759834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10137805342674255,
      "backward_entropy": 0.012212240270205907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.937591552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03662259131669998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1013445109128952,
      "backward_entropy": 0.021496287414005825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.7525634765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03666933625936508,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10131163895130157,
      "backward_entropy": 0.021396726369857788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.8894271850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036716241389513016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10127855837345123,
      "backward_entropy": 0.011871450713702611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.420108795166016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036766692996025085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10124434530735016,
      "backward_entropy": 0.011759095958301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.68144989013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036817166954278946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10121029615402222,
      "backward_entropy": 0.021107618297849382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.89163208007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036868754774332047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10117602348327637,
      "backward_entropy": 0.021019335303987776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.58807373046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03692243620753288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10114125162363052,
      "backward_entropy": 0.020935411964144026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.5986213684082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0369783379137516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1011061742901802,
      "backward_entropy": 0.020864350455147878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.6406478881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037032607942819595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10107176005840302,
      "backward_entropy": 0.011248986635889326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.07144927978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03708973526954651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10103648900985718,
      "backward_entropy": 0.02072787710598537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.195091247558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037148620933294296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1010010689496994,
      "backward_entropy": 0.011068205748285567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.57978820800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03720579668879509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10096646845340729,
      "backward_entropy": 0.010983230812208993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.47111511230469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03726333752274513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10093160718679428,
      "backward_entropy": 0.020551274929727827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.37540435791016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037321023643016815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10089636594057083,
      "backward_entropy": 0.010805035276072366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.640897750854492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03738017752766609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10086055845022202,
      "backward_entropy": 0.010714801294463021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.86870574951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037434957921504974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10082587599754333,
      "backward_entropy": 0.010621604110513414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.48537826538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03749049827456474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1007910966873169,
      "backward_entropy": 0.010532344026224954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.43792724609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03754350543022156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10075721889734268,
      "backward_entropy": 0.020217852933066233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.358686447143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03759411349892616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10072411596775055,
      "backward_entropy": 0.02015726055417742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.21855354309082,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.037642572075128555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10069165378808975,
      "backward_entropy": 0.09879148857934135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.0937728881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03768826648592949,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1006602942943573,
      "backward_entropy": 0.02004780513899667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.00029754638672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037736739963293076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10062813758850098,
      "backward_entropy": 0.01012110071522849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.79404067993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03778652846813202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10059548914432526,
      "backward_entropy": 0.01995287835597992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.75023651123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03783774375915527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10056257247924805,
      "backward_entropy": 0.009968062596661704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.27194213867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03788911923766136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10052984952926636,
      "backward_entropy": 0.009896657296589442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.58142852783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.037943847477436066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10049597173929214,
      "backward_entropy": 0.019837370940617154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.15352249145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03799755498766899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10046287626028061,
      "backward_entropy": 0.009763698492731367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.23931884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03805242478847504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1004297062754631,
      "backward_entropy": 0.01979144981929234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.88725280761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038107048720121384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10039633512496948,
      "backward_entropy": 0.019771311964307512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.9610710144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03816252201795578,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1003626361489296,
      "backward_entropy": 0.019750292812074934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.81646728515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03821774944663048,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10032902657985687,
      "backward_entropy": 0.009524941444396973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.311214447021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03827281668782234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1002955362200737,
      "backward_entropy": 0.019712688667433604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.899723052978516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038325436413288116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1002625972032547,
      "backward_entropy": 0.009409237120832716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.451812744140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038376983255147934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10022996366024017,
      "backward_entropy": 0.019676491618156433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.5246353149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03842863440513611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10019722580909729,
      "backward_entropy": 0.019657941801207408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.807861328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03848282992839813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10016398876905441,
      "backward_entropy": 0.09889665671757289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.09842300415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0385378822684288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1001303493976593,
      "backward_entropy": 0.009187219398362296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.83346176147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038592491298913956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10009659826755524,
      "backward_entropy": 0.009129972330161504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.37287139892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03864472359418869,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10006348788738251,
      "backward_entropy": 0.019588293773787364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.18253707885742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03870024532079697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10002917051315308,
      "backward_entropy": 0.009018623403140478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.01005554199219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03875645250082016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09999436140060425,
      "backward_entropy": 0.019544058612414768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.83601379394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038813330233097076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09995919466018677,
      "backward_entropy": 0.01952005922794342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.660743713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03887086361646652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09992372989654541,
      "backward_entropy": 0.008849730981247765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.70758819580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0389290377497673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09988801181316376,
      "backward_entropy": 0.008794640856129783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.90093994140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03898566961288452,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09985285252332687,
      "backward_entropy": 0.019455045461654663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.21025848388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03903854638338089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0998186245560646,
      "backward_entropy": 0.00868670376283782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.93543243408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03909555822610855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09978283941745758,
      "backward_entropy": 0.008630441235644477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.55611801147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039156474173069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09974581003189087,
      "backward_entropy": 0.008575335144996643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.41497039794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039216548204422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09970888495445251,
      "backward_entropy": 0.019347205758094788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.05400848388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.039275821298360825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09967206418514252,
      "backward_entropy": 0.09894060237067086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.52500915527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933322802186012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09963574260473251,
      "backward_entropy": 0.008410072752407618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.33242797851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03939221426844597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09959856420755386,
      "backward_entropy": 0.00835437114749636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.9647102355957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039452530443668365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09956056624650955,
      "backward_entropy": 0.008297521088804518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.459125518798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03951317444443703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09952248632907867,
      "backward_entropy": 0.00824222287961415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.287914276123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039570875465869904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0994853675365448,
      "backward_entropy": 0.008188428623335702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.35179138183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962487354874611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09944950044155121,
      "backward_entropy": 0.008137281984090805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.32376480102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039677608758211136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09941401332616806,
      "backward_entropy": 0.00808635460478919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.12521743774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03973257169127464,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09937772154808044,
      "backward_entropy": 0.01907749261174883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.94645690917969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039786309003829956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09934186935424805,
      "backward_entropy": 0.019057574016707286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.75503921508789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039842214435338974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09930524975061417,
      "backward_entropy": 0.007946261870009559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.71754455566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03990006819367409,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09926770627498627,
      "backward_entropy": 0.019027827041489736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.889253616333008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03995746001601219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09923019260168076,
      "backward_entropy": 0.007861470537526267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.979485511779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04001125693321228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09919402003288269,
      "backward_entropy": 0.019008048943110874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.47236633300781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040060531347990036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09915930032730103,
      "backward_entropy": 0.01899548726422446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.38214111328125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.040109194815158844,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0991247147321701,
      "backward_entropy": 0.09895764929907662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.07874298095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040157198905944824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09909026324748993,
      "backward_entropy": 0.018976705414908274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86736011505127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04020576924085617,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09905552864074707,
      "backward_entropy": 0.01896952305521284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.34629821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04025043547153473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09902217984199524,
      "backward_entropy": 0.01896234495299203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.18993377685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04029823839664459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09898759424686432,
      "backward_entropy": 0.007587227438177381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.786031723022461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040348682552576065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09895172715187073,
      "backward_entropy": 0.00755165730203901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.53221130371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04039512574672699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09891737997531891,
      "backward_entropy": 0.007517548544066293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.65026092529297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0404454842209816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0988813191652298,
      "backward_entropy": 0.007484307246548789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.22610855102539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0405014343559742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09884265810251236,
      "backward_entropy": 0.0074516162276268005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.29383087158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04055708646774292,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09880399703979492,
      "backward_entropy": 0.018957178507532393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.10144805908203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04061461240053177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0987643375992775,
      "backward_entropy": 0.007386081452880587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.89103317260742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04067365452647209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09872382879257202,
      "backward_entropy": 0.007350938660757882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.68141174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04073425382375717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0986824780702591,
      "backward_entropy": 0.01894075104168483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.524269104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079628363251686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09864037483930588,
      "backward_entropy": 0.007283109107187816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.72425842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04085526987910271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09859943389892578,
      "backward_entropy": 0.007250365402017321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.62821578979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04091683402657509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09855710715055466,
      "backward_entropy": 0.007217915462596076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.44536209106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040978532284498215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09851455688476562,
      "backward_entropy": 0.0071850429688181195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.26237869262695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104034602642059,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09847176820039749,
      "backward_entropy": 0.007151853293180466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.42658233642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04110223427414894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0984286293387413,
      "backward_entropy": 0.018898944769586836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.49070739746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04116842523217201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09838330000638962,
      "backward_entropy": 0.018886495913778032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.40795135498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041236430406570435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09833689033985138,
      "backward_entropy": 0.007050926664045879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.72176742553711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04130294546484947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09829091280698776,
      "backward_entropy": 0.007018732173102242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.665008544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04137026518583298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09824442863464355,
      "backward_entropy": 0.018860397594315664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.095149993896484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143402352929115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09819954633712769,
      "backward_entropy": 0.006958639515297753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.906524658203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04149783030152321,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0981544703245163,
      "backward_entropy": 0.01885521411895752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.605010986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041561540216207504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09810909628868103,
      "backward_entropy": 0.006903928305421557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.450435638427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04162416607141495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09806398302316666,
      "backward_entropy": 0.018852729882512773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.40070343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04168591648340225,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09801903367042542,
      "backward_entropy": 0.018856848989214216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.12065124511719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0417487770318985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09797334671020508,
      "backward_entropy": 0.018857681325503757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.016462326049805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04180961102247238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09792838990688324,
      "backward_entropy": 0.0068026020058563775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.84956359863281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04186643287539482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09788532555103302,
      "backward_entropy": 0.01886228152683803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.643619537353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04192286357283592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09784230589866638,
      "backward_entropy": 0.01886576839855739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.472476959228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04197990521788597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09779858589172363,
      "backward_entropy": 0.018867645944867815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.545692443847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042037446051836014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09775429964065552,
      "backward_entropy": 0.018865879092897688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.430898666381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04209356755018234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.097710520029068,
      "backward_entropy": 0.018869764038494656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.321807861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04214825481176376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09766734391450882,
      "backward_entropy": 0.006662010082176754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.010292053222656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0422016903758049,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09762462973594666,
      "backward_entropy": 0.018877110310963223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.64845275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042254965752363205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0975816547870636,
      "backward_entropy": 0.006618936147008624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.48368453979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04230920597910881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09753788262605667,
      "backward_entropy": 0.0065978967717715675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.169700622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042364250868558884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09749333560466766,
      "backward_entropy": 0.0065766700676509315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.46807098388672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04241693392395973,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09744999557733536,
      "backward_entropy": 0.09900397913796562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.671409606933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04246952384710312,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09740643948316574,
      "backward_entropy": 0.018886078681264604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.56924057006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04252098873257637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09736333042383194,
      "backward_entropy": 0.006513944161789758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.854297637939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042571526020765305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09732057899236679,
      "backward_entropy": 0.0188863958631243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.539634704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04262018948793411,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09727878868579865,
      "backward_entropy": 0.006475220301321575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.139759063720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042670175433158875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0972357988357544,
      "backward_entropy": 0.006455894559621811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.557518005371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04271726310253143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09719450771808624,
      "backward_entropy": 0.0064372287264892036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.56185531616211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042760852724313736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09715535491704941,
      "backward_entropy": 0.006421181772436414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.47669219970703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04280318692326546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09711694717407227,
      "backward_entropy": 0.09900610787527901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.31473922729492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042848534882068634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09707638621330261,
      "backward_entropy": 0.018912047147750854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.58832550048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04289659112691879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0970337763428688,
      "backward_entropy": 0.006372126085417611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.54022979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04294804856181145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09698837250471115,
      "backward_entropy": 0.006354453840426036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.55667114257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.043000634759664536,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09694172441959381,
      "backward_entropy": 0.09900702748979841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.47153663635254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043057143688201904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09689205884933472,
      "backward_entropy": 0.01891635145459856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.359270095825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043112143874168396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09684327989816666,
      "backward_entropy": 0.006302031023161752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.48654556274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04316579923033714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09679524600505829,
      "backward_entropy": 0.018914141825267246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.69395065307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043222226202487946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09674490243196487,
      "backward_entropy": 0.0062667615711688995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.76987075805664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043279148638248444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09669391810894012,
      "backward_entropy": 0.006248379392283303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.78086471557617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04333749786019325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09664162993431091,
      "backward_entropy": 0.018895523888724192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.390877723693848,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04339810460805893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09658735990524292,
      "backward_entropy": 0.006209527275391987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.97794723510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04345481097698212,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0965358167886734,
      "backward_entropy": 0.006191621933664594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.402992248535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04351198300719261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09648363292217255,
      "backward_entropy": 0.00617406889796257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.63248062133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04356654733419418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09643333405256271,
      "backward_entropy": 0.006157487630844116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.38737106323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04362177103757858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09638212621212006,
      "backward_entropy": 0.006141073469604764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.34030532836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04367661848664284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09633088856935501,
      "backward_entropy": 0.006125585841281074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.046443939208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04373309016227722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09627795219421387,
      "backward_entropy": 0.006110009338174548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.96227264404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04378610849380493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09622751921415329,
      "backward_entropy": 0.018847557050841197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.936817169189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04383892938494682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09617695212364197,
      "backward_entropy": 0.006083932838269642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.821277618408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388865455985069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09612837433815002,
      "backward_entropy": 0.006073160363095147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.57537841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043936531990766525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09608124196529388,
      "backward_entropy": 0.006063349545001984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.33921813964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043984729796648026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09603364765644073,
      "backward_entropy": 0.01886924888406481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.324928283691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04403417930006981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09598483145236969,
      "backward_entropy": 0.018874551568712507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.681623458862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044083818793296814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09593550860881805,
      "backward_entropy": 0.006034811692578452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.26043701171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04413064196705818,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09588845074176788,
      "backward_entropy": 0.018891577209745134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.95405960083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04417689889669418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09584135562181473,
      "backward_entropy": 0.006020052092415946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.363277435302734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044223617762327194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09579350054264069,
      "backward_entropy": 0.006013027791466031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.22423553466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04427269101142883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09574313461780548,
      "backward_entropy": 0.09901244299752372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.582271575927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431995376944542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09569428116083145,
      "backward_entropy": 0.005998385271855763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.530033111572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044367559254169464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09564483910799026,
      "backward_entropy": 0.005991730306829725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.65440368652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044418372213840485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0955919623374939,
      "backward_entropy": 0.005983253142663411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.824371337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04447110369801521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09553690254688263,
      "backward_entropy": 0.005974281047071729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.26606369018555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04452457278966904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09548087418079376,
      "backward_entropy": 0.005965290857212884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.163697242736816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457967355847359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09542281925678253,
      "backward_entropy": 0.005955891417605537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.427284240722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04463138431310654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09536796063184738,
      "backward_entropy": 0.01893370066370283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5279998779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044685836881399155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09531007707118988,
      "backward_entropy": 0.005939832755497524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.501747131347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04473598673939705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09525644779205322,
      "backward_entropy": 0.018929915768759593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.848628997802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044782258570194244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09520664066076279,
      "backward_entropy": 0.018934262650353566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.699459075927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044829875230789185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0951550304889679,
      "backward_entropy": 0.01893695763179234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.54602813720703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044878702610731125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09510166943073273,
      "backward_entropy": 0.005919702351093292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003461933694779873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04492861032485962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09504663944244385,
      "backward_entropy": 0.005914337933063507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.751137733459473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0449737012386322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09499649703502655,
      "backward_entropy": 0.018945227776254927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.409751892089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04501637443900108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09494882076978683,
      "backward_entropy": 0.005909764873129981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.979793548583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04505879431962967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09490127861499786,
      "backward_entropy": 0.018960905926568166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.14710998535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510290175676346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09485174715518951,
      "backward_entropy": 0.0059063466531889776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.130170822143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04514947533607483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09479887038469315,
      "backward_entropy": 0.005903179624250957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.57892608642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04519539326429367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0947464108467102,
      "backward_entropy": 0.005900403218609946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.925540924072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045246437191963196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09468778967857361,
      "backward_entropy": 0.018961959651538303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.024648666381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04529636725783348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09463001042604446,
      "backward_entropy": 0.005890562598194394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.71474838256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045346252620220184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09457218647003174,
      "backward_entropy": 0.005886234875236239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.763362884521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0453951321542263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0945151150226593,
      "backward_entropy": 0.005882485104458672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.381662368774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045444048941135406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09445755183696747,
      "backward_entropy": 0.01894374830382211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.206026077270508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04549109563231468,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09440191835165024,
      "backward_entropy": 0.005875944026878902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.392372131347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04553551226854324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09434930235147476,
      "backward_entropy": 0.00587469818336623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.219274520874023,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04558039829134941,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09429576992988586,
      "backward_entropy": 0.09901712621961321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.21742630004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0456247478723526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09424246847629547,
      "backward_entropy": 0.005872232041188649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.043617248535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045671455562114716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09418602287769318,
      "backward_entropy": 0.018935820886066983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.96301555633545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04572027176618576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09412652999162674,
      "backward_entropy": 0.005867335945367813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.823789596557617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04576626420021057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09407033026218414,
      "backward_entropy": 0.005865884678704398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.72830581665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045811574906110764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09401442110538483,
      "backward_entropy": 0.018921562603541782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.72563362121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458562858402729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09395891427993774,
      "backward_entropy": 0.005863086453505925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.425432205200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04589950665831566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0939050018787384,
      "backward_entropy": 0.01891582565648215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.587223052978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04594326391816139,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09384998679161072,
      "backward_entropy": 0.018912451607840403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.357128143310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459856316447258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09379656612873077,
      "backward_entropy": 0.005861962480204446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.08356475830078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04602766036987305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09374316781759262,
      "backward_entropy": 0.005862110427447728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.76224136352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04607032239437103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09368851780891418,
      "backward_entropy": 0.005861794842141015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.69996643066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046114467084407806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0936313271522522,
      "backward_entropy": 0.005860329206500735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.94858169555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046163689345121384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09356689453125,
      "backward_entropy": 0.005856598062174661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.010135650634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046215593814849854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09349845349788666,
      "backward_entropy": 0.01886886784008571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.80900955200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046268969774246216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09342743456363678,
      "backward_entropy": 0.018850075347082957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.632896423339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04632365331053734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09335411339998245,
      "backward_entropy": 0.018829047679901123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.77602005004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046376749873161316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09328263998031616,
      "backward_entropy": 0.01881003592695509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.403871536254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04643026366829872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09321022033691406,
      "backward_entropy": 0.018790894321032932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.147274017333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04648229852318764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09313946217298508,
      "backward_entropy": 0.00582374632358551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.550257205963135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04653111845254898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09307289123535156,
      "backward_entropy": 0.0058207325637340546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.13386535644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046576131135225296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09301163256168365,
      "backward_entropy": 0.00581964584333556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.48752212524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04662233591079712,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09294816106557846,
      "backward_entropy": 0.018738120794296265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.83488464355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04666866362094879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09288397431373596,
      "backward_entropy": 0.018726497888565063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.78987693786621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04671601206064224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09281779080629349,
      "backward_entropy": 0.005815505449260984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.269771575927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676244780421257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09275247901678085,
      "backward_entropy": 0.005814314952918461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.800162315368652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04680715873837471,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09268954396247864,
      "backward_entropy": 0.005814376154116222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.129779815673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046849384903907776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09263016283512115,
      "backward_entropy": 0.0058158524334430695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.065725326538086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046890296041965485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09257249534130096,
      "backward_entropy": 0.0186781074319567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.323890686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693005979061127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09251638501882553,
      "backward_entropy": 0.005822019917624337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.23996353149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0469723716378212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09245525300502777,
      "backward_entropy": 0.018669126289231435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.577228546142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0470142588019371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09239429235458374,
      "backward_entropy": 0.0058276184967585975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2697062492370605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04705391451716423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09233644604682922,
      "backward_entropy": 0.005831335272107806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.493794441223145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04709063470363617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09228311479091644,
      "backward_entropy": 0.005835990288427898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.359575271606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04712560400366783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09223220497369766,
      "backward_entropy": 0.018653358731951033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.65001678466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04716264456510544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09217721968889236,
      "backward_entropy": 0.005844443504299436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.1048583984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04720334708690643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09211549162864685,
      "backward_entropy": 0.018636407596724375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.165371894836426,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04724549874663353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09205068647861481,
      "backward_entropy": 0.0058461640562329975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.56144142150879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047284435480833054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09199108183383942,
      "backward_entropy": 0.018608125192778453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.596210479736328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047323182225227356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09193113446235657,
      "backward_entropy": 0.018592568380492076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.681644439697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04736269265413284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09186951816082001,
      "backward_entropy": 0.005847295480115073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.29913330078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047404710203409195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09180313348770142,
      "backward_entropy": 0.0185581168958119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.160561561584473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04744623601436615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09173718839883804,
      "backward_entropy": 0.005846166184970311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.09458065032959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04748649150133133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09167332202196121,
      "backward_entropy": 0.005847423204353878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.04987907409668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04752560332417488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09161140024662018,
      "backward_entropy": 0.005850331059523991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.94761848449707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047566309571266174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09154608100652695,
      "backward_entropy": 0.09901821613311768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.782419204711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047606684267520905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09148109704256058,
      "backward_entropy": 0.005855135087456022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.766340255737305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04764846712350845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09141285717487335,
      "backward_entropy": 0.00585633995277541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.84321403503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04768975451588631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09134504944086075,
      "backward_entropy": 0.005857526723827634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.27723693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04772885888814926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0912812128663063,
      "backward_entropy": 0.005860373377799988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.371004104614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047770384699106216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09121222794055939,
      "backward_entropy": 0.018422767519950867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.95538330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04781227558851242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09114205837249756,
      "backward_entropy": 0.005861915647983551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.13663673400879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04785625636577606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09106713533401489,
      "backward_entropy": 0.018376550504139492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.61622619628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.047900404781103134,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09099151194095612,
      "backward_entropy": 0.09901782444545201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.560977935791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04794641584157944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09091176837682724,
      "backward_entropy": 0.01832229324749538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.519195556640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04798973724246025,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09083697944879532,
      "backward_entropy": 0.09901738166809082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.465129852294922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04803409054875374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09075959026813507,
      "backward_entropy": 0.01826970492090498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.122106552124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048075925558805466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09068693220615387,
      "backward_entropy": 0.018246286681720188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.420133590698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04811631888151169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09061675518751144,
      "backward_entropy": 0.0058512261935642785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.988181114196777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04815717041492462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09054505825042725,
      "backward_entropy": 0.0058513422097478595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.56189727783203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04819666966795921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09047576785087585,
      "backward_entropy": 0.01817841189248221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.860553741455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04823584854602814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09040673077106476,
      "backward_entropy": 0.018157260758536204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.39043426513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048273902386426926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0903397649526596,
      "backward_entropy": 0.00585627555847168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.732970237731934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048311714082956314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09027272462844849,
      "backward_entropy": 0.005858659744262695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.227214813232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834844544529915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09020747244358063,
      "backward_entropy": 0.005861155156578336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.079691886901855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04838508367538452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09014199674129486,
      "backward_entropy": 0.005863612783806664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.09823226928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04841994494199753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.090080127120018,
      "backward_entropy": 0.0058676813329969135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.98895835876465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048456575721502304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0900137796998024,
      "backward_entropy": 0.005869876061167035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.383255004882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04849310591816902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0899471864104271,
      "backward_entropy": 0.005872055888175964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.826148986816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04853042587637901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08987843990325928,
      "backward_entropy": 0.005874072334596089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.746044158935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856758192181587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08980958163738251,
      "backward_entropy": 0.005876314959355763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.72618865966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048604656010866165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08974067121744156,
      "backward_entropy": 0.005879990756511688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.9598388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048645876348018646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08966201543807983,
      "backward_entropy": 0.017934117998395647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.9462890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048687346279621124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08958227932453156,
      "backward_entropy": 0.01790758967399597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.354522228240967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04873160645365715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0894956961274147,
      "backward_entropy": 0.017877091254506792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.972323417663574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048772431910037994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08941669762134552,
      "backward_entropy": 0.0058805570006370544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.203901290893555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0488118939101696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08934047818183899,
      "backward_entropy": 0.005882808672530311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.565964698791504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048850931227207184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08926479518413544,
      "backward_entropy": 0.005885310471057892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.550283432006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04888791963458061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08919358253479004,
      "backward_entropy": 0.0058895115341459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.716123580932617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04892648756504059,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08911825716495514,
      "backward_entropy": 0.017767970051084245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.72446823120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04896383360028267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08904536068439484,
      "backward_entropy": 0.005898820502417428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.74076461791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049004264175891876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08896444737911224,
      "backward_entropy": 0.005900772554533822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.35129165649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04904842749238014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08887428045272827,
      "backward_entropy": 0.005902107272829328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.003562927246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049094997346401215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08877772092819214,
      "backward_entropy": 0.005901611277035305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.82029151916504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04914287105202675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08867739140987396,
      "backward_entropy": 0.005899813558374133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.363792419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919198527932167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08857361972332001,
      "backward_entropy": 0.00589828086750848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.199532508850098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923958703875542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08847272396087646,
      "backward_entropy": 0.005896330944129399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.160198211669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049285076558589935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08837665617465973,
      "backward_entropy": 0.017529099115303585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.061159133911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04932946339249611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08828277885913849,
      "backward_entropy": 0.01749582907983235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.978775024414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049372799694538116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08819078654050827,
      "backward_entropy": 0.017461087022508894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.87714958190918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04941439628601074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.088102787733078,
      "backward_entropy": 0.005897159022944314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.845355033874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945532605051994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08801597356796265,
      "backward_entropy": 0.005899767258337566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.778225898742676,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.049494851380586624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08793242275714874,
      "backward_entropy": 0.09901636838912964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.415578842163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049533020704984665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08785191178321838,
      "backward_entropy": 0.0059105924197605676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.649559020996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049572426825761795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08776751160621643,
      "backward_entropy": 0.00591573491692543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.586732864379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04961042106151581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08768659085035324,
      "backward_entropy": 0.005920606532267162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.52590560913086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049647118896245956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08760802447795868,
      "backward_entropy": 0.005924686789512634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.648121356964111,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049682628363370895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08753181993961334,
      "backward_entropy": 0.0059277404631887165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.811641693115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971618577837944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08746062219142914,
      "backward_entropy": 0.00592945356454168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.355892181396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049751393496990204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08738428354263306,
      "backward_entropy": 0.01716916263103485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.297605514526367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04978565499186516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08731015026569366,
      "backward_entropy": 0.017136152301515852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.472089767456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049818988889455795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08723802864551544,
      "backward_entropy": 0.005936316081455776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.63079071044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04985400661826134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08716078102588654,
      "backward_entropy": 0.005939262786081859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.829991340637207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04988962784409523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08708111941814423,
      "backward_entropy": 0.005941154701369149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.751381874084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04992502182722092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08700167387723923,
      "backward_entropy": 0.01700069542442049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.67409896850586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049960192292928696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08692221343517303,
      "backward_entropy": 0.00594569423368999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.660557270050049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049995169043540955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08684289455413818,
      "backward_entropy": 0.016932430011885508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.406532287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0500275194644928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08677074313163757,
      "backward_entropy": 0.005951843623604093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.664060592651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05006231740117073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08669088780879974,
      "backward_entropy": 0.005953670080218997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.36885929107666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050098519772291183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08660636842250824,
      "backward_entropy": 0.00595458277634212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.152565002441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013442412018776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08652237057685852,
      "backward_entropy": 0.00595632940530777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.212785720825195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016842484474182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0864434614777565,
      "backward_entropy": 0.005958981279815946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018344389274716377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020226165652275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08636435121297836,
      "backward_entropy": 0.0059607018317495075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.586435317993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05023288354277611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08629484474658966,
      "backward_entropy": 0.005965823041541236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.994312286376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05026454105973244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0862216204404831,
      "backward_entropy": 0.00597104589853968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.884641647338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05029784515500069,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08614110946655273,
      "backward_entropy": 0.016629759754453386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934389114379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05033266171813011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08605477213859558,
      "backward_entropy": 0.005977281502314976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.22117805480957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05036568641662598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08597344905138016,
      "backward_entropy": 0.005981253193957465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.28314208984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050399553030729294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08588878810405731,
      "backward_entropy": 0.005986685731581279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.823727607727051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05043254420161247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08580626547336578,
      "backward_entropy": 0.01651101665837424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.561518669128418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05046388879418373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08572852611541748,
      "backward_entropy": 0.006000660892043795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.860410690307617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05049531161785126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08564962446689606,
      "backward_entropy": 0.006007277007613864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.771942138671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05052755028009415,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08556745201349258,
      "backward_entropy": 0.09901929753167289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.682307720184326,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05056055262684822,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08548206090927124,
      "backward_entropy": 0.09901932307652064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.594825744628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05059189349412918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08540165424346924,
      "backward_entropy": 0.016368178384644643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.91069221496582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05062413215637207,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08531777560710907,
      "backward_entropy": 0.006026470767600196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.138076782226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065561830997467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08523595333099365,
      "backward_entropy": 0.006032836224351611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.856966018676758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050687167793512344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08515363931655884,
      "backward_entropy": 0.0060392698006970546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.23683738708496,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05072110891342163,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08506228029727936,
      "backward_entropy": 0.09901962961469378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.916219711303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05075559392571449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08496874570846558,
      "backward_entropy": 0.0060482754239014214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.04633903503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050789762288331985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08487568795681,
      "backward_entropy": 0.006051589335714068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.389869689941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050824396312236786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08478044718503952,
      "backward_entropy": 0.006053503602743149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.861903190612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05085711553692818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08469125628471375,
      "backward_entropy": 0.00605513687644686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.61760425567627,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050890568643808365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08459913730621338,
      "backward_entropy": 0.006058040474142347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1508541107177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050923801958560944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0845072790980339,
      "backward_entropy": 0.006060652434825897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.247013568878174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05095463991165161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08442358672618866,
      "backward_entropy": 0.016010301453726634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.412867546081543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050983984023332596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08434481918811798,
      "backward_entropy": 0.006072078432355609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.348103523254395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05101357772946358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08426477760076523,
      "backward_entropy": 0.015952610543795993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.41315460205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05104340985417366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0841834545135498,
      "backward_entropy": 0.006086700196777072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162775993347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05107487738132477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08409560471773148,
      "backward_entropy": 0.00609302893280983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.208297729492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051105476915836334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08401031792163849,
      "backward_entropy": 0.00609818526676723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.045310974121094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051137614995241165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08391894400119781,
      "backward_entropy": 0.01583254975931985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.003840446472168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05116806551814079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08383326232433319,
      "backward_entropy": 0.006105711949723107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.959187507629395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0511992946267128,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08374413847923279,
      "backward_entropy": 0.0061085256082671026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.759862899780273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051229823380708694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08365732431411743,
      "backward_entropy": 0.006113491420234952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.743637084960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051262594759464264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08356167376041412,
      "backward_entropy": 0.006116530724934169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.724576950073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05129590630531311,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0834633857011795,
      "backward_entropy": 0.006119191646575928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.652111053466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05132890120148659,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08336597681045532,
      "backward_entropy": 0.015615219516413552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.688908576965332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051361627876758575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08326870203018188,
      "backward_entropy": 0.015574918261596135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.25591278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05139331519603729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08317500352859497,
      "backward_entropy": 0.015532738396099635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.436789512634277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051426343619823456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08307570219039917,
      "backward_entropy": 0.006122979734625135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.855539083480835,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05145905911922455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08297698199748993,
      "backward_entropy": 0.006122495446886335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.758338928222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051489319652318954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08288750052452087,
      "backward_entropy": 0.006123807281255722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.434307098388672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051521800458431244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08278898894786835,
      "backward_entropy": 0.0061245257300989965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.585592269897461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.051556941121816635,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.08267952501773834,
      "backward_entropy": 0.09901735612324306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.841232299804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05159018561244011,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08257730305194855,
      "backward_entropy": 0.015276093568120683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020239703357219696,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05162384361028671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08247298002243042,
      "backward_entropy": 0.006126538983413151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018381571397185326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05165425315499306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0823814868927002,
      "backward_entropy": 0.006130925246647426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.593368530273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051681604236364365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08230184018611908,
      "backward_entropy": 0.006135374307632446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.418003082275391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051710035651922226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08221685886383057,
      "backward_entropy": 0.015135239277567183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.124774932861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05173717811703682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08213692158460617,
      "backward_entropy": 0.015105841415269034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3575358390808105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051765985786914825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08204982429742813,
      "backward_entropy": 0.00615377351641655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.634001731872559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051793478429317474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0819677785038948,
      "backward_entropy": 0.006160936185291835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.766874313354492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05182112753391266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08188444375991821,
      "backward_entropy": 0.0061670467257499695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.263631343841553,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051852427423000336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.081785649061203,
      "backward_entropy": 0.00616879016160965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.837221145629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05188215523958206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08169297128915787,
      "backward_entropy": 0.006172645304884229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788713455200195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191120505332947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0816027820110321,
      "backward_entropy": 0.006178464740514755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.61618423461914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05193953216075897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08151504397392273,
      "backward_entropy": 0.014872112444468908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.48064422607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05197085812687874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08141444623470306,
      "backward_entropy": 0.006189159516777311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.559549331665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052004870027303696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08130235970020294,
      "backward_entropy": 0.006193996007953372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.58726692199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05203630030155182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08120067417621613,
      "backward_entropy": 0.006200814353568214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.044257164001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05206683278083801,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0811024159193039,
      "backward_entropy": 0.006208866834640503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9991021156311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05209728330373764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0810040682554245,
      "backward_entropy": 0.00621810502239636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9168701171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052126139402389526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08091205358505249,
      "backward_entropy": 0.006227259657212666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.937937259674072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052154991775751114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08081960678100586,
      "backward_entropy": 0.0146766368831907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.907959938049316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05218246579170227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08073261380195618,
      "backward_entropy": 0.006246166569846017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.311013221740723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05220858007669449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08065107464790344,
      "backward_entropy": 0.006255021052701133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.935718536376953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05223429948091507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08057111501693726,
      "backward_entropy": 0.014602495091302055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2249603271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05226236209273338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08047983050346375,
      "backward_entropy": 0.006272377180201667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.567973136901855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052289847284555435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08039088547229767,
      "backward_entropy": 0.006281399833304542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1367034912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052317507565021515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08030074834823608,
      "backward_entropy": 0.0062916406563350135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.52550506591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05234450474381447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0802130252122879,
      "backward_entropy": 0.006300992731537137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.389581680297852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05237368866801262,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08011509478092194,
      "backward_entropy": 0.014471933245658875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.654656410217285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052402786910533905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08001704514026642,
      "backward_entropy": 0.006315823112215314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.575688362121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05243237689137459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07991616427898407,
      "backward_entropy": 0.00632066119994436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.90523624420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05246249586343765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07981228828430176,
      "backward_entropy": 0.00632497136081968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.417251586914062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05249173939228058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07971091568470001,
      "backward_entropy": 0.00633012769477708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.810712814331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05252150073647499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07960611581802368,
      "backward_entropy": 0.01430645797933851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.012346267700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05255036801099777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07950473576784134,
      "backward_entropy": 0.00633830896445683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.183441162109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052579108625650406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07940328121185303,
      "backward_entropy": 0.0063421108892985755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.53860092163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052608367055654526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07929866015911102,
      "backward_entropy": 0.006344570645264217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.821414947509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052639465779066086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07918518781661987,
      "backward_entropy": 0.006345758480685098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755443572998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0526701956987381,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07907265424728394,
      "backward_entropy": 0.006346692464181355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.523143291473389,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052700676023960114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0789603516459465,
      "backward_entropy": 0.006349240030561175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627490997314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05273020267486572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07885236293077469,
      "backward_entropy": 0.006352672619479043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5654935836792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05275960639119148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0787445455789566,
      "backward_entropy": 0.014008996742112296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.10673713684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05278877541422844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07863723486661911,
      "backward_entropy": 0.006363466914211001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2290730476379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282098054885864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07851506769657135,
      "backward_entropy": 0.006365547222750527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1966047286987305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052851200103759766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0784023106098175,
      "backward_entropy": 0.006365816508020673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.310574531555176,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05287974327802658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07829714566469193,
      "backward_entropy": 0.00636674091219902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.136395454406738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05290810391306877,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07819242030382156,
      "backward_entropy": 0.013812395078795297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.279117584228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05293494462966919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07809491455554962,
      "backward_entropy": 0.006369066557713917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.133673667907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05296308174729347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07799039036035538,
      "backward_entropy": 0.006370047373431069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.048608779907227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05299115553498268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07788580656051636,
      "backward_entropy": 0.00637315000806536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.02143931388855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0530177503824234,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07778821885585785,
      "backward_entropy": 0.013654431062085288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.967191219329834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05304240435361862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07770019769668579,
      "backward_entropy": 0.0063818639942577905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.915189743041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053067173808813095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0776110291481018,
      "backward_entropy": 0.006385892629623413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.782919883728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05309201776981354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07752127945423126,
      "backward_entropy": 0.013543752687317985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.700061798095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05311824753880501,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07742364704608917,
      "backward_entropy": 0.013501341853822981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.817720890045166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314566567540169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07731965184211731,
      "backward_entropy": 0.006388045315231595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.693393230438232,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05317232757806778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07721920311450958,
      "backward_entropy": 0.006388101726770401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.830108165740967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0531989224255085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07711868733167648,
      "backward_entropy": 0.006388626460518155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022771261632442474,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05322416499257088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07702483236789703,
      "backward_entropy": 0.0063900356846196315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415685653686523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05324679985642433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07694429159164429,
      "backward_entropy": 0.006390679627656937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.487563133239746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532703697681427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07685856521129608,
      "backward_entropy": 0.0063912469361509594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.437724590301514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0532941110432148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07677146792411804,
      "backward_entropy": 0.006391469389200211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.70503830909729,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05331802740693092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07668309658765793,
      "backward_entropy": 0.006391812648091998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.339909076690674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0533408485352993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07660020887851715,
      "backward_entropy": 0.006393209631953921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6572113037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053363949060440063,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07651560753583908,
      "backward_entropy": 0.013070928198950631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.051525115966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05338612571358681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07643556594848633,
      "backward_entropy": 0.006400347820350102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991860389709473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05340921878814697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07634979486465454,
      "backward_entropy": 0.006403980510575431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929545402526855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05343325063586235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07625901699066162,
      "backward_entropy": 0.012966100658689226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.328159809112549,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05345794931054115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07616429030895233,
      "backward_entropy": 0.006412721638168607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.803409576416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05348195880651474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07607276737689972,
      "backward_entropy": 0.006414258054324559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739598274230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05350662022829056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0759773701429367,
      "backward_entropy": 0.012846261262893677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.943878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053531959652900696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07587788254022598,
      "backward_entropy": 0.012804890317576272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4568376541137695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05355735123157501,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07577784359455109,
      "backward_entropy": 0.006417759295020785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4321494102478027,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05358147248625755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07568448781967163,
      "backward_entropy": 0.006421592618737902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.408721446990967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05360447242856026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07559694349765778,
      "backward_entropy": 0.006426728197506496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.386122941970825,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05362650379538536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07551440596580505,
      "backward_entropy": 0.006434080856187003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.707113265991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053647611290216446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07543672621250153,
      "backward_entropy": 0.00644239889723914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.663656711578369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05366905778646469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07535666972398758,
      "backward_entropy": 0.0064498622502599445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.619442462921143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05369085446000099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07527436316013336,
      "backward_entropy": 0.006457809891019549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6600658893585205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053712885826826096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07519041001796722,
      "backward_entropy": 0.006464685712541852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.789294242858887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05373341217637062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07511456310749054,
      "backward_entropy": 0.006473339561905179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8720316886901855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05375559628009796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07502903044223785,
      "backward_entropy": 0.0064828576786177495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050741195678711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05377734452486038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07494577765464783,
      "backward_entropy": 0.006490999034472874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.805158615112305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05380005016922951,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07485654205083847,
      "backward_entropy": 0.006500286715371268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.188150644302368,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05382223054766655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.074769988656044,
      "backward_entropy": 0.0065078772604465485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.030839920043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053843431174755096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07468871772289276,
      "backward_entropy": 0.0123990997672081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5825345516204834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05386669188737869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07459545135498047,
      "backward_entropy": 0.006522852927446365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.772881507873535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0538882277905941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07451166212558746,
      "backward_entropy": 0.0065298570053918025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.560189962387085,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053910646587610245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07442259788513184,
      "backward_entropy": 0.006537310779094696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0790884494781494,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05393148958683014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07434214651584625,
      "backward_entropy": 0.006546361637966973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.097153186798096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053951408714056015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07426666468381882,
      "backward_entropy": 0.006554598787001201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.584099769592285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053971678018569946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07418888807296753,
      "backward_entropy": 0.006561710366180965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510250568389893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05399392917752266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07409927248954773,
      "backward_entropy": 0.00656515679189137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.939105033874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054016850888729095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0740056186914444,
      "backward_entropy": 0.0065673403441905975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867240905761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054040975868701935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07390457391738892,
      "backward_entropy": 0.00656822110925402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.944652557373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406610295176506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07379745692014694,
      "backward_entropy": 0.006567060947418213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.920850992202759,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05408988147974014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07369787991046906,
      "backward_entropy": 0.006566599011421204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.652936935424805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.054112471640110016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07360512018203735,
      "backward_entropy": 0.0990159000669207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3016438484191895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054136257618665695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07350490242242813,
      "backward_entropy": 0.0065671343888555255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.928299903869629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05415942519903183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0734080895781517,
      "backward_entropy": 0.0065683163702487946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439409255981445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054184384644031525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07330051809549332,
      "backward_entropy": 0.006571046475853238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8020448684692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054210368543863297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07318650186061859,
      "backward_entropy": 0.011866735560553414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.778170108795166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05423497408628464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07308045029640198,
      "backward_entropy": 0.006580742342131478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.857675075531006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05425833538174629,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07298152148723602,
      "backward_entropy": 0.01181340856211526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.798917293548584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05428209900856018,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07287995517253876,
      "backward_entropy": 0.01178346254995891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.053064346313477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05430638790130615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07277524471282959,
      "backward_entropy": 0.006599049483026777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.018838882446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432998389005661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07267409563064575,
      "backward_entropy": 0.00660572520324162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.628851890563965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05435297638177872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07257595658302307,
      "backward_entropy": 0.006613502545016152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02239149808883667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05437648668885231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07247453927993774,
      "backward_entropy": 0.006620699805872781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.522219181060791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05439765378832817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0723872259259224,
      "backward_entropy": 0.006628363260201046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.181210041046143,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05441949889063835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07229549437761307,
      "backward_entropy": 0.006635710597038269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3021597862243652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054441336542367935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07220346480607986,
      "backward_entropy": 0.006641786013330732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.909852027893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05446149781346321,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0721215009689331,
      "backward_entropy": 0.011569902300834656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022716356441378593,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05448346212506294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07202823460102081,
      "backward_entropy": 0.011538128767694746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.270522594451904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05450320243835449,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07194840908050537,
      "backward_entropy": 0.011505825178963798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.221200942993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05452374368906021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07186338305473328,
      "backward_entropy": 0.00665911499943052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4815165996551514,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054545044898986816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07177332043647766,
      "backward_entropy": 0.006665082914488656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.124726295471191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05456535518169403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07168895751237869,
      "backward_entropy": 0.006672261548893792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286287784576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05458630248904228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07160043716430664,
      "backward_entropy": 0.006677950067179543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.822806358337402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054608333855867386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07150499522686005,
      "backward_entropy": 0.011360966733523778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.780789852142334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05463032051920891,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07140948623418808,
      "backward_entropy": 0.011329665780067444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3803701400756836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465231090784073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07131363451480865,
      "backward_entropy": 0.006690017879009247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3605101108551025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054673247039318085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0712241530418396,
      "backward_entropy": 0.006696539265768868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.82597541809082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054693251848220825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07114008069038391,
      "backward_entropy": 0.006705378847462791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.475283622741699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054713837802410126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07105211913585663,
      "backward_entropy": 0.006711760801928384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.590157508850098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473395064473152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07096695899963379,
      "backward_entropy": 0.006717902741261891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.551580429077148,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05475408211350441,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0708814412355423,
      "backward_entropy": 0.006722041538783482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.759511470794678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05477429926395416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07079504430294037,
      "backward_entropy": 0.006725967462573733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.362060070037842,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05479566752910614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07070127129554749,
      "backward_entropy": 0.006730128079652786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7479705810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054816436022520065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07061108201742172,
      "backward_entropy": 0.006733389837401254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3936309814453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054838698357343674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07051078230142593,
      "backward_entropy": 0.006734114672456469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.354191780090332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054860908538103104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07041069865226746,
      "backward_entropy": 0.006737256688731057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3126091957092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488298833370209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07031126320362091,
      "backward_entropy": 0.0067409175847257885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.337698459625244,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05490501597523689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0702117532491684,
      "backward_entropy": 0.006746644420283181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.234838485717773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05492737516760826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07010992616415024,
      "backward_entropy": 0.006751470799957003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1521692276000977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054949481040239334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07000961899757385,
      "backward_entropy": 0.006754719253097262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.18765926361084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054970838129520416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06991389393806458,
      "backward_entropy": 0.006756738360439028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.13946533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054992616176605225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06981533020734787,
      "backward_entropy": 0.0067592625107084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0469541549682617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055014707148075104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06971439719200134,
      "backward_entropy": 0.006761220949036735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0357882976531982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05503573641180992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0696200430393219,
      "backward_entropy": 0.006766819528170994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0055394172668457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055056095123291016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06953000277280807,
      "backward_entropy": 0.006770932248660496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9947501420974731,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055076006799936295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06944248080253601,
      "backward_entropy": 0.006777231182370867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9564170837402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055094923824071884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06936129927635193,
      "backward_entropy": 0.010690741240978241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9334325790405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511339008808136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06928281486034393,
      "backward_entropy": 0.006788981280156544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023028649389743805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05513136088848114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06920759379863739,
      "backward_entropy": 0.09901568719318934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.933595895767212,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055147528648376465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06914420425891876,
      "backward_entropy": 0.006794801780155727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.863474130630493,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055162928998470306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06908556818962097,
      "backward_entropy": 0.0067954691393034795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.726322650909424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055178314447402954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06902679800987244,
      "backward_entropy": 0.0067980193666049415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9550643563270569,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055194538086652756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0689622312784195,
      "backward_entropy": 0.006799222103187016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.583539962768555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055209655314683914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06890486925840378,
      "backward_entropy": 0.0068017978753362384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.541153430938721,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05522611364722252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06883811950683594,
      "backward_entropy": 0.006802685558795929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.405160427093506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524369701743126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06876393407583237,
      "backward_entropy": 0.006800728184836251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7294375896453857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05526282638311386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06867924332618713,
      "backward_entropy": 0.0067973871316228595,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.24714050186798,
    "avg_log_Z": -0.05422735422849655,
    "success_rate": 1.0,
    "avg_reward": 75.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.16,
      "2": 0.82
    },
    "avg_forward_entropy": 0.07303020365536213,
    "avg_backward_entropy": 0.009338007148887429,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}