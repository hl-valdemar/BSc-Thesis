{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09902099200657435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09890929290226527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.5176544189453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707002997398376,
      "backward_entropy": 0.09895878178732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.9636993408203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707037270069122,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.92529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0002001241664402187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707050681114197,
      "backward_entropy": 0.0989004373550415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.3286895751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0003003804595209658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370704621076584,
      "backward_entropy": 0.09889592443193708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.69036865234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000399027339881286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707013428211212,
      "backward_entropy": 0.0988912922995431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.99490356445312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004967220011167228,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706955313682556,
      "backward_entropy": 0.0990206343787057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.1663818359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005953598883934319,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706877827644348,
      "backward_entropy": 0.09902043001992362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.98838806152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0006947264773771167,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706785440444946,
      "backward_entropy": 0.09902021714619227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.5521697998047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0007950408617034554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706673681735992,
      "backward_entropy": 0.09901998724256243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.52029418945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008961008861660957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706547021865845,
      "backward_entropy": 0.09886700766427177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.46876525878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.000995455775409937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706381618976593,
      "backward_entropy": 0.09886197532926287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.97073364257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0010957932099699974,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370619237422943,
      "backward_entropy": 0.09901917832238334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.93121337890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0011962864082306623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705982267856598,
      "backward_entropy": 0.09885195323399135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.98976135253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0012969025410711765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705749809741974,
      "backward_entropy": 0.09891906806400844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.74085998535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013959071366116405,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370549350976944,
      "backward_entropy": 0.09901830979755946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 261.7187194824219,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014934127684682608,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13705208897590637,
      "backward_entropy": 0.09901797771453857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.60711669921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0015932635869830847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704898953437805,
      "backward_entropy": 0.0988309383392334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.95556640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0016939762281253934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704568147659302,
      "backward_entropy": 0.09882564204079765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.03643798828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017953509232029319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704216480255127,
      "backward_entropy": 0.09882034574236188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.25892639160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0018956697313115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703837990760803,
      "backward_entropy": 0.09881487062999181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.8232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001996668055653572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370343565940857,
      "backward_entropy": 0.09889664820262364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.67054748535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0020982916466891766,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13703010976314545,
      "backward_entropy": 0.09901624066489083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.125244140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021968588698655367,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370256096124649,
      "backward_entropy": 0.09901595115661621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.06195068359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0022963546216487885,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13702085614204407,
      "backward_entropy": 0.09901568719318934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.61480712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0023951104376465082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701589405536652,
      "backward_entropy": 0.09888329676219396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.79319763183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002493936335667968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701055943965912,
      "backward_entropy": 0.09878227540424891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.36154174804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0025929557159543037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700498640537262,
      "backward_entropy": 0.0987765874181475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.2722625732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026936752256006002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699913024902344,
      "backward_entropy": 0.09877097606658936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.0550079345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00279233162291348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699273765087128,
      "backward_entropy": 0.0988692045211792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 211.40020751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0028911151457577944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698606193065643,
      "backward_entropy": 0.09886554309300014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 244.16506958007812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.002989944303408265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697901368141174,
      "backward_entropy": 0.09901387350899833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.71302795410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030905576422810555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369716078042984,
      "backward_entropy": 0.09874631677355085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.31736755371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003191862255334854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369638442993164,
      "backward_entropy": 0.09874003274100167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.83389282226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00329218921251595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695581257343292,
      "backward_entropy": 0.09901324340275355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.9610137939453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003392402781173587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369473785161972,
      "backward_entropy": 0.09872721774237496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.41036987304688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0034942394122481346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693855702877045,
      "backward_entropy": 0.09901289428983416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.92510986328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0035917391069233418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369294971227646,
      "backward_entropy": 0.09871390887669154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.6520538330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00368957850150764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13692018389701843,
      "backward_entropy": 0.0987070117677961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.83990478515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003787578782066703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691052794456482,
      "backward_entropy": 0.09883135557174683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.3238067626953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0038847955875098705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13690058887004852,
      "backward_entropy": 0.0990120427949088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.87956237792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003983157221227884,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368902623653412,
      "backward_entropy": 0.098822968346732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.45703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004074979107826948,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687971234321594,
      "backward_entropy": 0.09881821700504848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.03965759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0041687325574457645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686887919902802,
      "backward_entropy": 0.09866932460239955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.62779235839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004263194743543863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368577480316162,
      "backward_entropy": 0.09880893571036202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 195.11871337890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004357252735644579,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13684633374214172,
      "backward_entropy": 0.09901074852262225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.2853240966797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004450648091733456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683445751667023,
      "backward_entropy": 0.09864442689078194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.90687561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004544757306575775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682223856449127,
      "backward_entropy": 0.09879422187805176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.92640686035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004637265577912331,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680967688560486,
      "backward_entropy": 0.09862635816846575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.84779357910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004729937762022018,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679705560207367,
      "backward_entropy": 0.09900963306427002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.47947692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00482548400759697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678403198719025,
      "backward_entropy": 0.0986084256853376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.7762908935547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0049214488826692104,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367706060409546,
      "backward_entropy": 0.09900924137660436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.17538452148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00501882703974843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675673305988312,
      "backward_entropy": 0.09900907107761928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 243.39178466796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0051145609468221664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367427408695221,
      "backward_entropy": 0.09876319340297154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.89764404296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005212689284235239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367282122373581,
      "backward_entropy": 0.09875799928392683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.85794067382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00530769070610404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13671334087848663,
      "backward_entropy": 0.09875236238752093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.8056182861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0053998869843780994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669809699058533,
      "backward_entropy": 0.09855217593056816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.72470092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005492977797985077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136682391166687,
      "backward_entropy": 0.09874023709978376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.38246154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005584713537245989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666637241840363,
      "backward_entropy": 0.09853082043784005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.80560302734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005676307249814272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366499364376068,
      "backward_entropy": 0.0987274135862078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.65582275390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005765883252024651,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366335153579712,
      "backward_entropy": 0.09900684016091484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 258.49212646484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005853225011378527,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13661672174930573,
      "backward_entropy": 0.09900639738355364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.4384765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0059453160502016544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659930229187012,
      "backward_entropy": 0.09848539318357195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.37921142578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006037408486008644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658158481121063,
      "backward_entropy": 0.09900580133710589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.02130126953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006131654139608145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365637630224228,
      "backward_entropy": 0.09869357517787389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.86602783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006226714700460434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654541969299316,
      "backward_entropy": 0.09868696757725307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.24310302734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006325693801045418,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365259438753128,
      "backward_entropy": 0.09900518826075963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.73342895507812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006423907354474068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13650590181350708,
      "backward_entropy": 0.09900506905147008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.3905487060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006522714160382748,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648541271686554,
      "backward_entropy": 0.09866804736001152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.77076721191406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006620935630053282,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13646456599235535,
      "backward_entropy": 0.0990049157823835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.9722900390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006716317497193813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13644380867481232,
      "backward_entropy": 0.09839762960161481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.6841278076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006813486572355032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13642233610153198,
      "backward_entropy": 0.09864687919616699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.00672912597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006907917559146881,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640065491199493,
      "backward_entropy": 0.09863884108407157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.43450927734375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007005569990724325,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637837767601013,
      "backward_entropy": 0.09900436231068202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.5164489746094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007105751894414425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13635525107383728,
      "backward_entropy": 0.09900435379573277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.09786987304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007209426257759333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13633139431476593,
      "backward_entropy": 0.0983417204448155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.94517517089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00730696739628911,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630740344524384,
      "backward_entropy": 0.09832962921687535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.1534881591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007400291506201029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362832486629486,
      "backward_entropy": 0.09831627777644567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.72406005859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0074920631013810635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362585723400116,
      "backward_entropy": 0.09830195563180107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.54376220703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00758802704513073,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13623282313346863,
      "backward_entropy": 0.09900355339050293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.00399780273438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007684467360377312,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362065076828003,
      "backward_entropy": 0.09900330645697457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.57591247558594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0077816578559577465,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361798495054245,
      "backward_entropy": 0.09900309358324323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.2991638183594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007879598066210747,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13615284860134125,
      "backward_entropy": 0.09900293179920741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.96441650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007982137612998486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13612475991249084,
      "backward_entropy": 0.09823197977883476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.8696746826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008083519525825977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609632849693298,
      "backward_entropy": 0.09821821110589164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.58558654785156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00818483904004097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360672265291214,
      "backward_entropy": 0.09852348906653267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.89459228515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008284964598715305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13603763282299042,
      "backward_entropy": 0.09851336479187012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4684600830078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00838393997400999,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13600744307041168,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4097137451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008481970988214016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597673177719116,
      "backward_entropy": 0.09815561771392822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.77996826171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008579160086810589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13594548404216766,
      "backward_entropy": 0.09813792364937919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.3601531982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008674508891999722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359139382839203,
      "backward_entropy": 0.09811937808990479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.55270385742188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008768295869231224,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135882169008255,
      "backward_entropy": 0.09900055612836565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.13816833496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008864975534379482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584917783737183,
      "backward_entropy": 0.09808082239968437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.12554931640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008957709185779095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581639528274536,
      "backward_entropy": 0.09806052276066371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.05636596679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009052569046616554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578222692012787,
      "backward_entropy": 0.09840821368353707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.71585083007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009149321354925632,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357467919588089,
      "backward_entropy": 0.09839371272495814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.53887939453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009246859699487686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13571061193943024,
      "backward_entropy": 0.09800078187670026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.49884033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009346798993647099,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13567280769348145,
      "backward_entropy": 0.09836384228297643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.04632568359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00944577157497406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13563433289527893,
      "backward_entropy": 0.09796025923320226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.32554626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009544714353978634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355946660041809,
      "backward_entropy": 0.0979386568069458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.3899688720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009645176120102406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13555413484573364,
      "backward_entropy": 0.09831593717847552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.82090759277344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009741364978253841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551466166973114,
      "backward_entropy": 0.09789500917707171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8920135498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009828388690948486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13547633588314056,
      "backward_entropy": 0.09786983898707799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.26258850097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009915619157254696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354370266199112,
      "backward_entropy": 0.0982586145401001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.8934783935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009998117573559284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13539756834506989,
      "backward_entropy": 0.09781622886657715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.77244567871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010084696114063263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13535545766353607,
      "backward_entropy": 0.09821705307279315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.1398162841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010170761495828629,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353122889995575,
      "backward_entropy": 0.09776089872632708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.12937927246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010261834599077702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352670043706894,
      "backward_entropy": 0.09817608765193395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.48895263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01035303995013237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13522092998027802,
      "backward_entropy": 0.09815559216908046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.83006286621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010444034822285175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351747363805771,
      "backward_entropy": 0.09767858471189227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.31582641601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010530452243983746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13512907922267914,
      "backward_entropy": 0.0981119189943586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.0460968017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010613653808832169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350831538438797,
      "backward_entropy": 0.09808807713644845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.95294189453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01069679856300354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13503682613372803,
      "backward_entropy": 0.09806379250117711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.06936645507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01077840756624937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13499003648757935,
      "backward_entropy": 0.09755443675177437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.72023010253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010864533483982086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349412500858307,
      "backward_entropy": 0.098014235496521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.25741577148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01095111109316349,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348913311958313,
      "backward_entropy": 0.09798962729317802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.58079528808594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011033385992050171,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13484174013137817,
      "backward_entropy": 0.09898280245917183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.74729919433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011113234795629978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134792298078537,
      "backward_entropy": 0.09793647697993688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.3100700378418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011194650083780289,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347421109676361,
      "backward_entropy": 0.09790947607585362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5439910888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011266362853348255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13469475507736206,
      "backward_entropy": 0.09897933687482562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.2537841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011337722651660442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346469521522522,
      "backward_entropy": 0.09731213535581316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.7812957763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011411383748054504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345977634191513,
      "backward_entropy": 0.09727432898112706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.37322998046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01148443017154932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13454768061637878,
      "backward_entropy": 0.09779032639094762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.7083282470703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011557023972272873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134496808052063,
      "backward_entropy": 0.09719427994319371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.99285888671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011630409397184849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1344446986913681,
      "backward_entropy": 0.098972601549966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.85951232910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011704430915415287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13439124822616577,
      "backward_entropy": 0.09769703660692487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.122802734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011776469647884369,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343371868133545,
      "backward_entropy": 0.09706476756504603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.02980041503906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011845335364341736,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13428275287151337,
      "backward_entropy": 0.09896819932120186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.020751953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011911620385944843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13422825932502747,
      "backward_entropy": 0.0975938013621739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.26699829101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01197531446814537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13417327404022217,
      "backward_entropy": 0.09755655697413854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.60894775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012039772234857082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13411761820316315,
      "backward_entropy": 0.09686625003814697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.1953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012107167392969131,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13405998051166534,
      "backward_entropy": 0.09681505816323417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.77430725097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012178575620055199,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340002417564392,
      "backward_entropy": 0.0967644282749721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.0236053466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012251119129359722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1339384764432907,
      "backward_entropy": 0.09671338966914586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.32251739501953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012323576025664806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13387545943260193,
      "backward_entropy": 0.09895673819950648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.52882385253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012390836142003536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13381347060203552,
      "backward_entropy": 0.09660767657416207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 236.08331298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012462276965379715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133748859167099,
      "backward_entropy": 0.09729017530168806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.82711791992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012539814226329327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13368076086044312,
      "backward_entropy": 0.09650169100080218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.51842498779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01261309627443552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13361382484436035,
      "backward_entropy": 0.09721226351601737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.2312774658203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012680735439062119,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13354770839214325,
      "backward_entropy": 0.09895012208393641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.88604736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012751259841024876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13347937166690826,
      "backward_entropy": 0.09633225202560425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.21090698242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012822133488953114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13341040909290314,
      "backward_entropy": 0.09894746541976929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.15625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01289192121475935,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13334114849567413,
      "backward_entropy": 0.09894609451293945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.51870727539062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012968171387910843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13326813280582428,
      "backward_entropy": 0.09615801061902728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.21682739257812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013047565706074238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331922858953476,
      "backward_entropy": 0.09610003232955933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.6361083984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013127559795975685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13311538100242615,
      "backward_entropy": 0.0960413898740496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.1477813720703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013205118477344513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13303785026073456,
      "backward_entropy": 0.09894339527402606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.2899627685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013281908817589283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329592615365982,
      "backward_entropy": 0.09682595729827881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.0395050048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013364547863602638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328771561384201,
      "backward_entropy": 0.0967814496585301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.50108337402344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013449703343212605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13279251754283905,
      "backward_entropy": 0.09894135168620519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.38450622558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013538464903831482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327049732208252,
      "backward_entropy": 0.09572660071509224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.19956970214844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013622869737446308,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13262027502059937,
      "backward_entropy": 0.09894065346036639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4577178955078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01370441447943449,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1325354427099228,
      "backward_entropy": 0.09893975939069476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.72186279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01378330122679472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13245008885860443,
      "backward_entropy": 0.09551565987723214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.56878662109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013859983533620834,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13236446678638458,
      "backward_entropy": 0.09893715381622314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.28805541992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013938563875854015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13227656483650208,
      "backward_entropy": 0.09643162999834333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.99380493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014017635025084019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13218717277050018,
      "backward_entropy": 0.09528144768306188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.09674072265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014093340374529362,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1320985108613968,
      "backward_entropy": 0.09893259831837245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.02301025390625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014169584959745407,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1320076733827591,
      "backward_entropy": 0.09893058027539935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.1199951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014249122701585293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1319139003753662,
      "backward_entropy": 0.09619416509355817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.86549377441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014325171709060669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13182082772254944,
      "backward_entropy": 0.09494559253965106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.31204223632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014402283355593681,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13172663748264313,
      "backward_entropy": 0.0948587315423148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.97500610351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014484948478639126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13162779808044434,
      "backward_entropy": 0.0947721004486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.88470458984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0145706906914711,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13152699172496796,
      "backward_entropy": 0.09594472817012242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.43243408203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014656157232820988,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13142475485801697,
      "backward_entropy": 0.09892191205705915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.00973510742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014741207472980022,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313207745552063,
      "backward_entropy": 0.09581763403756278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.46249389648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014825978316366673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312151998281479,
      "backward_entropy": 0.09575166021074567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.00056457519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014913120307028294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1311066746711731,
      "backward_entropy": 0.09432333707809448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 263.6336975097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014993319287896156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13100095093250275,
      "backward_entropy": 0.09422366959708077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.77633666992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015081636607646942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13088953495025635,
      "backward_entropy": 0.09412860870361328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.47975158691406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015166772529482841,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13077837228775024,
      "backward_entropy": 0.09891750131334577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.81295776367188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01525064930319786,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13066703081130981,
      "backward_entropy": 0.09891670942306519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.1124267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01533577498048544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13055336475372314,
      "backward_entropy": 0.09382448877607073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.30523681640625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01542341336607933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13043682277202606,
      "backward_entropy": 0.09891573020390101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 215.57601928710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015513217076659203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13031750917434692,
      "backward_entropy": 0.09891561099461146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6260528564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015606326051056385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13019531965255737,
      "backward_entropy": 0.09351365906851632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 247.00526428222656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01569720357656479,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13007286190986633,
      "backward_entropy": 0.09891589198793684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.10140991210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015793709084391594,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12994521856307983,
      "backward_entropy": 0.09891657318387713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 231.94227600097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01589135266840458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12981663644313812,
      "backward_entropy": 0.0931943484715053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.47157287597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01599237695336342,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296839714050293,
      "backward_entropy": 0.09308571474892753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 262.0081787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0160926915705204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12954971194267273,
      "backward_entropy": 0.09297258513314384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.74794006347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016198787838220596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12941023707389832,
      "backward_entropy": 0.0928628955568586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.45535278320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01630164124071598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1292724609375,
      "backward_entropy": 0.09275032792772565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.13137817382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016403738409280777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12913350760936737,
      "backward_entropy": 0.09263411590031215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.0302276611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016501348465681076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12899595499038696,
      "backward_entropy": 0.09251167093004499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.14996337890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01659492217004299,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1288597583770752,
      "backward_entropy": 0.09428516456059047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.4208526611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01668601483106613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12872327864170074,
      "backward_entropy": 0.0922494615827288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.00021362304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01677653007209301,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12858620285987854,
      "backward_entropy": 0.09211373329162598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.907958984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016866615042090416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12844887375831604,
      "backward_entropy": 0.09398449318749565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.07073974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01695483922958374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1283130943775177,
      "backward_entropy": 0.09387906108583723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.6927947998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017042793333530426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12817616760730743,
      "backward_entropy": 0.0937713895525251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.29180908203125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017129112035036087,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280386745929718,
      "backward_entropy": 0.0989142826625279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 228.79400634765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01721642166376114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12789879739284515,
      "backward_entropy": 0.0989128862108503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.99515533447266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017308473587036133,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12775354087352753,
      "backward_entropy": 0.09343796116965157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.8452606201172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01739591173827648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12761078774929047,
      "backward_entropy": 0.09891060420445033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 197.27801513671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01748160645365715,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12746746838092804,
      "backward_entropy": 0.09890885863985334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.53085327148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017569663003087044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12732039391994476,
      "backward_entropy": 0.09308006082262311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.37464904785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017657402902841568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12717223167419434,
      "backward_entropy": 0.09061639649527413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.55692291259766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01774575561285019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12702086567878723,
      "backward_entropy": 0.09044873714447021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.40252685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01782718300819397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1268741339445114,
      "backward_entropy": 0.09269509996686663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.25523376464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017911512404680252,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1267225295305252,
      "backward_entropy": 0.09889929635184151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.77281188964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01799844577908516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12656623125076294,
      "backward_entropy": 0.08992181505475726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.9747314453125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018084945157170296,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1264071762561798,
      "backward_entropy": 0.09889551571437291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.5003204345703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01817663013935089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12624286115169525,
      "backward_entropy": 0.09889445986066546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.2103271484375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018267396837472916,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12607689201831818,
      "backward_entropy": 0.09889347212655204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.04693603515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018358808010816574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12590885162353516,
      "backward_entropy": 0.09188495363507952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 227.54193115234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018451930955052376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573695182800293,
      "backward_entropy": 0.08901625020163399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.18537139892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018548892810940742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12555855512619019,
      "backward_entropy": 0.08882380383355278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.87716674804688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018640616908669472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12538348138332367,
      "backward_entropy": 0.0914625610624041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.98240661621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01873280480504036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12520618736743927,
      "backward_entropy": 0.0913142306464059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.92820739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018822800368070602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12502914667129517,
      "backward_entropy": 0.08820546524865287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.59378051757812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018909674137830734,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12485411763191223,
      "backward_entropy": 0.09888760532651629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.63583374023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01899523101747036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12467966973781586,
      "backward_entropy": 0.09083853449140276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.73294067382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01908068172633648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1245032250881195,
      "backward_entropy": 0.09067146267209734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.4456787109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01916372776031494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12432890385389328,
      "backward_entropy": 0.08731784990855626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.3258514404297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019244369119405746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12415552139282227,
      "backward_entropy": 0.0870847191129412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.49728393554688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01932285539805889,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12398327887058258,
      "backward_entropy": 0.09887502874646868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.0192413330078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019400741904973984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12380997836589813,
      "backward_entropy": 0.08660237278257098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.2354736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019480420276522636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12363336980342865,
      "backward_entropy": 0.08635519232068743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.36959838867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019557977095246315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1234564483165741,
      "backward_entropy": 0.08610110623495919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.17800903320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019634971395134926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1232777014374733,
      "backward_entropy": 0.08584298406328474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.5615997314453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019710374996066093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12310028076171875,
      "backward_entropy": 0.08558143888201032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1714324951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01978561095893383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1229219064116478,
      "backward_entropy": 0.08531711782727923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.0357208251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019864356145262718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12273719906806946,
      "backward_entropy": 0.08505119596208845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.74041748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019943779334425926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12254951149225235,
      "backward_entropy": 0.08478224277496338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.1998291015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020022166892886162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12235958874225616,
      "backward_entropy": 0.08450601782117571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.62081909179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02010144479572773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1221691444516182,
      "backward_entropy": 0.0842294522694179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.8391876220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02018105238676071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1219751238822937,
      "backward_entropy": 0.08394554683140346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.68353271484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020262524485588074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12177743017673492,
      "backward_entropy": 0.08365956374577113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.28936767578125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020341848954558372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12158169597387314,
      "backward_entropy": 0.09883661781038557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.63655853271484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020425546914339066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12137818336486816,
      "backward_entropy": 0.08307594060897827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.36517333984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02050434984266758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12118048220872879,
      "backward_entropy": 0.08277635063443865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.25286865234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02058774046599865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12097550928592682,
      "backward_entropy": 0.08686719621930804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.02061462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020669827237725258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12076888233423233,
      "backward_entropy": 0.0821740882737296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.51182556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02075347863137722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12055928260087967,
      "backward_entropy": 0.0818656257220677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.38591766357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02083698660135269,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12034661322832108,
      "backward_entropy": 0.08154841831752233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.95701599121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02091659978032112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12013722956180573,
      "backward_entropy": 0.08122028623308454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.19696044921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020998205989599228,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11992499232292175,
      "backward_entropy": 0.08568121705736433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.06317138671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021079113706946373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11971385776996613,
      "backward_entropy": 0.0988165991646903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.33766174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021160731092095375,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11950168013572693,
      "backward_entropy": 0.08518018892833165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.96189880371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021239859983325005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11928842961788177,
      "backward_entropy": 0.08492306300571986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.2700653076172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02131848782300949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11907483637332916,
      "backward_entropy": 0.07954846109662737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.87722778320312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021397851407527924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11885866522789001,
      "backward_entropy": 0.07920147691454206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.35749816894531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02147662825882435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11864225566387177,
      "backward_entropy": 0.07884946891239711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.31118774414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021549325436353683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11843235790729523,
      "backward_entropy": 0.07848261935370308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.6560516357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.021622201427817345,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11822198331356049,
      "backward_entropy": 0.09879820687430245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.1957244873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02169901132583618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11800451576709747,
      "backward_entropy": 0.07774735348565238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.28158569335938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021777160465717316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11778637766838074,
      "backward_entropy": 0.08299825872693743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.64456176757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021854810416698456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11756694316864014,
      "backward_entropy": 0.08270752429962158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.36615753173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021932173520326614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11734701693058014,
      "backward_entropy": 0.08241296666009086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8559112548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0220080204308033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11712881177663803,
      "backward_entropy": 0.07626581192016602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.05824279785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02208489179611206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11690670996904373,
      "backward_entropy": 0.07588352475847517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4699249267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02216416969895363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11668006330728531,
      "backward_entropy": 0.07550145898546491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.00218200683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02224414050579071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11645122617483139,
      "backward_entropy": 0.07511397770472936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.56905364990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02232355624437332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11622282862663269,
      "backward_entropy": 0.07472114903586251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.02082061767578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022401291877031326,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11599694192409515,
      "backward_entropy": 0.09878574098859515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.47059631347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022472167387604713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11578191816806793,
      "backward_entropy": 0.07391354015895299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.11042785644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022542161867022514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11556714028120041,
      "backward_entropy": 0.07990744284221105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.6220932006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022610168904066086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11535556614398956,
      "backward_entropy": 0.07308088881628853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.68695068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022676175460219383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11514510214328766,
      "backward_entropy": 0.07265457085200719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.1578369140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022744446992874146,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11492961645126343,
      "backward_entropy": 0.09876493045261928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.6486358642578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022817356511950493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11470501124858856,
      "backward_entropy": 0.07180582625525338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.3909454345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022892961278557777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11447284370660782,
      "backward_entropy": 0.07138071741376605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.58297729492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022973772138357162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1142316460609436,
      "backward_entropy": 0.07784673145839147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.68057250976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023054253309965134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11399255692958832,
      "backward_entropy": 0.0775066784449986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.4093780517578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023135563358664513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.113752081990242,
      "backward_entropy": 0.0771617123058864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.25616455078125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02321643754839897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11351218819618225,
      "backward_entropy": 0.09876111575535365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.8316650390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023298118263483047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1132705956697464,
      "backward_entropy": 0.0692619000162397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.03865814208984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02337750792503357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1130288690328598,
      "backward_entropy": 0.06881690876824516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.602783203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02344985119998455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11279802024364471,
      "backward_entropy": 0.06835760389055524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.14649200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02352508157491684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1125609502196312,
      "backward_entropy": 0.06789842673710414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.34728240966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023596705868840218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11233256757259369,
      "backward_entropy": 0.07493971926825387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.45631408691406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02366616576910019,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1121070384979248,
      "backward_entropy": 0.07454146657671247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.55978393554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023736312985420227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11187902837991714,
      "backward_entropy": 0.06650059138025556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.58316040039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023808153346180916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11164489388465881,
      "backward_entropy": 0.06603351661137172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.50189971923828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023884452879428864,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11140409111976624,
      "backward_entropy": 0.07335262639181954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.051513671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02395823411643505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11116817593574524,
      "backward_entropy": 0.07295003959110805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.00481414794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024028338491916656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11093834042549133,
      "backward_entropy": 0.07253519977842059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.33364868164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024097777903079987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11070884764194489,
      "backward_entropy": 0.06415049944605146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.80171966552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024171698838472366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1104683130979538,
      "backward_entropy": 0.07170798948832921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4031524658203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02424074523150921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11023758351802826,
      "backward_entropy": 0.06317952701023646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.65267944335938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024310408160090446,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11000555753707886,
      "backward_entropy": 0.09871368748801095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.38150024414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024380842223763466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10976959764957428,
      "backward_entropy": 0.06219269548143659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.87367248535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02445458061993122,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10952423512935638,
      "backward_entropy": 0.09870883396693639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.15943145751953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02452736347913742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10928334295749664,
      "backward_entropy": 0.061219249452863424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.64242553710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0245980191975832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.109047070145607,
      "backward_entropy": 0.06072483743940081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.32233428955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024671992287039757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10880423337221146,
      "backward_entropy": 0.06876283032553536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.2143096923828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024743547663092613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10856398940086365,
      "backward_entropy": 0.05973632846559797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.72149658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024815822020173073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10832306742668152,
      "backward_entropy": 0.05923989415168762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.72360229492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02489134855568409,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10807717591524124,
      "backward_entropy": 0.09869781562260219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.91130828857422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.024971116334199905,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10782463848590851,
      "backward_entropy": 0.0986991013799395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.49710083007812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02504819631576538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10757835954427719,
      "backward_entropy": 0.05778065323829651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.85205078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0251254141330719,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10733170062303543,
      "backward_entropy": 0.05729176316942487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.2612762451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025199072435498238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10709567368030548,
      "backward_entropy": 0.0568001355443682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.8324737548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025275951251387596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10685235261917114,
      "backward_entropy": 0.056318700313568115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.13274383544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025354409590363503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1066080778837204,
      "backward_entropy": 0.0648854672908783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.56379699707031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02543170563876629,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10636729001998901,
      "backward_entropy": 0.09869851384844099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.18741607666016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025502527132630348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1061384454369545,
      "backward_entropy": 0.05485996178218296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.7134246826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025572791695594788,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10590935498476028,
      "backward_entropy": 0.06352870804922921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.99879455566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025645414367318153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10567708313465118,
      "backward_entropy": 0.06307336262294225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.23991394042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025718597695231438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10544167459011078,
      "backward_entropy": 0.06262084415980748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.6975860595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02578706480562687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1052146777510643,
      "backward_entropy": 0.06215691566467285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.16485595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025858230888843536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.104985311627388,
      "backward_entropy": 0.052361837455204556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.07720947265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02593020722270012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10475355386734009,
      "backward_entropy": 0.051865262644631524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.27249145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02600286714732647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10452009737491608,
      "backward_entropy": 0.05136616315160479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.6194305419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02607639506459236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10428555309772491,
      "backward_entropy": 0.05087333917617798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.75595092773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026150893419981003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10405274480581284,
      "backward_entropy": 0.059867224522999356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.04112243652344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02622957155108452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10380925238132477,
      "backward_entropy": 0.04990484033312116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.82447814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026309622451663017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10356281697750092,
      "backward_entropy": 0.04942047595977783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.61337280273438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026388341560959816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1033191829919815,
      "backward_entropy": 0.04892913358552115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.49747467041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026467138901352882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10307487845420837,
      "backward_entropy": 0.048436147826058526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.95066833496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02654470130801201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10283276438713074,
      "backward_entropy": 0.05763019834245954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.85195922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02662380039691925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10258737951517105,
      "backward_entropy": 0.04744149957384382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.92086029052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02670297957956791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10234139859676361,
      "backward_entropy": 0.04694416267531259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.2116241455078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02678087167441845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10209763050079346,
      "backward_entropy": 0.046441610370363505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.31509399414062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02685905061662197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10185565799474716,
      "backward_entropy": 0.04594021609851292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.98243713378906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026934919878840446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10161744058132172,
      "backward_entropy": 0.04543718269893101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.16522216796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02700878120958805,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10138388723134995,
      "backward_entropy": 0.05490004590579441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.46551513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02708469144999981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10114836692810059,
      "backward_entropy": 0.04443817479269845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.81617736816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027163811028003693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10090796649456024,
      "backward_entropy": 0.04395200950758798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.904052734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02724042348563671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1006719172000885,
      "backward_entropy": 0.043458138193402975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.63318634033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027316277846693993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10043927282094955,
      "backward_entropy": 0.042965586696352275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.54785919189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027388717979192734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10021218657493591,
      "backward_entropy": 0.04246853079114642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.16336059570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027460798621177673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09998811781406403,
      "backward_entropy": 0.0419723561831883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.18428802490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027535347267985344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09975818544626236,
      "backward_entropy": 0.051694273948669434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.64015197753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02760930173099041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09952955693006516,
      "backward_entropy": 0.04100865977151053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.18568420410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.027680212631821632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09930934011936188,
      "backward_entropy": 0.09868954760687691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.13784790039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027751188725233078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09909149259328842,
      "backward_entropy": 0.04004471642630441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.1094970703125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02781844139099121,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09888474643230438,
      "backward_entropy": 0.09868308476039342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.77137756347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027888571843504906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0986722856760025,
      "backward_entropy": 0.039100395781653266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.13401794433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02795979753136635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09845642745494843,
      "backward_entropy": 0.03862976176398141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.17979431152344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028029659762978554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.09824331104755402,
      "backward_entropy": 0.09867635795048305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.210296630859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02810223028063774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0980265885591507,
      "backward_entropy": 0.0377012916973659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.64733123779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028168005868792534,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0978238433599472,
      "backward_entropy": 0.047536347593579976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.53128051757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02822890877723694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09763006865978241,
      "backward_entropy": 0.036751244749341695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.84464263916016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02829729951918125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09741932153701782,
      "backward_entropy": 0.036292816911424906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.76174926757812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02836725488305092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09720795601606369,
      "backward_entropy": 0.03584235906600952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.73736572265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028438536450266838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0969938337802887,
      "backward_entropy": 0.03539640137127468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.12184143066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028508523479104042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09678370505571365,
      "backward_entropy": 0.03495133348873684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.808563232421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02858368121087551,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09656274318695068,
      "backward_entropy": 0.0345172860792705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.04961395263672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028653128072619438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0963522270321846,
      "backward_entropy": 0.034071896757398336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.73167419433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02872295118868351,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0961441770195961,
      "backward_entropy": 0.03363459876605442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.42620849609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028793176636099815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09593807905912399,
      "backward_entropy": 0.03320634365081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.33143615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028867412358522415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09572461247444153,
      "backward_entropy": 0.03278730171067374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.6317901611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02894020825624466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09551513195037842,
      "backward_entropy": 0.032368949481419156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.81816101074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02901686169207096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09530061483383179,
      "backward_entropy": 0.031961994511740546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.50273132324219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02908918634057045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09509439766407013,
      "backward_entropy": 0.03154840639659336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.5239028930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02915906347334385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09489420801401138,
      "backward_entropy": 0.031137353607586453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.47544860839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029226627200841904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09470086544752121,
      "backward_entropy": 0.04108916010175433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.13766479492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029297277331352234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0945005863904953,
      "backward_entropy": 0.0303236437695367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.93045806884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0293732937425375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09429043531417847,
      "backward_entropy": 0.029940547687666758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.70999908447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02944515086710453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09408993273973465,
      "backward_entropy": 0.0295518445117133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.322021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029517102986574173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09388786554336548,
      "backward_entropy": 0.029165184923580716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.94961547851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0295879989862442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09368893504142761,
      "backward_entropy": 0.028781282050268992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.200660705566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02965928427875042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09349099546670914,
      "backward_entropy": 0.03874516912869045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.58332061767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029725754633545876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.093303382396698,
      "backward_entropy": 0.028022531952176775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.22059631347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029793014749884605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09311473369598389,
      "backward_entropy": 0.0379567699772971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.87952423095703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0298610832542181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09292739629745483,
      "backward_entropy": 0.027281443987573897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.54351043701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029923468828201294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09275266528129578,
      "backward_entropy": 0.03717594487326486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.67532348632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02998846024274826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09257147461175919,
      "backward_entropy": 0.02655184268951416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.01846313476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030054427683353424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09238563477993011,
      "backward_entropy": 0.03641495108604431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.123138427734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030122673138976097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09219896793365479,
      "backward_entropy": 0.02585590524332864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.43727111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030186600983142853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09202233701944351,
      "backward_entropy": 0.035674950906208584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.91448974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03024919144809246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09184928238391876,
      "backward_entropy": 0.03530217068535941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.75933837890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030315713956952095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09167046844959259,
      "backward_entropy": 0.024838683860642568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.65581512451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03038191795349121,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09149236977100372,
      "backward_entropy": 0.034584990569523404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.89942169189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030450493097305298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09131160378456116,
      "backward_entropy": 0.024191575390951976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.04959106445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030517172068357468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09113375842571259,
      "backward_entropy": 0.033884135740143914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.78579711914062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.030583608895540237,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.090957872569561,
      "backward_entropy": 0.0986781120300293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.63735961914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030649881809949875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09078244119882584,
      "backward_entropy": 0.033187770417758396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.31227111816406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030713386833667755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09061117470264435,
      "backward_entropy": 0.03283861705235073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.75458526611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030777093023061752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09044158458709717,
      "backward_entropy": 0.022616748298917497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.54534912109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030844612047076225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.09026601910591125,
      "backward_entropy": 0.02232115183557783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.87992477416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030910605564713478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.09009361267089844,
      "backward_entropy": 0.0318384404693331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.60040283203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03097401186823845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08992697298526764,
      "backward_entropy": 0.02172968430178506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.97502136230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031035203486680984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08976580202579498,
      "backward_entropy": 0.02143562478678567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.46003723144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031099462881684303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0895993709564209,
      "backward_entropy": 0.02115351813180106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.63320922851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031161312013864517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08943934738636017,
      "backward_entropy": 0.02087291862283434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.67396545410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03122604638338089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08927364647388458,
      "backward_entropy": 0.020599250282560076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.08922576904297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03129463270306587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08910064399242401,
      "backward_entropy": 0.02033401812825884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.10718536376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03136032819747925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08893106877803802,
      "backward_entropy": 0.020064347556659153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.66769409179688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031426239758729935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08876338601112366,
      "backward_entropy": 0.01980179122516087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.11998748779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03149457648396492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08859013020992279,
      "backward_entropy": 0.019542704735483443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.71542739868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03155907988548279,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08842553198337555,
      "backward_entropy": 0.019284280283110484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.85079574584961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03161897510290146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08827288448810577,
      "backward_entropy": 0.019027420452662876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.93719482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03167591989040375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08812671899795532,
      "backward_entropy": 0.01877196558884212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 110.16566467285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03173140808939934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08798278868198395,
      "backward_entropy": 0.02780096871512277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.408203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031790655106306076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08783416450023651,
      "backward_entropy": 0.018274213586534773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.8001480102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03184580057859421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08769389986991882,
      "backward_entropy": 0.027211304221834456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.3725814819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03190464898943901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08754297345876694,
      "backward_entropy": 0.01779331373316901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.16671752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03196445852518082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08738991618156433,
      "backward_entropy": 0.017563301537718092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.95919799804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03202515468001366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08723568916320801,
      "backward_entropy": 0.01733942542757307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.75662994384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03208666667342186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08708283305168152,
      "backward_entropy": 0.017119368272168294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.53739929199219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03215012326836586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08692651987075806,
      "backward_entropy": 0.016903210963521684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.023193359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03221415355801582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0867699384689331,
      "backward_entropy": 0.016690327652863095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.84050750732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032283563166856766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08660420775413513,
      "backward_entropy": 0.016485175916126797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.59127807617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03235545754432678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08643481135368347,
      "backward_entropy": 0.016286153878484453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.65077209472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03242954984307289,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0862618237733841,
      "backward_entropy": 0.016092316380568912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.56971740722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03250318393111229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0860910639166832,
      "backward_entropy": 0.0159002457346235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.40431213378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03257525712251663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08592377603054047,
      "backward_entropy": 0.024381135191236223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8749771118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032645903527736664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08575938642024994,
      "backward_entropy": 0.015525079199245997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.99236297607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03271658346056938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0855969563126564,
      "backward_entropy": 0.02391548454761505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.040761947631836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03278602287173271,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0854383036494255,
      "backward_entropy": 0.09880209820611137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.55492401123047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0328495018184185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08529368042945862,
      "backward_entropy": 0.023445355040686473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.55564880371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03291616961359978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08514152467250824,
      "backward_entropy": 0.014808775058814458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.856809616088867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0329783670604229,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08499768376350403,
      "backward_entropy": 0.02298735933644431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.59839630126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03303533047437668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08486391603946686,
      "backward_entropy": 0.014461684439863478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.33281707763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03309379518032074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0847301185131073,
      "backward_entropy": 0.014294564723968506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.70238494873047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033151157200336456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0845993384718895,
      "backward_entropy": 0.014130199594157082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.6527099609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0332062654197216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08447221666574478,
      "backward_entropy": 0.013966202735900879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.8564682006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03326897323131561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08432657271623611,
      "backward_entropy": 0.013809531927108765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.62965393066406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03333495184779167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08417607843875885,
      "backward_entropy": 0.013656510838440486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.757755279541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03340156748890877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08402591943740845,
      "backward_entropy": 0.013506976621491569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.64045715332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033463895320892334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0838845819234848,
      "backward_entropy": 0.013356887868472509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.67613220214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0335283987224102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08373923599720001,
      "backward_entropy": 0.02107794157096318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.50234985351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03359245881438255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08359455317258835,
      "backward_entropy": 0.01306564680167607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.98602294921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03365612402558327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08345021307468414,
      "backward_entropy": 0.012922440256391252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.10811614990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033718280494213104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08331073820590973,
      "backward_entropy": 0.012780625905309404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.22239303588867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03378031775355339,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08317125588655472,
      "backward_entropy": 0.0126419940165111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.54799270629883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03383854776620865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08303765952587128,
      "backward_entropy": 0.012502216867038183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.79841613769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03389585018157959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08290507644414902,
      "backward_entropy": 0.012365435915333884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.62149047851562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033954769372940063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08276855945587158,
      "backward_entropy": 0.01223476869719369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.949058532714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034015119075775146,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0826319009065628,
      "backward_entropy": 0.019609123468399048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.47648620605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034073200076818466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0825004130601883,
      "backward_entropy": 0.011982184435640062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.819618225097656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03413521498441696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0823594257235527,
      "backward_entropy": 0.01927613147667476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.90121459960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03419600799679756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08222100138664246,
      "backward_entropy": 0.019113836543900625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.65484619140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03425927087664604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08207660168409348,
      "backward_entropy": 0.011626280844211578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.39320373535156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03432478383183479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08192908763885498,
      "backward_entropy": 0.011513261922768183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.212623596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03439115360379219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0817800909280777,
      "backward_entropy": 0.011402551616941179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.046749114990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034454748034477234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08163723349571228,
      "backward_entropy": 0.011292805629117149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.62101745605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03451704978942871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08149794489145279,
      "backward_entropy": 0.011184842458793096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.56522369384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03458293527364731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08135148882865906,
      "backward_entropy": 0.011081905237265996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.45730590820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03464965149760246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08120284974575043,
      "backward_entropy": 0.010980096246515001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.74861145019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034715987741947174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08105554431676865,
      "backward_entropy": 0.01088016267333712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.46439743041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034778423607349396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08091650158166885,
      "backward_entropy": 0.01078032170023237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.93240356445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034838560968637466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08078265190124512,
      "backward_entropy": 0.017663479915687015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.23728561401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034898992627859116,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08064768463373184,
      "backward_entropy": 0.01058727183512279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.53047943115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034957338124513626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08051736652851105,
      "backward_entropy": 0.01739190412419183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.82774353027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035020872950553894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08037520945072174,
      "backward_entropy": 0.017266754593167986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.90463256835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0350867323577404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.08022861182689667,
      "backward_entropy": 0.010319192494664873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.33291625976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03515353053808212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.08008024841547012,
      "backward_entropy": 0.017026324357305254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.31119537353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03522234782576561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07992767542600632,
      "backward_entropy": 0.0101532159107072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.06337356567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035295307636260986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07976768910884857,
      "backward_entropy": 0.010075696877070836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.34794616699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035366181284189224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07961224764585495,
      "backward_entropy": 0.009999768010207586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.74467468261719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03543401136994362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0794631689786911,
      "backward_entropy": 0.009924268083912986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.07987976074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03550027683377266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07931658625602722,
      "backward_entropy": 0.009849374847752708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.43246078491211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0355663076043129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07917094230651855,
      "backward_entropy": 0.009775803557464055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.984222412109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0356309749186039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07902957499027252,
      "backward_entropy": 0.009703160396644048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.54389190673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03569091111421585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07889733463525772,
      "backward_entropy": 0.016135597867625102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.239994049072266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03575127199292183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07876254618167877,
      "backward_entropy": 0.009558733020509993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.20796585083008,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03580852597951889,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07863298058509827,
      "backward_entropy": 0.0989367025239127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.04197692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035866495221853256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07850005477666855,
      "backward_entropy": 0.009419141071183341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.0627670288086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03592511638998985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07836779952049255,
      "backward_entropy": 0.009351885744503565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.22828674316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035988949239254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07822473347187042,
      "backward_entropy": 0.009287702185767037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.03628158569336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03605516999959946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07807663083076477,
      "backward_entropy": 0.009225201393876756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.70355987548828,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03611891344189644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07793474197387695,
      "backward_entropy": 0.09894614560263497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.798152923583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036179281771183014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07779955118894577,
      "backward_entropy": 0.009103062961782728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.29624938964844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03623777627944946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07766805589199066,
      "backward_entropy": 0.009043648838996887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.31454467773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0362992100417614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07752948999404907,
      "backward_entropy": 0.008986996752875192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.81495666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0363655686378479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0773816928267479,
      "backward_entropy": 0.008932911923953466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.49635314941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03643408045172691,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0772293210029602,
      "backward_entropy": 0.0088801628776959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.36422729492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.036503393203020096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.0770740658044815,
      "backward_entropy": 0.09895736830575126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.02647399902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03657682612538338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07691045105457306,
      "backward_entropy": 0.008779528949941908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.869441986083984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03665170818567276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07674340903759003,
      "backward_entropy": 0.008731160845075334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.77796936035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036724455654621124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07658077776432037,
      "backward_entropy": 0.008683601660387856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.02345275878906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036794114857912064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07642590999603271,
      "backward_entropy": 0.008636260139090675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.22926712036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03686781972646713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0762624591588974,
      "backward_entropy": 0.008590390107461385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.01947021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03694064915180206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07610096037387848,
      "backward_entropy": 0.008545413613319397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.4158706665039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03701271489262581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0759405568242073,
      "backward_entropy": 0.00850120825426919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.14598083496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037086330354213715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07577706128358841,
      "backward_entropy": 0.008457954440798079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.40793991088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037161316722631454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07560992240905762,
      "backward_entropy": 0.008416098675557546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.81559371948242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03723530471324921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07544516772031784,
      "backward_entropy": 0.00837481873376029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.9823989868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037306129932403564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07528769969940186,
      "backward_entropy": 0.008333964007241386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.53840637207031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03737973794341087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07512328773736954,
      "backward_entropy": 0.008294599396841866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.224510192871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03745025396347046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07496564090251923,
      "backward_entropy": 0.008255951638732637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.9703140258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037515703588724136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.074819415807724,
      "backward_entropy": 0.008217436926705497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.62786102294922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03758224472403526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07467012107372284,
      "backward_entropy": 0.00817976998431342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.0417594909668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03764526546001434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07452870905399323,
      "backward_entropy": 0.008142485682453428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.387001037597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03770622983574867,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07439185678958893,
      "backward_entropy": 0.013768319572721208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.92081642150879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037766531109809875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07425545156002045,
      "backward_entropy": 0.008071094751358032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.705810546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03782280907034874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07412850111722946,
      "backward_entropy": 0.00803638675383159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.59264373779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03787769004702568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07400497049093246,
      "backward_entropy": 0.008001942719732012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.844417572021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03793135657906532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07388406246900558,
      "backward_entropy": 0.013527745647089822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.05807876586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03798510506749153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07376144826412201,
      "backward_entropy": 0.007936085973467146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.84153747558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03804002329707146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07363615930080414,
      "backward_entropy": 0.007905171918017524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.16714859008789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03809930384159088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07349984347820282,
      "backward_entropy": 0.007875547877379827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.56092071533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03815691918134689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07336768507957458,
      "backward_entropy": 0.00784611382654735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.716087341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038215309381484985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07323352992534637,
      "backward_entropy": 0.007817506790161133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.4264907836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03827099874615669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07310598343610764,
      "backward_entropy": 0.00778913391487939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.883506774902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03832877799868584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07297271490097046,
      "backward_entropy": 0.007761987724474498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.04557037353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838622570037842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0728398859500885,
      "backward_entropy": 0.007735612136977059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.8331298828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03844550997018814,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.07270282506942749,
      "backward_entropy": 0.0989890354020255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.28458023071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038506507873535156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07256117463111877,
      "backward_entropy": 0.0076844362275941035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.53871154785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038564592599868774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07242700457572937,
      "backward_entropy": 0.007659643888473511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.183021545410156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03862672299146652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07228196412324905,
      "backward_entropy": 0.007636127727372306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.99925994873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03868919238448143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0721360445022583,
      "backward_entropy": 0.012860864400863647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.78071975708008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03875304386019707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07198648154735565,
      "backward_entropy": 0.007591089499848229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.75109100341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03881813585758209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07183368504047394,
      "backward_entropy": 0.007569333804505212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.431190490722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0388810895383358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07168680429458618,
      "backward_entropy": 0.007548511560474124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.73268127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03894433006644249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0715370923280716,
      "backward_entropy": 0.007529464151178088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.37127685546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039012178778648376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07137557864189148,
      "backward_entropy": 0.0075116945164544245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.25160598754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03907760977745056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.07122035324573517,
      "backward_entropy": 0.012620073344026293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.130550384521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03914080560207367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07107054442167282,
      "backward_entropy": 0.007477630461965289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.0001220703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03920196741819382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0709259957075119,
      "backward_entropy": 0.012546824557440621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.899410247802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03926558047533035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07077585160732269,
      "backward_entropy": 0.0074428633919784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.393674850463867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03932700678706169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07063160836696625,
      "backward_entropy": 0.007424070898975644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.2234115600586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03938440605998039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07049741595983505,
      "backward_entropy": 0.007405819637434823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.38686752319336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039447978138923645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07034742832183838,
      "backward_entropy": 0.007387826485293252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.75592041015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0395127609372139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07019410282373428,
      "backward_entropy": 0.00737019521849496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.808143615722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03957967832684517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.07003526389598846,
      "backward_entropy": 0.007353185542992183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.179290771484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039645347744226456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06987911462783813,
      "backward_entropy": 0.007337136992386409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.43558502197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03971089795231819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06972312182188034,
      "backward_entropy": 0.007321195943014962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.408361434936523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03978174552321434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06955356895923615,
      "backward_entropy": 0.0073055678180285865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.00009536743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03984866663813591,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06939414888620377,
      "backward_entropy": 0.012141810996191842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.54010772705078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03991636633872986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06923294067382812,
      "backward_entropy": 0.00727410614490509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.50144958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03998690843582153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0690644308924675,
      "backward_entropy": 0.007258340184177671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.25333023071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04005797207355499,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06889419257640839,
      "backward_entropy": 0.007246252681527819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.56299591064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04012949392199516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06872177869081497,
      "backward_entropy": 0.00723589797105108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.4990234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04020358622074127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06854242086410522,
      "backward_entropy": 0.007226995591606412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.29450988769531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04027675837278366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06836501508951187,
      "backward_entropy": 0.007219100104910987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.90139389038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04034898057579994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06819017231464386,
      "backward_entropy": 0.007210945976631982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.00572204589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040419310331344604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06802123785018921,
      "backward_entropy": 0.0072029099932738715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.65513610839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040490008890628815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06784982979297638,
      "backward_entropy": 0.011835301561014993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.30607604980469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040559977293014526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06767985969781876,
      "backward_entropy": 0.0071871717061315265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.112619400024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04062720015645027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06751774996519089,
      "backward_entropy": 0.007179601916245052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.047441482543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040689773857593536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06736814975738525,
      "backward_entropy": 0.0071717607123511174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.83400344848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04074924439191818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06722669303417206,
      "backward_entropy": 0.007163916315351214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.49760437011719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04081018641591072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0670807957649231,
      "backward_entropy": 0.007156323109354291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.77589225769043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04087452590465546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06692546606063843,
      "backward_entropy": 0.0071487682206290105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.16655349731445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040935516357421875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06677934527397156,
      "backward_entropy": 0.007140475724424634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.48470306396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04099782556295395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06662911176681519,
      "backward_entropy": 0.007133126258850098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.52018356323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04106436297297478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06646747887134552,
      "backward_entropy": 0.011524167444024767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.6038818359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04113265126943588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06630086153745651,
      "backward_entropy": 0.007117701428277152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.25967788696289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04119616374373436,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06614744663238525,
      "backward_entropy": 0.09900832176208496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.32344436645508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041256584227085114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06600174307823181,
      "backward_entropy": 0.007103656551667622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.12309646606445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0413171648979187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06585577130317688,
      "backward_entropy": 0.007096762635878154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.57909393310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04137798398733139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06570872664451599,
      "backward_entropy": 0.0070906079241207665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.14078903198242,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.041440073400735855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06555762887001038,
      "backward_entropy": 0.09900792155947004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.14332962036133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04150110110640526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0654095783829689,
      "backward_entropy": 0.007078806204455239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.47498321533203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04156329482793808,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.06525812298059464,
      "backward_entropy": 0.09900760650634766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.080167770385742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041627515107393265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06510138511657715,
      "backward_entropy": 0.0070653121386255536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.4223403930664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0416874885559082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06495630741119385,
      "backward_entropy": 0.007059851395232337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.88254165649414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04175088554620743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06479978561401367,
      "backward_entropy": 0.007056409759180886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.74570083618164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041812021285295486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06465055048465729,
      "backward_entropy": 0.007052133658102581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.01447296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04187119007110596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06450670957565308,
      "backward_entropy": 0.007047950157097408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.422945022583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04192960634827614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06436487287282944,
      "backward_entropy": 0.011042886546679906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.70100402832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04198319837450981,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06423673033714294,
      "backward_entropy": 0.007039640098810196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.673080444335938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04203673079609871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06410777568817139,
      "backward_entropy": 0.007037397474050522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.8939266204834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042086947709321976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06398855149745941,
      "backward_entropy": 0.007034890353679657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.54970169067383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04213523864746094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0638742744922638,
      "backward_entropy": 0.00703256470816476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.87879943847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042185038328170776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06375472247600555,
      "backward_entropy": 0.007032118205513273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.83296775817871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04223799332976341,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06362640857696533,
      "backward_entropy": 0.007030567952564785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.734806060791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042289912700653076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06350027024745941,
      "backward_entropy": 0.010831756251198905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.506210327148438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04234081506729126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06337663531303406,
      "backward_entropy": 0.007031375276190894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.890560150146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042389627546072006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06325939297676086,
      "backward_entropy": 0.007030893117189407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.542091369628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04244068264961243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06313560903072357,
      "backward_entropy": 0.007029895271573748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.43492126464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042491570115089417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0630129873752594,
      "backward_entropy": 0.01071738132408687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.208457946777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042543549090623856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06288671493530273,
      "backward_entropy": 0.007023982171501432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.08698081970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042593155056238174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.06276831030845642,
      "backward_entropy": 0.010647915303707123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.94806671142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04264089837670326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06265497207641602,
      "backward_entropy": 0.007013920162405286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.900068283081055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04269007220864296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06253679096698761,
      "backward_entropy": 0.007010613701173237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.563697814941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042738351970911026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.062421251088380814,
      "backward_entropy": 0.007006872445344925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.08828735351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042789001017808914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06229817867279053,
      "backward_entropy": 0.007004245051315853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.4346923828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042844727635383606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06216026842594147,
      "backward_entropy": 0.007002487778663635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.2925910949707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04289993271231651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06202482804656029,
      "backward_entropy": 0.0070004766540867945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.39278793334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042954619973897934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.061890069395303726,
      "backward_entropy": 0.01041771365063531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.41122055053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04301285743713379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06174461543560028,
      "backward_entropy": 0.006995200578655515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.83847427368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04306834936141968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06160789728164673,
      "backward_entropy": 0.006993062262024198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.81808090209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04312727972865105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061461351811885834,
      "backward_entropy": 0.006989986768790654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.19403076171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318838566541672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06130840629339218,
      "backward_entropy": 0.006987313606909343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.98915481567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04324937239289284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06115599721670151,
      "backward_entropy": 0.00698422800217356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.02431106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04331028461456299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.061003804206848145,
      "backward_entropy": 0.006981337709086282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.579959869384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04337312653660774,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060845911502838135,
      "backward_entropy": 0.0069787874817848206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.280269622802734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043435730040073395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06068861484527588,
      "backward_entropy": 0.006976883326257978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.74414825439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04349609836935997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.06053794175386429,
      "backward_entropy": 0.006975361279078892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.00568199157715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04355933889746666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060379091650247574,
      "backward_entropy": 0.006973244782005038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.43800163269043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04362030699849129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.060226716101169586,
      "backward_entropy": 0.006972102182252067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.57988357543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043678153306245804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0600837767124176,
      "backward_entropy": 0.006970856338739395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.18208312988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04373624548316002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05993987247347832,
      "backward_entropy": 0.0069708190858364105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.476112365722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04379640147089958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05978997051715851,
      "backward_entropy": 0.009984322956630163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.62606430053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04385465756058693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05964508652687073,
      "backward_entropy": 0.009959167667797633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.218605041503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391516000032425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05949283018708229,
      "backward_entropy": 0.006974882313183376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.3673095703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043973714113235474,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.059345848858356476,
      "backward_entropy": 0.009921005793980189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.757408142089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04403137043118477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.059201620519161224,
      "backward_entropy": 0.0069850534200668335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.856618881225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0440862774848938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05906558036804199,
      "backward_entropy": 0.00699035610471453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.927011489868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044139713048934937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05893366038799286,
      "backward_entropy": 0.006996266543865204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.49616813659668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04419267922639847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05880331993103027,
      "backward_entropy": 0.0070011961672987255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.04576873779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04424333944916725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05867987871170044,
      "backward_entropy": 0.00982791291815894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.67399597167969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04429631307721138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.058551304042339325,
      "backward_entropy": 0.009797241006578718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.33159065246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044350698590278625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058418914675712585,
      "backward_entropy": 0.007002336638314384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.27871322631836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04440458491444588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.058287590742111206,
      "backward_entropy": 0.0070006996393203735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.01933288574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0444607175886631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05815032869577408,
      "backward_entropy": 0.006997353264263698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.791927337646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044517114758491516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05801130086183548,
      "backward_entropy": 0.006995411855833871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.445003509521484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457468539476395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057868920266628265,
      "backward_entropy": 0.006994078201907021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.547529220581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04463507980108261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05771864950656891,
      "backward_entropy": 0.006991394928523472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.43689727783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04469433054327965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05757160857319832,
      "backward_entropy": 0.006989829242229462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.92422103881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044752273708581924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.057429440319538116,
      "backward_entropy": 0.00953971381698336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.67474365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04481096565723419,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.057286083698272705,
      "backward_entropy": 0.00697968208364078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.20622253417969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04487042501568794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05714030563831329,
      "backward_entropy": 0.006973882338830403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.63002014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04493149369955063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05699067562818527,
      "backward_entropy": 0.00696746792112078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.17498016357422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044995084404945374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05683264136314392,
      "backward_entropy": 0.006962757557630539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.438788414001465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04505523294210434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05668523162603378,
      "backward_entropy": 0.006959183407681329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.49665069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04511123150587082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0565507635474205,
      "backward_entropy": 0.006955366049494062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.27503204345703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04516824334859848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05641323700547218,
      "backward_entropy": 0.00928399179662977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.61405944824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04522615671157837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05627311393618584,
      "backward_entropy": 0.009249477514198847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.84391403198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04528578370809555,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.056128088384866714,
      "backward_entropy": 0.006944657436438969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.09567642211914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04534802585840225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055974945425987244,
      "backward_entropy": 0.006943154547895704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.960275650024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045405998826026917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05583467334508896,
      "backward_entropy": 0.00694274583033153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.58042526245117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04546196013689041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05570043995976448,
      "backward_entropy": 0.006942864507436752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.69668197631836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04551970213651657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05556152015924454,
      "backward_entropy": 0.009095707109996251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.007230758666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045575495809316635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05542812496423721,
      "backward_entropy": 0.006941864533083779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.846580505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04563014209270477,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05529949069023132,
      "backward_entropy": 0.009032479354313441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.37909698486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04568658769130707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05516611412167549,
      "backward_entropy": 0.006934475153684616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.27146339416504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04574095085263252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.055039774626493454,
      "backward_entropy": 0.006928267755678722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.388090133666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04579336941242218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05492018163204193,
      "backward_entropy": 0.006919751209872109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.43426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045844994485378265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05480342358350754,
      "backward_entropy": 0.006910079291888646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.097177505493164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045896925032138824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054685890674591064,
      "backward_entropy": 0.006900623440742493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.80690574645996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0459480956196785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05457109212875366,
      "backward_entropy": 0.006890078740460532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.732696533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599761590361595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0544620156288147,
      "backward_entropy": 0.006877810295139041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.88032913208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04604697600007057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05435220152139664,
      "backward_entropy": 0.006869948336056301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.408817291259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04609760269522667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.054239191114902496,
      "backward_entropy": 0.00863058865070343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.35453987121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04614565894007683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054134972393512726,
      "backward_entropy": 0.006849194743803569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.265602111816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046193499118089676,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.054030902683734894,
      "backward_entropy": 0.006839653210980552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.084053993225098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04624189808964729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053925417363643646,
      "backward_entropy": 0.006829837071044105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.045658111572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046288322657346725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05382516235113144,
      "backward_entropy": 0.006823237985372543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.91702651977539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04633277282118797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05373100936412811,
      "backward_entropy": 0.006816825164215905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.871370315551758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04637569934129715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05364048480987549,
      "backward_entropy": 0.006814291966812951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.35985565185547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04641712084412575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053554169833660126,
      "backward_entropy": 0.006813422909804753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.373491287231445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046460773795843124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05346071347594261,
      "backward_entropy": 0.006814133375883102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.523235321044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046505291014909744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05336540564894676,
      "backward_entropy": 0.0068127768380301336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.42485809326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046548884361982346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05327330902218819,
      "backward_entropy": 0.0068110280803271705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.861637115478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046591635793447495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.053183820098638535,
      "backward_entropy": 0.0068088918924331665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.229177474975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04663563892245293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05308987945318222,
      "backward_entropy": 0.006810234061309269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.607322692871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04667874798178673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05299902334809303,
      "backward_entropy": 0.006810774228402546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.312915802001953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672285541892052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05290535092353821,
      "backward_entropy": 0.006811182413782392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.199541091918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046765174716711044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05281738564372063,
      "backward_entropy": 0.006811060011386871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.84746551513672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04680607467889786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05273322016000748,
      "backward_entropy": 0.006813351064920425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.705467224121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04684903100132942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05264287069439888,
      "backward_entropy": 0.006815156234162194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.63829803466797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.046891361474990845,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.05255404859781265,
      "backward_entropy": 0.09899299485342843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.53021240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04693298786878586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05246751382946968,
      "backward_entropy": 0.006822501974446433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.297849655151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04697404056787491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.052382566034793854,
      "backward_entropy": 0.006826822246823992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.60007095336914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04701277241110802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05230467766523361,
      "backward_entropy": 0.006831269711256027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.787492752075195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047054510563611984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.0522187277674675,
      "backward_entropy": 0.00786511440362249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.697904586791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04709650203585625,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.052131276577711105,
      "backward_entropy": 0.00783662817307881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14242172241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047138575464487076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05204435810446739,
      "backward_entropy": 0.006838223763874599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.89829444885254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047178078442811966,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.05196579545736313,
      "backward_entropy": 0.007773016180310931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.4601411819458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04721888527274132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.051883190870285034,
      "backward_entropy": 0.007740846702030727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.437713623046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047258228063583374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05180499702692032,
      "backward_entropy": 0.006839381796973092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.918928146362305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04729604348540306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05173221230506897,
      "backward_entropy": 0.006837080099752971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.7049617767334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047336019575595856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051653407514095306,
      "backward_entropy": 0.006833165884017944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.84514808654785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047375116497278214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05157860368490219,
      "backward_entropy": 0.006824498730046409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.77549934387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04741480574011803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0515010692179203,
      "backward_entropy": 0.006819725036621094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753068923950195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047454822808504105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05142251402139664,
      "backward_entropy": 0.0068156155092375615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.582073211669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04749258980154991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051350608468055725,
      "backward_entropy": 0.006812551191874913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.946781158447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047530725598335266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05127819627523422,
      "backward_entropy": 0.006807684366192136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.15024185180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04757107421755791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.051198966801166534,
      "backward_entropy": 0.006803785583802632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.21408462524414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04761054366827011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05112345144152641,
      "backward_entropy": 0.006796267415796008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.260826110839844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04765033349394798,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.051046937704086304,
      "backward_entropy": 0.09898919718606132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.315202713012695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04769137501716614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05096619576215744,
      "backward_entropy": 0.006785317191055843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.143310546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04773423448204994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050880178809165955,
      "backward_entropy": 0.0067813290016991755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.83423614501953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047778718173503876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050789687782526016,
      "backward_entropy": 0.006777356777872358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.57451057434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047823887318372726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05069709196686745,
      "backward_entropy": 0.0067747096930231366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.275787830352783,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04786890745162964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05060465633869171,
      "backward_entropy": 0.006774575050388064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.31456756591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04791005700826645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05052522197365761,
      "backward_entropy": 0.006771201533930642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.255857467651367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047951508313417435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05044332146644592,
      "backward_entropy": 0.0067722781428268975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.126182556152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799294099211693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050361961126327515,
      "backward_entropy": 0.006772370742900031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.121981620788574,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048035990446805954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050276756286621094,
      "backward_entropy": 0.00677103762115751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.68741226196289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048076994717121124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.05019867420196533,
      "backward_entropy": 0.006766018058572497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.93014144897461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812179505825043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050111327320337296,
      "backward_entropy": 0.006754785776138306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.796072959899902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04816458374261856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.050029903650283813,
      "backward_entropy": 0.00674425544483321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.34280014038086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0482061542570591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04995322600007057,
      "backward_entropy": 0.0067308396100997925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.498855590820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04824891686439514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049874238669872284,
      "backward_entropy": 0.006712310016155243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.63773250579834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04829096049070358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04979633167386055,
      "backward_entropy": 0.006699708423444203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.706974029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04833126440644264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04972345381975174,
      "backward_entropy": 0.006688444742134639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.242545127868652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048373498022556305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04964413121342659,
      "backward_entropy": 0.00668214208313397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.162760734558105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048414912074804306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04956679046154022,
      "backward_entropy": 0.006678654679230281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.498498916625977,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048455510288476944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049491725862026215,
      "backward_entropy": 0.006676505186728069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.272613525390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04849710687994957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.049413323402404785,
      "backward_entropy": 0.006677267806870597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.887232780456543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048537056893110275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04933968931436539,
      "backward_entropy": 0.006679193781954902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.380672454833984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04857631400227547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04926803708076477,
      "backward_entropy": 0.0066818685403891975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.068997383117676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04861839488148689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04918740689754486,
      "backward_entropy": 0.006688694868768964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.79840087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04865875840187073,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0491119921207428,
      "backward_entropy": 0.006695952798639025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.553275108337402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048700153827667236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04903300851583481,
      "backward_entropy": 0.006706185106720243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.569623947143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04874052479863167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04895778000354767,
      "backward_entropy": 0.006713760218450001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.946609497070312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04878167808055878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048880625516176224,
      "backward_entropy": 0.006720612091677529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.753055572509766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04882444813847542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048798684030771255,
      "backward_entropy": 0.006728797618831907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.17336654663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04886702448129654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048717349767684937,
      "backward_entropy": 0.006737500961337771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.629110336303711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048911526799201965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048631682991981506,
      "backward_entropy": 0.006742128836257117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.959980010986328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04895378276705742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048553429543972015,
      "backward_entropy": 0.00674326132450785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.277666091918945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0489950068295002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04847830533981323,
      "backward_entropy": 0.006744499717439924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.179012298583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049036137759685516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048403069376945496,
      "backward_entropy": 0.006747015884944371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.717608451843262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0490771047770977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04832863062620163,
      "backward_entropy": 0.006749143557889121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.580391883850098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049116987735033035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048257842659950256,
      "backward_entropy": 0.006748732179403305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.509453773498535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04915611445903778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04818904027342796,
      "backward_entropy": 0.006749798144612994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.763827800750732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919447749853134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04812249168753624,
      "backward_entropy": 0.006751056760549545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.376415252685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04923076182603836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048061106353998184,
      "backward_entropy": 0.006755411624908447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.749204635620117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04926639795303345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.048002250492572784,
      "backward_entropy": 0.006756877260548728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.950786590576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929991438984871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047949809581041336,
      "backward_entropy": 0.006756394037178585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658932209014893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04933236166834831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047900572419166565,
      "backward_entropy": 0.006755066769463676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.688517093658447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04936308041214943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04785630851984024,
      "backward_entropy": 0.006753324397972652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.763416290283203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049391936510801315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047818537801504135,
      "backward_entropy": 0.0067462628441197535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.280561447143555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04942033067345619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04778144508600235,
      "backward_entropy": 0.006741068192890712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664594650268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04945056885480881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04773857444524765,
      "backward_entropy": 0.00673806614109448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.537295818328857,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04948020353913307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04769705608487129,
      "backward_entropy": 0.006737535553319114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.380523681640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04950816556811333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04766120761632919,
      "backward_entropy": 0.006733054029090064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.81947135925293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04953379184007645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04763293266296387,
      "backward_entropy": 0.006724179855414799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.463229179382324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049560546875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04760158807039261,
      "backward_entropy": 0.006714272711958204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40369701385498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04958711937069893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04756990075111389,
      "backward_entropy": 0.0067090434687478205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.365593433380127,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04961360618472099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047537315636873245,
      "backward_entropy": 0.0067093696977411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.546293258666992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049638815224170685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0475088506937027,
      "backward_entropy": 0.006706949855600085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.351594924926758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496661551296711,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04747404158115387,
      "backward_entropy": 0.006706439490829196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.267562866210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04969391971826553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04743760824203491,
      "backward_entropy": 0.005592874650444303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.22186279296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04972124844789505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04740222543478012,
      "backward_entropy": 0.006710594253880637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.182945251464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04974817857146263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04736775532364845,
      "backward_entropy": 0.006714058241673878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.13856029510498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049777042120695114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04732764512300491,
      "backward_entropy": 0.0067186855844088966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.986855506896973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04980667680501938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04728592187166214,
      "backward_entropy": 0.006720869668892452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.113328456878662,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049837369471788406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047240424901247025,
      "backward_entropy": 0.006727080792188644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.78274917602539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986583814024925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047200947999954224,
      "backward_entropy": 0.0067341189299310955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961530685424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04989568144083023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04715617746114731,
      "backward_entropy": 0.006748562412602561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.589439392089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04992469772696495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047114331275224686,
      "backward_entropy": 0.006760135293006897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80758285522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049955449998378754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.047067370265722275,
      "backward_entropy": 0.006773089723927634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.55742359161377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04998556151986122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04702174291014671,
      "backward_entropy": 0.006787806749343872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.642230987548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05001632496714592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04697486013174057,
      "backward_entropy": 0.006799878818648202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.503206253051758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004678666591644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0469297356903553,
      "backward_entropy": 0.006807198481900352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.25029468536377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05007733777165413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046883903443813324,
      "backward_entropy": 0.006816182817731585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.398307800292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010875687003136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04683502018451691,
      "backward_entropy": 0.006828102150133678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.742184162139893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050140004605054855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0467868335545063,
      "backward_entropy": 0.006838969354118619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.572359085083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016963928937912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04674314334988594,
      "backward_entropy": 0.006849379943949836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.675554275512695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05020156875252724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04669300466775894,
      "backward_entropy": 0.006860114634037018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.870311737060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050234902650117874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046638548374176025,
      "backward_entropy": 0.006872874285493579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34515380859375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05026854947209358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0465836226940155,
      "backward_entropy": 0.006883656339985984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.661859512329102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0503009557723999,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046532586216926575,
      "backward_entropy": 0.006891801953315735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.844780921936035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050333887338638306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04647986590862274,
      "backward_entropy": 0.006900836846658162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.196950912475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05036427825689316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04643414542078972,
      "backward_entropy": 0.006909503468445369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.406558990478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05039593577384949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046385377645492554,
      "backward_entropy": 0.006915740668773651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3861517906188965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05042815953493118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04633476585149765,
      "backward_entropy": 0.006922845861741475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.468219757080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05045883357524872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0462878942489624,
      "backward_entropy": 0.006933064333030156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.361989974975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050491634756326675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046234577894210815,
      "backward_entropy": 0.006944632955959865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.934284687042236,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05052626132965088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.046176619827747345,
      "backward_entropy": 0.006955503353050777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.970307350158691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050559476017951965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04612315446138382,
      "backward_entropy": 0.006963026310716357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.795102596282959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05059304088354111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04606863856315613,
      "backward_entropy": 0.0069710809205259594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709870338439941,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050625432282686234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04601731151342392,
      "backward_entropy": 0.006978792271443776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.659862995147705,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05065691098570824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04596789553761482,
      "backward_entropy": 0.00698861586196082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6261086463928223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050687555223703384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04592021182179451,
      "backward_entropy": 0.007000425032206944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.529621124267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05071597546339035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04587821289896965,
      "backward_entropy": 0.005083361906664712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.170896053314209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05074654519557953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045830607414245605,
      "backward_entropy": 0.00702478044799396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.99845027923584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05077511444687843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04578990861773491,
      "backward_entropy": 0.007028224212782723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.360431671142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05080348625779152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04575037583708763,
      "backward_entropy": 0.007027986858572278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.282989501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050832442939281464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045709751546382904,
      "backward_entropy": 0.00702550049339022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.186447143554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05086192116141319,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04566788673400879,
      "backward_entropy": 0.0070210205657141546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.158330917358398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0508919358253479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04562465846538544,
      "backward_entropy": 0.00701662791626794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64810562133789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050922196358442307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04558175802230835,
      "backward_entropy": 0.007007754806961332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.92651653289795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05095222219824791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04553934186697006,
      "backward_entropy": 0.006999577794756208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1914215087890625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05098279193043709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045495204627513885,
      "backward_entropy": 0.006992891430854797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.78287124633789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05101233348250389,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045453958213329315,
      "backward_entropy": 0.006985640951565334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.065608024597168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051042377948760986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045411400496959686,
      "backward_entropy": 0.006978617714984077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.687151908874512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05107330530881882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04536754637956619,
      "backward_entropy": 0.006967160318578992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.438349485397339,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05110427364706993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04532458633184433,
      "backward_entropy": 0.004764400954757418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.541428565979004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05113283172249794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045287810266017914,
      "backward_entropy": 0.006936513951846531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149384498596191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05116158351302147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04525187239050865,
      "backward_entropy": 0.00691627391747066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.551432609558105,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051190152764320374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04521619528532028,
      "backward_entropy": 0.006897609148706708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6063008308410645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0512198880314827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04517766833305359,
      "backward_entropy": 0.0068795936448233464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02384090423584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05124794319272041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045143671333789825,
      "backward_entropy": 0.006862224212714604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.026961326599121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051275577396154404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.045111656188964844,
      "backward_entropy": 0.006840494062219348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.900125503540039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05130411684513092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04507619887590408,
      "backward_entropy": 0.006826600325959069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.905946731567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05133219063282013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04504304751753807,
      "backward_entropy": 0.006808534264564514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.534245014190674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05136096477508545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04500734806060791,
      "backward_entropy": 0.006795066275766918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.407445907592773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05138913914561272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04497240483760834,
      "backward_entropy": 0.006788165441581181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.450290203094482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05141589045524597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04494103416800499,
      "backward_entropy": 0.0067830873387200495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.49247407913208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051440976560115814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04491518437862396,
      "backward_entropy": 0.006772451102733612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.339354515075684,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051465362310409546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04489172250032425,
      "backward_entropy": 0.0067591848117964605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12674221396446228,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05148863419890404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04487112909555435,
      "backward_entropy": 0.006747482078416007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.31722354888916,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05150984972715378,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04485499858856201,
      "backward_entropy": 0.006742249642099653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24237060546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05153011903166771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044841744005680084,
      "backward_entropy": 0.006735245564154216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.459983825683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051549844443798065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04482930898666382,
      "backward_entropy": 0.006732262670993805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.214301109313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05157299339771271,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04480759799480438,
      "backward_entropy": 0.00422302633523941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.228168487548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0515960268676281,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04478566348552704,
      "backward_entropy": 0.0067380523043019435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13515853881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05162014812231064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04476074501872063,
      "backward_entropy": 0.006744930786745889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.129080772399902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05164475739002228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04473384469747543,
      "backward_entropy": 0.0067564696073532104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.081435203552246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051668938249349594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04470806568861008,
      "backward_entropy": 0.006768144134964261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13317734003067017,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051693838089704514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044681061059236526,
      "backward_entropy": 0.006776477609361921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0451178550720215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05171644315123558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04465949162840843,
      "backward_entropy": 0.0067878429378782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.905552864074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05173864588141441,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04463939368724823,
      "backward_entropy": 0.006796577679259437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.628621101379395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05176173523068428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044617533683776855,
      "backward_entropy": 0.006802193288292203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.730541229248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05178765207529068,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0445886105298996,
      "backward_entropy": 0.006806700357369014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.816901206970215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05181436985731125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044557180255651474,
      "backward_entropy": 0.006813938596418926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.674955368041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051840804517269135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04452717304229736,
      "backward_entropy": 0.006817051342555455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.75126838684082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.051867496222257614,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04449548199772835,
      "backward_entropy": 0.006825870701244899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.880382537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05189371481537819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04446423798799515,
      "backward_entropy": 0.00683921469109399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36357307434082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05191865563392639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044436246156692505,
      "backward_entropy": 0.006852557084390095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.402982711791992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05194466561079025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044404465705156326,
      "backward_entropy": 0.006871509764875684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.803705930709839,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05197102203965187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044372789561748505,
      "backward_entropy": 0.006884215665715081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.417893409729004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05199605971574783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04434449225664139,
      "backward_entropy": 0.0068961626717022485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.547976016998291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052021127194166183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04431620240211487,
      "backward_entropy": 0.006907004330839429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6765594482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05204567313194275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04428896680474281,
      "backward_entropy": 0.00691861765725272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.031503677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05206935480237007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044262923300266266,
      "backward_entropy": 0.006935622010912214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226773738861084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052093930542469025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04423443228006363,
      "backward_entropy": 0.003979044301169259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.220239639282227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052118539810180664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04420604556798935,
      "backward_entropy": 0.0069676946316446576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.09889030456543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052145592868328094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044171981513500214,
      "backward_entropy": 0.006979023771626609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.326107501983643,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05217255651950836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044137854129076004,
      "backward_entropy": 0.006991322019270488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.315783500671387,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.052198752760887146,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.044105567038059235,
      "backward_entropy": 0.09901048455919538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.945894718170166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05222409591078758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044075820595026016,
      "backward_entropy": 0.007012055388518742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.276104927062988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0522494874894619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04404560849070549,
      "backward_entropy": 0.007021487823554448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.198580741882324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05227618291974068,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.044011734426021576,
      "backward_entropy": 0.007032633892127446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.135014057159424,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052304040640592575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04397464171051979,
      "backward_entropy": 0.007045267948082515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0817999839782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05233099311590195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04393979161977768,
      "backward_entropy": 0.007056985582624163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.058721542358398,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05235719308257103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043906599283218384,
      "backward_entropy": 0.007069321083171027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.022279739379883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05238262936472893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043875306844711304,
      "backward_entropy": 0.0070806874760559625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.12215518951416,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05240736901760101,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04384575039148331,
      "backward_entropy": 0.09901681968144008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4139187335968018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05243426561355591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04381176829338074,
      "backward_entropy": 0.0070948973298072815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.507254123687744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05245933681726456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043783463537693024,
      "backward_entropy": 0.007091009191104344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8747148513793945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052484314888715744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043755270540714264,
      "backward_entropy": 0.007087329136473792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.272106170654297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05250861868262291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0437285378575325,
      "backward_entropy": 0.0070842648191111425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.373143672943115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05253579840064049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04369501397013664,
      "backward_entropy": 0.0070793186979634425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.49041748046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05256258323788643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043662674725055695,
      "backward_entropy": 0.007073199110371726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.77655029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052591390907764435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043625637888908386,
      "backward_entropy": 0.007066224302564349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.621626377105713,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05261882394552231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04359280318021774,
      "backward_entropy": 0.007054202790771212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12308523058891296,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05264562740921974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043560221791267395,
      "backward_entropy": 0.007050252918686185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07391357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052669841796159744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04353387653827667,
      "backward_entropy": 0.0070484791483197895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.008950710296631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05269521847367287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043504223227500916,
      "backward_entropy": 0.0070482417941093445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.445548057556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05272064730525017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043473877012729645,
      "backward_entropy": 0.007052401346819741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.511490821838379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05274660512804985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04344189167022705,
      "backward_entropy": 0.007058804588658469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.980164527893066,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0527716688811779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043412379920482635,
      "backward_entropy": 0.007063401596886771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8194355964660645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05279618129134178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04338555037975311,
      "backward_entropy": 0.007059829043490546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.350027084350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05282079800963402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043357688933610916,
      "backward_entropy": 0.007061223366430828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.21237850189209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05284494534134865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04333013296127319,
      "backward_entropy": 0.007067529218537467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51369571685791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052869390696287155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04330258443951607,
      "backward_entropy": 0.007069706384624753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.053694725036621,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05289487913250923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0432724729180336,
      "backward_entropy": 0.007072401366063527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.268293857574463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05292074382305145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043241340667009354,
      "backward_entropy": 0.007075367229325431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.922125816345215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05294568091630936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04321271553635597,
      "backward_entropy": 0.007076695029224668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.935789108276367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05297110229730606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043182626366615295,
      "backward_entropy": 0.007080732711723873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120454788208008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052996568381786346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.043153293430805206,
      "backward_entropy": 0.007079153188637325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.402952671051025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05302135646343231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04312507435679436,
      "backward_entropy": 0.007081350045544761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.749852657318115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053046148270368576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04309619963169098,
      "backward_entropy": 0.007088141249758857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4451287984848022,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05307109281420708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04306761175394058,
      "backward_entropy": 0.007090665400028229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.285006999969482,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053094081580638885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0430438406765461,
      "backward_entropy": 0.007092354020902089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10610580444336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05311714857816696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04301943629980087,
      "backward_entropy": 0.007097101637295314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184248447418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05314188823103905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04299088567495346,
      "backward_entropy": 0.007102725761277335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.682194471359253,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05316659063100815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042961835861206055,
      "backward_entropy": 0.007112120943410056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8726556301116943,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053189802914857864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04293686896562576,
      "backward_entropy": 0.0071177541145256585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.410888433456421,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053212426602840424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042913101613521576,
      "backward_entropy": 0.007124321801321847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.2595853805542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05323314666748047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04289449378848076,
      "backward_entropy": 0.0071260567222322735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.97918176651001,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05325651913881302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04287036508321762,
      "backward_entropy": 0.007123613463980811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.181626319885254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053279951214790344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042845286428928375,
      "backward_entropy": 0.00712562831384795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.967946529388428,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0533037967979908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04281920939683914,
      "backward_entropy": 0.007127951830625534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.70284366607666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053327254951000214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04279468208551407,
      "backward_entropy": 0.007126394659280777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.289916753768921,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05334999039769173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04277178645133972,
      "backward_entropy": 0.007125088146754673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3091894388198853,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05337110906839371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04275226965546608,
      "backward_entropy": 0.007126391998359135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4089808464050293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05339061841368675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04273664578795433,
      "backward_entropy": 0.0033083935933453695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.550534248352051,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053409501910209656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04272165149450302,
      "backward_entropy": 0.007132561079093388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704898357391357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053428325802087784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042706072330474854,
      "backward_entropy": 0.007142587964023862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.359163284301758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05344745144248009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042689740657806396,
      "backward_entropy": 0.007152355675186429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5494349002838135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05346596986055374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04267413914203644,
      "backward_entropy": 0.007166120622839246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.72212028503418,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05348405987024307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042660221457481384,
      "backward_entropy": 0.0071749139044966015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962443828582764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05350308120250702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04264385253190994,
      "backward_entropy": 0.007184887038809913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.704079627990723,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0535237155854702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04262441396713257,
      "backward_entropy": 0.007190250392471041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906975746154785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053545743227005005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04260079562664032,
      "backward_entropy": 0.007201484271458217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.402256965637207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05356971174478531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04257301241159439,
      "backward_entropy": 0.007210322788783482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.732121467590332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0535927452147007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042547814548015594,
      "backward_entropy": 0.00721580588391849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4113287925720215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05361765995621681,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.04251829907298088,
      "backward_entropy": 0.0032199565321207047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.280660629272461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05364202708005905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04249049723148346,
      "backward_entropy": 0.007223834948880332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.265531301498413,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05366555228829384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04246450960636139,
      "backward_entropy": 0.007226844983441489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.386240482330322,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053688231855630875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042440593242645264,
      "backward_entropy": 0.007228748074599675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.266872882843018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05371146649122238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04241623356938362,
      "backward_entropy": 0.007225122834954943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.196791172027588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053734857589006424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042391616851091385,
      "backward_entropy": 0.007220447595630374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.151601552963257,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053757891058921814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042368024587631226,
      "backward_entropy": 0.0072150879672595435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1359100341796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05377954617142677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04234777390956879,
      "backward_entropy": 0.007208205759525299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.111612319946289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053801413625478745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04232735186815262,
      "backward_entropy": 0.007199014936174665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.031488418579102,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05382290855050087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04230820760130882,
      "backward_entropy": 0.007186708173581532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.942002296447754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05384429544210434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04228893667459488,
      "backward_entropy": 0.007176492363214493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10095623880624771,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.053866539150476456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.042267680168151855,
      "backward_entropy": 0.09900731699807304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0120930671691895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053886692970991135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04225073754787445,
      "backward_entropy": 0.007162494318825858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0232694149017334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0539059154689312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042235590517520905,
      "backward_entropy": 0.007159637553351266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8611373901367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05392414703965187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04222290217876434,
      "backward_entropy": 0.007155621690409524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0724036693572998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05394257605075836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04220954328775406,
      "backward_entropy": 0.007153260388544628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8156514167785645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053959548473358154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04219980537891388,
      "backward_entropy": 0.007148472326142448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.800022602081299,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05397676303982735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04218956083059311,
      "backward_entropy": 0.007144036569765636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.708517074584961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05399411544203758,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04217926040291786,
      "backward_entropy": 0.09900072642735072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.607229232788086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054011907428503036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042168620973825455,
      "backward_entropy": 0.007127903934035983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08414626121520996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05403047055006027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04215582460165024,
      "backward_entropy": 0.007121672587735313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3155388832092285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054047416895627975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042145926505327225,
      "backward_entropy": 0.0071207338145801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6391398906707764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05406612902879715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04213181883096695,
      "backward_entropy": 0.007122459156172616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8580968379974365,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0540848933160305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0421176478266716,
      "backward_entropy": 0.007124042936733791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.687472343444824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05410278961062431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04210536926984787,
      "backward_entropy": 0.007126574005399432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5277397632598877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0541205033659935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04209301620721817,
      "backward_entropy": 0.007132951702390399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7904175519943237,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05413850024342537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04207970201969147,
      "backward_entropy": 0.0071421414613723755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.29615592956543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05415583774447441,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04206741601228714,
      "backward_entropy": 0.007154356688261032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4933183193206787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05417407676577568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04205242916941643,
      "backward_entropy": 0.007171522293772016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.084624767303467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05419221892952919,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.042038291692733765,
      "backward_entropy": 0.0028471877532345907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.040259838104248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05421145260334015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04202155023813248,
      "backward_entropy": 0.007196828722953796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7419652938842773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054231658577919006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.042002465575933456,
      "backward_entropy": 0.007210657000541687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3635761737823486,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054250795394182205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04198583960533142,
      "backward_entropy": 0.007223323519740786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.918816566467285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05426977202296257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04196997731924057,
      "backward_entropy": 0.007232525518962315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4691107273101807,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05428962782025337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04195217415690422,
      "backward_entropy": 0.007241188415459224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.682228922843933,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.054309017956256866,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.041935041546821594,
      "backward_entropy": 0.09901035683495658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.016971111297607,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05432738736271858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04192019999027252,
      "backward_entropy": 0.007261897836412702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.757200241088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05434614419937134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04190467298030853,
      "backward_entropy": 0.00726916321686336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.931382179260254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054365675896406174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041887685656547546,
      "backward_entropy": 0.007273842181478228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8682844638824463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054385535418987274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04186997935175896,
      "backward_entropy": 0.007278229509081159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1147046089172363,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0544058233499527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041850678622722626,
      "backward_entropy": 0.007285859967981066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.351386785507202,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054425835609436035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04183224216103554,
      "backward_entropy": 0.007291200969900403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0299530029296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054445087909698486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04181577265262604,
      "backward_entropy": 0.007293382393462318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.256939172744751,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054464295506477356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041799068450927734,
      "backward_entropy": 0.007297580263444355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9604403972625732,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05448310449719429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04178261011838913,
      "backward_entropy": 0.007305718958377838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8179078102111816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054501973092556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04176555946469307,
      "backward_entropy": 0.007316977317844119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.509876012802124,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05451939254999161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04175174981355667,
      "backward_entropy": 0.0073264459414141515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2158212661743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05453599616885185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04173960164189339,
      "backward_entropy": 0.007335661777428218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1978864669799805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05455220863223076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041728466749191284,
      "backward_entropy": 0.007342688739299774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.141972780227661,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054568056017160416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04171828180551529,
      "backward_entropy": 0.007347650293792997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5141406059265137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05458379536867142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041707754135131836,
      "backward_entropy": 0.007355761847325734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4463613033294678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05460018292069435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04169563949108124,
      "backward_entropy": 0.007364099047013691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4375981092453003,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054617367684841156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041680943220853806,
      "backward_entropy": 0.007378110396010535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.134533882141113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0546337254345417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041668035089969635,
      "backward_entropy": 0.007390940827982766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7685320377349854,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05465082824230194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04165417701005936,
      "backward_entropy": 0.007397882108177457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0724267959594727,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054667770862579346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04164115712046623,
      "backward_entropy": 0.007400234895093101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.321291923522949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05468422919511795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04162932187318802,
      "backward_entropy": 0.0074005478194781715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.06134033203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05470127612352371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041615813970565796,
      "backward_entropy": 0.007403491330998284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.633115768432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05471767485141754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04160434380173683,
      "backward_entropy": 0.007400907043899808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.609320640563965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473417788743973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04159219563007355,
      "backward_entropy": 0.00739997997879982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.427773356437683,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054750774055719376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04157968610525131,
      "backward_entropy": 0.007400320576769965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.976604700088501,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05476606264710426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041571445763111115,
      "backward_entropy": 0.007388853601046971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3533761501312256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05478094145655632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04156429320573807,
      "backward_entropy": 0.007375277578830719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.157036781311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05479498580098152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041559331119060516,
      "backward_entropy": 0.007358684603657041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7487993240356445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05480961501598358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041553132236003876,
      "backward_entropy": 0.007342169327395303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8741888999938965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05482509359717369,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04154553264379501,
      "backward_entropy": 0.007323805242776871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.846516489982605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05484037846326828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041537702083587646,
      "backward_entropy": 0.007310385682753154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.21750009059906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05485555902123451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04152935743331909,
      "backward_entropy": 0.007303302309342793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6054301261901855,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054870400577783585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04152074083685875,
      "backward_entropy": 0.0073057008641106745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2601916790008545,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05488612875342369,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041510388255119324,
      "backward_entropy": 0.007306223469121116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.390007257461548,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05490103363990784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04150214046239853,
      "backward_entropy": 0.0073048195668629235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9289586544036865,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05491603910923004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04149380326271057,
      "backward_entropy": 0.007303090499980109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.860708236694336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054931577295064926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04148422181606293,
      "backward_entropy": 0.007302374712058476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2157551050186157,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0549478717148304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041472163051366806,
      "backward_entropy": 0.0073090121150016785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7184443473815918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054963283240795135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04146231710910797,
      "backward_entropy": 0.007313506943838937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7645604610443115,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05497854948043823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041452206671237946,
      "backward_entropy": 0.0073221426989351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2428982257843018,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05499326065182686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041444096714258194,
      "backward_entropy": 0.007324349135160446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.76265549659729,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.055008187890052795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.04143521189689636,
      "backward_entropy": 0.09900680610111781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.142737627029419,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0550236813724041,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.041424866765737534,
      "backward_entropy": 0.09900726590837751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.262596845626831,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055038485676050186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04141588881611824,
      "backward_entropy": 0.007344009088618415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.677110195159912,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05505407974123955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04140543192625046,
      "backward_entropy": 0.007349820541484016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1715383529663086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055069129914045334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04139664024114609,
      "backward_entropy": 0.007351316511631012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.626627206802368,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05508412420749664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041388243436813354,
      "backward_entropy": 0.007350105260099683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.071173071861267,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05509969964623451,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04137807711958885,
      "backward_entropy": 0.007352638457502637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5957168340682983,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05511470139026642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041368547827005386,
      "backward_entropy": 0.007360061896698815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.062211036682129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05512933433055878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04135990887880325,
      "backward_entropy": 0.007366174033709935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5848267078399658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05514413118362427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041350603103637695,
      "backward_entropy": 0.00737429569874491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.061704158782959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515778064727783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04134399816393852,
      "backward_entropy": 0.00738005552973066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5846307873725891,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05517082288861275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04133868217468262,
      "backward_entropy": 0.007385138422250748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9509241580963135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055182818323373795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041335947811603546,
      "backward_entropy": 0.0073866040578910285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0262699127197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055195994675159454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04133029654622078,
      "backward_entropy": 0.007391351674284253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.959883213043213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05520867183804512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04132549464702606,
      "backward_entropy": 0.0073969268373080665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4531266689300537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055221669375896454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041319653391838074,
      "backward_entropy": 0.007404296525887081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.404179573059082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05523472651839256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041313014924526215,
      "backward_entropy": 0.0074164654527391705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5378127694129944,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05524833872914314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04130525141954422,
      "backward_entropy": 0.007427748292684555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5056273937225342,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05526096373796463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04129958897829056,
      "backward_entropy": 0.0074378640523978645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8798338174819946,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055272895842790604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0412948876619339,
      "backward_entropy": 0.007451557687350682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8648505210876465,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05528518185019493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04128919914364815,
      "backward_entropy": 0.007465575954743794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.849536418914795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05529777333140373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041282691061496735,
      "backward_entropy": 0.007479862443038395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8619567155838013,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05531063303351402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04127545282244682,
      "backward_entropy": 0.007494289427995682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.14237117767334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055323526263237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04126854985952377,
      "backward_entropy": 0.007503769227436611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.508006751537323,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05533767491579056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04125891998410225,
      "backward_entropy": 0.007512531110218593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.76621675491333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05535074695944786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04125162959098816,
      "backward_entropy": 0.007519587342228208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7965742349624634,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055364131927490234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.0412430465221405,
      "backward_entropy": 0.007530636021069118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7523643970489502,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05537746846675873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.041234999895095825,
      "backward_entropy": 0.007536987108843667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9675365090370178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05539094656705856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04122641682624817,
      "backward_entropy": 0.007544000766107014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7296240329742432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05540335178375244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04122145473957062,
      "backward_entropy": 0.0075389498046466285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3360775709152222,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05541591718792915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04121600091457367,
      "backward_entropy": 0.007534087768622807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2795830965042114,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05542803183197975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04121214896440506,
      "backward_entropy": 0.00752321577497891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04066493734717369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055440064519643784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04120798036456108,
      "backward_entropy": 0.007515258022717067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8549496531486511,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055451083928346634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.04120533540844917,
      "backward_entropy": 0.007512670542512622,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.3582352435961367,
    "avg_log_Z": -0.05471969235688448,
    "success_rate": 1.0,
    "avg_reward": 84.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.05,
      "1": 0.01,
      "2": 0.94
    },
    "avg_forward_entropy": 0.041649407632648947,
    "avg_backward_entropy": 0.011871021895536354,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}