{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13640512228012086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.1367715835571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.22740173339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303157885869345,
      "backward_entropy": 0.13649591207504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.6006317138672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302770455678305,
      "backward_entropy": 0.13650166988372803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.31565856933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00019996849005110562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830235719680786,
      "backward_entropy": 0.13642301559448242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.9459228515625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0002992681984324008,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301926056543985,
      "backward_entropy": 0.13684368133544922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.48617553710938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0003992185811512172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301471074422201,
      "backward_entropy": 0.13644034862518312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 194.03712463378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0004991218447685242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300994237263998,
      "backward_entropy": 0.13644907474517823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 177.17575073242188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0005990491481497884,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300493558247885,
      "backward_entropy": 0.13691405057907105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.90919494628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0006982163758948445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299973011016846,
      "backward_entropy": 0.1364659547805786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.6957244873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007970629376359284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829944054285685,
      "backward_entropy": 0.1364739179611206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.6478729248047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0008955318480730057,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829888423283895,
      "backward_entropy": 0.1369813561439514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.216064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009952584514394403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18298306067784628,
      "backward_entropy": 0.1364895820617676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.9890899658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0010944328969344497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297706047693887,
      "backward_entropy": 0.13649728298187255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.3609619140625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0011939671821892262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297078212102255,
      "backward_entropy": 0.13704702854156495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.91262817382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001293728593736887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829642653465271,
      "backward_entropy": 0.1365125894546509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.65133666992188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0013937389012426138,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18295749028523764,
      "backward_entropy": 0.13708982467651368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.22084045410156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0014953159261494875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829504370689392,
      "backward_entropy": 0.13711128234863282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.15158081054688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0015975250862538815,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18294310569763184,
      "backward_entropy": 0.1371323823928833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.89491271972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0017009532311931252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293551603953043,
      "backward_entropy": 0.136590838432312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1267852783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0018058918649330735,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292762835820517,
      "backward_entropy": 0.13717467784881593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.58496856689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.001909913495182991,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291950225830078,
      "backward_entropy": 0.13660489320755004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.34011840820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002007867442443967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829113761583964,
      "backward_entropy": 0.13656785488128662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.7433624267578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021082914900034666,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829029122988383,
      "backward_entropy": 0.1372342586517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.3343048095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0022099700290709734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828941305478414,
      "backward_entropy": 0.13658210039138793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.8321533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002311323070898652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828854282697042,
      "backward_entropy": 0.13662660121917725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.7697296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002414408605545759,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828764279683431,
      "backward_entropy": 0.13663256168365479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.50137329101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002514714142307639,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18286732832590738,
      "backward_entropy": 0.13660287857055664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.5789337158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0026135374791920185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18285803000132242,
      "backward_entropy": 0.13664140701293945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.2072296142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0027129226364195347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18284849325815836,
      "backward_entropy": 0.13664529323577881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1524658203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0028111659921705723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283883730570474,
      "backward_entropy": 0.1366487503051758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.7361602783203,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0029091062024235725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18282892306645712,
      "backward_entropy": 0.1373821020126343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.83297729492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0030095423571765423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18281867106755575,
      "backward_entropy": 0.13665542602539063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.22438049316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031063745263963938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828083594640096,
      "backward_entropy": 0.13663583993911743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.7796173095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003203190164640546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827978491783142,
      "backward_entropy": 0.1366403579711914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.48167419433594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003300076350569725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278712034225464,
      "backward_entropy": 0.13744856119155885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.59945678710938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0033979425206780434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277613321940103,
      "backward_entropy": 0.13666454553604127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.61001586914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0034944515209645033,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276492754618326,
      "backward_entropy": 0.13665306568145752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6637725830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003588989144191146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827536622683207,
      "backward_entropy": 0.13665637969970704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.91578674316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0036804976407438517,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274233738581339,
      "backward_entropy": 0.13750910758972168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9664306640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0037737966049462557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273069461186728,
      "backward_entropy": 0.13666157722473143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.9296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00386754609644413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18271881341934204,
      "backward_entropy": 0.13667140007019044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.86366271972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003961704205721617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827066739400228,
      "backward_entropy": 0.1366724729537964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.97769165039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040540555492043495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826944351196289,
      "backward_entropy": 0.1375636100769043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.9891357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004147914703935385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182681938012441,
      "backward_entropy": 0.13667101860046388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.30433654785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004240184556692839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266944090525308,
      "backward_entropy": 0.13667334318161012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.25904846191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004333918448537588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826567848523458,
      "backward_entropy": 0.1366732358932495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.81942749023438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0044267973862588406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264396985371908,
      "backward_entropy": 0.1366725206375122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.56289672851562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00451668119058013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826310952504476,
      "backward_entropy": 0.1376276731491089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 159.05557250976562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004608703777194023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18261786301930746,
      "backward_entropy": 0.13666956424713134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.29638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004699057899415493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18260453144709268,
      "backward_entropy": 0.13666765689849852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.75892639160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004791355691850185,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18259080251057944,
      "backward_entropy": 0.13766448497772216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 257.4699401855469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0048862118273973465,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257659673690796,
      "backward_entropy": 0.137677001953125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.43472290039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0049855150282382965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256179491678873,
      "backward_entropy": 0.13666462898254395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.4518280029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005081388168036938,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825470527013143,
      "backward_entropy": 0.13770265579223634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.4976806640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005177489947527647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825320521990458,
      "backward_entropy": 0.13666248321533203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.45596313476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005274751223623753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825166940689087,
      "backward_entropy": 0.1366851210594177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.93824768066406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005373039282858372,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250093857447305,
      "backward_entropy": 0.13774003982543945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.76904296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005467580631375313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248520294825235,
      "backward_entropy": 0.13665791749954223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.33143615722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005560106597840786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246938784917197,
      "backward_entropy": 0.13668617010116577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.8961639404297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005654230713844299,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18245315551757812,
      "backward_entropy": 0.13777453899383546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.90855407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.005746577400714159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824368635813395,
      "backward_entropy": 0.13664839267730713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.8431854248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005841610953211784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182420015335083,
      "backward_entropy": 0.13668510913848878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.81736755371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005939444061368704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240276972452799,
      "backward_entropy": 0.13668529987335204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.27230072021484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006039307452738285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238496780395508,
      "backward_entropy": 0.13664135932922364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.9761962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006134228780865669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18236738443374634,
      "backward_entropy": 0.13668520450592042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.05615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00622847443446517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823496421178182,
      "backward_entropy": 0.13668446540832518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.2037811279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00631972448900342,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233197927474976,
      "backward_entropy": 0.13785214424133302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.03855895996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006412460934370756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231376012166342,
      "backward_entropy": 0.1366260528564453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 192.0812530517578,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006503431126475334,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1822956403096517,
      "backward_entropy": 0.137872314453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.8331298828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006594925187528133,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18227712313334146,
      "backward_entropy": 0.13661574125289916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 158.3433380126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0066871801391243935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18225830793380737,
      "backward_entropy": 0.13661046028137208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.56031799316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006777631584554911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822393536567688,
      "backward_entropy": 0.13667373657226561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.55673217773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006868788506835699,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822201410929362,
      "backward_entropy": 0.13667142391204834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.45999145507812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00696307048201561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220057090123495,
      "backward_entropy": 0.13659141063690186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.03262329101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007056599948555231,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18218080202738443,
      "backward_entropy": 0.13666722774505616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.58226013183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007149070501327515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182160754998525,
      "backward_entropy": 0.13657715320587158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.33914184570312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007241191808134317,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18214050928751627,
      "backward_entropy": 0.13794870376586915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.30606079101562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007331736385822296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821202039718628,
      "backward_entropy": 0.13656105995178222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.67825317382812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007420875132083893,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820998191833496,
      "backward_entropy": 0.13796591758728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.6421356201172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007512346375733614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1820788780848185,
      "backward_entropy": 0.1365439176559448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.40818786621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007603306323289871,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18205765883127847,
      "backward_entropy": 0.1365349769592285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.5678253173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007693616207689047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18203614155451456,
      "backward_entropy": 0.13652522563934327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.1197509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007783554494380951,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18201432625452676,
      "backward_entropy": 0.13663634061813354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 175.29519653320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007874345406889915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819920539855957,
      "backward_entropy": 0.13663146495819092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.87229919433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007964526303112507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18196950356165567,
      "backward_entropy": 0.13649311065673828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.93246459960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008053169585764408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18194683392842612,
      "backward_entropy": 0.1364811420440674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.42906188964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00814644806087017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819231907526652,
      "backward_entropy": 0.1366153836250305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.4547119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008236327208578587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818996469179789,
      "backward_entropy": 0.13660929203033448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.88639831542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008329777978360653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18187532822291055,
      "backward_entropy": 0.1366037130355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.22935485839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008415032178163528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18185190359751383,
      "backward_entropy": 0.1365963339805603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.1493377685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008501548320055008,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18182786305745444,
      "backward_entropy": 0.1365889549255371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.70970916748047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008590774610638618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18180318673451742,
      "backward_entropy": 0.13640506267547609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7478485107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008675739169120789,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18177823225657144,
      "backward_entropy": 0.13657376766204835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.49900817871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008761020377278328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18175284067789713,
      "backward_entropy": 0.1365654230117798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.8202667236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00884103961288929,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18172770738601685,
      "backward_entropy": 0.13655574321746827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.5411834716797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008923234418034554,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18170185883839926,
      "backward_entropy": 0.13808995485305786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.82057189941406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00900357961654663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18167593081792197,
      "backward_entropy": 0.13632298707962037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.33247375488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009088479913771152,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18164889017740884,
      "backward_entropy": 0.13630642890930175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.6405487060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009169338271021843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18162192900975546,
      "backward_entropy": 0.1362878441810608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.607666015625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00924817007035017,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18159488836924234,
      "backward_entropy": 0.13811185359954833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.55836486816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009325189515948296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18156770865122476,
      "backward_entropy": 0.13624746799468995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.269287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009404266253113747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18153969446818033,
      "backward_entropy": 0.13622655868530273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.41361236572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009483015164732933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18151114384333292,
      "backward_entropy": 0.13620538711547853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.76251983642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009554129093885422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18148340781529745,
      "backward_entropy": 0.13645541667938232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6751251220703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009623258374631405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814557115236918,
      "backward_entropy": 0.13813304901123047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.7265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00969439186155796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18142720063527426,
      "backward_entropy": 0.1364261031150818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.2923126220703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009766167029738426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18139817317326865,
      "backward_entropy": 0.13641107082366943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.04224395751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009838643483817577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18136866887410483,
      "backward_entropy": 0.1363958239555359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.91110229492188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009908925741910934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18133918444315592,
      "backward_entropy": 0.13814785480499267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.5723114013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009981061331927776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18130886554718018,
      "backward_entropy": 0.13603124618530274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.36094665527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010056368075311184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18127753337224325,
      "backward_entropy": 0.1363478422164917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.5279541015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010126417502760887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181246817111969,
      "backward_entropy": 0.13633058071136475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.08021545410156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010191372595727444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812166372934977,
      "backward_entropy": 0.13631186485290528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.53269958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01025457214564085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18118627866109213,
      "backward_entropy": 0.13629236221313476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.39254760742188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010317551903426647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18115546305974325,
      "backward_entropy": 0.1358874797821045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.74974060058594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010388711467385292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18112260103225708,
      "backward_entropy": 0.13585808277130126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.0304412841797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010460525751113892,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18108914295832315,
      "backward_entropy": 0.13817121982574462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.33837127685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010531388223171234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1810553272565206,
      "backward_entropy": 0.13817405700683594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.5116424560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010600403882563114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18102129300435385,
      "backward_entropy": 0.13619487285614013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 189.11474609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010672111064195633,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18098624547322592,
      "backward_entropy": 0.13817923069000243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.9085922241211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010747214779257774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18094988663991293,
      "backward_entropy": 0.13570495843887329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.9627685546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010816864669322968,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18091422319412231,
      "backward_entropy": 0.13818458318710328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.75457000732422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010883680544793606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18087885777155557,
      "backward_entropy": 0.1356383204460144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.57467651367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010948623530566692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18084331353505453,
      "backward_entropy": 0.1356028437614441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.91592407226562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011019285768270493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18080592155456543,
      "backward_entropy": 0.13556883335113526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.63327026367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011094948276877403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18076682090759277,
      "backward_entropy": 0.13553566932678224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011174006387591362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18072648843129477,
      "backward_entropy": 0.13601982593536377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.60035705566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011253033764660358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18068552017211914,
      "backward_entropy": 0.13547003269195557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.32811737060547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011338725686073303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18064232667287192,
      "backward_entropy": 0.1359756588935852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.28961944580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011420450173318386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18059929211934408,
      "backward_entropy": 0.13540271520614625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.76748657226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011498604901134968,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18055641651153564,
      "backward_entropy": 0.13820877075195312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.8304214477539,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011582063511013985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18051151434580484,
      "backward_entropy": 0.13821179866790773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.20730590820312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01166099589318037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18046722809473673,
      "backward_entropy": 0.13528766632080078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.57861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011741035617887974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18042190869649252,
      "backward_entropy": 0.13524739742279052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.12667846679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011822530068457127,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18037559588750204,
      "backward_entropy": 0.13582749366760255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.87227630615234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011902552098035812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18032916386922201,
      "backward_entropy": 0.13580100536346434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.2076416015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0119795436039567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18028285106023154,
      "backward_entropy": 0.1357731819152832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.7824249267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012058116495609283,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18023542563120523,
      "backward_entropy": 0.13574520349502564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6737823486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012135304510593414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18018774191538492,
      "backward_entropy": 0.1350358247756958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.47898864746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012213620357215405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18013864755630493,
      "backward_entropy": 0.13498939275741578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.942138671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012290360406041145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18008891741434732,
      "backward_entropy": 0.13565657138824463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.7269287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012371640652418137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800370216369629,
      "backward_entropy": 0.13489348888397218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.5859603881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012455889955163002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17998361587524414,
      "backward_entropy": 0.13484838008880615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.2500457763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012536720372736454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17993042866388956,
      "backward_entropy": 0.13480100631713868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.93299865722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012617221102118492,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17987648646036783,
      "backward_entropy": 0.13475182056427001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.0936737060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012700692750513554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17982091506322226,
      "backward_entropy": 0.1347035527229309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.19438171386719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012785041704773903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179764191309611,
      "backward_entropy": 0.13465399742126466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012865740805864334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17970756689707437,
      "backward_entropy": 0.13460102081298828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.38514709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012946267612278461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17965014775594076,
      "backward_entropy": 0.1354041576385498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.03573608398438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013022253289818764,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1795934041341146,
      "backward_entropy": 0.13824470043182374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.3322296142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013097541406750679,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17953632275263467,
      "backward_entropy": 0.13533148765563965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.65766143798828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013171499595046043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17947882413864136,
      "backward_entropy": 0.1343716025352478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.5939178466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013241455890238285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17942182223002115,
      "backward_entropy": 0.1352536678314209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.0943603515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013315252959728241,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17936259508132935,
      "backward_entropy": 0.13424695730209352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.9615936279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01338940393179655,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1793025334676107,
      "backward_entropy": 0.13824424743652344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.52127075195312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0134627316147089,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17924189567565918,
      "backward_entropy": 0.13824405670166015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.85989379882812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013535448350012302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791807015736898,
      "backward_entropy": 0.13405225276947022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.14894104003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013607506640255451,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791188915570577,
      "backward_entropy": 0.13398520946502684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.4698944091797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013681534677743912,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17905519406000772,
      "backward_entropy": 0.13824317455291749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.49742126464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013760427013039589,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17898865540822348,
      "backward_entropy": 0.13824350833892823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.0490264892578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013845345936715603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1789189577102661,
      "backward_entropy": 0.13378500938415527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.58761596679688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01393262017518282,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17884733279546103,
      "backward_entropy": 0.13824598789215087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.406639099121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014017782174050808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17877562840779623,
      "backward_entropy": 0.13365635871887208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.31349182128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014092338271439075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1787079175313314,
      "backward_entropy": 0.1347985625267029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.66220092773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014166424050927162,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17863972981770834,
      "backward_entropy": 0.13824622631072997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.67086029052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01424113567918539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17857027053833008,
      "backward_entropy": 0.13344281911849976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.08038330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01431193295866251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1785015066464742,
      "backward_entropy": 0.13336641788482667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.09580993652344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014379698783159256,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17843341827392578,
      "backward_entropy": 0.13824357986450195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 187.2441864013672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014448889531195164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17836372057596842,
      "backward_entropy": 0.13320914506912232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.9352798461914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014521926641464233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17829116185506186,
      "backward_entropy": 0.13312950134277343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.65608215332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014592914842069149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17821858326594034,
      "backward_entropy": 0.13444268703460693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.1884765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014661820605397224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17814590533574423,
      "backward_entropy": 0.13296222686767578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.40095520019531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014722898602485657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17807616790135702,
      "backward_entropy": 0.1328708291053772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.50704193115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014783262275159359,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17800599336624146,
      "backward_entropy": 0.13426551818847657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.68878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014842621050775051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17793520291646323,
      "backward_entropy": 0.13420333862304687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.4080810546875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01490133348852396,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1778637965520223,
      "backward_entropy": 0.13822562694549562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.74609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014959226362407207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.177791694800059,
      "backward_entropy": 0.1324893355369568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.10569763183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0150228813290596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17771593729654947,
      "backward_entropy": 0.13401226997375487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 202.674072265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015088623389601707,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17763825257619223,
      "backward_entropy": 0.1382171630859375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.35781860351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015160133130848408,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1775564750035604,
      "backward_entropy": 0.13388631343841553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.0550537109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015232821926474571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17747310797373453,
      "backward_entropy": 0.13210556507110596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.41310119628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015308122150599957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1773874560991923,
      "backward_entropy": 0.13200865983963012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.1851043701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015380032360553741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.177302877108256,
      "backward_entropy": 0.13190896511077882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.6984100341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015455704182386398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17721499999364218,
      "backward_entropy": 0.13180797100067138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.42937469482422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015532286837697029,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1771256923675537,
      "backward_entropy": 0.13820834159851075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.5069580078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0156031409278512,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17703827222188315,
      "backward_entropy": 0.13349286317825318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.0870361328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01566760055720806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17695353428522745,
      "backward_entropy": 0.13341693878173827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.45823669433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015736879780888557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1768649419148763,
      "backward_entropy": 0.13334124088287352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.9229278564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015805935487151146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17677533626556396,
      "backward_entropy": 0.1332659125328064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.9466094970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015878545120358467,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1766831080118815,
      "backward_entropy": 0.13319264650344848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.7170181274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01595073565840721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1765899658203125,
      "backward_entropy": 0.13103139400482178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.87635803222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016019634902477264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17649783690770468,
      "backward_entropy": 0.13091214895248413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.1942138671875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016086667776107788,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1764054298400879,
      "backward_entropy": 0.1381837844848633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.75457000732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01615520566701889,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1763108174006144,
      "backward_entropy": 0.13287723064422607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.31513977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016221927478909492,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1762161652247111,
      "backward_entropy": 0.13279316425323487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.88485717773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016287151724100113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.176121195157369,
      "backward_entropy": 0.13040179014205933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.13929748535156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016355929896235466,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17602290709813437,
      "backward_entropy": 0.13816676139831544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.61959075927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01642633229494095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17592243353525797,
      "backward_entropy": 0.13253551721572876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.5572509765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016495399177074432,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1758220394452413,
      "backward_entropy": 0.13000805377960206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.96314239501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01656327396631241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17572168509165445,
      "backward_entropy": 0.13235960006713868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.31291961669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01662658527493477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17562323808670044,
      "backward_entropy": 0.12973458766937257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.8701400756836,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01668865606188774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17552419503529867,
      "backward_entropy": 0.1381455421447754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.05625915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016748249530792236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17542568842569986,
      "backward_entropy": 0.13207279443740844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.63399505615234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016810350120067596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1753242015838623,
      "backward_entropy": 0.12928941249847412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.30958557128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016870371997356415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17522279421488443,
      "backward_entropy": 0.13187284469604493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.29381561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01692977547645569,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17511979738871256,
      "backward_entropy": 0.12897899150848388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.37216186523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016985610127449036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1750180721282959,
      "backward_entropy": 0.13166202306747438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.92007446289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017044518142938614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17491267124811807,
      "backward_entropy": 0.1315556526184082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 120.0484390258789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017106328159570694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1748037338256836,
      "backward_entropy": 0.1284925103187561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.12899780273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017167378216981888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17469394207000732,
      "backward_entropy": 0.13134102821350097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.41604614257812,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017231011763215065,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17458095153172812,
      "backward_entropy": 0.13809220790863036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.70664978027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017296848818659782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17446553707122803,
      "backward_entropy": 0.1280005693435669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.94808959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01736813597381115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17434497674306235,
      "backward_entropy": 0.13101475238800048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.97640991210938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.017439503222703934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17422314484914145,
      "backward_entropy": 0.1380797505378723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.50836181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017515258863568306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17409640550613403,
      "backward_entropy": 0.1307966709136963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.48976135253906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01758929155766964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17397002379099527,
      "backward_entropy": 0.12735278606414796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.09403991699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017666112631559372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17384006579717,
      "backward_entropy": 0.12718758583068848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.26116943359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01774085871875286,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17371050516764322,
      "backward_entropy": 0.1380655884742737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.44271850585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01781071163713932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17358388503392538,
      "backward_entropy": 0.1303349494934082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.81297302246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01788083277642727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17345581452051798,
      "backward_entropy": 0.12666022777557373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.0040740966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017953932285308838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1733236312866211,
      "backward_entropy": 0.1300877094268799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.59674835205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01802673190832138,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17319009701410928,
      "backward_entropy": 0.12629127502441406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.1983642578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018096113577485085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17305795351664224,
      "backward_entropy": 0.1260979175567627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.90028381347656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018167603760957718,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17292300860087076,
      "backward_entropy": 0.13803446292877197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.19200134277344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018234550952911377,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17279112339019775,
      "backward_entropy": 0.12956588268280028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.731201171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018302371725440025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1726574500401815,
      "backward_entropy": 0.13802223205566405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.2472686767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01837184652686119,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17252043883005777,
      "backward_entropy": 0.12929186820983887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.52748107910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018445083871483803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1723791758219401,
      "backward_entropy": 0.12511532306671141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.41796112060547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018519440665841103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17223501205444336,
      "backward_entropy": 0.12491145133972167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 180.7678985595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018592314794659615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17209132512410483,
      "backward_entropy": 0.12887282371520997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.29679870605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01866973005235195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17194201548894247,
      "backward_entropy": 0.12449880838394164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.72294616699219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018743189051747322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17179473241170248,
      "backward_entropy": 0.1242823600769043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.6009521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018810005858540535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17165237665176392,
      "backward_entropy": 0.12842464447021484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.43511962890625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01887519657611847,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17150948445002237,
      "backward_entropy": 0.13797385692596437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.3508758544922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01893932744860649,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17136605580647787,
      "backward_entropy": 0.12357125282287598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.01304626464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019004305824637413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17122050126393637,
      "backward_entropy": 0.12792638540267945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.39823913574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01907818578183651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17106546958287558,
      "backward_entropy": 0.12776365280151367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.6729736328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019149020314216614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17091262340545654,
      "backward_entropy": 0.12285308837890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.98616027832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019221942871809006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17075689633687338,
      "backward_entropy": 0.12261556386947632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.85379028320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019289856776595116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17060470581054688,
      "backward_entropy": 0.1272558569908142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.76637268066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01935826614499092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17045054833094278,
      "backward_entropy": 0.12707872390747071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.93937683105469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019428519532084465,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17029313246409097,
      "backward_entropy": 0.13791148662567138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.84030151367188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01949792169034481,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1701359748840332,
      "backward_entropy": 0.1267208933830261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.7975311279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019567960873246193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16997758547465006,
      "backward_entropy": 0.12133452892303467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 178.485107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019638190045952797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16981943448384604,
      "backward_entropy": 0.12106828689575196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.64102172851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019713522866368294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.169654647509257,
      "backward_entropy": 0.12617318630218505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.4219207763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01978813111782074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1694885492324829,
      "backward_entropy": 0.12598540782928466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.80156707763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019863879308104515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1693194309870402,
      "backward_entropy": 0.12025301456451416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.84302520751953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019931402057409286,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1691580812136332,
      "backward_entropy": 0.13785390853881835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.8522186279297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.019995039328932762,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16900010903676352,
      "backward_entropy": 0.13784220218658447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.15000915527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020059289410710335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16883949438730875,
      "backward_entropy": 0.12517547607421875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.82484436035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020127419382333755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1686728596687317,
      "backward_entropy": 0.12496476173400879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.13377380371094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020197391510009766,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16850701967875162,
      "backward_entropy": 0.1378091812133789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.67718505859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020267894491553307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16833311319351196,
      "backward_entropy": 0.12454054355621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.414306640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02033553645014763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16816139221191406,
      "backward_entropy": 0.11811243295669556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.4506378173828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020405495539307594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16798814137776694,
      "backward_entropy": 0.11779762506484985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.1630401611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020476147532463074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16781270503997803,
      "backward_entropy": 0.11748124361038208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.9340057373047,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020548831671476364,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16763291756312051,
      "backward_entropy": 0.1377602458000183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.81973266601562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020621292293071747,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16745140155156454,
      "backward_entropy": 0.13774991035461426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.24308013916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02069864794611931,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.167262593905131,
      "backward_entropy": 0.12321387529373169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.92093658447266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020768985152244568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16708076000213623,
      "backward_entropy": 0.13772987127304076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.4866943359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02083483524620533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1669031778971354,
      "backward_entropy": 0.11580783128738403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.31825256347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020903635770082474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1667214035987854,
      "backward_entropy": 0.12248528003692627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.91383361816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020972641184926033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16653619209925333,
      "backward_entropy": 0.11510001420974732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.33118438720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02104364149272442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16634660959243774,
      "backward_entropy": 0.12198294401168823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.8906021118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021113630384206772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16615723570187887,
      "backward_entropy": 0.11437487602233887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.69343566894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021182455122470856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16596798102060953,
      "backward_entropy": 0.12146300077438354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.30509948730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02124595455825329,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1657854119936625,
      "backward_entropy": 0.12119131088256836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.21930694580078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021305695176124573,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16560630003611246,
      "backward_entropy": 0.12091138362884521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.11847686767578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021364163607358932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16542824109395346,
      "backward_entropy": 0.11284568309783935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.05501556396484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021420691162347794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1652506391207377,
      "backward_entropy": 0.12033767700195312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 174.76046752929688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021474985405802727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16507605711619058,
      "backward_entropy": 0.11203956604003906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.68336486816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021536219865083694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1648906668027242,
      "backward_entropy": 0.11164401769638062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.11670684814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02160034514963627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16469988226890564,
      "backward_entropy": 0.11124539375305176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 144.07022094726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021660970523953438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16451317071914673,
      "backward_entropy": 0.1191704511642456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.60006713867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021724704653024673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16432265440622965,
      "backward_entropy": 0.11043081283569336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.86883544921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021791376173496246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1641241510709127,
      "backward_entropy": 0.11002618074417114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.6527557373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021858884021639824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1639246940612793,
      "backward_entropy": 0.11828458309173584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.4733123779297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02192922867834568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1637213627497355,
      "backward_entropy": 0.13745943307876587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.06382751464844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022001737728714943,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16351398825645447,
      "backward_entropy": 0.13744754791259767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.3049774169922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02207140624523163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16330963373184204,
      "backward_entropy": 0.10838499069213867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.16065979003906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022141648456454277,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16310334205627441,
      "backward_entropy": 0.1374199151992798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 128.01454162597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02221241593360901,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16289550065994263,
      "backward_entropy": 0.13740758895874022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.91087341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02228366769850254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16268588105837503,
      "backward_entropy": 0.10707781314849854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.20079040527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022355763241648674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16247465213139853,
      "backward_entropy": 0.10663846731185914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.19600677490234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022430039942264557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16225957870483398,
      "backward_entropy": 0.1062007188796997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.32554626464844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022503452375531197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620460251967112,
      "backward_entropy": 0.10576400756835938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.2212371826172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022575564682483673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16183343529701233,
      "backward_entropy": 0.10531880855560302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.65005493164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022653216496109962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16161271929740906,
      "backward_entropy": 0.10488181114196778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 185.85302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022734439000487328,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16138706604639688,
      "backward_entropy": 0.1044505000114441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.5092010498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022821759805083275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16115264097849527,
      "backward_entropy": 0.10402711629867553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.59050750732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022911135107278824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16091489791870117,
      "backward_entropy": 0.11396267414093017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.41445922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022994522005319595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16068577766418457,
      "backward_entropy": 0.11363760232925416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.66619873046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023080244660377502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16045247515042624,
      "backward_entropy": 0.10269583463668823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.3635711669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02316022291779518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16022709012031555,
      "backward_entropy": 0.10222150087356567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.3487319946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023241238668560982,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15999903281529745,
      "backward_entropy": 0.11262397766113282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.15985107421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02331659197807312,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1597781479358673,
      "backward_entropy": 0.10123227834701538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.69328308105469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023392321541905403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15955821673075357,
      "backward_entropy": 0.10072575807571411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.66276550292969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02346852980554104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15933539470036825,
      "backward_entropy": 0.10022063255310058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.65997314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023541679605841637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15911664565404257,
      "backward_entropy": 0.11116704940795899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.40521240234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023610519245266914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1589052379131317,
      "backward_entropy": 0.09917402267456055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.18045043945312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02368003875017166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15869181354840597,
      "backward_entropy": 0.09863529205322266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.41172790527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0237521231174469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15847435593605042,
      "backward_entropy": 0.11001108884811402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.99188232421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023827793076634407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1582512060801188,
      "backward_entropy": 0.10962717533111573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.06562042236328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023904899135231972,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15802489717801413,
      "backward_entropy": 0.13720352649688722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.7721939086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023977354168891907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1578057607014974,
      "backward_entropy": 0.09647197723388672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.65623474121094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02404862456023693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1575880448023478,
      "backward_entropy": 0.13717353343963623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.01200103759766,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02411792241036892,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15737128257751465,
      "backward_entropy": 0.1371543288230896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.8632354736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024184683337807655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571582555770874,
      "backward_entropy": 0.09470861554145812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.95867919921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024254364892840385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15694111585617065,
      "backward_entropy": 0.09411404132843018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.50874328613281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02432655170559883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15672033031781515,
      "backward_entropy": 0.09352338314056396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.39520263671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024399718269705772,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15649942557017008,
      "backward_entropy": 0.10629842281341553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.55812072753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02446766383945942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15628776947657266,
      "backward_entropy": 0.0923568069934845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.30860900878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02452985756099224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1560837229092916,
      "backward_entropy": 0.10541197061538696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.3206024169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02459484338760376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15587511658668518,
      "backward_entropy": 0.10496108531951905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.78945922851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024664541706442833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15565968553225198,
      "backward_entropy": 0.10451792478561402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.82051086425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024736810475587845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1554408073425293,
      "backward_entropy": 0.10407636165618897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.62013244628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02480308711528778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15523119767506918,
      "backward_entropy": 0.10361578464508056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.0667266845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02488015778362751,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15500583251317343,
      "backward_entropy": 0.10317772626876831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.8378143310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02496134489774704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15477661291758218,
      "backward_entropy": 0.10275013446807861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.9148406982422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025046227499842644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15454402565956116,
      "backward_entropy": 0.08758721947669983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.9685821533203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025135552510619164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15430613358815512,
      "backward_entropy": 0.0870465874671936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.8351821899414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025225721299648285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15406825145085654,
      "backward_entropy": 0.08650295734405518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.75678253173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0253136083483696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15383513768513998,
      "backward_entropy": 0.1010785698890686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.66123962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025397660210728645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1536086102326711,
      "backward_entropy": 0.08539285659790039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.89310455322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025477755814790726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15338780482610068,
      "backward_entropy": 0.10018975734710693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.0709457397461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02555852383375168,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1531679630279541,
      "backward_entropy": 0.13693222999572754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.15542221069336,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0256387609988451,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15294846892356873,
      "backward_entropy": 0.13692350387573243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.35724639892578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02571299858391285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15273958444595337,
      "backward_entropy": 0.0987929344177246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.93819427490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025788024067878723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1525301734606425,
      "backward_entropy": 0.09831379055976867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.15675354003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025863386690616608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15232014656066895,
      "backward_entropy": 0.09783129692077637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.98188018798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025935988873243332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15211417277654013,
      "backward_entropy": 0.09733821153640747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.81883239746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02600444108247757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1519144574801127,
      "backward_entropy": 0.0968311071395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.88710021972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02607584558427334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15170969565709433,
      "backward_entropy": 0.0963314414024353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.33615112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02614698000252247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15150741736094156,
      "backward_entropy": 0.0793139636516571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.08888244628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026222463697195053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15129963556925455,
      "backward_entropy": 0.07870821356773376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.756591796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02629537135362625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15109652280807495,
      "backward_entropy": 0.07809057235717773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.96697998046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02636442705988884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15090018510818481,
      "backward_entropy": 0.0774613618850708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.4581298828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026436811313033104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15070050954818726,
      "backward_entropy": 0.09379882216453553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.29935455322266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02650812827050686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1505022943019867,
      "backward_entropy": 0.07622028589248657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.22288513183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02657528594136238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1503103772799174,
      "backward_entropy": 0.09274094104766846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.88411712646484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026644477620720863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1501173973083496,
      "backward_entropy": 0.09220938682556153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.84360885620117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026712968945503235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14992618560791016,
      "backward_entropy": 0.0916680097579956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.77119064331055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026776589453220367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14974308013916016,
      "backward_entropy": 0.07361100316047668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.89288330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026836352422833443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14956717689832053,
      "backward_entropy": 0.07295365333557129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.70157623291016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02689252607524395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1493983268737793,
      "backward_entropy": 0.07229801416397094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.364219665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026946529746055603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14923330148061117,
      "backward_entropy": 0.07163268327713013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.47890090942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026997169479727745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14907397826512656,
      "backward_entropy": 0.08882992267608643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.54228210449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027044668793678284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14891968170801798,
      "backward_entropy": 0.07027616500854492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 129.36911010742188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027092857286334038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14876513679822287,
      "backward_entropy": 0.0876459538936615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.92224884033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027146194130182266,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14860333998998007,
      "backward_entropy": 0.08706942200660706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.31360626220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027197234332561493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14844460288683572,
      "backward_entropy": 0.06825479865074158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.87849426269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027248544618487358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14828646183013916,
      "backward_entropy": 0.08588271141052246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.46073150634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027303211390972137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1481243371963501,
      "backward_entropy": 0.0852923035621643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.83637237548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02736104093492031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14795962969462076,
      "backward_entropy": 0.06624730825424194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.52098846435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027418524026870728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14779583613077799,
      "backward_entropy": 0.06559368968009949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.23538589477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02747378684580326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14763553937276205,
      "backward_entropy": 0.08353363275527954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.87606048583984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02752513252198696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14748146136601767,
      "backward_entropy": 0.06424771547317505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.35209655761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027579931542277336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1473236878712972,
      "backward_entropy": 0.06357488632202149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.32718658447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02763606607913971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14716504017512003,
      "backward_entropy": 0.06290483474731445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.1211395263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02769392542541027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14700579643249512,
      "backward_entropy": 0.08112047910690308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.88542938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02775995060801506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14683789014816284,
      "backward_entropy": 0.08055848479270936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.44122314453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027824826538562775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14667299389839172,
      "backward_entropy": 0.07999091148376465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.39366912841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02788751758635044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14651350180308023,
      "backward_entropy": 0.06040283441543579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027953363955020905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14635220170021057,
      "backward_entropy": 0.07886620759963989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.99304962158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028016719967126846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1461959977944692,
      "backward_entropy": 0.0783032476902008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.97894287109375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02807747758924961,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14604397614796957,
      "backward_entropy": 0.05861738920211792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.0609359741211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02813899889588356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1458915968736013,
      "backward_entropy": 0.07714167833328248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.52838134765625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028200432658195496,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14574140310287476,
      "backward_entropy": 0.1360177993774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.29438018798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028259525075554848,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14559508363405863,
      "backward_entropy": 0.0759729027748108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.40245056152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028315356001257896,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14545464515686035,
      "backward_entropy": 0.05616718530654907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.95416259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028376080095767975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1453091005484263,
      "backward_entropy": 0.05556730031967163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.0556411743164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02843162603676319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14517194032669067,
      "backward_entropy": 0.05495594739913941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.02539825439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02848907560110092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1450329820315043,
      "backward_entropy": 0.054358839988708496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.42340850830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028549296781420708,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14489136139551798,
      "backward_entropy": 0.0730620265007019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.86264419555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028607552871108055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14475351572036743,
      "backward_entropy": 0.05316550135612488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.65247344970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028658919036388397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14462498823801676,
      "backward_entropy": 0.07188584804534912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.44140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028715986758470535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14449119567871094,
      "backward_entropy": 0.07130656242370606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.82561492919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02877643145620823,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1443548301855723,
      "backward_entropy": 0.07074024677276611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.06060791015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028836024925112724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14421993494033813,
      "backward_entropy": 0.05077308416366577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.22749710083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028897015377879143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.144084761540095,
      "backward_entropy": 0.06958826184272766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.99878692626953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028954563662409782,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14395525058110556,
      "backward_entropy": 0.13576867580413818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.4577407836914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029013516381382942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14382511377334595,
      "backward_entropy": 0.048993974924087524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.78937530517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02907399833202362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14369461933771768,
      "backward_entropy": 0.04841160476207733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.69381713867188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029137879610061646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14356239636739096,
      "backward_entropy": 0.04785129427909851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.83989715576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029199784621596336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14343416690826416,
      "backward_entropy": 0.04728816151618957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.69580841064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02926298789680004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1433059573173523,
      "backward_entropy": 0.0467318594455719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.42243957519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029324088245630264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14318140347798666,
      "backward_entropy": 0.046174240112304685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.46427154541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02938416600227356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1430608630180359,
      "backward_entropy": 0.06505203247070312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.473777770996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02944718860089779,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14293766021728516,
      "backward_entropy": 0.04509877860546112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.5463638305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029505616053938866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14282172918319702,
      "backward_entropy": 0.06395376324653626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.565547943115234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029567552730441093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14270373185475668,
      "backward_entropy": 0.044046080112457274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.50590515136719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029624812304973602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14259245991706848,
      "backward_entropy": 0.0435214102268219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.9088134765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02968621253967285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14247886339823404,
      "backward_entropy": 0.062331199645996094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.918365478515625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029744088649749756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1423697272936503,
      "backward_entropy": 0.04251261353492737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.6758804321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02979869581758976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14226454496383667,
      "backward_entropy": 0.041985884308815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.09134674072266,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.029855670407414436,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14215819040934244,
      "backward_entropy": 0.1356182336807251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.92033004760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029916543513536453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14204972982406616,
      "backward_entropy": 0.06017482876777649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.64507293701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029972998425364494,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14194726943969727,
      "backward_entropy": 0.059646505117416385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.77409362792969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030034830793738365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14184053738911948,
      "backward_entropy": 0.04000594019889832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.35271453857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03009711392223835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14173553387324014,
      "backward_entropy": 0.039539453387260434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.77203369140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030160510912537575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14163013299306235,
      "backward_entropy": 0.03906547725200653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.12908172607422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030232174322009087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14151924848556519,
      "backward_entropy": 0.03862806558609009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.1114501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030306002125144005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14140795667966208,
      "backward_entropy": 0.0381904274225235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.759765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03037567250430584,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14130218823750815,
      "backward_entropy": 0.05671405792236328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.49624633789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030447624623775482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14119567473729452,
      "backward_entropy": 0.056238341331481936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.25904846191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030517159029841423,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14109293619791666,
      "backward_entropy": 0.03685357868671417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.7303924560547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030589023604989052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1409894327322642,
      "backward_entropy": 0.03641299307346344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.09880828857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030667534098029137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14088177680969238,
      "backward_entropy": 0.035985136032104494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.923831939697266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030742917209863663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1407785415649414,
      "backward_entropy": 0.0355509102344513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.51020812988281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03081238828599453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14068190256754556,
      "backward_entropy": 0.035107359290122986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.46324920654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030879907310009003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14058889945348105,
      "backward_entropy": 0.0534076452255249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.950439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03094557859003544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14049863815307617,
      "backward_entropy": 0.03422947824001312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.58782958984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031009957194328308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14041093985239664,
      "backward_entropy": 0.05246373414993286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.521751403808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031076285988092422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.140323539574941,
      "backward_entropy": 0.03339338302612305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.39521026611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03114141710102558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1402389407157898,
      "backward_entropy": 0.03299497663974762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.786746978759766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031208233907818794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1401543915271759,
      "backward_entropy": 0.032602688670158385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.08760070800781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03127051517367363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14007486899693808,
      "backward_entropy": 0.03220697045326233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.53043365478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03133469820022583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13999491930007935,
      "backward_entropy": 0.03181861042976379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.6777114868164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0314035527408123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13991261521975198,
      "backward_entropy": 0.03143939971923828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.80753326416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03147616609930992,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13982832431793213,
      "backward_entropy": 0.031058180332183837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.54537200927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031551044434309006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13974368572235107,
      "backward_entropy": 0.030681049823760985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.86622619628906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03162797540426254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13965904712677002,
      "backward_entropy": 0.0303078293800354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.804168701171875,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.031705524772405624,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13957575956980386,
      "backward_entropy": 0.13595683574676515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.35131072998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03177787363529205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13949812451998392,
      "backward_entropy": 0.02957959473133087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.96427917480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03184976428747177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13942222793896994,
      "backward_entropy": 0.02922013998031616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.235015869140625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03192147985100746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13934804995854697,
      "backward_entropy": 0.028869494795799255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.05327606201172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031989339739084244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13927731911341348,
      "backward_entropy": 0.04658392369747162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.83637237548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032063066959381104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13920397559801737,
      "backward_entropy": 0.04619061052799225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.229082107543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03213896229863167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13913037379582724,
      "backward_entropy": 0.04580431580543518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.942745208740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03220837935805321,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13906269272168478,
      "backward_entropy": 0.027469763159751893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.16492462158203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03227514773607254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13899840911229452,
      "backward_entropy": 0.02713584303855896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 108.24864196777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03234472870826721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13893295327822366,
      "backward_entropy": 0.0268042653799057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.3341293334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032419055700302124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13886630535125732,
      "backward_entropy": 0.044308912754058835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.22575378417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03249455615878105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13880044221878052,
      "backward_entropy": 0.04396661818027496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.11140823364258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03257223963737488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13873445987701416,
      "backward_entropy": 0.04362761378288269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.0807876586914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032646775245666504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13867217302322388,
      "backward_entropy": 0.025600558519363402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.51056671142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.032720740884542465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13861127694447836,
      "backward_entropy": 0.042964449524879454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.53152465820312,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03279586508870125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13855096697807312,
      "backward_entropy": 0.13628551959991456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.1898193359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.032870613038539886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13849210739135742,
      "backward_entropy": 0.13631291389465333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.76055145263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03294171020388603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13843614856402078,
      "backward_entropy": 0.04198084473609924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.64883041381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0330154187977314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1383796532948812,
      "backward_entropy": 0.04165091216564178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.13142776489258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03308696299791336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13832515478134155,
      "backward_entropy": 0.023868972063064577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.3378677368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033153798431158066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13827396432558695,
      "backward_entropy": 0.02357231080532074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.56340789794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03322556987404823,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1382213830947876,
      "backward_entropy": 0.04065232872962952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.87196731567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03329399228096008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1381712555885315,
      "backward_entropy": 0.023006147146224974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.42578887939453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03335798159241676,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13812407851219177,
      "backward_entropy": 0.13641731739044188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.53565216064453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03342152759432793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1380782127380371,
      "backward_entropy": 0.02243638038635254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.7337875366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03348713740706444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1380320986111959,
      "backward_entropy": 0.039350280165672304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.19252014160156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033556148409843445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13798524936040243,
      "backward_entropy": 0.0218904972076416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.50526809692383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03363136202096939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1379367709159851,
      "backward_entropy": 0.03875581622123718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.280906677246094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03370344638824463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13789092501004538,
      "backward_entropy": 0.02138453722000122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.47317123413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03377077728509903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1378475824991862,
      "backward_entropy": 0.038178691267967226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.22936248779297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03383538872003555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13780629634857178,
      "backward_entropy": 0.020867149531841277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.18804168701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03389778360724449,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1377666393915812,
      "backward_entropy": 0.037585824728012085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.647064208984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.033960048109292984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13772796591122946,
      "backward_entropy": 0.03730430603027344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.56682586669922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03401905298233032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13769137859344482,
      "backward_entropy": 0.02011798173189163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.015235900878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03408084064722061,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13765440384546915,
      "backward_entropy": 0.03675575852394104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.26859283447266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034142110496759415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13761820395787558,
      "backward_entropy": 0.01964283883571625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.61224365234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03420758247375488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13758117953936258,
      "backward_entropy": 0.019415657222270965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.1739501953125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034272413700819016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13754514853159586,
      "backward_entropy": 0.019190870225429535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.304527282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03433729708194733,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13751020034154257,
      "backward_entropy": 0.035742339491844174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.02396774291992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034398287534713745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13747708002726236,
      "backward_entropy": 0.018761493265628815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.96273040771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03445620462298393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13744564851125082,
      "backward_entropy": 0.018544843792915343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.755367279052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03451602905988693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1374142269293467,
      "backward_entropy": 0.018338558077812196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.770206451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034574661403894424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13738389809926352,
      "backward_entropy": 0.01813856065273285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.745399475097656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034631941467523575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13735457261403403,
      "backward_entropy": 0.017939642071723938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.678199768066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03468640521168709,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1373265782992045,
      "backward_entropy": 0.03435608148574829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.26176452636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03474099189043045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13729873299598694,
      "backward_entropy": 0.01753440499305725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.6596908569336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03480022773146629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13726982474327087,
      "backward_entropy": 0.01733512282371521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.98313903808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03486583009362221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13723977406819662,
      "backward_entropy": 0.01715240478515625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.206851959228516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034932296723127365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1372100512186686,
      "backward_entropy": 0.033517387509346006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.00926208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034995339810848236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1371819575627645,
      "backward_entropy": 0.016790714859962464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.159934997558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03505561873316765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13715539375940958,
      "backward_entropy": 0.0331368088722229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.51416015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03511274233460426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1371301213900248,
      "backward_entropy": 0.016434615850448607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.84000396728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03517024591565132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13710502783457437,
      "backward_entropy": 0.03275291621685028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.466976165771484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0352310985326767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13707959651947021,
      "backward_entropy": 0.03257310390472412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.627606987953186,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03529069200158119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1370550294717153,
      "backward_entropy": 0.015921249985694885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.25904083251953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03534315153956413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1370327671368917,
      "backward_entropy": 0.01575167179107666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.14345932006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035399604588747025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13700993855794272,
      "backward_entropy": 0.01558944433927536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.90278625488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03545529395341873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13698774576187134,
      "backward_entropy": 0.03188607096672058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.802839279174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03551467880606651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13696510593096414,
      "backward_entropy": 0.03173302114009857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.69066047668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03556986153125763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13694377740224203,
      "backward_entropy": 0.03157499730587006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.485143661499023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03562146797776222,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13692368070284525,
      "backward_entropy": 0.01497223824262619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.35960388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035670436918735504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13690473635991415,
      "backward_entropy": 0.03127909600734711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.09058380126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03572642058134079,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13688445091247559,
      "backward_entropy": 0.031147307157516478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.86119079589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03578299656510353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1368643840154012,
      "backward_entropy": 0.014553722739219666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.85140037536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.035846009850502014,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1368433932463328,
      "backward_entropy": 0.030894735455513002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.46495819091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03590625151991844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13682340582211813,
      "backward_entropy": 0.030774277448654175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.4748420715332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03596991300582886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1368031402428945,
      "backward_entropy": 0.01416725516319275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.45167541503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03603371977806091,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13678330183029175,
      "backward_entropy": 0.01404544711112976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.531333923339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0361020602285862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1367630958557129,
      "backward_entropy": 0.013930201530456543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.77664566040039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0361715629696846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13674314816792807,
      "backward_entropy": 0.013818949460983276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.74059295654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03623891994357109,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1367239753405253,
      "backward_entropy": 0.030283480882644653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.31143951416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03631054610013962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13670454422632852,
      "backward_entropy": 0.013597175478935242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.880271911621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036384209990501404,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1366852124532064,
      "backward_entropy": 0.03011906147003174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.50627899169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036458175629377365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13666621843973795,
      "backward_entropy": 0.030031898617744447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.70584869384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03653087839484215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13664782047271729,
      "backward_entropy": 0.029938265681266785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.078609466552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036605264991521835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13662946224212646,
      "backward_entropy": 0.029840418696403505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.899044036865234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036678969860076904,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1366117795308431,
      "backward_entropy": 0.013049954175949096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.93456268310547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036750100553035736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13659486174583435,
      "backward_entropy": 0.0129404678940773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.509733200073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03682377189397812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13657812277475992,
      "backward_entropy": 0.012839430570602417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.51539993286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03689395636320114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13656234741210938,
      "backward_entropy": 0.02951570153236389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.35272979736328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036965176463127136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13654683033625284,
      "backward_entropy": 0.012646077573299408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.14644622802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03703581169247627,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13653173049290976,
      "backward_entropy": 0.029384762048721313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.07027816772461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03710871562361717,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13651669025421143,
      "backward_entropy": 0.012458930909633636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.7894287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03718071058392525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13650208711624146,
      "backward_entropy": 0.02925351858139038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.961267471313477,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03725357726216316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13648778200149536,
      "backward_entropy": 0.012275192141532897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.792449951171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0373230054974556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13647425174713135,
      "backward_entropy": 0.012186893075704575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.26693344116211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03739021345973015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13646119832992554,
      "backward_entropy": 0.012093666195869445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.09145736694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03745870664715767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13644832372665405,
      "backward_entropy": 0.029005232453346252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.626928329467773,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03752836212515831,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13643564780553183,
      "backward_entropy": 0.011915485560894012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.01353073120117,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03759469464421272,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1364236076672872,
      "backward_entropy": 0.011826404184103013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.29082489013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03766091167926788,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13641180594762167,
      "backward_entropy": 0.028824833035469056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.09306335449219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03772987425327301,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13640005389849344,
      "backward_entropy": 0.011653313785791397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.58022689819336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03780123218894005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13638836145401,
      "backward_entropy": 0.01156904473900795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.034873962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03786802664399147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13637739419937134,
      "backward_entropy": 0.011487302929162979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.43812561035156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0379362590610981,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13636656602223715,
      "backward_entropy": 0.011409012228250503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.55812454223633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038007430732250214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1363558272520701,
      "backward_entropy": 0.011337386071681976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.61495208740234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03807661682367325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1363455057144165,
      "backward_entropy": 0.011264668405056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.84261322021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038149431347846985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13633515437444052,
      "backward_entropy": 0.028512614965438842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.62247467041016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03822433575987816,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13632490237553915,
      "backward_entropy": 0.011117424070835113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.0495491027832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03830111399292946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13631480932235718,
      "backward_entropy": 0.011046016961336136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.33485794067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03837544471025467,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13630518317222595,
      "backward_entropy": 0.02840166389942169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.42354393005371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03844905644655228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13629590471585593,
      "backward_entropy": 0.010906946659088135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.75813293457031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03851891681551933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13628709316253662,
      "backward_entropy": 0.010835491865873337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.231292724609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03859108313918114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13627835114796957,
      "backward_entropy": 0.010764541476964951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.42717361450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03866363689303398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362697978814443,
      "backward_entropy": 0.01069033145904541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.84505081176758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03873419389128685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362616022427877,
      "backward_entropy": 0.010617767274379731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.658836364746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03880567476153374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13625361522038779,
      "backward_entropy": 0.010547110438346862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.476463317871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03887806087732315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1362458070119222,
      "backward_entropy": 0.010479146242141723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.93779754638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03895118832588196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13623817761739096,
      "backward_entropy": 0.028084439039230347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.10924530029297,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03902206942439079,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1362308661142985,
      "backward_entropy": 0.13808896541595458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.04317474365234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039093777537345886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13622373342514038,
      "backward_entropy": 0.010276447981595993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.466217041015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0391676090657711,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13621671994527182,
      "backward_entropy": 0.027965286374092103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.4931640625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039238106459379196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13621006409327188,
      "backward_entropy": 0.010146364569664001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.229316711425781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03930823877453804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13620359698931375,
      "backward_entropy": 0.027904707193374633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.20268630981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03937235847115517,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619746764500937,
      "backward_entropy": 0.027872490882873534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.115781784057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03943689540028572,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13619154691696167,
      "backward_entropy": 0.027849531173706053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.9310417175293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.039498839527368546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13618583480517069,
      "backward_entropy": 0.027826863527297973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.87297821044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03956115245819092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13618025183677673,
      "backward_entropy": 0.00984494835138321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.55881118774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03962276130914688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13617482781410217,
      "backward_entropy": 0.00979021042585373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.26309585571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03968648985028267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13616947333017984,
      "backward_entropy": 0.009739511460065842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.38301467895508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03975308686494827,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13616424798965454,
      "backward_entropy": 0.02776740789413452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.23621368408203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0398198626935482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1361591418584188,
      "backward_entropy": 0.00963921844959259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.88333511352539,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03988640382885933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13615421454111734,
      "backward_entropy": 0.009588317573070526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919800758361816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03995455801486969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13614938656489053,
      "backward_entropy": 0.02775024175643921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.09001159667969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040016934275627136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136144757270813,
      "backward_entropy": 0.027742621302604676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.97993850708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040078744292259216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13614028692245483,
      "backward_entropy": 0.027747920155525206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.8731803894043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04013985022902489,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613593578338623,
      "backward_entropy": 0.009405653923749924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.77029800415039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040200263261795044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13613168398539224,
      "backward_entropy": 0.009364669770002365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.034570693969727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04026011750102043,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13612755139668783,
      "backward_entropy": 0.027783477306365968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.56033706665039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04031791538000107,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13612353801727295,
      "backward_entropy": 0.027795401215553284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 60.20124053955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04037516191601753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1361196239789327,
      "backward_entropy": 0.027803373336791993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.36207580566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04043610766530037,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136115829149882,
      "backward_entropy": 0.027811822295188905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.77750778198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04049644619226456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13611209392547607,
      "backward_entropy": 0.009171642363071442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.660600662231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040557343512773514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13610851764678955,
      "backward_entropy": 0.027833211421966552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.04774856567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04061659052968025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13610498110453287,
      "backward_entropy": 0.027856439352035522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.8390007019043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040675338357686996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13610154390335083,
      "backward_entropy": 0.009069565683603287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.26020050048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04073603078722954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13609822591145834,
      "backward_entropy": 0.009034405648708343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.924686431884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04079724848270416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360950469970703,
      "backward_entropy": 0.008997975289821625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.629844665527344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04086156189441681,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13609198729197183,
      "backward_entropy": 0.008959946781396865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.159622192382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0409250482916832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13608898719151816,
      "backward_entropy": 0.02791997492313385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.719974517822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040986090898513794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13608608643213907,
      "backward_entropy": 0.027929142117500305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.88395309448242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041047681123018265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136083314816157,
      "backward_entropy": 0.027937650680541992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.44791030883789,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04111121594905853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360806425412496,
      "backward_entropy": 0.008819973468780518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.552772521972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04117504507303238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360780398050944,
      "backward_entropy": 0.02795961797237396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.96251678466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.041240591555833817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13607558608055115,
      "backward_entropy": 0.02797141969203949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.032676696777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04130500927567482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13607319196065268,
      "backward_entropy": 0.008720297366380692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.74662399291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04136974364519119,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13607088724772134,
      "backward_entropy": 0.02800230085849762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.750980377197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04143360257148743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13606861233711243,
      "backward_entropy": 0.008660972118377686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.212889671325684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04149777069687843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13606644670168558,
      "backward_entropy": 0.02805073857307434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.69719696044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04155688360333443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13606427113215128,
      "backward_entropy": 0.008604614436626435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.35102081298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04162057489156723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360622743765513,
      "backward_entropy": 0.0280980259180069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.1696720123291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04168469458818436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13606034715970358,
      "backward_entropy": 0.008547023683786393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.06363296508789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04174648970365524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13605844974517822,
      "backward_entropy": 0.02815956175327301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.052045822143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04181010648608208,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360566814740499,
      "backward_entropy": 0.028195306658744812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.976212501525879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04187034070491791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13605486353238425,
      "backward_entropy": 0.008471997082233429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.60202407836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04192714765667915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360530455907186,
      "backward_entropy": 0.028287768363952637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.98349666595459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04198641702532768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13605135679244995,
      "backward_entropy": 0.028337866067886353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.428714752197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042041029781103134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13604958852132162,
      "backward_entropy": 0.008402637392282485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.787261009216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04209684208035469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13604795932769775,
      "backward_entropy": 0.02843136787414551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.914506435394287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04214987903833389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360463003317515,
      "backward_entropy": 0.028482437133789062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.4965877532959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042198993265628815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360445817311605,
      "backward_entropy": 0.028533658385276793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.425947189331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04224736988544464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13604286313056946,
      "backward_entropy": 0.028590157628059387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.12800979614258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042294979095458984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360411842664083,
      "backward_entropy": 0.028647458553314208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.552264213562012,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04234819486737251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603973388671875,
      "backward_entropy": 0.008274971693754195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.928569793701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042398739606142044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603830337524414,
      "backward_entropy": 0.028736788034439086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.59629440307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04244951158761978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603691260019937,
      "backward_entropy": 0.028777629137039185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.74765968322754,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04250575602054596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360357403755188,
      "backward_entropy": 0.008204372972249985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.26886749267578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04256179928779602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360345979531606,
      "backward_entropy": 0.028859210014343262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.31138801574707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04261867329478264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603358467419943,
      "backward_entropy": 0.008156844973564148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.050785064697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04267256706953049,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603252172470093,
      "backward_entropy": 0.0289289653301239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.78867530822754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042727939784526825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603152831395468,
      "backward_entropy": 0.028973370790481567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.24981117248535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04278193414211273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603049516677856,
      "backward_entropy": 0.00809193253517151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.67308807373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04283584654331207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360295315583547,
      "backward_entropy": 0.02907394468784332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.05881118774414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04289098083972931,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602864742279053,
      "backward_entropy": 0.029122355580329894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.4346923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04294596239924431,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602781295776367,
      "backward_entropy": 0.029171487689018248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.97485637664795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04300214350223541,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602705796559653,
      "backward_entropy": 0.029222923517227172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.44995880126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04305555671453476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602622350056967,
      "backward_entropy": 0.007999781519174576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.461219787597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04311404377222061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602562745412192,
      "backward_entropy": 0.007981812953948975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.93574142456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04317469149827957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360251506169637,
      "backward_entropy": 0.00796479508280754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.81715774536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043236080557107925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602469364802042,
      "backward_entropy": 0.007949835807085037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.013675689697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043301790952682495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360244353612264,
      "backward_entropy": 0.029498076438903807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.048587799072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04336497187614441,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602413733800253,
      "backward_entropy": 0.029554522037506102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.595359802246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043430592864751816,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602404793103537,
      "backward_entropy": 0.029591602087020875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.516219139099121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043492574244737625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602382938067117,
      "backward_entropy": 0.029639583826065064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.47226619720459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043550923466682434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602355122566223,
      "backward_entropy": 0.007862431555986404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.610647201538086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04360613226890564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602318366368613,
      "backward_entropy": 0.007844512164592744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.0112190246582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04365992546081543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602282603581747,
      "backward_entropy": 0.029774609208106994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.450841903686523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04371635243296623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602253794670105,
      "backward_entropy": 0.007813748717308045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.388479232788086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04377106577157974,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602222998936972,
      "backward_entropy": 0.029880708456039427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.47416687011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04382440075278282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360219120979309,
      "backward_entropy": 0.02993626892566681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.28512954711914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043878909200429916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360216736793518,
      "backward_entropy": 0.007770223170518875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.204204559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04393307864665985,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602148493131003,
      "backward_entropy": 0.030033415555953978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.08034610748291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04398718476295471,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602131605148315,
      "backward_entropy": 0.007738913595676422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.96601486206055,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04403860121965408,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13602107763290405,
      "backward_entropy": 0.13859107494354247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.87185287475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04409385472536087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602101802825928,
      "backward_entropy": 0.007708641886711121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.785625457763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044150106608867645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602105776468912,
      "backward_entropy": 0.03021993041038513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.522430419921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044205665588378906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602117697397867,
      "backward_entropy": 0.007673617452383041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.47542953491211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0442633256316185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602141539255777,
      "backward_entropy": 0.030273118615150453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.493026733398438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04432156682014465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602174321810404,
      "backward_entropy": 0.007632219046354294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.711727142333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044379230588674545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360220710436503,
      "backward_entropy": 0.007612062990665436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.8878173828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04444126412272453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602258761723837,
      "backward_entropy": 0.030332866311073303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.468971252441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044504910707473755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360231637954712,
      "backward_entropy": 0.030355221033096312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.277612686157227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04457097873091698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602385918299356,
      "backward_entropy": 0.007549174875020981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.774069786071777,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04463426396250725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360244850317637,
      "backward_entropy": 0.007527294754981995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.436272621154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04469276964664459,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360249121983846,
      "backward_entropy": 0.030403262376785277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.36638259887695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0447482205927372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360252102216085,
      "backward_entropy": 0.007492002844810486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.14105987548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04480450972914696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602556784947714,
      "backward_entropy": 0.007475112378597259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.70781707763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044865112751722336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360261340936025,
      "backward_entropy": 0.030479982495307922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.216402053833008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.044927265495061874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602674007415771,
      "backward_entropy": 0.030494892597198488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.82711410522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04498596116900444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602721691131592,
      "backward_entropy": 0.007417277991771698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.142940521240234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04504525661468506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360277235507965,
      "backward_entropy": 0.030544528365135194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.540672779083252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510359466075897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360282301902771,
      "backward_entropy": 0.007382453978061676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.476301193237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04515746980905533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602858781814575,
      "backward_entropy": 0.030588331818580627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.951446533203125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04520990699529648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602891564369202,
      "backward_entropy": 0.007349956035614014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.33145523071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04525981470942497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602916399637857,
      "backward_entropy": 0.007336042076349259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.46707534790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045308638364076614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602938254674277,
      "backward_entropy": 0.007322964817285537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.575204849243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045359957963228226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602972030639648,
      "backward_entropy": 0.0073072463274002075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.761216163635254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045411281287670135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360300580660502,
      "backward_entropy": 0.00729219913482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.39763069152832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04546014592051506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603033622105917,
      "backward_entropy": 0.030773606896400452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.303606033325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045509353280067444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603059450785318,
      "backward_entropy": 0.0072665028274059296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.332396507263184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045558828860521317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603087266286215,
      "backward_entropy": 0.030857962369918824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.394399642944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045604802668094635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.136031041542689,
      "backward_entropy": 0.03090733289718628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.524166107177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565254598855972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603127002716064,
      "backward_entropy": 0.007236665487289429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.72243309020996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045702990144491196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360315481821696,
      "backward_entropy": 0.007225906848907471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 43.45438766479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045752376317977905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603182633717856,
      "backward_entropy": 0.031052595376968382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.6396369934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.045805562287569046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603222370147705,
      "backward_entropy": 0.031099507212638856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.6339111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04586460068821907,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603273034095764,
      "backward_entropy": 0.031141579151153564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.78273391723633,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04592275246977806,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1360332171122233,
      "backward_entropy": 0.1386083483695984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.4194278717041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04598264768719673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603370388348898,
      "backward_entropy": 0.007171736657619476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.43836212158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04604162275791168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603416085243225,
      "backward_entropy": 0.03126517534255981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.387142181396484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046102073043584824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.136034627755483,
      "backward_entropy": 0.007148143649101257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.0915641784668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046167392283678055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603518406550089,
      "backward_entropy": 0.03132553100585937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.97747230529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046233586966991425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360357403755188,
      "backward_entropy": 0.007118047028779983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.774215698242188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04629707336425781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603615760803223,
      "backward_entropy": 0.007105042040348053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.47880935668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04636034369468689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360365649064382,
      "backward_entropy": 0.007091355323791504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.818719863891602,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046425942331552505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603695233662924,
      "backward_entropy": 0.007077907025814056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.755928993225098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046487681567668915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603723049163818,
      "backward_entropy": 0.007066774368286133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.36614990234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046545881778001785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603744904200235,
      "backward_entropy": 0.031522932648658755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.261852264404297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046603232622146606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603762785593668,
      "backward_entropy": 0.03157045841217041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.932125091552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046659842133522034,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603776693344116,
      "backward_entropy": 0.031619778275489806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.80156898498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046716898679733276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360378861427307,
      "backward_entropy": 0.03166702091693878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.94489860534668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046774376183748245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603798548380533,
      "backward_entropy": 0.00701940506696701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.441747665405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04683110862970352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603803515434265,
      "backward_entropy": 0.00701061487197876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.07215690612793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04688486456871033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603803515434265,
      "backward_entropy": 0.007003967463970184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 39.60167694091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04693717509508133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603800535202026,
      "backward_entropy": 0.03188954591751099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.542469024658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04699280112981796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603795568148294,
      "backward_entropy": 0.03195683360099792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.837026596069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04704789072275162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603786627451578,
      "backward_entropy": 0.03202776610851288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.329452514648438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04710128530859947,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13603774706522623,
      "backward_entropy": 0.13861900568008423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.788915634155273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047154203057289124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603760798772177,
      "backward_entropy": 0.03217046856880188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.132938385009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04720793291926384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603744904200235,
      "backward_entropy": 0.0069776646792888645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.533926010131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047261159867048264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603724042574564,
      "backward_entropy": 0.032299911975860594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.47395133972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047312792390584946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603701194127402,
      "backward_entropy": 0.0069669999182224275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.30168342590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047363150864839554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603675365447998,
      "backward_entropy": 0.03243650197982788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.310840606689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04741453751921654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360364556312561,
      "backward_entropy": 0.006960093975067139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.843506813049316,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04746437817811966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603615760803223,
      "backward_entropy": 0.006955210864543915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.793099403381348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04751180484890938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603583971659342,
      "backward_entropy": 0.006951278448104859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.122499465942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04755696654319763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603552182515463,
      "backward_entropy": 0.03270211517810821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3767499923706055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04760134965181351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603520393371582,
      "backward_entropy": 0.006943850964307785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3532843589782715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04764276742935181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603490591049194,
      "backward_entropy": 0.0069425016641616825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.249181747436523,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04768145829439163,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.136034627755483,
      "backward_entropy": 0.1386256694793701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.46707534790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04772106930613518,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603432973225912,
      "backward_entropy": 0.032999342679977416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.826909065246582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047762706875801086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603398203849792,
      "backward_entropy": 0.0069384992122650145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.52131462097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04780377820134163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603359460830688,
      "backward_entropy": 0.03313466310501099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.62574005126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04784783348441124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13603313763936362,
      "backward_entropy": 0.033193206787109374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.849794387817383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04789571091532707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360325813293457,
      "backward_entropy": 0.006923125684261322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386685371398926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047943610697984695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13603198528289795,
      "backward_entropy": 0.006916020810604095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.511955261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04798915609717369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360313892364502,
      "backward_entropy": 0.006908981502056122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.721084594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04803382605314255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360307733217875,
      "backward_entropy": 0.03339261412620544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.387255668640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048079829663038254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360300878683726,
      "backward_entropy": 0.033434551954269406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.315061569213867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04812498018145561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602938254674277,
      "backward_entropy": 0.006887596100568771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.325870513916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048169225454330444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602868715922037,
      "backward_entropy": 0.03353327214717865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.189826965332031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048213742673397064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1360279122988383,
      "backward_entropy": 0.006873440742492676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.193056106567383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048257436603307724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602712750434875,
      "backward_entropy": 0.006866171956062317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.101930618286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04830257594585419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602624336878458,
      "backward_entropy": 0.033661335706710815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.001867294311523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04835018888115883,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360252300898234,
      "backward_entropy": 0.03369554877281189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.82955551147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04839550331234932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602423667907715,
      "backward_entropy": 0.006839040666818619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.811311721801758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048443157225847244,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602308432261148,
      "backward_entropy": 0.0337599515914917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.556880950927734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04849085211753845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13602188229560852,
      "backward_entropy": 0.006818302720785141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.516584396362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04854065552353859,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13602052132288614,
      "backward_entropy": 0.03381674885749817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.14716339111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859127476811409,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13601903120676676,
      "backward_entropy": 0.006794866919517517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.566733360290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04864487424492836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13601733247439066,
      "backward_entropy": 0.03385608494281769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.322607040405273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04869665950536728,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13601561387379965,
      "backward_entropy": 0.033876174688339235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.423879623413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048748016357421875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360138456026713,
      "backward_entropy": 0.03390224874019623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.679574966430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04879786819219589,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360121270020803,
      "backward_entropy": 0.03393525779247284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.02920913696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04884966462850571,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360101799170176,
      "backward_entropy": 0.033967995643615724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.198201179504395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04890101030468941,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13600819309552512,
      "backward_entropy": 0.03400435745716095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.53329849243164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048950742930173874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13600622614224753,
      "backward_entropy": 0.03404116630554199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.739110946655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04900122433900833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13600409030914307,
      "backward_entropy": 0.034074866771698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.983773231506348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04905135929584503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1360019346078237,
      "backward_entropy": 0.034112673997879026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.808427810668945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049100007861852646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359997590382894,
      "backward_entropy": 0.006698494404554367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.48503875732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049150582402944565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135997345050176,
      "backward_entropy": 0.034185802936553954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.765524864196777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04920612648129463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135994424422582,
      "backward_entropy": 0.03420869708061218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.131657600402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049259696155786514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13599157333374023,
      "backward_entropy": 0.034238564968109134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.558863162994385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049310363829135895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359888712565104,
      "backward_entropy": 0.006659583747386932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.559982299804688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04935743287205696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598642746607462,
      "backward_entropy": 0.006654608994722366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.962404251098633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04940541461110115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359837849934896,
      "backward_entropy": 0.006648506224155426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.874168395996094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049453165382146835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13598106304804483,
      "backward_entropy": 0.006642328947782517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.782241821289062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04950074478983879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359782616297404,
      "backward_entropy": 0.006636551022529602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859048843383789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04954813793301582,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13597538073857626,
      "backward_entropy": 0.03451409637928009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.602445602416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049593258649110794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13597267866134644,
      "backward_entropy": 0.03456912040710449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.270784378051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04963836073875427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13596983750661215,
      "backward_entropy": 0.034619840979576114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.374599933624268,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968562722206116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359666387240092,
      "backward_entropy": 0.006616386771202088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.675819396972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049729540944099426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13596378763516745,
      "backward_entropy": 0.034720268845558164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637371063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04977785050868988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13596036036809286,
      "backward_entropy": 0.006606554985046387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591185569763184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04982372745871544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13595710198084512,
      "backward_entropy": 0.034814614057540896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.083877563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04986736923456192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13595394293467203,
      "backward_entropy": 0.006597383320331574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514058113098145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049911126494407654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1359506150086721,
      "backward_entropy": 0.03491505980491638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.91802406311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049952950328588486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13594754536946616,
      "backward_entropy": 0.006589693576097488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.25284767150879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04999499395489693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13594430685043335,
      "backward_entropy": 0.0065855905413627625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.200369358062744,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050039369612932205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13594061136245728,
      "backward_entropy": 0.006579691171646118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.51622200012207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050080571323633194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13593725363413492,
      "backward_entropy": 0.006575024127960205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.457320213317871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05012109503149986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359339157740275,
      "backward_entropy": 0.006571186333894729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.03386306762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050160977989435196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135930597782135,
      "backward_entropy": 0.03521638512611389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.652761459350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05020543187856674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13592645525932312,
      "backward_entropy": 0.03525509238243103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183180809020996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05025191977620125,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13592183589935303,
      "backward_entropy": 0.006553517282009124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.331401824951172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05029606446623802,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1359174648920695,
      "backward_entropy": 0.0065465569496154785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.059053421020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05034124478697777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13591280579566956,
      "backward_entropy": 0.03535430133342743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.12668228149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05038321390748024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590856393178305,
      "backward_entropy": 0.006533575803041458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.017426490783691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05042647570371628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13590403397878012,
      "backward_entropy": 0.006528013199567795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.903133392333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05046771839261055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358997424443563,
      "backward_entropy": 0.006523403525352478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.858613967895508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05051126703619957,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135894904534022,
      "backward_entropy": 0.006517285108566284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.898067474365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05055484175682068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13588992754618326,
      "backward_entropy": 0.03555878102779388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.696474075317383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050596412271261215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588523864746094,
      "backward_entropy": 0.006506682187318802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819663047790527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05063818767666817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13588040073712668,
      "backward_entropy": 0.006502069532871246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.77964448928833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05067814886569977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587584098180136,
      "backward_entropy": 0.006499131768941879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.333877563476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05071642994880676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358715295791626,
      "backward_entropy": 0.00649731308221817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.085641860961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05075627192854881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13586684068044028,
      "backward_entropy": 0.03581316471099853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.787456512451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.050798553973436356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358614961306254,
      "backward_entropy": 0.035862937569618225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.418652534484863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0508439838886261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1358553965886434,
      "backward_entropy": 0.03590405583381653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.363296508789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0508880652487278,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13584930698076883,
      "backward_entropy": 0.006478763371706009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.296216011047363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05093107372522354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13584336638450623,
      "backward_entropy": 0.03598207533359528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.500907897949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05097299814224243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583743572235107,
      "backward_entropy": 0.03602124750614166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.185091972351074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051013048738241196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13583187262217203,
      "backward_entropy": 0.036068177223205565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.943811416625977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051052410155534744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13582636912663779,
      "backward_entropy": 0.03611947000026703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7032649517059326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05109512805938721,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13581993182500204,
      "backward_entropy": 0.006455819308757782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.343594551086426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05113492161035538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13581417004267374,
      "backward_entropy": 0.03621695935726166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.309455394744873,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05117295682430267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1358086665471395,
      "backward_entropy": 0.006451550126075745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.90311336517334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05120944231748581,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13580344120661417,
      "backward_entropy": 0.036333012580871585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.85649585723877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05124548077583313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13579817612965903,
      "backward_entropy": 0.036390066146850586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.99847984313965,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05128120258450508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13579291105270386,
      "backward_entropy": 0.006447882950305938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1704301834106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05131860822439194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13578712940216064,
      "backward_entropy": 0.006446072459220886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.260316848754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05135446786880493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13578158617019653,
      "backward_entropy": 0.0365642786026001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.742639541625977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05139090120792389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13577571511268616,
      "backward_entropy": 0.036615633964538576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.067750453948975,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05142896994948387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13576934734980264,
      "backward_entropy": 0.006438802927732468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.543745040893555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05146544799208641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357632875442505,
      "backward_entropy": 0.036721402406692506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.984824180603027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05150148272514343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575722773869833,
      "backward_entropy": 0.03677622079849243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.390634536743164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051538076251745224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13575085004170737,
      "backward_entropy": 0.03682703375816345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.302104949951172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051576122641563416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1357439160346985,
      "backward_entropy": 0.036869576573371886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8868865966796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051615502685308456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13573630650838217,
      "backward_entropy": 0.03690634965896607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.70002555847168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05165302753448486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572907447814941,
      "backward_entropy": 0.006421451270580292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.026866912841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05169098451733589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13572156429290771,
      "backward_entropy": 0.006416097283363342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3962910175323486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05173018202185631,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13571343819300333,
      "backward_entropy": 0.03699997663497925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.117027282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05176663398742676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13570602734883627,
      "backward_entropy": 0.03703124225139618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.415452003479004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051802631467580795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13569867610931396,
      "backward_entropy": 0.037067112326622007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3459529876708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05183916538953781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13569106658299765,
      "backward_entropy": 0.006393119692802429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.282855033874512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05187324434518814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13568416237831116,
      "backward_entropy": 0.03714504539966583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.911157608032227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05190804973244667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13567692041397095,
      "backward_entropy": 0.03718758225440979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.151716232299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.051942404359579086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13566954930623373,
      "backward_entropy": 0.037224370241165164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.0848970413208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05197742581367493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13566185037295023,
      "backward_entropy": 0.006376646459102631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.268726348876953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05201302468776703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356537938117981,
      "backward_entropy": 0.03729563355445862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.41255760192871,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052050091326236725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13564504186312357,
      "backward_entropy": 0.006365370005369186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.657121658325195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05208937078714371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1356352468331655,
      "backward_entropy": 0.006357033550739288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.60305118560791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052127812057733536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13562552134195963,
      "backward_entropy": 0.006349284946918487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.906471252441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05216551199555397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13561595479647318,
      "backward_entropy": 0.006342292577028274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.818862915039062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05220441520214081,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13560567299524942,
      "backward_entropy": 0.006334617733955383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.86198616027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05224451422691345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13559488455454508,
      "backward_entropy": 0.037442263960838315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.863977432250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0522865355014801,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13558313250541687,
      "backward_entropy": 0.03746315538883209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.61532211303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05233120918273926,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13557000954945883,
      "backward_entropy": 0.037476712465286256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.4805850982666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05237732082605362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1355560620625814,
      "backward_entropy": 0.006298723816871643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.291258811950684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05242462456226349,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13554118076960245,
      "backward_entropy": 0.037488406896591185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.110587120056152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05247209221124649,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13552585244178772,
      "backward_entropy": 0.006273671239614487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.059403419494629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05251780524849892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13551088174184164,
      "backward_entropy": 0.006261563301086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.965850830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.052562907338142395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1354960004488627,
      "backward_entropy": 0.037492969632148744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.796655654907227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05260841175913811,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13548046350479126,
      "backward_entropy": 0.037497499585151674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.801149368286133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05265612155199051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13546359539031982,
      "backward_entropy": 0.03749797940254211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.864750862121582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052703067660331726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13544684648513794,
      "backward_entropy": 0.006215134635567665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.625792503356934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.052747488021850586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13543121019999185,
      "backward_entropy": 0.006206904724240303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.54369831085205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05279136449098587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13541537523269653,
      "backward_entropy": 0.03754864931106568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.463376998901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05283474549651146,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353993515173594,
      "backward_entropy": 0.03757062256336212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013046992011368275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05287768691778183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353832483291626,
      "backward_entropy": 0.03759370446205139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.783327102661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05291657894849777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.135369082291921,
      "backward_entropy": 0.037629279494285586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.0379638671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05295814573764801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13535305857658386,
      "backward_entropy": 0.00617215484380722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.582211971282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053000304847955704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13533630967140198,
      "backward_entropy": 0.03767673373222351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.541982173919678,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05304025858640671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13532041509946188,
      "backward_entropy": 0.006158274784684181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.512355327606201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053078148514032364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1353052258491516,
      "backward_entropy": 0.03772767186164856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.944802284240723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05311429873108864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13529086112976074,
      "backward_entropy": 0.03775976002216339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.876960754394531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05315067991614342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.135276198387146,
      "backward_entropy": 0.006142439320683479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.503660202026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05318724364042282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1352610190709432,
      "backward_entropy": 0.03782798051834106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.419183731079102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05322474241256714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13524478673934937,
      "backward_entropy": 0.037854206562042234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.331754684448242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05326312407851219,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352276106675466,
      "backward_entropy": 0.006125111877918243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.304222106933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053302325308322906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1352095901966095,
      "backward_entropy": 0.006117533892393112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.04042625427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05333961173892021,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13519253333409628,
      "backward_entropy": 0.03791738152503967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.452303886413574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05338045209646225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13517282406489053,
      "backward_entropy": 0.03793187737464905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.556979179382324,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05342099443078041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1351530154546102,
      "backward_entropy": 0.006095390021800995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.15580415725708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05346296355128288,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13513185580571493,
      "backward_entropy": 0.0379635214805603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.673702239990234,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053502727299928665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13511196772257486,
      "backward_entropy": 0.00607946515083313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.693161964416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053541406989097595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13509249687194824,
      "backward_entropy": 0.038011586666107176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.602829933166504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053580883890390396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13507231076558432,
      "backward_entropy": 0.03804272413253784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5138843059539795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053621064871549606,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13505143920580545,
      "backward_entropy": 0.00606343112885952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.90427303314209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0536583736538887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13503251473108926,
      "backward_entropy": 0.03812182545661926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4807722568511963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05369734391570091,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1350118617216746,
      "backward_entropy": 0.03815883994102478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.147693634033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05373359099030495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13499321540196738,
      "backward_entropy": 0.03820926547050476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.734049797058105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.053772423416376114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1349720557530721,
      "backward_entropy": 0.03824802041053772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.843470096588135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05381101369857788,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1349507768948873,
      "backward_entropy": 0.03828543126583099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8056511878967285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.053847797214984894,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13493086894353232,
      "backward_entropy": 0.006044399365782738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.058090209960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05388282984495163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13491183519363403,
      "backward_entropy": 0.03838739991188049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.829732894897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05392135679721832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1348896026611328,
      "backward_entropy": 0.0384248286485672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.05049467086792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05396048724651337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13486645619074503,
      "backward_entropy": 0.03845880925655365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.668547630310059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05399847403168678,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13484392563501993,
      "backward_entropy": 0.03849602937698364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.263094902038574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054034531116485596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13482256730397543,
      "backward_entropy": 0.03853537440299988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.903122901916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05407056584954262,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1348008712132772,
      "backward_entropy": 0.03857382237911224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.856708526611328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05410575866699219,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13477967182795206,
      "backward_entropy": 0.0386158287525177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.072896003723145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054140206426382065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13475892941157022,
      "backward_entropy": 0.038662385940551755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2590749263763428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05417472496628761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13473761081695557,
      "backward_entropy": 0.038704556226730344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2506515979766846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05420674383640289,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.134718120098114,
      "backward_entropy": 0.038746827840805055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.682941436767578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05423665791749954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1347006062666575,
      "backward_entropy": 0.038799405097961426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.642330646514893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05426633730530739,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1346831520398458,
      "backward_entropy": 0.03885581791400909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798027038574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05429575964808464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13466575741767883,
      "backward_entropy": 0.006001870334148407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.561903953552246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05432570353150368,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13464736938476562,
      "backward_entropy": 0.03896477222442627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.868307113647461,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05435528978705406,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1346290111541748,
      "backward_entropy": 0.13862922191619872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.641219139099121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054386310279369354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13460910320281982,
      "backward_entropy": 0.03906330466270447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.583871841430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05441774055361748,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13458857933680216,
      "backward_entropy": 0.03911266624927521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.398288249969482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054449472576379776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13456732034683228,
      "backward_entropy": 0.03915759325027466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.589479446411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05448064208030701,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13454624017079672,
      "backward_entropy": 0.03919979929924011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.314915180206299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05451296269893646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13452372948328653,
      "backward_entropy": 0.03923753499984741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.449518203735352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05454466491937637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13450133800506592,
      "backward_entropy": 0.03927560448646546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.3740234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05457748472690582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13447757562001547,
      "backward_entropy": 0.005968039482831955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.126557350158691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0546112023293972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13445234298706055,
      "backward_entropy": 0.005960942059755325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0982537269592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05464332178235054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13442848126093546,
      "backward_entropy": 0.03937103152275086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13072681427002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.054673999547958374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13440585136413574,
      "backward_entropy": 0.039403879642486574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011226712726056576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0547049418091774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13438243667284647,
      "backward_entropy": 0.03943120837211609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.024984836578369,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05473296716809273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13436208168665567,
      "backward_entropy": 0.005935417860746384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.972112655639648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05476077273488045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13434176643689474,
      "backward_entropy": 0.03950363695621491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.947196006774902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05478993430733681,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13431952397028604,
      "backward_entropy": 0.03953361511230469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.846671104431152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05481865629553795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13429728150367737,
      "backward_entropy": 0.03955857455730438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.644132614135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05484865978360176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13427317142486572,
      "backward_entropy": 0.039581435918807986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7696003913879395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0548822283744812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13424464066823324,
      "backward_entropy": 0.03959799110889435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.784153938293457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.054915834218263626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1342158317565918,
      "backward_entropy": 0.005889597162604332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.468050003051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05494861304759979,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13418765862782797,
      "backward_entropy": 0.039640820026397704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.593542575836182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05498288571834564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.134156862894694,
      "backward_entropy": 0.005870305746793747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8951358795166016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055017102509737015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13412585854530334,
      "backward_entropy": 0.03966301679611206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.208776473999023,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05504896864295006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1340978741645813,
      "backward_entropy": 0.005853026732802391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.266932487487793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05508247762918472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13406741619110107,
      "backward_entropy": 0.005844514816999435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.359499454498291,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05511658638715744,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13403515021006265,
      "backward_entropy": 0.13862903118133546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6588385105133057,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05515056475996971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13400273521741232,
      "backward_entropy": 0.005824550986289978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246975421905518,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05518295243382454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13397233684857687,
      "backward_entropy": 0.005816835165023804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5998268127441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055215418338775635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13394155104955038,
      "backward_entropy": 0.005809842050075531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1338348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05524633824825287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13391250371932983,
      "backward_entropy": 0.03983021676540375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.083563327789307,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05527732893824577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1338826815287272,
      "backward_entropy": 0.005796150863170623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.541807174682617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055308450013399124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13385220368703207,
      "backward_entropy": 0.0057886503636837006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.235506534576416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05534125491976738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1338191032409668,
      "backward_entropy": 0.005780961364507675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.920794486999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055373284965753555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1337868571281433,
      "backward_entropy": 0.03994210958480835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4401791095733643,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05540533363819122,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1337541937828064,
      "backward_entropy": 0.13862893581390381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7127621173858643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055435910820961,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13372342785199484,
      "backward_entropy": 0.04001526832580567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7694172859191895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055464375764131546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13369552294413248,
      "backward_entropy": 0.005758899077773094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.750445365905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05549324303865433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13366689284642538,
      "backward_entropy": 0.04011181592941284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.664697170257568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055524665862321854,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13363389174143472,
      "backward_entropy": 0.0401557981967926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.264890670776367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05555605888366699,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1336003541946411,
      "backward_entropy": 0.040195155143737796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197630882263184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.055588219314813614,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13356517752011618,
      "backward_entropy": 0.04023297429084778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.374269485473633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055621061474084854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13352843125661215,
      "backward_entropy": 0.005733662098646164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.622660517692566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05565593019127846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13348775108655295,
      "backward_entropy": 0.040295928716659546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01043293159455061,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05568829923868179,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13345104455947876,
      "backward_entropy": 0.040334808826446536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.759631156921387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05571756884455681,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13341893752415976,
      "backward_entropy": 0.04037855267524719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.724170684814453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05574622005224228,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13338702917099,
      "backward_entropy": 0.13862931728363037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252118110656738,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05577430501580238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13335559765497842,
      "backward_entropy": 0.005704400688409805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.202899932861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.055802688002586365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13332337141036987,
      "backward_entropy": 0.005698788538575172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.156517028808594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05583124980330467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13329021135965982,
      "backward_entropy": 0.005692220479249954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58687162399292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05585998296737671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13325634598731995,
      "backward_entropy": 0.040560761094093324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.551543235778809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05588821694254875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13322303692499796,
      "backward_entropy": 0.04059667587280273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5129374265670776,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05591597408056259,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13319013516108194,
      "backward_entropy": 0.005673299357295036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.467215061187744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05594182759523392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13316065073013306,
      "backward_entropy": 0.04068031907081604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.931193828582764,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05596880614757538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1331281860669454,
      "backward_entropy": 0.005662534013390541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.359325408935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05599604547023773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13309485713640848,
      "backward_entropy": 0.0407505452632904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.296314239501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05602433159947395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13305935263633728,
      "backward_entropy": 0.04078466296195984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4557466506958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056053366512060165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13302152355511984,
      "backward_entropy": 0.04080655574798584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.75081205368042,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05608031898736954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13298718134562174,
      "backward_entropy": 0.005631240457296372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8603098392486572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0561075434088707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13295186559359232,
      "backward_entropy": 0.0408566951751709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012128201313316822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05613365024328232,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13291857639948526,
      "backward_entropy": 0.04088919758796692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.029537677764893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05615733563899994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13288992643356323,
      "backward_entropy": 0.005609729886054992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.193795680999756,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05618225783109665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1328583061695099,
      "backward_entropy": 0.005602922663092614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5478339195251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05620696023106575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1328269044558207,
      "backward_entropy": 0.041005492210388184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.879459381103516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056232139468193054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13279413183530173,
      "backward_entropy": 0.005590545013546944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4662628173828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05625835433602333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13275861740112305,
      "backward_entropy": 0.005582877248525619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.777018070220947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05628489702939987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13272221883138022,
      "backward_entropy": 0.04110835194587707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.354058027267456,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05631242319941521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13268343607584634,
      "backward_entropy": 0.005568219348788261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3444783687591553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056338075548410416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13264842828114828,
      "backward_entropy": 0.04118291437625885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008790007792413235,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05636205896735191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13261677821477255,
      "backward_entropy": 0.005558047071099281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.953138589859009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05638372525572777,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13258954882621765,
      "backward_entropy": 0.04128307104110718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012103124521672726,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05640542134642601,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13256192207336426,
      "backward_entropy": 0.005549615621566773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.903245687484741,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.056425146758556366,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13253861665725708,
      "backward_entropy": 0.13862942457199096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7502946853637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05644502118229866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13251437743504843,
      "backward_entropy": 0.0414456695318222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5740561485290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05646700784564018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13248467445373535,
      "backward_entropy": 0.04148458242416382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8317065238952637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056488290429115295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1324563423792521,
      "backward_entropy": 0.041525626182556154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.805729627609253,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056509632617235184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13242765267690024,
      "backward_entropy": 0.0415680319070816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0374956130981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05653097853064537,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13239861528078714,
      "backward_entropy": 0.041609132289886476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.008048057556152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05655298009514809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13236763079961142,
      "backward_entropy": 0.00551319420337677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.487318277359009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05657574534416199,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13233510653177896,
      "backward_entropy": 0.041692095994949344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4709134101867676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05659762769937515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13230396310488382,
      "backward_entropy": 0.00550248883664608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6788973808288574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05661873146891594,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1322741707166036,
      "backward_entropy": 0.041773039102554324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2262319326400757,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056639835238456726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13224400083223978,
      "backward_entropy": 0.005489951372146607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6316914558410645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05665967985987663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13221671183904013,
      "backward_entropy": 0.00548500157892704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2073307037353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05667963996529579,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13218878706296286,
      "backward_entropy": 0.041900670528411864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.973557472229004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05669831484556198,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13216338555018106,
      "backward_entropy": 0.00547417439520359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1953248977661133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056718554347753525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13213396072387695,
      "backward_entropy": 0.04197981357574463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.719773292541504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056737590581178665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13210737705230713,
      "backward_entropy": 0.04202398657798767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.689502239227295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05675744265317917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13207833965619406,
      "backward_entropy": 0.042063137888908385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.819572448730469,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.05677802115678787,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.13204713662465414,
      "backward_entropy": 0.13862922191619872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.319643497467041,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056799862533807755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1320121685663859,
      "backward_entropy": 0.005441677197813988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1550161838531494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05682104825973511,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13197908798853555,
      "backward_entropy": 0.042158812284469604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.840334892272949,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056840892881155014,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1319490373134613,
      "backward_entropy": 0.005429393425583839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1400820016860962,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05686277523636818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13191338380177817,
      "backward_entropy": 0.04223453402519226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2534661293029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.056883279234170914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13188124696413675,
      "backward_entropy": 0.042276781797409055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.469259738922119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05690312758088112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13185039162635803,
      "backward_entropy": 0.04231841266155243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.32954740524292,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05692369118332863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13181735078493753,
      "backward_entropy": 0.00540635958313942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.508144378662109,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.056944191455841064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13178390264511108,
      "backward_entropy": 0.005399856343865394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.284097194671631,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05696600675582886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13174684842427573,
      "backward_entropy": 0.005393297970294952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2569797039031982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05698771774768829,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13170990347862244,
      "backward_entropy": 0.04246638417243957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0843675136566162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05700921267271042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1316728194554647,
      "backward_entropy": 0.04249860048294067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280013561248779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05702933296561241,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13163926204045615,
      "backward_entropy": 0.04253593683242798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1314804553985596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05705009773373604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13160358866055807,
      "backward_entropy": 0.04257120490074158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.11521577835083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057070281356573105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1315696438153585,
      "backward_entropy": 0.04261728227138519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0999321937561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05708988383412361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13153724869092306,
      "backward_entropy": 0.04266851246356964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.162026405334473,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05710891634225845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.131506085395813,
      "backward_entropy": 0.005356022715568542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.102133274078369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057128630578517914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1314725081125895,
      "backward_entropy": 0.0427670419216156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0319888591766357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057148344814777374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13143848379453024,
      "backward_entropy": 0.005346425250172615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.094936847686768,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057166799902915955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13140763839085898,
      "backward_entropy": 0.005341482162475586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0385074615478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05718659609556198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13137234250704447,
      "backward_entropy": 0.042889738082885744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.024518013000488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05720636621117592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13133672873179117,
      "backward_entropy": 0.04292371869087219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9894444942474365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05722741782665253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1312973896662394,
      "backward_entropy": 0.042958307266235354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.970076322555542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05724894255399704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13125624259312949,
      "backward_entropy": 0.0429910808801651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.968230128288269,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05727025121450424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1312152842680613,
      "backward_entropy": 0.04302249550819397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9545032978057861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057290803641080856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13117624322573343,
      "backward_entropy": 0.04305864572525024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.832724094390869,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05731072649359703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13113919893900552,
      "backward_entropy": 0.043103072047233584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8387796878814697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05733177438378334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1310982902844747,
      "backward_entropy": 0.04313988089561462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.95765221118927,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057353291660547256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13105549414952597,
      "backward_entropy": 0.04317779839038849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7785987854003906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057373370975255966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13101675113042197,
      "backward_entropy": 0.04321784973144531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.811948776245117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057393983006477356,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13097608089447021,
      "backward_entropy": 0.043256670236587524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.791541576385498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05741436779499054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1309353212515513,
      "backward_entropy": 0.005267801508307457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9284576177597046,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05743461847305298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13089455167452493,
      "backward_entropy": 0.0052609343081712725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.490659236907959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057453546673059464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1308575471242269,
      "backward_entropy": 0.005254552513360977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6339573860168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057474229484796524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1308145523071289,
      "backward_entropy": 0.04338100552558899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7036678791046143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.057495325803756714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13076985875765482,
      "backward_entropy": 0.04340646266937256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8993512392044067,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05751614272594452,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1307253042856852,
      "backward_entropy": 0.0434283196926117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6618459224700928,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.057535573840141296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13068495194117227,
      "backward_entropy": 0.005222969874739647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.15157413482666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0575549341738224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13064444065093994,
      "backward_entropy": 0.04348106980323792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7465533018112183,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.05757651850581169,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13059608141581217,
      "backward_entropy": 0.04349790215492248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4591925144195557,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05759714916348457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1305501659711202,
      "backward_entropy": 0.005196578428149223,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.094702419992537,
    "avg_log_Z": -0.056528057642281054,
    "success_rate": 1.0,
    "avg_reward": 38.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.04,
      "1": 0.6,
      "2": 0.36
    },
    "avg_forward_entropy": 0.13230261385440825,
    "avg_backward_entropy": 0.03262393003329634,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}