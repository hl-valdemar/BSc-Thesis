{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13789570331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13847941160202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.8006896972656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830343802769979,
      "backward_entropy": 0.13853843212127687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.34405517578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303092320760092,
      "backward_entropy": 0.13790109157562255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.89466857910156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00019967532716691494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830271085103353,
      "backward_entropy": 0.13790566921234132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 275.60260009765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.000298760220175609,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302287658055624,
      "backward_entropy": 0.13848921060562133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.7770538330078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.00039840509998612106,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301820755004883,
      "backward_entropy": 0.13856000900268556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.0944519042969,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0004975073388777673,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301316102345785,
      "backward_entropy": 0.13856478929519653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 259.4676208496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0005967842880636454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300769726435342,
      "backward_entropy": 0.13791849613189697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 226.66500854492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0006961473263800144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830018162727356,
      "backward_entropy": 0.13792076110839843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.5386962890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0007944134413264692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299559752146402,
      "backward_entropy": 0.13850233554840088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.9132537841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0008925454458221793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298896153767905,
      "backward_entropy": 0.13792320489883422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.4178009033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0009905369952321053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18298190832138062,
      "backward_entropy": 0.1385063648223877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.77981567382812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0010884760413318872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297441800435385,
      "backward_entropy": 0.13792608976364135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.94544982910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.001185166765935719,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829665501912435,
      "backward_entropy": 0.13850955963134765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.2354278564453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001281436299905181,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18295828501383463,
      "backward_entropy": 0.1385939598083496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 209.05393981933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0013780177105218172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18294954299926758,
      "backward_entropy": 0.13851072788238525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.77322387695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0014735640725120902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182940403620402,
      "backward_entropy": 0.1379241466522217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 242.91700744628906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0015689124120399356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293080727259317,
      "backward_entropy": 0.13860108852386474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 210.1897430419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0016646701842546463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182920773824056,
      "backward_entropy": 0.13851052522659302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.63333129882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0017593639204278588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291032314300537,
      "backward_entropy": 0.13850982189178468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.1104278564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0018548661610111594,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289937575658163,
      "backward_entropy": 0.1385090947151184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.6214599609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.001950276899151504,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18288795153299967,
      "backward_entropy": 0.13860814571380614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.1125946044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0020456791389733553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18287585179011026,
      "backward_entropy": 0.13790230751037597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 208.62222290039062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0021370251197367907,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18286365270614624,
      "backward_entropy": 0.13861083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.75900268554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.002228092635050416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285095691680908,
      "backward_entropy": 0.1385037899017334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 241.98670959472656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0023205087054520845,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283766508102417,
      "backward_entropy": 0.13861300945281982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.59945678710938,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0024139282759279013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18282375733057657,
      "backward_entropy": 0.13861401081085206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.67478942871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00250696181319654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828093727429708,
      "backward_entropy": 0.13786840438842773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.21450805664062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0025987778790295124,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279463052749634,
      "backward_entropy": 0.13861567974090577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.87562561035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0026911674067378044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277931213378906,
      "backward_entropy": 0.1384925961494446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.81185913085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0027847725432366133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827633778254191,
      "backward_entropy": 0.13848981857299805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.46340942382812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0028794475365430117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274682760238647,
      "backward_entropy": 0.1384868860244751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.57310485839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.002974298782646656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182729701201121,
      "backward_entropy": 0.13782421350479127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.61891174316406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003066158387809992,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271243572235107,
      "backward_entropy": 0.13861873149871826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.15660095214844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0031593525782227516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18269451459248862,
      "backward_entropy": 0.13847634792327881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.10047912597656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003252244321629405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267611662546793,
      "backward_entropy": 0.13861942291259766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 305.90966796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003344880882650614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182657261689504,
      "backward_entropy": 0.1377803325653076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.09315490722656,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.003441640641540289,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18263731400171915,
      "backward_entropy": 0.1386199951171875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.9757080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003534202463924885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826174259185791,
      "backward_entropy": 0.1384596347808838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.825927734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00362873962149024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18259700139363608,
      "backward_entropy": 0.13845500946044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.4120788574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.003723346861079335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257610003153482,
      "backward_entropy": 0.13773226737976074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.9975128173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003819761797785759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255484104156494,
      "backward_entropy": 0.13844506740570067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.0339813232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.003913912922143936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825336217880249,
      "backward_entropy": 0.13843972682952882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 239.54562377929688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0040091536939144135,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825117071469625,
      "backward_entropy": 0.13862078189849852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 273.2162780761719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004105426371097565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248915672302246,
      "backward_entropy": 0.13767980337142943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.26101684570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004203994292765856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18246606985727945,
      "backward_entropy": 0.137666654586792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.51950073242188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004303056746721268,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244252602259317,
      "backward_entropy": 0.13841720819473266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 240.55136108398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004399987403303385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824187437693278,
      "backward_entropy": 0.13841068744659424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.00204467773438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004497548099607229,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239430586496988,
      "backward_entropy": 0.13862067461013794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 256.63104248046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004595032427459955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18236937125523886,
      "backward_entropy": 0.1376030683517456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.40782165527344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.004693913273513317,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18234366178512573,
      "backward_entropy": 0.13862032890319825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.97434997558594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.004790039733052254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231789271036783,
      "backward_entropy": 0.13756709098815917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.97305297851562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0048863934352993965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18229162693023682,
      "backward_entropy": 0.1383746862411499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.0631103515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.004981860052794218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18226492404937744,
      "backward_entropy": 0.13836654424667358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.8574981689453,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0050739711150527,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18223830064137778,
      "backward_entropy": 0.138619327545166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.97410583496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005165670067071915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18221122026443481,
      "backward_entropy": 0.13861894607543945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 224.6048583984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005254397634416819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18218417962392172,
      "backward_entropy": 0.13833847045898437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 223.2863006591797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0053437259048223495,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821564237276713,
      "backward_entropy": 0.13832801580429077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.4365997314453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0054338239133358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18212797244389853,
      "backward_entropy": 0.13831729888916017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.3265380859375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005522020161151886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18209936221440634,
      "backward_entropy": 0.1386169195175171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 255.85684204101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0056112902238965034,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207003672917685,
      "backward_entropy": 0.1382945656776428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 238.3674774169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005703110247850418,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820396383603414,
      "backward_entropy": 0.13861587047576904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.976318359375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.005796518176794052,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18200838565826416,
      "backward_entropy": 0.13861544132232667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.5,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005889512598514557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18197665611902872,
      "backward_entropy": 0.13826004266738892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 207.10433959960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.005982221569865942,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819444497426351,
      "backward_entropy": 0.13824799060821533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.81576538085938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0060743787325918674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18191170692443848,
      "backward_entropy": 0.13724145889282227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.73606872558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006165481638163328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818786859512329,
      "backward_entropy": 0.1382224440574646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 140.28292846679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006256454158574343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818451682726542,
      "backward_entropy": 0.1382089614868164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 270.9927673339844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00634351558983326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818119684855143,
      "backward_entropy": 0.13819427490234376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.7050323486328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006434472277760506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18177727858225504,
      "backward_entropy": 0.1381802201271057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 156.282958984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006523288320749998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1817424496014913,
      "backward_entropy": 0.13816525936126708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.84925842285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006609424948692322,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18170770009358725,
      "backward_entropy": 0.1370644450187683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.13685607910156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.006695921067148447,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18167227506637573,
      "backward_entropy": 0.1386096715927124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.0186309814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006783066317439079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816361943880717,
      "backward_entropy": 0.13699960708618164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.31784057617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.006871615070849657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18159921964009604,
      "backward_entropy": 0.13810073137283324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.30101013183594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.006959549617022276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18156238396962485,
      "backward_entropy": 0.13693604469299317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.3374786376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0070487502962350845,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152499198913574,
      "backward_entropy": 0.13690392971038817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.9730224609375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0071360329166054726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814874013264974,
      "backward_entropy": 0.1386062502861023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.5894775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0072226994670927525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18144933382670084,
      "backward_entropy": 0.1368337392807007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 205.3616485595703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007308053784072399,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814111272493998,
      "backward_entropy": 0.13801145553588867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.48709106445312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007393944542855024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18137208620707193,
      "backward_entropy": 0.13799166679382324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 252.66746520996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007478621788322926,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18133286635080972,
      "backward_entropy": 0.1386023759841919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 253.4108428955078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007567037828266621,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18129209677378336,
      "backward_entropy": 0.13860158920288085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.92583465576172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.007658618036657572,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18124977747599283,
      "backward_entropy": 0.13860101699829103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 237.18765258789062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007745085749775171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18120819330215454,
      "backward_entropy": 0.1379111409187317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.63058471679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.007833979092538357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18116525808970133,
      "backward_entropy": 0.13657655715942382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.04481506347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.007921269163489342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18112218379974365,
      "backward_entropy": 0.13786808252334595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 235.74691772460938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008008075878024101,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18107863267262778,
      "backward_entropy": 0.13784546852111818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00809754803776741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18103369077046713,
      "backward_entropy": 0.13646039962768555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.64735412597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008182455785572529,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18098962306976318,
      "backward_entropy": 0.1364201068878174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.62063598632812,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008267393335700035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18094495932261148,
      "backward_entropy": 0.13638014793395997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.86080932617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008351954631507397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18089969952901205,
      "backward_entropy": 0.13775067329406737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 222.19105529785156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.008434423245489597,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18085455894470215,
      "backward_entropy": 0.13859291076660157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.13227081298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00851853284984827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18080788850784302,
      "backward_entropy": 0.13624725341796876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.5968017578125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008597916923463345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18076159556706747,
      "backward_entropy": 0.13766720294952392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.55319213867188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.008678757585585117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18071413040161133,
      "backward_entropy": 0.13763713836669922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 171.43380737304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.00876194704324007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1806651751200358,
      "backward_entropy": 0.1360926389694214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.74082946777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008844112046062946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1806157430013021,
      "backward_entropy": 0.13604068756103516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 221.35617065429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.008923554793000221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18056670824686685,
      "backward_entropy": 0.13598742485046386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.46145629882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009005130268633366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18051588535308838,
      "backward_entropy": 0.1375112295150757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.00485229492188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009087111800909042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18046430746714273,
      "backward_entropy": 0.13587796688079834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.9620361328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009170188568532467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18041137854258218,
      "backward_entropy": 0.13582241535186768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.91942596435547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009249282069504261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803592840830485,
      "backward_entropy": 0.13576393127441405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.83053588867188,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009324789047241211,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18030784527460733,
      "backward_entropy": 0.13857476711273192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.4753189086914,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009400386363267899,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18025575081507364,
      "backward_entropy": 0.1356416940689087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.492431640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009470115415751934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1802048683166504,
      "backward_entropy": 0.13728346824645996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.42955017089844,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009541034698486328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18015257517496744,
      "backward_entropy": 0.13856714963912964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 172.3988037109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.00961303897202015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1800988713900248,
      "backward_entropy": 0.13719232082366944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 203.86483764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.009684928692877293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180044154326121,
      "backward_entropy": 0.1353600025177002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 201.8076171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009759020991623402,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17998762925465903,
      "backward_entropy": 0.13709621429443358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.6738739013672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009835531935095787,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1799295941988627,
      "backward_entropy": 0.13855516910552979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.51388549804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.009910746477544308,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1798712412516276,
      "backward_entropy": 0.13855185508728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 139.013916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.009987028315663338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17981169621149698,
      "backward_entropy": 0.13695061206817627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.6530303955078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010060838423669338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17975221077601114,
      "backward_entropy": 0.13689887523651123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.5927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010134957730770111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17969197034835815,
      "backward_entropy": 0.134916090965271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.8569793701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010209367610514164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17963093519210815,
      "backward_entropy": 0.13679424524307252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.97019958496094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.0102815181016922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17956988016764322,
      "backward_entropy": 0.1385344982147217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 250.97108459472656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010354956611990929,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17950725555419922,
      "backward_entropy": 0.13467953205108643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.69039154052734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010433860123157501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17944125334421793,
      "backward_entropy": 0.13460311889648438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.45947265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010508038103580475,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17937660217285156,
      "backward_entropy": 0.13852345943450928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.82196807861328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010582282207906246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17931095759073892,
      "backward_entropy": 0.13444061279296876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.94102478027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.010652448982000351,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792470614115397,
      "backward_entropy": 0.13435521125793456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.00875854492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.010723206214606762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17918227116266885,
      "backward_entropy": 0.13639419078826903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.92433166503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01079623680561781,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17911499738693237,
      "backward_entropy": 0.13633182048797607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.08615112304688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01086844690144062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17904732624689737,
      "backward_entropy": 0.13408956527709961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 219.26455688476562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.010940113104879856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17897929747899374,
      "backward_entropy": 0.13849852085113526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.3557891845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011015222407877445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17890912294387817,
      "backward_entropy": 0.1361376166343689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.6837158203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01108942274004221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.178839643796285,
      "backward_entropy": 0.1360710859298706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 153.2364044189453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01116272620856762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1787696878115336,
      "backward_entropy": 0.1337178111076355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.03514099121094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01123532559722662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17869927485783896,
      "backward_entropy": 0.133620285987854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.8229522705078,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011308461427688599,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17862778902053833,
      "backward_entropy": 0.13847815990447998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.28067779541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011383241973817348,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.178554634253184,
      "backward_entropy": 0.13342713117599486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.07756042480469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.011453474871814251,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17848251263300577,
      "backward_entropy": 0.13332271575927734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.25834655761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011520804837346077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1784107486406962,
      "backward_entropy": 0.1356348514556885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.6252899169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011585713364183903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17833934227625528,
      "backward_entropy": 0.13555099964141845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.6815643310547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.011651548556983471,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17826602856318155,
      "backward_entropy": 0.13845114707946776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.80784606933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01172093115746975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17819001277287802,
      "backward_entropy": 0.13283710479736327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.97616577148438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011794562451541424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17811073859532675,
      "backward_entropy": 0.13529958724975585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.62681579589844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011866996064782143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17803055047988892,
      "backward_entropy": 0.13521384000778197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.13651275634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.011941171251237392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17794849475224814,
      "backward_entropy": 0.13512861728668213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 234.53196716308594,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012011080980300903,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17786792914072672,
      "backward_entropy": 0.13842514753341675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.74063110351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012085854075849056,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17778297265370688,
      "backward_entropy": 0.1349456191062927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.8072967529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01216428354382515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17769487698872885,
      "backward_entropy": 0.13485649824142457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 218.05978393554688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012240622192621231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17760719855626425,
      "backward_entropy": 0.13195133209228516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.74266052246094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012320118024945259,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17751580476760864,
      "backward_entropy": 0.13840713500976562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.9921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012399422004818916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17742331822713217,
      "backward_entropy": 0.13168694972991943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.97412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012476473115384579,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17733188470204672,
      "backward_entropy": 0.13447928428649902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.21026611328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012554867193102837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1772392193476359,
      "backward_entropy": 0.13438100814819337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.7993927001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012627577409148216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17714923620224,
      "backward_entropy": 0.13427550792694093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.846435546875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.012698712758719921,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17705931266148886,
      "backward_entropy": 0.13112022876739501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.50070190429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.012772918678820133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17696630954742432,
      "backward_entropy": 0.13405858278274535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.66232299804688,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012849705293774605,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17687020699183145,
      "backward_entropy": 0.13837137222290039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.7374725341797,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.012928993441164494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17677128314971924,
      "backward_entropy": 0.13836673498153687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.22776794433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01300827506929636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17667152484258017,
      "backward_entropy": 0.13053321838378906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.20375061035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013083772733807564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17657254139582315,
      "backward_entropy": 0.13361759185791017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.01942443847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013159762136638165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17647196849187216,
      "backward_entropy": 0.13021416664123536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.33766174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01323117408901453,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17637290557225546,
      "backward_entropy": 0.13337357044219972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.66925048828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013302313163876534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17627573013305664,
      "backward_entropy": 0.12987016439437865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.9256591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013371721841394901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17617841561635336,
      "backward_entropy": 0.13311190605163575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 216.42446899414062,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013440895825624466,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17607998847961426,
      "backward_entropy": 0.13831710815429688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 151.04275512695312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013514205813407898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17597679297129312,
      "backward_entropy": 0.1293109655380249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 136.02114868164062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013587091118097305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17587300141652426,
      "backward_entropy": 0.12911713123321533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.34542846679688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.013658199459314346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17576913038889566,
      "backward_entropy": 0.12891488075256347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.9222412109375,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013732370920479298,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1756616234779358,
      "backward_entropy": 0.1382833957672119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.7310333251953,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.013806900009512901,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17555226882298788,
      "backward_entropy": 0.1382749319076538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 167.74267578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01388091966509819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17544243733088175,
      "backward_entropy": 0.12829883098602296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.85226440429688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.013955335132777691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17533065875371298,
      "backward_entropy": 0.13196442127227784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.95623016357422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01403169333934784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1752165953318278,
      "backward_entropy": 0.1318136692047119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 199.08421325683594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014101279899477959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17510676383972168,
      "backward_entropy": 0.12765278816223144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.8954620361328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014174067415297031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17499226331710815,
      "backward_entropy": 0.12742829322814941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.89772033691406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014246935024857521,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17487545808156332,
      "backward_entropy": 0.12720899581909179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 183.1499786376953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014321574941277504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.174754798412323,
      "backward_entropy": 0.12698783874511718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.8880157470703,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014397724531590939,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1746305227279663,
      "backward_entropy": 0.1382051706314087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.91433715820312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014477729797363281,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1745011806488037,
      "backward_entropy": 0.1308450222015381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.316890716552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01455701980739832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17437201738357544,
      "backward_entropy": 0.13067963123321533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.78553771972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014628195203840733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17424889405568442,
      "backward_entropy": 0.12608687877655028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 213.04580688476562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014700133353471756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1741226315498352,
      "backward_entropy": 0.1258434534072876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 181.0935516357422,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.014776494354009628,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17399078607559204,
      "backward_entropy": 0.1381644368171692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.57266235351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.014854597859084606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17385637760162354,
      "backward_entropy": 0.12996034622192382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.78814697265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.014931650832295418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17372095584869385,
      "backward_entropy": 0.12513840198516846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 166.61622619628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015004322864115238,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17358815670013428,
      "backward_entropy": 0.12958523035049438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 182.04183959960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015077555552124977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1734523375829061,
      "backward_entropy": 0.1246187925338745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.58572387695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.015152528882026672,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17331190903981528,
      "backward_entropy": 0.129192316532135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 196.63536071777344,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015226123854517937,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1731723149617513,
      "backward_entropy": 0.13810603618621825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.31199645996094,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01530284620821476,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17302783330281576,
      "backward_entropy": 0.13809657096862793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.6681137084961,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.015376124531030655,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17288424571355185,
      "backward_entropy": 0.13808445930480956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 134.29367065429688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015443079173564911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1727461814880371,
      "backward_entropy": 0.12322278022766113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.1595001220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015508923679590225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1726070245107015,
      "backward_entropy": 0.12290875911712647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 135.13150024414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01557434443384409,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17246784766515097,
      "backward_entropy": 0.12787797451019287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.28611755371094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015638547018170357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17232704162597656,
      "backward_entropy": 0.12226688861846924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 179.3060302734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015704642981290817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17218307654062906,
      "backward_entropy": 0.12194064855575562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.04185485839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01577378436923027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1720347801844279,
      "backward_entropy": 0.1216245412826538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 133.06825256347656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.015840480104088783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17188719908396402,
      "backward_entropy": 0.12129454612731934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.4169464111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01590634137392044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17173904180526733,
      "backward_entropy": 0.12664439678192138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 165.40859985351562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01597244292497635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17158830165863037,
      "backward_entropy": 0.12638394832611083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.20323181152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01603984460234642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17143350839614868,
      "backward_entropy": 0.12025671005249024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.83970642089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016107356175780296,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17127645015716553,
      "backward_entropy": 0.1258505702018738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 148.323974609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016176143661141396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17111579577128092,
      "backward_entropy": 0.1195276141166687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.9024200439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01624510996043682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17095349232355753,
      "backward_entropy": 0.11915761232376099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 162.8403778076172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01631462201476097,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17079023520151773,
      "backward_entropy": 0.1250239133834839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.66590881347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01638570800423622,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17062461376190186,
      "backward_entropy": 0.12474825382232665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.23007202148438,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01645686849951744,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1704575220743815,
      "backward_entropy": 0.13783884048461914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.66303253173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01652820035815239,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17028876145680746,
      "backward_entropy": 0.12418596744537354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.58831024169922,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01659458316862583,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1701246698697408,
      "backward_entropy": 0.13781025409698486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.59486389160156,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.016656510531902313,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16996479034423828,
      "backward_entropy": 0.13779059648513795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 193.1349334716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016718575730919838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1698045333226522,
      "backward_entropy": 0.12325115203857422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 147.96018981933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.016785472631454468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1696371634801229,
      "backward_entropy": 0.11617299318313598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 225.4029541015625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01685265265405178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16946705182393393,
      "backward_entropy": 0.11578683853149414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.20087432861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016926100477576256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16928641001383463,
      "backward_entropy": 0.1223260760307312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.7445297241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.016997192054986954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16910467545191446,
      "backward_entropy": 0.12201361656188965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 146.8470916748047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01706460304558277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16892544428507486,
      "backward_entropy": 0.12168395519256592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.9813690185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017132466658949852,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1687437891960144,
      "backward_entropy": 0.12134954929351807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 115.11981964111328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017203373834490776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1685572862625122,
      "backward_entropy": 0.12102364301681519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.18009948730469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017272118479013443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1683721343676249,
      "backward_entropy": 0.11341317892074584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.46073913574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01733643002808094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1681912342707316,
      "backward_entropy": 0.12033716440200806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.60025024414062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017398787662386894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16800957918167114,
      "backward_entropy": 0.11997253894805908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.4815673828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017460690811276436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16782552003860474,
      "backward_entropy": 0.11959989070892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 176.13743591308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01752007007598877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1676438252131144,
      "backward_entropy": 0.11159956455230713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.33847045898438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017583448439836502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16745521624883017,
      "backward_entropy": 0.11114051342010497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 206.56570434570312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017646584659814835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16726505756378174,
      "backward_entropy": 0.1184619426727295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 160.7964630126953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017715802416205406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1670650045077006,
      "backward_entropy": 0.11023750305175781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.4066162109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017786681652069092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16686097780863443,
      "backward_entropy": 0.11774272918701172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.32933044433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.017854375764727592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16666116317113241,
      "backward_entropy": 0.11736986637115479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.194091796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.017922628670930862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16645830869674683,
      "backward_entropy": 0.10891364812850952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.00078582763672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01799139566719532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16625299056371054,
      "backward_entropy": 0.10846058130264283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 191.53163146972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.01805693283677101,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1660512089729309,
      "backward_entropy": 0.11620991230010987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.79485321044922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018126757815480232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1658400297164917,
      "backward_entropy": 0.10751814842224121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.814697265625,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018193267285823822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16563275456428528,
      "backward_entropy": 0.13742871284484864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.71192932128906,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018258102238178253,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16542688012123108,
      "backward_entropy": 0.13740880489349366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 190.2430877685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01832742616534233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16521159807840982,
      "backward_entropy": 0.10604050159454345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 143.35467529296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018400873988866806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16498751441637674,
      "backward_entropy": 0.11417746543884277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 204.94808959960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018474655225872993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16476323207219443,
      "backward_entropy": 0.10508888959884644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 113.49503326416016,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.01855337619781494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16452890634536743,
      "backward_entropy": 0.13736389875411986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.03254699707031,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.018629154190421104,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16429824630419412,
      "backward_entropy": 0.1373543381690979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.079345703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018701082095503807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16407318909962973,
      "backward_entropy": 0.11256486177444458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.28289794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018769823014736176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16385320822397867,
      "backward_entropy": 0.103152596950531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.99763488769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.018836915493011475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16363519430160522,
      "backward_entropy": 0.11168413162231446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.86727142333984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.018902262672781944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16341809431711832,
      "backward_entropy": 0.10211077928543091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.4696502685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0189647413790226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16320409377415976,
      "backward_entropy": 0.10156095027923584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 173.6644287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019029946997761726,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16298498709996542,
      "backward_entropy": 0.11028856039047241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 126.6603775024414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01909845508635044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16275725762049356,
      "backward_entropy": 0.10048978328704834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.63956451416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019166693091392517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625302036603292,
      "backward_entropy": 0.09995774030685425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.87998962402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01923077367246151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16230986515680948,
      "backward_entropy": 0.09940522909164429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.57162475585938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019296174868941307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16208638747533163,
      "backward_entropy": 0.09885778427124023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.31027221679688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019356030970811844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16187010208765665,
      "backward_entropy": 0.10788722038269043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.77136993408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019418690353631973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1616459091504415,
      "backward_entropy": 0.10738331079483032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 186.00534057617188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019477603957057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16142712036768594,
      "backward_entropy": 0.09709309339523316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 111.6109619140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019542289897799492,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16119821866353354,
      "backward_entropy": 0.10636178255081177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 170.74681091308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019605593755841255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1609702209631602,
      "backward_entropy": 0.09595399498939514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 81.35089111328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.019672956317663193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16073455413182577,
      "backward_entropy": 0.10535292625427246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 157.06570434570312,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0197361521422863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1605052351951599,
      "backward_entropy": 0.09482318162918091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.62654876708984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01980162225663662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16026902198791504,
      "backward_entropy": 0.0942355751991272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.27325439453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.01986331306397915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003958384195963,
      "backward_entropy": 0.09363157749176025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.13053894042969,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019925469532608986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15980835755666098,
      "backward_entropy": 0.09303535223007202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.29263305664062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.019988059997558594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15957540273666382,
      "backward_entropy": 0.09244086742401122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.8476791381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020051835104823112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15933736165364584,
      "backward_entropy": 0.09183162450790405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 184.81045532226562,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020116260275244713,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1590998967488607,
      "backward_entropy": 0.13683369159698486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.71932220458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02018577605485916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1588513453801473,
      "backward_entropy": 0.09067141413688659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 169.3877716064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.020250914618372917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1586095094680786,
      "backward_entropy": 0.10055627822875976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 155.65087890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02031988836824894,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15835916996002197,
      "backward_entropy": 0.10002498626708985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 124.55323028564453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020390590652823448,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15810168782869974,
      "backward_entropy": 0.08887460827827454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.675048828125,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02046077884733677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.157844344774882,
      "backward_entropy": 0.1367441177368164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.99893951416016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020529206842184067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15758943557739258,
      "backward_entropy": 0.08764205574989319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.45563507080078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020595889538526535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15733625491460165,
      "backward_entropy": 0.0869993269443512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 168.8592529296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020659958943724632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15708728631337485,
      "backward_entropy": 0.0863426923751831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8290252685547,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.020727800205349922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15682844320933023,
      "backward_entropy": 0.1366483211517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.29966735839844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.020798170939087868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15656453371047974,
      "backward_entropy": 0.0850795865058899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.91532897949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02086312510073185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15631271402041116,
      "backward_entropy": 0.08443163633346558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.30332946777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02092568762600422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15606538454691568,
      "backward_entropy": 0.09490865468978882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.53050231933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02098708599805832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15581788619359335,
      "backward_entropy": 0.08308383822441101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.47667694091797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021048855036497116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15556764602661133,
      "backward_entropy": 0.08239502906799316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.19822692871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021107440814375877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1553251842657725,
      "backward_entropy": 0.0930362582206726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 152.8179931640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021166713908314705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15507906675338745,
      "backward_entropy": 0.0924006998538971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.2256088256836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021228991448879242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1548237403233846,
      "backward_entropy": 0.09177513122558593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.47319793701172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021290726959705353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15457040071487427,
      "backward_entropy": 0.09114966988563537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.51590728759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021352969110012054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15431496500968933,
      "backward_entropy": 0.09052391648292542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.48658752441406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021411800757050514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15406600634256998,
      "backward_entropy": 0.07822057008743286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 150.95498657226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021472442895174026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1538105010986328,
      "backward_entropy": 0.08923847675323486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.54317474365234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02153637446463108,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15354782342910767,
      "backward_entropy": 0.0886134922504425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 122.01915740966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021596606820821762,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15329124530156454,
      "backward_entropy": 0.08796394467353821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 164.99874877929688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021657412871718407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15303194522857666,
      "backward_entropy": 0.08731328248977661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 92.37361145019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021722761914134026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1527626315752665,
      "backward_entropy": 0.08668667078018188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.05072021484375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021785730496048927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15249778827031454,
      "backward_entropy": 0.07400134801864625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 149.31607055664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.021848144009709358,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1522352695465088,
      "backward_entropy": 0.08539812564849854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 106.703857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.021913927048444748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1519664724667867,
      "backward_entropy": 0.07263705134391785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.8515167236328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02197849377989769,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15169954299926758,
      "backward_entropy": 0.07195234298706055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.78105926513672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022047296166419983,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15142184495925903,
      "backward_entropy": 0.13600165843963624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.07545471191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022114858031272888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15114684899648032,
      "backward_entropy": 0.07063884735107422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 163.13418579101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02218008041381836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1508780519167582,
      "backward_entropy": 0.08228243589401245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.6967544555664,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02224951609969139,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15059983730316162,
      "backward_entropy": 0.13593666553497313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.57490539550781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02231604978442192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15032612284024557,
      "backward_entropy": 0.06865707635879517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 104.55804443359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022382862865924835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15005087852478027,
      "backward_entropy": 0.0679885983467102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 90.485107421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022448871284723282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1497786045074463,
      "backward_entropy": 0.0797889769077301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.26079559326172,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02251269295811653,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14951159556706747,
      "backward_entropy": 0.13583531379699706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.65007781982422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022573158144950867,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14925160010655722,
      "backward_entropy": 0.07848682999610901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.3287353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.022632263600826263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1489959955215454,
      "backward_entropy": 0.07782628536224365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.64695739746094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02269216813147068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14873534440994263,
      "backward_entropy": 0.06458591818809509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.7164535522461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02275443635880947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14846952756245932,
      "backward_entropy": 0.063914954662323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.89800262451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022814981639385223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14820758501688638,
      "backward_entropy": 0.0632379412651062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.55830383300781,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.022875236347317696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14794586102167764,
      "backward_entropy": 0.13563160896301268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.7296371459961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022935327142477036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1476845939954122,
      "backward_entropy": 0.06189068555831909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 188.42233276367188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.022995600476861,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14742554227511087,
      "backward_entropy": 0.06123846769332886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.46516799926758,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023063331842422485,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14714967211087546,
      "backward_entropy": 0.13555854558944702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 131.3477020263672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02312498725950718,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14688816666603088,
      "backward_entropy": 0.1355311393737793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 117.22039794921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023188870400190353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14662110805511475,
      "backward_entropy": 0.059353423118591306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.91317749023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023253388702869415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14635119835535684,
      "backward_entropy": 0.07141900062561035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.02896118164062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023319879546761513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14607652028401694,
      "backward_entropy": 0.07080526947975159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.17157745361328,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023389307782053947,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14579339822133383,
      "backward_entropy": 0.1354549527168274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.40098571777344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023452969267964363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14552807807922363,
      "backward_entropy": 0.056876498460769656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 200.65223693847656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02351604774594307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14526256918907166,
      "backward_entropy": 0.05625116229057312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.51932525634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02358737774193287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1449758211771647,
      "backward_entropy": 0.06837664246559143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.37217712402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023655064404010773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14470012982686362,
      "backward_entropy": 0.05507211089134216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.30656814575195,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.023719485849142075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.14443292220433554,
      "backward_entropy": 0.13536797761917113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 87.41094970703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023779667913913727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14417598644892374,
      "backward_entropy": 0.05384443998336792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 142.5175323486328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.023838460445404053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14392094810803732,
      "backward_entropy": 0.05321527123451233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.39193725585938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.023901386186480522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14365694920221964,
      "backward_entropy": 0.06525536775588989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.34716796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02396181784570217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14340136448542276,
      "backward_entropy": 0.05202449560165405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.14820861816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02402365580201149,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1431428094704946,
      "backward_entropy": 0.05144190788269043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 114.34022521972656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02408677712082863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14288129409154257,
      "backward_entropy": 0.05087288618087769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.7673454284668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024150853976607323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1426163613796234,
      "backward_entropy": 0.05030646324157715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.12986755371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02420947141945362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1423646608988444,
      "backward_entropy": 0.06221948862075806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 141.24551391601562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.024268804118037224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.14211455980936685,
      "backward_entropy": 0.061615598201751706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 154.6137237548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02433212287724018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14185434579849243,
      "backward_entropy": 0.04859051406383515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.33466339111328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024400392547249794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1415830651919047,
      "backward_entropy": 0.048068398237228395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 99.1406478881836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024468032643198967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14131293694178262,
      "backward_entropy": 0.04754528999328613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.23155975341797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024535121396183968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1410436431566874,
      "backward_entropy": 0.04702271819114685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.30990982055664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024599339812994003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14078301191329956,
      "backward_entropy": 0.046492868661880495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 71.06121063232422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02465975098311901,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14053318897883096,
      "backward_entropy": 0.04595447182655334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.16386413574219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024717921391129494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14028873046239218,
      "backward_entropy": 0.045412486791610716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 125.7539291381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024776704609394073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.14004300038019815,
      "backward_entropy": 0.044882658123970035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.04947662353516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02483830600976944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13978907465934753,
      "backward_entropy": 0.056528341770172116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.04924011230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.024901099503040314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1395301620165507,
      "backward_entropy": 0.043837171792984006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.53429412841797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02496279962360859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1392751932144165,
      "backward_entropy": 0.04331673383712768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.66357421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025024766102433205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1390205224355062,
      "backward_entropy": 0.042803019285202026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.75677490234375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025086788460612297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13876391450564066,
      "backward_entropy": 0.0422897458076477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.8653335571289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02514771744608879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1385105848312378,
      "backward_entropy": 0.041777580976486206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 137.4716796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02520911768078804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13825756311416626,
      "backward_entropy": 0.05323894619941712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.76424407958984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025274556130170822,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13799428939819336,
      "backward_entropy": 0.052724921703338624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.44523620605469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025342358276247978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13772489627202353,
      "backward_entropy": 0.040335440635681154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.40338897705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025407401844859123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13746358950932822,
      "backward_entropy": 0.05171966552734375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.55792999267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02547147497534752,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13720724980036417,
      "backward_entropy": 0.0394031822681427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.42948150634766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025536879897117615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1369479497273763,
      "backward_entropy": 0.050724124908447264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 109.20294189453125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025603435933589935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13668493429819742,
      "backward_entropy": 0.038500869274139406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.48381042480469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025671042501926422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13641905784606934,
      "backward_entropy": 0.04975663423538208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 161.71395874023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02573845535516739,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13615475098292032,
      "backward_entropy": 0.049276101589202884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.19300079345703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.025812074542045593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13587727149327597,
      "backward_entropy": 0.037199932336807254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 94.94572448730469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.025881126523017883,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1356118122736613,
      "backward_entropy": 0.048370260000228885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.33641815185547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02594982087612152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13534650206565857,
      "backward_entropy": 0.04790749847888946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 107.88197326660156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026020634919404984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13507558902104697,
      "backward_entropy": 0.035936403274536136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.15407943725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026092099025845528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13480226198832193,
      "backward_entropy": 0.035526233911514285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.82135772705078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026156822219491005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1345475415388743,
      "backward_entropy": 0.04654081165790558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.67650604248047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026219118386507034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13429837425549826,
      "backward_entropy": 0.0346610814332962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 132.9340057373047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026281999424099922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1340481440226237,
      "backward_entropy": 0.03424094021320343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.127685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02634911611676216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13378924131393433,
      "backward_entropy": 0.04516237676143646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.9522476196289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026415148749947548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1335352063179016,
      "backward_entropy": 0.03345508575439453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 119.30204010009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02648022398352623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.133285125096639,
      "backward_entropy": 0.03306835889816284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.95594024658203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.026547912508249283,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13302789131800333,
      "backward_entropy": 0.04386444687843323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.73505401611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02661421336233616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1327736179033915,
      "backward_entropy": 0.03230398893356323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.49126434326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026681827381253242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13251501321792603,
      "backward_entropy": 0.031926783919334414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 118.13536071777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02674694173038006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13226325313250223,
      "backward_entropy": 0.04258875250816345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 130.78402709960938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026814842596650124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1320054034392039,
      "backward_entropy": 0.03117806911468506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.7113265991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02688651531934738,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.13173908988634744,
      "backward_entropy": 0.04179137945175171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.55989837646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.026957927271723747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13147443532943726,
      "backward_entropy": 0.030487635731697084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.099891662597656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027029063552618027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13121102253595987,
      "backward_entropy": 0.03014855980873108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.535099029541016,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027095934376120567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13095672925313315,
      "backward_entropy": 0.029789409041404723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.498779296875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027159379795193672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13071314493815103,
      "backward_entropy": 0.029427546262741088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 116.64849090576172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027225911617279053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13046089808146158,
      "backward_entropy": 0.02908644378185272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 103.41490936279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02729484811425209,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.13020110130310059,
      "backward_entropy": 0.028750041127204896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 102.8897705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027364926412701607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12993856271107992,
      "backward_entropy": 0.039081108570098874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.12571716308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027436314150691032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12967488169670105,
      "backward_entropy": 0.028097128868103026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.904579162597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027506545186042786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12941700220108032,
      "backward_entropy": 0.03837134838104248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 76.86955261230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027572957798838615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12916894753774008,
      "backward_entropy": 0.027466806769371032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.59006118774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02763863280415535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12892458836237589,
      "backward_entropy": 0.027153486013412477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.836002349853516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027701033279299736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12868844469388327,
      "backward_entropy": 0.026834014058113097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.037094116210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.027759289368987083,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12846378485361734,
      "backward_entropy": 0.03690209686756134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.87592315673828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027812719345092773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12825489044189453,
      "backward_entropy": 0.02617926001548767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.4117546081543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027867881581187248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12803848584493002,
      "backward_entropy": 0.025864970684051514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 138.7489776611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.027919834479689598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12783149878184,
      "backward_entropy": 0.025553444027900697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 88.45398712158203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02797839231789112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1276041865348816,
      "backward_entropy": 0.03544259071350098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.7250747680664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028038067743182182,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12737423181533813,
      "backward_entropy": 0.02497379332780838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.67170333862305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028097614645957947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12714375058809915,
      "backward_entropy": 0.024687594175338744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 112.36304473876953,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028154604136943817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12691980600357056,
      "backward_entropy": 0.02439652234315872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.916969299316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02821575291454792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12668752670288086,
      "backward_entropy": 0.024127496778964995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.53037643432617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028275329619646072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12645792961120605,
      "backward_entropy": 0.023851454257965088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.93448257446289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.02833380177617073,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1262317697207133,
      "backward_entropy": 0.1355215549468994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 123.78395080566406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028388546779751778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1260150671005249,
      "backward_entropy": 0.02329837381839752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.90250778198242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02844887040555477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12578489383061728,
      "backward_entropy": 0.023043608665466307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.17705535888672,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.028506718575954437,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.12556219100952148,
      "backward_entropy": 0.1355683445930481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.25312805175781,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028564993292093277,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12533867359161377,
      "backward_entropy": 0.022541533410549163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.973264694213867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028623342514038086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12511264284451803,
      "backward_entropy": 0.02229519784450531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.88520050048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.028677193447947502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12490153312683105,
      "backward_entropy": 0.022047753632068633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 73.49901580810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02873164229094982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12468769152959187,
      "backward_entropy": 0.021802736818790434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 121.99072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02878696285188198,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12447343269983928,
      "backward_entropy": 0.021570149064064025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.11033248901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028847843408584595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12424490849177043,
      "backward_entropy": 0.030875086784362793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 145.6393585205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02890627272427082,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1240229606628418,
      "backward_entropy": 0.030616748332977294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 85.1092300415039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.028972353786230087,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1237810452779134,
      "backward_entropy": 0.030386444926261903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.672607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02903907001018524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12353641788164775,
      "backward_entropy": 0.03015560507774353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.607521057128906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02910543605685234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12329407533009847,
      "backward_entropy": 0.020559978485107423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 96.36620330810547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029167622327804565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12306289871533711,
      "backward_entropy": 0.020361657440662383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.18659210205078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029232218861579895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12282482782999675,
      "backward_entropy": 0.02017102241516113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.03453826904297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02929776906967163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1225842038790385,
      "backward_entropy": 0.02924383282661438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.12508010864258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029363002628087997,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12234507004419963,
      "backward_entropy": 0.02902469038963318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 95.39910888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029425423592329025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12211291988690694,
      "backward_entropy": 0.02880045771598816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 83.35108184814453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029490308836102486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1218726634979248,
      "backward_entropy": 0.019430601596832277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.917198181152344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029556158930063248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12163070837656657,
      "backward_entropy": 0.019256484508514405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.086544036865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.02961798384785652,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12140018741289775,
      "backward_entropy": 0.02816988229751587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.83625030517578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.029674887657165527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.12118228276570638,
      "backward_entropy": 0.018884000182151795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.66414642333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029728492721915245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1209714412689209,
      "backward_entropy": 0.027709174156188964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.13906478881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029784055426716805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12074657281239827,
      "backward_entropy": 0.027479800581932067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.44935607910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029838133603334427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12052367130915324,
      "backward_entropy": 0.027257063984870912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 93.673828125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.02989322692155838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1202961007754008,
      "backward_entropy": 0.018119119107723236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 105.0631332397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.029951537027955055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.12005797028541565,
      "backward_entropy": 0.0268483966588974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.2711067199707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03001399151980877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11980732282002766,
      "backward_entropy": 0.0177912101149559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 127.70884704589844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03007557801902294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11956089735031128,
      "backward_entropy": 0.017639002203941344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.64411926269531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03014335408806801,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11929619312286377,
      "backward_entropy": 0.017498095333576203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.98552703857422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030210677534341812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11903156836827596,
      "backward_entropy": 0.017356988787651063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.351423263549805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030278775840997696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11876299977302551,
      "backward_entropy": 0.017216742038726807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 80.5827407836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030341483652591705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11850967009862264,
      "backward_entropy": 0.025803512334823607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.9680404663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030405381694436073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11825038989384969,
      "backward_entropy": 0.025629597902297973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.43181610107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03046908974647522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1179895003636678,
      "backward_entropy": 0.025454211235046386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.5760269165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030529357492923737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11774082978566487,
      "backward_entropy": 0.025278666615486146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.3213882446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030589887872338295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11748908956845601,
      "backward_entropy": 0.016467665135860444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.901853561401367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030650846660137177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11723627646764119,
      "backward_entropy": 0.01632264256477356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.43239974975586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.030707309022545815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1169975996017456,
      "backward_entropy": 0.024756328761577608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 79.10459899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03076212666928768,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11676416794459026,
      "backward_entropy": 0.01602456867694855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 101.40924072265625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03081911988556385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11652203400929768,
      "backward_entropy": 0.015882104635238647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.301692962646484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030880412086844444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11626437306404114,
      "backward_entropy": 0.015748921036720275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.27499389648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.030940793454647064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11600977182388306,
      "backward_entropy": 0.015616275370121002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 100.59041595458984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031001724302768707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11575416723887126,
      "backward_entropy": 0.015489378571510315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.68184280395508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03106665052473545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11548573772112529,
      "backward_entropy": 0.015369813144207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.8023910522461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03112923912703991,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11522541443506877,
      "backward_entropy": 0.023655505478382112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.551666259765625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03119196929037571,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11496259768803914,
      "backward_entropy": 0.015130770206451417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.341896057128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031253643333911896,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11470197637875874,
      "backward_entropy": 0.023368111252784728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.21712493896484,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03131454810500145,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.11444469292958577,
      "backward_entropy": 0.1369241714477539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 77.03950500488281,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031375911086797714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11418528358141582,
      "backward_entropy": 0.014776189625263215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.9237174987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031438808888196945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11392001310984294,
      "backward_entropy": 0.022952884435653687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 98.40887451171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03150072321295738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11365650097529094,
      "backward_entropy": 0.014551651477813721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 65.49271392822266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03156663849949837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11338065067927043,
      "backward_entropy": 0.014449290931224823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.009350776672363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03163248673081398,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11310434341430664,
      "backward_entropy": 0.022572307288646697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.787841796875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03169231861829758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11284925540288289,
      "backward_entropy": 0.014242474734783173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.38084411621094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03174799680709839,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11260857184727986,
      "backward_entropy": 0.014135004580020904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 86.33992004394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.031808145344257355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11235034465789795,
      "backward_entropy": 0.02218415290117264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 64.59244537353516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.031871140003204346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11208160718282063,
      "backward_entropy": 0.013932089507579803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.54421043395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03193438798189163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11181133985519409,
      "backward_entropy": 0.013833969831466675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.89934539794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03199314698576927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11155735452969869,
      "backward_entropy": 0.013733671605587005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.38756561279297,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032053835690021515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11129569013913472,
      "backward_entropy": 0.013638325035572052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.49134826660156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03211386874318123,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11103620131810506,
      "backward_entropy": 0.02157975435256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.87708282470703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03217567875981331,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.11076982816060384,
      "backward_entropy": 0.021463803946971893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.49558639526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03224025294184685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11049322287241618,
      "backward_entropy": 0.013365241885185241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.687320709228516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032304953783750534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.11021559437115987,
      "backward_entropy": 0.013278678059577942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.61429214477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03236628696322441,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10995116829872131,
      "backward_entropy": 0.021128425002098085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.9967155456543,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03242690861225128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10968771576881409,
      "backward_entropy": 0.01310805231332779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.973955154418945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03248567506670952,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10942898193995158,
      "backward_entropy": 0.01302315592765808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.171607971191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.032540462911129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10918507973353068,
      "backward_entropy": 0.012936654686927795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.82733917236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03259522467851639,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10894065101941426,
      "backward_entropy": 0.020686954259872437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.523338317871094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03265226632356644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1086865762869517,
      "backward_entropy": 0.012769365310668945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.76105499267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03270789235830307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10843720038731892,
      "backward_entropy": 0.012687362730503082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.21057891845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03276689723134041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1081742246945699,
      "backward_entropy": 0.012608125805854797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 61.71415328979492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03282780945301056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10790342092514038,
      "backward_entropy": 0.012531468272209167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.285240173339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03288929909467697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10763070980707805,
      "backward_entropy": 0.012458203732967377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.91339874267578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03295012190937996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10736006498336792,
      "backward_entropy": 0.012385886907577515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 91.73383331298828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03300919383764267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1070959468682607,
      "backward_entropy": 0.012314260005950928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.6688117980957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03307244926691055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10681482156117757,
      "backward_entropy": 0.019880589842796326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.29182243347168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03313368931412697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10654095808664958,
      "backward_entropy": 0.012177283316850663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.5184211730957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033190805464982986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10628324747085571,
      "backward_entropy": 0.012107864767313004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.37469482421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03324770927429199,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10602531830469768,
      "backward_entropy": 0.012040464580059052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.067648887634277,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03330440819263458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10576752821604411,
      "backward_entropy": 0.011973975598812104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.06611442565918,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033356331288814545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1055302123228709,
      "backward_entropy": 0.011907726526260376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.98781394958496,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03340626135468483,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1053005854288737,
      "backward_entropy": 0.011842164397239684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.7960319519043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03345440328121185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10507789254188538,
      "backward_entropy": 0.011777490377426147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 89.45079803466797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033504411578178406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10484686493873596,
      "backward_entropy": 0.01171526089310646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 69.37699127197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.033559516072273254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10459359486897786,
      "backward_entropy": 0.011655015498399734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.898730278015137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03361692652106285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10433056950569153,
      "backward_entropy": 0.01159638687968254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.9784164428711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03366952762007713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10408816734949748,
      "backward_entropy": 0.011537988483905793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 68.77790069580078,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03372468426823616,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10383385419845581,
      "backward_entropy": 0.01148182973265648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.39626121520996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03378213942050934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10356885194778442,
      "backward_entropy": 0.018723517656326294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.310428619384766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03383709862828255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10331547260284424,
      "backward_entropy": 0.011383554339408875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 97.38822174072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03388981148600578,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10307233532269795,
      "backward_entropy": 0.018562860786914825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.549659729003906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03394846245646477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10280363758405049,
      "backward_entropy": 0.011293772608041763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.074344635009766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03400678187608719,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10253565510114034,
      "backward_entropy": 0.01125069260597229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.24412155151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03406594321131706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10226355989774068,
      "backward_entropy": 0.011208757758140564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 67.32093811035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.034124720841646194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.10199289520581563,
      "backward_entropy": 0.01824842542409897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.93006134033203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03418542444705963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10171339909235637,
      "backward_entropy": 0.011127457022666931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.566190719604492,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03424561023712158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10143540302912395,
      "backward_entropy": 0.01108797937631607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 57.153324127197266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034300755709409714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10118057330449422,
      "backward_entropy": 0.011048336327075959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.974090576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03435705229640007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10091927647590637,
      "backward_entropy": 0.011010067164897918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 66.25699615478516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03441439941525459,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.10065263509750366,
      "backward_entropy": 0.010972288250923157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 75.4716796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03447381779551506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1003759503364563,
      "backward_entropy": 0.017823706567287444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.01352310180664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0345362089574337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1000854770342509,
      "backward_entropy": 0.010898850858211517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.1176815032959,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034597866237163544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09979823231697083,
      "backward_entropy": 0.01086256206035614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 74.70396423339844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034656595438718796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09952474633852641,
      "backward_entropy": 0.010826023668050766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 46.5321044921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03471832722425461,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09923717379570007,
      "backward_entropy": 0.010790009796619416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.637962341308594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.034779395908117294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09895237286885579,
      "backward_entropy": 0.010754219442605972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.9659309387207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03484102338552475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09866478045781453,
      "backward_entropy": 0.010719330608844757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 82.8775405883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03490089997649193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09838443994522095,
      "backward_entropy": 0.017366911470890044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.536190032958984,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03496473282575607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09808528423309326,
      "backward_entropy": 0.01065206527709961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.994834899902344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03502541407942772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09780152638753255,
      "backward_entropy": 0.01061876118183136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.54680252075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035087790340185165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09750902652740479,
      "backward_entropy": 0.010587166249752044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.45914077758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0351494736969471,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09721925854682922,
      "backward_entropy": 0.017111825942993163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 72.34379577636719,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03521161153912544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09692686796188354,
      "backward_entropy": 0.010526007413864136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 63.056602478027344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035276349633932114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09662207961082458,
      "backward_entropy": 0.010495558381080627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.83949661254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03534235432744026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09631093343098958,
      "backward_entropy": 0.01692652553319931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 62.56192398071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0354083776473999,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09599924087524414,
      "backward_entropy": 0.01043669879436493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.415870666503906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03547552600502968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09568192561467488,
      "backward_entropy": 0.010408388823270798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.60343360900879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03554251790046692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09536532560984294,
      "backward_entropy": 0.010379742085933685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.16726303100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035606130957603455,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0950646201769511,
      "backward_entropy": 0.010352446138858796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 70.37339782714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03566881641745567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09476825594902039,
      "backward_entropy": 0.0166251078248024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.064353942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03573405370116234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09445907672246297,
      "backward_entropy": 0.016565382480621338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.92329025268555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03579707443714142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09416073560714722,
      "backward_entropy": 0.010270044207572937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 78.24967193603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0358581505715847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09387194116910298,
      "backward_entropy": 0.010242781043052674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 51.966552734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03592294827103615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09356433153152466,
      "backward_entropy": 0.010216017067432404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.51180648803711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.035987772047519684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0932568113009135,
      "backward_entropy": 0.010188750922679901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.199033737182617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03605043515563011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09295980135599773,
      "backward_entropy": 0.010161631554365159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.23991775512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.036108992993831635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09268319606781006,
      "backward_entropy": 0.016182611882686614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.12856674194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03616609424352646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09241326649983723,
      "backward_entropy": 0.010111168771982194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.50767707824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03622172772884369,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09215049942334493,
      "backward_entropy": 0.0160553976893425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 84.65361022949219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03627501800656319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09189931551615398,
      "backward_entropy": 0.010060704499483108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.75344467163086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0363338440656662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09162022670110066,
      "backward_entropy": 0.01003534346818924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.226367950439453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03639109060168266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09134892622629802,
      "backward_entropy": 0.010010086745023728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.612056732177734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03644585236907005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09109000364939372,
      "backward_entropy": 0.00998597890138626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.0501708984375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03650263696908951,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09082067012786865,
      "backward_entropy": 0.009960409253835678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.56233596801758,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03656020760536194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.09054710467656453,
      "backward_entropy": 0.00993485376238823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.39177322387695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03661730885505676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09027594327926636,
      "backward_entropy": 0.01558091938495636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 41.2349853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03667411208152771,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.09000623226165771,
      "backward_entropy": 0.015509255230426788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.27969741821289,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03673061355948448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.0897374947865804,
      "backward_entropy": 0.1383191466331482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.0838737487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0367879644036293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08946426709493001,
      "backward_entropy": 0.01536981612443924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.761436462402344,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0368461012840271,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08918660879135132,
      "backward_entropy": 0.009811368584632874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 48.70183181762695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.036903683096170425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08891213933626811,
      "backward_entropy": 0.009787748754024505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.3440055847168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03696190193295479,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0886345108350118,
      "backward_entropy": 0.009763840585947037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.17159652709961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03701864928007126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08836415410041809,
      "backward_entropy": 0.009742212295532227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.10840606689453,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037073004990816116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08810623486836751,
      "backward_entropy": 0.009723098576068878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.93136215209961,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0371273010969162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08784838517506917,
      "backward_entropy": 0.009704603999853133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 55.69279098510742,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03718265891075134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08758471409479777,
      "backward_entropy": 0.009687404334545135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.799320220947266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03724002465605736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0873104731241862,
      "backward_entropy": 0.009670907258987426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.711559295654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0372948981821537,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.08704946438471477,
      "backward_entropy": 0.014786247909069062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 47.19218826293945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037347462028265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08680073420206706,
      "backward_entropy": 0.009640717506408691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 54.81618881225586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037401072680950165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08654663960138957,
      "backward_entropy": 0.009623540937900544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.427215576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03745686635375023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08628082275390625,
      "backward_entropy": 0.009607768058776856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.596999168395996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03751035034656525,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08602731426556905,
      "backward_entropy": 0.009594158083200455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.2554874420166,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03756042197346687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08579268058141072,
      "backward_entropy": 0.009577856957912445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.578468322753906,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03760867938399315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08556767304738362,
      "backward_entropy": 0.009562506526708602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 53.786705017089844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03765743225812912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08533978462219238,
      "backward_entropy": 0.009547615051269531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.353596687316895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03770875558257103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0850978394349416,
      "backward_entropy": 0.009533311426639556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.524932861328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.037757083773612976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08487243453661601,
      "backward_entropy": 0.009520535916090011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.432437896728516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03780491650104523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08464938402175903,
      "backward_entropy": 0.00951000228524208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.31667709350586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03785208240151405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08443004886309306,
      "backward_entropy": 0.009497233480215073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.739498138427734,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0378987155854702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0842136840025584,
      "backward_entropy": 0.00948389619588852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.100648880004883,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0379459485411644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08399383227030437,
      "backward_entropy": 0.00947057008743286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.02667236328125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03799260035157204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0837775468826294,
      "backward_entropy": 0.009456311911344528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 59.677467346191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038036711513996124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08357495069503784,
      "backward_entropy": 0.009443613141775132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.768266677856445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0380849614739418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08334978421529134,
      "backward_entropy": 0.009432454407215119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 37.05579376220703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03813259303569794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08312809467315674,
      "backward_entropy": 0.0094214528799057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.27823257446289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03818066045641899,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08290426433086395,
      "backward_entropy": 0.009409274160861968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.770965576171875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03823019191622734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08267275492350261,
      "backward_entropy": 0.009396165609359741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.3221378326416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03827992081642151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08244071404139201,
      "backward_entropy": 0.009381288290023803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 58.29794692993164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038328707218170166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08221390843391418,
      "backward_entropy": 0.009364190697669982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07887408882379532,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03838104009628296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08196873466173808,
      "backward_entropy": 0.009348908811807633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.956758499145508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03842819482088089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08175246914227803,
      "backward_entropy": 0.009336860477924347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.852888107299805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038474809378385544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08153908451398213,
      "backward_entropy": 0.00932542085647583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.22649002075195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03852085396647453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08132920662562053,
      "backward_entropy": 0.009312893450260162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 50.01862716674805,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03856953978538513,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.08110526204109192,
      "backward_entropy": 0.1384074091911316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.61191177368164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03862063214182854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08086862663427989,
      "backward_entropy": 0.009284588694572448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 42.506038665771484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03867167606949806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08063296476999919,
      "backward_entropy": 0.009267862141132354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.224821090698242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038723982870578766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08039064705371857,
      "backward_entropy": 0.009254281967878341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.138134002685547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038774020969867706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.08016140262285869,
      "backward_entropy": 0.009238720685243607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.001741409301758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.038823116570711136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07993777592976888,
      "backward_entropy": 0.012793104350566863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.938079833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.03887157887220383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07971768577893575,
      "backward_entropy": 0.012727230787277222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.706329345703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03891840949654579,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07950661579767863,
      "backward_entropy": 0.00920073315501213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.56389236450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.038965705782175064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07929330070813496,
      "backward_entropy": 0.009191198647022248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.686922073364258,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039013415575027466,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07907794912656148,
      "backward_entropy": 0.009181688725948333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.28855514526367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03905951604247093,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0788716971874237,
      "backward_entropy": 0.009174257516860962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.339599609375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03910604491829872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.078663503130277,
      "backward_entropy": 0.009164477884769439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.99649429321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03915194422006607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07845920324325562,
      "backward_entropy": 0.009153292328119279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.61052322387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03919841721653938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07825190822283427,
      "backward_entropy": 0.009143040329217911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.547354698181152,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03924636170268059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07803703844547272,
      "backward_entropy": 0.009132056683301925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.575355529785156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03929160535335541,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07783740758895874,
      "backward_entropy": 0.009123235195875167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.099716186523438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03933742269873619,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07763489087422688,
      "backward_entropy": 0.009114212542772292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.368067741394043,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03938179835677147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07744056979815166,
      "backward_entropy": 0.009107426553964616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.958999633789062,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03942401334643364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07725804050763448,
      "backward_entropy": 0.009106361865997314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.02213668823242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03946493938565254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07708299656709035,
      "backward_entropy": 0.009102726727724076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.693179607391357,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03950713947415352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07690062125523885,
      "backward_entropy": 0.009104195982217789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 52.40567398071289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039545945823192596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07673776149749756,
      "backward_entropy": 0.009102223813533783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 45.682769775390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03958901762962341,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07655180493990581,
      "backward_entropy": 0.009098871797323226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.06290054321289,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03963492065668106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07635081807772319,
      "backward_entropy": 0.009095089882612229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.8442268371582,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03968008980154991,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07615460952123006,
      "backward_entropy": 0.009087133407592773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.824054718017578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039726775139570236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07595092058181763,
      "backward_entropy": 0.009077996015548706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.103355407714844,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03977278620004654,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07575126489003499,
      "backward_entropy": 0.009068509936332703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.68714141845703,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.039819225668907166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07554991046587627,
      "backward_entropy": 0.009059112519025803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.133407592773438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03986811637878418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07533587018648784,
      "backward_entropy": 0.00905059427022934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 56.887569427490234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.03991515934467316,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.0751324196656545,
      "backward_entropy": 0.13844192028045654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 44.071998596191406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.03996653109788895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0749070147673289,
      "backward_entropy": 0.009034838527441025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.08332633972168,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04001956060528755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07467406491438548,
      "backward_entropy": 0.009021047502756119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.739744186401367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.040071453899145126,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07444781064987183,
      "backward_entropy": 0.011164236068725585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.042110443115234,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04012139514088631,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.07423241933186848,
      "backward_entropy": 0.13844621181488037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.72482681274414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040171146392822266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07401912411053975,
      "backward_entropy": 0.008999605476856232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.384023666381836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040219906717538834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07381173968315125,
      "backward_entropy": 0.008991914987564086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.296957015991211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040265657007694244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07362139225006104,
      "backward_entropy": 0.00898265615105629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.394521713256836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04030901938676834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07344392438729604,
      "backward_entropy": 0.008978798985481262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.30251121520996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04035189747810364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07326955596605937,
      "backward_entropy": 0.008972561359405518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.169456481933594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040395524352788925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07309144735336304,
      "backward_entropy": 0.008967910706996918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.015769958496094,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04043663293123245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07292742530504863,
      "backward_entropy": 0.008961287885904312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.949604034423828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04047967493534088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07275328040122986,
      "backward_entropy": 0.008956681191921233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.008245468139648,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040522463619709015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07258057594299316,
      "backward_entropy": 0.008954689651727677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.97489070892334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040562864392995834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07242128252983093,
      "backward_entropy": 0.00895160213112831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.762706756591797,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04060094431042671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07227510213851929,
      "backward_entropy": 0.008943964540958405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.403850555419922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04063834622502327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0721323440472285,
      "backward_entropy": 0.008940941095352173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 29.25541114807129,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040677059441804886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0719825526078542,
      "backward_entropy": 0.008940313756465913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18892696499824524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0407172292470932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07182454069455464,
      "backward_entropy": 0.010312509536743165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.50702476501465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04075298830866814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07169130444526672,
      "backward_entropy": 0.010259801149368286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.18605613708496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04078799858689308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07156238953272502,
      "backward_entropy": 0.010204227268695831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.091381072998047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04082346335053444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07143105069796245,
      "backward_entropy": 0.00894373208284378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.023807525634766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040859390050172806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07129718363285065,
      "backward_entropy": 0.008944145590066909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 40.02018356323242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0408954992890358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07116275032361348,
      "backward_entropy": 0.008941398561000824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.130979537963867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04093456268310547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07101351022720337,
      "backward_entropy": 0.00893213003873825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.714475631713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.040972884744405746,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07086814939975739,
      "backward_entropy": 0.008929213136434555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.014333724975586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041011370718479156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07072196404139201,
      "backward_entropy": 0.008929149061441422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 33.71575164794922,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04104887321591377,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07058143615722656,
      "backward_entropy": 0.008928172290325165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.874717712402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04108850285410881,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.07043007016181946,
      "backward_entropy": 0.009775795042514801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.959938049316406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04112696647644043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07028540968894958,
      "backward_entropy": 0.008925293385982514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.19188117980957,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0411684475839138,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.07012543082237244,
      "backward_entropy": 0.008923567831516266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.15456485748291,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04120774567127228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06997727354367574,
      "backward_entropy": 0.008923058956861496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.522624969482422,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04124495014548302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06984064976374309,
      "backward_entropy": 0.008921078592538833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.03592586517334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04128309339284897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06969971458117168,
      "backward_entropy": 0.008915139734745026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 27.26788330078125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04131949320435524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06956791877746582,
      "backward_entropy": 0.008913487941026688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1725965291261673,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04135708138346672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06943025191624959,
      "backward_entropy": 0.008911777287721634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.650949478149414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0413907952606678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06931336720784505,
      "backward_entropy": 0.008909133076667786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.565582275390625,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04142513871192932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06919316450754802,
      "backward_entropy": 0.00891004353761673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.489343643188477,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04145650565624237,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06908954679965973,
      "backward_entropy": 0.13846123218536377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.114337921142578,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04148866608738899,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06898140410582225,
      "backward_entropy": 0.008894884586334228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.012704849243164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041520364582538605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06887603799502055,
      "backward_entropy": 0.008887208998203278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.537153244018555,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04155207425355911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06877018014589946,
      "backward_entropy": 0.008887383341789245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.922821998596191,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0415852889418602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06865689158439636,
      "backward_entropy": 0.008884862810373307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 31.536283493041992,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041617993265390396,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06854649384816487,
      "backward_entropy": 0.00888168215751648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 36.61699295043945,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04165326803922653,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06842295825481415,
      "backward_entropy": 0.13845739364624024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.313358306884766,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04169170930981636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06828373670578003,
      "backward_entropy": 0.008880048245191573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.506034851074219,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04172762483358383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06815730532010396,
      "backward_entropy": 0.008888081461191178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.545626640319824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04176163300871849,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06804134448369344,
      "backward_entropy": 0.00889117568731308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 35.96070861816406,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04179546236991882,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06792595982551575,
      "backward_entropy": 0.13846399784088134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.633544921875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0418328121304512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06779282788435619,
      "backward_entropy": 0.008917378634214402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.37513256072998,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041871167719364166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06765513618787129,
      "backward_entropy": 0.008930419385433198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 25.38237953186035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.041908517479896545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06752309203147888,
      "backward_entropy": 0.008942102640867233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.24361801147461,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04194697365164757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06738577286402385,
      "backward_entropy": 0.008954834192991257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.147543907165527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04198543727397919,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06724885602792104,
      "backward_entropy": 0.008968217670917511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 30.04233169555664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042022064328193665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06712137659390767,
      "backward_entropy": 0.008983634412288666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 34.82085418701172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04206037521362305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06698665022850037,
      "backward_entropy": 0.008989927172660828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.002036094665527,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04210134968161583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06683957576751709,
      "backward_entropy": 0.008993228524923324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.648794174194336,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04214021936058998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0667032649119695,
      "backward_entropy": 0.008999312669038773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.801102638244629,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042179979383945465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06656293074289958,
      "backward_entropy": 0.00900653749704361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8399019241333,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04221846163272858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06642960508664449,
      "backward_entropy": 0.009010742604732513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 38.759315490722656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04225519672036171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06630489230155945,
      "backward_entropy": 0.009020388126373291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.828238487243652,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042295780032873154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06616198519865672,
      "backward_entropy": 0.009029301255941391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.495338439941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.042333681136369705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06603375573952992,
      "backward_entropy": 0.008275449275970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.662214279174805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04237058386206627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06591068704922994,
      "backward_entropy": 0.00902484953403473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 28.505115509033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04240947961807251,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06577817598978679,
      "backward_entropy": 0.008185857534408569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.273885726928711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042450226843357086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06563701232274373,
      "backward_entropy": 0.00902862399816513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.901195526123047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0424896739423275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06550264358520508,
      "backward_entropy": 0.009032003581523895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.141572952270508,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04252864047884941,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06537164251009624,
      "backward_entropy": 0.1385009765625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 32.564613342285156,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04256633669137955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06524736682573955,
      "backward_entropy": 0.009024550765752792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.975678443908691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04260658472776413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0651114284992218,
      "backward_entropy": 0.009016555547714234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.494091033935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04264556244015694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06498197714487712,
      "backward_entropy": 0.009009429812431335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.801350593566895,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04268414154648781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06485508879025777,
      "backward_entropy": 0.008999031037092209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.745818138122559,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.042721811681985855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0647323230902354,
      "backward_entropy": 0.008994530886411667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.1787052154541,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0427585206925869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06461463371912639,
      "backward_entropy": 0.008992289751768112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.13560676574707,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04279524087905884,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06449713309605916,
      "backward_entropy": 0.1384950637817383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 49.131370544433594,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04283155873417854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06438259283701579,
      "backward_entropy": 0.008981616795063018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.949655532836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04287446290254593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06423820058504741,
      "backward_entropy": 0.007629097998142242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 26.540552139282227,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0429161936044693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06410093108812968,
      "backward_entropy": 0.00896151438355446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.272299766540527,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04295943304896355,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06395662327607472,
      "backward_entropy": 0.13848869800567626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.209980964660645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043001268059015274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06381936371326447,
      "backward_entropy": 0.008951372653245925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857895851135254,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043041691184043884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06368914246559143,
      "backward_entropy": 0.008951297402381897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.060559272766113,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04307961463928223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06357151766618092,
      "backward_entropy": 0.008945858478546143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.252519607543945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043116502463817596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06345891952514648,
      "backward_entropy": 0.008943023532629013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.212575912475586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04315338656306267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06334659457206726,
      "backward_entropy": 0.008943065255880355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.252870559692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04318983852863312,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0632372001806895,
      "backward_entropy": 0.008936168253421783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26917994022369385,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04322746396064758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06312224765618642,
      "backward_entropy": 0.008938421308994294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.883153915405273,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043260764330625534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06302853425343831,
      "backward_entropy": 0.00892857313156128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.78775978088379,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04329439625144005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06293322642644246,
      "backward_entropy": 0.00892222449183464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.853805541992188,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04332839325070381,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06283620993296306,
      "backward_entropy": 0.008920706808567047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2066522091627121,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04336342588067055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0627348820368449,
      "backward_entropy": 0.00891948789358139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.29892635345459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043394893407821655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06265003482500713,
      "backward_entropy": 0.008918179571628571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.483272552490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043424006551504135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.06257608532905579,
      "backward_entropy": 0.0069584488868713375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 24.51665687561035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04345369711518288,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06249974171320597,
      "backward_entropy": 0.008912907540798187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.281904220581055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0434856042265892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0624138613541921,
      "backward_entropy": 0.008907763659954071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.232177734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04351703077554703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.062330166498819985,
      "backward_entropy": 0.008905264735221862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.176398277282715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.043549854308366776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.062240282694498696,
      "backward_entropy": 0.006788688898086548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.143177509307861,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04358195513486862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06215400497118632,
      "backward_entropy": 0.00890645682811737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.910079956054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04361192509531975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06207698086897532,
      "backward_entropy": 0.00891217440366745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.970025062561035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04364404082298279,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06199103593826294,
      "backward_entropy": 0.008914744853973389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.649248123168945,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.043675705790519714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06190707286198934,
      "backward_entropy": 0.008920751512050629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.620058059692383,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04370947182178497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06181421875953674,
      "backward_entropy": 0.00892690196633339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.658272743225098,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04374435916543007,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.06171665589014689,
      "backward_entropy": 0.1384752631187439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.445363998413086,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04377926141023636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06161952018737793,
      "backward_entropy": 0.008944634348154068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.618203163146973,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04381478205323219,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06152044733365377,
      "backward_entropy": 0.00894748866558075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.815272808074951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04384969547390938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061423818270365395,
      "backward_entropy": 0.008958792686462403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.517769813537598,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04388270899653435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06133607029914856,
      "backward_entropy": 0.00896637663245201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.008272171020508,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04391512647271156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061250915129979454,
      "backward_entropy": 0.008976554870605469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.88368797302246,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04394843801856041,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061162590980529785,
      "backward_entropy": 0.008981893956661224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.347992897033691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04398269206285477,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.061070650815963745,
      "backward_entropy": 0.00898611769080162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.942876815795898,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04401605948805809,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060982863108317055,
      "backward_entropy": 0.008989699184894562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.22984504699707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044049739837646484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06089366475741068,
      "backward_entropy": 0.008998826891183854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.482345581054688,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04408518970012665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06079745292663574,
      "backward_entropy": 0.009007097780704498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.466504096984863,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04412110149860382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060700307289759316,
      "backward_entropy": 0.009008298814296722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.240955352783203,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04415503889322281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06061191360155741,
      "backward_entropy": 0.009007961302995682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.936437606811523,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04418971389532089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060521031419436135,
      "backward_entropy": 0.009005109965801238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.782386541366577,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044223569333553314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06043359637260437,
      "backward_entropy": 0.009005407989025115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.823164939880371,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04425475373864174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06035776933034261,
      "backward_entropy": 0.009003207832574845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 17.827619552612305,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044285379350185394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06028434634208679,
      "backward_entropy": 0.009002296626567841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.229069709777832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04431704059243202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.060207088788350425,
      "backward_entropy": 0.008998807519674301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.08807373046875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04434705525636673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06013709803422292,
      "backward_entropy": 0.008992726355791092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 14.0325288772583,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044379182159900665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.06005846460660299,
      "backward_entropy": 0.00899018496274948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.119206428527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04441159591078758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0599786639213562,
      "backward_entropy": 0.00899190381169319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.466512680053711,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044442206621170044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05990687012672424,
      "backward_entropy": 0.008988154679536819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.43934154510498,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04447229206562042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.059837316473325096,
      "backward_entropy": 0.008986004441976548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.72217845916748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04450167343020439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05977108081181844,
      "backward_entropy": 0.005768291652202606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.646575927734375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04453159496188164,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.059702535470326744,
      "backward_entropy": 0.008976985514163972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.64927864074707,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044561997056007385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05963188409805298,
      "backward_entropy": 0.008979842811822892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.512818336486816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044592224061489105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05956299106280009,
      "backward_entropy": 0.008971595764160156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849699974060059,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044622741639614105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05949310461680094,
      "backward_entropy": 0.00896495059132576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 23.281179428100586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04465163126587868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05943025151888529,
      "backward_entropy": 0.008954136818647384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.79929542541504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.044683001935482025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05935842792193095,
      "backward_entropy": 0.008934988081455231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.700447082519531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04471633955836296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05927875638008118,
      "backward_entropy": 0.008922534435987473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.532609939575195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04474800080060959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05920594930648804,
      "backward_entropy": 0.008912180364131928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.213064193725586,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04478173702955246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0591248075167338,
      "backward_entropy": 0.008910979330539703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.386505365371704,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04481639713048935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05904014905293783,
      "backward_entropy": 0.008915726095438004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.526355266571045,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04484846070408821,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058966015775998436,
      "backward_entropy": 0.008922082930803299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.80778694152832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04487903043627739,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05889774362246195,
      "backward_entropy": 0.008930780738592149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 22.124887466430664,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04490964859724045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05882983406384786,
      "backward_entropy": 0.008935472369194031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.711583137512207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04494262486696243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058753649393717446,
      "backward_entropy": 0.008933495730161667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3773322105407715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04497654736042023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05867390334606171,
      "backward_entropy": 0.008937427401542663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3279290199279785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04500869661569595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05860123038291931,
      "backward_entropy": 0.008941895514726638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.441008567810059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04503932222723961,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05853454271952311,
      "backward_entropy": 0.005183056741952896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.355714797973633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045070864260196686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05846468607584635,
      "backward_entropy": 0.008954203873872756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.168644905090332,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04510513320565224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058384587367375694,
      "backward_entropy": 0.00896691232919693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.147716999053955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04513963311910629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058303276697794594,
      "backward_entropy": 0.008990360796451569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098158836364746,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045172497630119324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05822825928529104,
      "backward_entropy": 0.009017647057771683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02987003326416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04520447552204132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.058156877756118774,
      "backward_entropy": 0.009043144434690476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.893353462219238,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04523571953177452,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0580884317557017,
      "backward_entropy": 0.009068724513053895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0051445960998535,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045267123728990555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05801951885223389,
      "backward_entropy": 0.009095092117786408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.898497581481934,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04529706761240959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05795612931251526,
      "backward_entropy": 0.009122131764888764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.687736511230469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04532620310783386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057896251479784645,
      "backward_entropy": 0.009142471849918366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.617030143737793,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04535558819770813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05783560872077942,
      "backward_entropy": 0.009161409735679627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 20.069700241088867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04538518190383911,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057774374882380165,
      "backward_entropy": 0.009178954362869262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16862782835960388,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045417193323373795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05770485599835714,
      "backward_entropy": 0.009192023426294327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.849559783935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04544622451066971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05764591693878174,
      "backward_entropy": 0.009210356324911118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525012016296387,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04547745734453201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05757999916871389,
      "backward_entropy": 0.009217651933431626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.727929592132568,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0455080047249794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05751656492551168,
      "backward_entropy": 0.009227625280618667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.505918502807617,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04553702846169472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057458688815434776,
      "backward_entropy": 0.009237061440944671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.855387687683105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04556501284241676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05740541219711304,
      "backward_entropy": 0.0048531867563724514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.71610164642334,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045593928545713425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057349185148874916,
      "backward_entropy": 0.00922854095697403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.232027053833008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04562399536371231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0572886069615682,
      "backward_entropy": 0.009228942543268203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.572858810424805,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04565362632274628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057229081789652504,
      "backward_entropy": 0.009236639738082886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.429837226867676,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045684076845645905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05716705322265625,
      "backward_entropy": 0.009242336452007293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 21.335235595703125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0457155741751194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057101125518480934,
      "backward_entropy": 0.009254704415798187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.689627647399902,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04574969783425331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.057027146220207214,
      "backward_entropy": 0.009257049858570099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.608532905578613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04578327015042305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05695578455924988,
      "backward_entropy": 0.009254375100135803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.502009391784668,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0458163321018219,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056886802117029824,
      "backward_entropy": 0.009246537089347839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.07427406311035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045849092304706573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056819140911102295,
      "backward_entropy": 0.009239386767148972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.454710006713867,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04588388279080391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05674492319424947,
      "backward_entropy": 0.00923428013920784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.755828857421875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04591936618089676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056669423977533974,
      "backward_entropy": 0.00922127291560173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.168843269348145,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.045955073088407516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05659349759419759,
      "backward_entropy": 0.009211359918117524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.147834777832031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04599151387810707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05651592214902242,
      "backward_entropy": 0.009199090301990509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50481653213501,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.046025775372982025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05644601583480835,
      "backward_entropy": 0.00444503016769886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458667278289795,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046059105545282364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05637901027997335,
      "backward_entropy": 0.009185869991779328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8671875,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046091508120298386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05631508926550547,
      "backward_entropy": 0.009188845008611678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9924516677856445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046123430132865906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056253393491109215,
      "backward_entropy": 0.009186825901269912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.081056594848633,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04615360125899315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05619775255521139,
      "backward_entropy": 0.009184597432613373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.577655076980591,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046184275299310684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05614092946052551,
      "backward_entropy": 0.009179080277681351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5606157779693604,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046212539076805115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056092262268066406,
      "backward_entropy": 0.009172482043504715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.219574451446533,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04623863101005554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.056050896644592285,
      "backward_entropy": 0.009164932370185851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.416081428527832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04626397788524628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05601249635219574,
      "backward_entropy": 0.009150270372629166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.6483736038208,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04628976434469223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055972556273142494,
      "backward_entropy": 0.00914004147052765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4957516193389893,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04631662741303444,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05592915415763855,
      "backward_entropy": 0.009132739901542664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 16.059833526611328,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04634147137403488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055892388025919594,
      "backward_entropy": 0.009125488251447678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6854658126831055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046368587762117386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0558490256468455,
      "backward_entropy": 0.009111698716878891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.861544132232666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04639451205730438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055809338887532554,
      "backward_entropy": 0.009102171659469605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 15.708390235900879,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046420205384492874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05576999485492706,
      "backward_entropy": 0.009100323915481568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.241217613220215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046448227018117905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055723691980044045,
      "backward_entropy": 0.009096799790859223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 13.267463684082031,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04647665098309517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05567683776219686,
      "backward_entropy": 0.009084418416023254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.020057678222656,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0465066023170948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055625329415003456,
      "backward_entropy": 0.009077222645282745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.966828346252441,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04653708264231682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055572266379992165,
      "backward_entropy": 0.009071327000856399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 19.371950149536133,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046567779034376144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055519272883733116,
      "backward_entropy": 0.009059392660856248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.521510601043701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04660148173570633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05545774598916372,
      "backward_entropy": 0.009043107181787491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56729793548584,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046633992344141006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05540017286936442,
      "backward_entropy": 0.009031299501657486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.564592361450195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04666599631309509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05534449716409048,
      "backward_entropy": 0.009020109474658967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.376472473144531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0466981939971447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05528865257898966,
      "backward_entropy": 0.009008271247148513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 18.54387855529785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04672916233539581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055236950516700745,
      "backward_entropy": 0.008995739370584488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2254109382629395,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04676283895969391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05517798662185669,
      "backward_entropy": 0.008974677324295044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.16367244720459,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04679465666413307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05512471000353495,
      "backward_entropy": 0.008960099518299102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 12.096026420593262,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046827465295791626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055068761110305786,
      "backward_entropy": 0.008949318528175354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.946185111999512,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04686081036925316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.055011878410975136,
      "backward_entropy": 0.008932965248823166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.878999710083008,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04689488187432289,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05495327711105347,
      "backward_entropy": 0.008918709307909011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.874328136444092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04692904278635979,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05489468574523926,
      "backward_entropy": 0.00890985205769539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.864972114562988,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04696255549788475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0548382302125295,
      "backward_entropy": 0.008904366195201874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8447041511535645,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.046995099633932114,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054784427086512245,
      "backward_entropy": 0.00891016200184822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9749722480773926,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04702650383114815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05473413070042928,
      "backward_entropy": 0.008918822556734086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.861081600189209,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04705590009689331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054690236846605934,
      "backward_entropy": 0.00892145186662674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.540825366973877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04708408564329147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05464946230252584,
      "backward_entropy": 0.00345427505671978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.125151634216309,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04711207002401352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0546095073223114,
      "backward_entropy": 0.00894758477807045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.368484020233154,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04714101180434227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05456734697024027,
      "backward_entropy": 0.00895375683903694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.340758323669434,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0471699982881546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05452480912208557,
      "backward_entropy": 0.008969122171401977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.338688850402832,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04719875380396843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05448307593663534,
      "backward_entropy": 0.008984734117984772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.707785129547119,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04722685366868973,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054443945487340294,
      "backward_entropy": 0.008988194167613983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.20642614364624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04725356772542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05440859993298849,
      "backward_entropy": 0.00334601029753685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.386468410491943,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04727989435195923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05437483390172323,
      "backward_entropy": 0.00899375081062317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.067355632781982,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04730552062392235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05434305469195048,
      "backward_entropy": 0.008992590010166168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2661333084106445,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047331031411886215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05431181192398071,
      "backward_entropy": 0.008988551795482635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9148200750350952,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04735617712140083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054281264543533325,
      "backward_entropy": 0.008993123471736909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5381224155426025,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04737935587763786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054256310065587364,
      "backward_entropy": 0.00899503007531166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5589749813079834,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04740161821246147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054233700037002563,
      "backward_entropy": 0.009000489860773087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4781975746154785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04742271080613136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05421459674835205,
      "backward_entropy": 0.00899955928325653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.104762554168701,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04744317755103111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0541968842347463,
      "backward_entropy": 0.009005299210548401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7830051183700562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047463588416576385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05417916178703308,
      "backward_entropy": 0.009013424813747405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.680017948150635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.047483015805482864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05416358510653178,
      "backward_entropy": 0.003138832375407219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.59430456161499,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047502901405096054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05414685606956482,
      "backward_entropy": 0.00904873088002205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.550903797149658,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047523532062768936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05412784218788147,
      "backward_entropy": 0.009069357812404633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125859260559082,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047544822096824646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05410676201184591,
      "backward_entropy": 0.009094209223985673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2869515419006348,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04756702855229378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05408331751823425,
      "backward_entropy": 0.009114739298820496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.034921646118164,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047588709741830826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05406069755554199,
      "backward_entropy": 0.009146853536367416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.294904947280884,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04761107638478279,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.054036607344945274,
      "backward_entropy": 0.003067903779447079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2719531059265137,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04763246327638626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.054015149672826133,
      "backward_entropy": 0.009188416600227355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.314229488372803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.0476529598236084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05399604638417562,
      "backward_entropy": 0.0030422084033489226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2828190326690674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04767381027340889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05397599935531616,
      "backward_entropy": 0.009221740812063218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.205425262451172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0476933978497982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05395983656247457,
      "backward_entropy": 0.009223432838916778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2594375610351562,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047712262719869614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0539454718430837,
      "backward_entropy": 0.009225782006978989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.69791316986084,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04772990569472313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05393506089846293,
      "backward_entropy": 0.00921187996864319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.113248825073242,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04774727672338486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053925663232803345,
      "backward_entropy": 0.009190063923597336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.021989822387695,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04776440188288689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05391627053419749,
      "backward_entropy": 0.00917922705411911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16271290183067322,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04778335988521576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05390167236328125,
      "backward_entropy": 0.009167640656232833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0637857913970947,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04780062660574913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0538913756608963,
      "backward_entropy": 0.0091635063290596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.685669898986816,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047817591577768326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0538816104332606,
      "backward_entropy": 0.009166616201400756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.352530002593994,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047838084399700165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05386184652646383,
      "backward_entropy": 0.009181579202413559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.688569068908691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04785948991775513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05383978287378947,
      "backward_entropy": 0.009193100035190582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5617949962615967,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04788258671760559,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05381299058596293,
      "backward_entropy": 0.009210211783647537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.157288074493408,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04790421947836876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05378983418146769,
      "backward_entropy": 0.009232909977436065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.725562572479248,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.047926850616931915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05376385649045309,
      "backward_entropy": 0.009258793294429779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.288905620574951,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0479496493935585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053737491369247437,
      "backward_entropy": 0.009283708781003952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5229376554489136,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04797210171818733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05371188620726267,
      "backward_entropy": 0.00931076854467392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9539690017700195,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04799304157495499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05369011561075846,
      "backward_entropy": 0.009339255094528199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.890480995178223,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04801482707262039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05366620421409607,
      "backward_entropy": 0.009364648908376693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.15663480758667,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04803743585944176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053640072544415794,
      "backward_entropy": 0.009388568997383117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.490730285644531,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04805966839194298,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0536147803068161,
      "backward_entropy": 0.009413996338844299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.367923736572266,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048081789165735245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05359011888504028,
      "backward_entropy": 0.009429959952831269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7402901649475098,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0481044165790081,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05356363455454508,
      "backward_entropy": 0.009456335008144379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.014410972595215,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048126161098480225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05353913207848867,
      "backward_entropy": 0.009486871212720871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6971757411956787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048147644847631454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05351511140664419,
      "backward_entropy": 0.009519794583320617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.515177249908447,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048168331384658813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053492854038874306,
      "backward_entropy": 0.00955558493733406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718691825866699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048189833760261536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053468525409698486,
      "backward_entropy": 0.009587299823760987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.153800964355469,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048212673515081406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05344080924987793,
      "backward_entropy": 0.009617091715335846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.39812707901001,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04823554307222366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053413028518358864,
      "backward_entropy": 0.009644546359777451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.643932580947876,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048258647322654724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053385138511657715,
      "backward_entropy": 0.009658963978290558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.277192115783691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048280343413352966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05336110293865204,
      "backward_entropy": 0.009664639830589294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.744089365005493,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04830244556069374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05333632230758667,
      "backward_entropy": 0.00966128259897232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9233808517456055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04832422733306885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05331199367841085,
      "backward_entropy": 0.009664800763130189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1366095542907715,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04834616929292679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05328704913457235,
      "backward_entropy": 0.0096710205078125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.489555835723877,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04836830869317055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053262174129486084,
      "backward_entropy": 0.009663744270801545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3541977405548096,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04838942736387253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053239633639653526,
      "backward_entropy": 0.009659954905509948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.607728958129883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.048408716917037964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05322190125783285,
      "backward_entropy": 0.0025727687403559684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.899499416351318,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04842779412865639,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.053204516569773354,
      "backward_entropy": 0.13854541778564453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.750940799713135,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048447564244270325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053185602029164634,
      "backward_entropy": 0.009626945108175277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.539306879043579,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04846712946891785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053167675932248436,
      "backward_entropy": 0.009602904319763184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.61085844039917,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04848630726337433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053150683641433716,
      "backward_entropy": 0.0095794677734375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4700493812561035,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04850580543279648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05313268800576528,
      "backward_entropy": 0.009560728818178177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.468474864959717,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04852500557899475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0531153678894043,
      "backward_entropy": 0.009544921666383743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.403566837310791,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04854371398687363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05309951305389404,
      "backward_entropy": 0.009524688124656677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4277501106262207,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04856228455901146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05308380722999573,
      "backward_entropy": 0.009510037302970887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2074987888336182,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04858028143644333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053069879611333214,
      "backward_entropy": 0.009486302733421326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1821168661117554,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04859713837504387,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053058514992396034,
      "backward_entropy": 0.009468819200992584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2485334873199463,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04861312359571457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0530488391717275,
      "backward_entropy": 0.009461910277605057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.247924566268921,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048628680408000946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053039997816085815,
      "backward_entropy": 0.00945887267589569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2846572399139404,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04864370822906494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053032477696736656,
      "backward_entropy": 0.009455200284719467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1353631019592285,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04865868762135506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05302515625953674,
      "backward_entropy": 0.009447790682315826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.180605888366699,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04867314174771309,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05301862955093384,
      "backward_entropy": 0.00945553258061409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.178328275680542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0486874021589756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.053012341260910034,
      "backward_entropy": 0.009468833357095719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.225024223327637,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048702120780944824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05300458272298177,
      "backward_entropy": 0.009490032494068146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.155902862548828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04871723800897598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052996243039766945,
      "backward_entropy": 0.009502027928829194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.125550270080566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04873313754796982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05298581222693125,
      "backward_entropy": 0.009518937766551971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.117583990097046,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048750296235084534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05297208825747172,
      "backward_entropy": 0.009541786462068557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1127525568008423,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04876731336116791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05295873681704203,
      "backward_entropy": 0.009563727676868439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.093633733689785,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04878321662545204,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05294796327749888,
      "backward_entropy": 0.009586510062217713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0723938941955566,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04879790171980858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05293967326482137,
      "backward_entropy": 0.009619949758052826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.010026454925537,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04881245642900467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05293195446332296,
      "backward_entropy": 0.00964365154504776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9487807750701904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048827510327100754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05292309820652008,
      "backward_entropy": 0.009661959856748581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.898535251617432,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048843350261449814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05291201174259186,
      "backward_entropy": 0.009686080366373062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9321606159210205,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04886016622185707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0528985857963562,
      "backward_entropy": 0.009707768261432648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0557068586349487,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.048877157270908356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.05288429061571757,
      "backward_entropy": 0.1385366439819336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718590259552002,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04889299347996712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052872657775878906,
      "backward_entropy": 0.00976644903421402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.75707483291626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048910316079854965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05285747845967611,
      "backward_entropy": 0.00979272797703743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8461155891418457,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04892834648489952,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05284067988395691,
      "backward_entropy": 0.009813275188207626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.677338600158691,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0489463172852993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052823697527249656,
      "backward_entropy": 0.009839490056037903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7163538932800293,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048964906483888626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05280536413192749,
      "backward_entropy": 0.009859892725944518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9903616905212402,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.048983700573444366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052786409854888916,
      "backward_entropy": 0.009880318492650985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.541830062866211,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04900124669075012,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05277015765508016,
      "backward_entropy": 0.00990343764424324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.640974760055542,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04901954531669617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05275209744771322,
      "backward_entropy": 0.00992453396320343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8673763275146484,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04903784021735191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052734206120173134,
      "backward_entropy": 0.009938022494316101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8299607038497925,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04905511811375618,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05271882812182108,
      "backward_entropy": 0.009944388270378112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8076283931732178,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04907167702913284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052704950173695884,
      "backward_entropy": 0.009950799494981765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7999106645584106,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04908765107393265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05269216497739156,
      "backward_entropy": 0.009959686547517776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.491140127182007,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049103032797575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052680651346842446,
      "backward_entropy": 0.009968806058168411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.617021083831787,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04911866784095764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05266865094502767,
      "backward_entropy": 0.009971952438354493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9310029149055481,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04913413152098656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0526570330063502,
      "backward_entropy": 0.009972842782735825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.376183271408081,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049148522317409515,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05264773964881897,
      "backward_entropy": 0.009973781555891037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7358142137527466,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0491635762155056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05263662338256836,
      "backward_entropy": 0.009980474412441254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7160745859146118,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04917805641889572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05262678861618042,
      "backward_entropy": 0.009985384345054627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120192527770996,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04919208213686943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05261784791946411,
      "backward_entropy": 0.009990963339805602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.47251558303833,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04920712113380432,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052606518069903054,
      "backward_entropy": 0.009996342658996581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8929694294929504,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04922228679060936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05259456733862559,
      "backward_entropy": 0.010007531940937042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4344310760498047,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049236346036195755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0525851845741272,
      "backward_entropy": 0.010015248507261276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9707751274108887,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04925061762332916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05257496734460195,
      "backward_entropy": 0.010029253363609315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1731858253479004,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04926609620451927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05256164073944092,
      "backward_entropy": 0.010050676763057709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.134324312210083,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04928207769989967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05254689355691274,
      "backward_entropy": 0.01007489264011383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3489608764648438,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04929862171411514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05253058671951294,
      "backward_entropy": 0.010105900466442108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.328270435333252,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04931515082716942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05251405636469523,
      "backward_entropy": 0.010141821205615997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3400187492370605,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049331653863191605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052497307459513344,
      "backward_entropy": 0.01018180400133133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.294250011444092,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049347806721925735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05248154203097025,
      "backward_entropy": 0.010214275121688843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8052871823310852,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049363873898983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05246574183305105,
      "backward_entropy": 0.01024816334247589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.022287368774414,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04937891289591789,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05245204269886017,
      "backward_entropy": 0.010282827168703079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5456533432006836,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04939408227801323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05243833859761556,
      "backward_entropy": 0.010306049883365632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5197340250015259,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049408480525016785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05242649217446645,
      "backward_entropy": 0.010320755839347839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2158162593841553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04942230507731438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.052415892481803894,
      "backward_entropy": 0.0019248327240347861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.87392258644104,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04943609982728958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0524052232503891,
      "backward_entropy": 0.010341896116733551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.187425136566162,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049450602382421494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05239251752694448,
      "backward_entropy": 0.010359793901443481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1494369506835938,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049464933574199677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05238023400306702,
      "backward_entropy": 0.010372644662857056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.214505672454834,
      "terminal_state_reached": true,
      "terminal_reward": 0,
      "log_Z": -0.04947928711771965,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.05236763755480448,
      "backward_entropy": 0.13859004974365235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8320844173431396,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04949487745761871,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052352299292882286,
      "backward_entropy": 0.010398389399051666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4474380016326904,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04951047897338867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05233725905418396,
      "backward_entropy": 0.01039929836988449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7678070068359375,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04952523112297058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052324255307515465,
      "backward_entropy": 0.010393184423446656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0689430236816406,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04954018443822861,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052310844262441,
      "backward_entropy": 0.010384038835763932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.365863800048828,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04955495893955231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0522977610429128,
      "backward_entropy": 0.01037527620792389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.672783374786377,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049570467323064804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05228293935457865,
      "backward_entropy": 0.010367696732282638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3012373447418213,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04958627372980118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0522673229376475,
      "backward_entropy": 0.010363902896642685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.003185510635376,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049602702260017395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0522503654162089,
      "backward_entropy": 0.01036054790019989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2348453998565674,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0496186763048172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05223455528418223,
      "backward_entropy": 0.010352957248687743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.358618140220642,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04963524267077446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05221738417943319,
      "backward_entropy": 0.010346046090126038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6756377816200256,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04965068772435188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05220307409763336,
      "backward_entropy": 0.010327838361263275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.365877628326416,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049665190279483795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052190532286961876,
      "backward_entropy": 0.010317672789096833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6744325757026672,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04968128725886345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052174538373947144,
      "backward_entropy": 0.01031016856431961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4677047729492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049696266651153564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.052160829305648804,
      "backward_entropy": 0.0017509886994957924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.074535608291626,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04971156269311905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052146315574645996,
      "backward_entropy": 0.010305026173591613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.440366506576538,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049727194011211395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.052131483952204384,
      "backward_entropy": 0.010294994711875916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2500160932540894,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.049742840230464935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.05211681624253591,
      "backward_entropy": 0.0017198342829942703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07373858988285065,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049757640808820724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05210408568382263,
      "backward_entropy": 0.010265752673149109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.917418956756592,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": -0.04977095499634743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.052094499270121254,
      "backward_entropy": 0.001695803925395012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3410584926605225,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04978519305586815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05208266774813334,
      "backward_entropy": 0.010243842005729675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6393528580665588,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049799636006355286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05207045873006185,
      "backward_entropy": 0.01023598313331604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.518200874328613,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04981297627091408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05206067363421122,
      "backward_entropy": 0.010226231813430787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2541913986206055,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04982827976346016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05204679568608602,
      "backward_entropy": 0.010217078030109406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.698266863822937,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04984390363097191,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05203208327293396,
      "backward_entropy": 0.010216309875249862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7560577392578125,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04985925555229187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05201794703801473,
      "backward_entropy": 0.010217638313770294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.246316909790039,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049875181168317795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05200262864430746,
      "backward_entropy": 0.010221152007579804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6480045318603516,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049892161041498184,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051984945933024086,
      "backward_entropy": 0.010231832414865494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6867687702178955,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04990866035223007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051968385775883995,
      "backward_entropy": 0.01024116575717926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.667919158935547,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0499253012239933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05195184051990509,
      "backward_entropy": 0.010240624845027923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6130549907684326,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04994303733110428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0519331693649292,
      "backward_entropy": 0.010238096117973328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5708352327346802,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.04996088519692421,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051914473374684654,
      "backward_entropy": 0.010232145339250565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5474581718444824,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.049978140741586685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05189703404903412,
      "backward_entropy": 0.010227128863334656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04197505861520767,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.0499955378472805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05187951525052389,
      "backward_entropy": 0.010219260305166244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9936023950576782,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05001156032085419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051864415407180786,
      "backward_entropy": 0.010225655138492584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.448240280151367,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050027575343847275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05184931059678396,
      "backward_entropy": 0.010233476012945174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9514751434326172,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05004393681883812,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05183357000350952,
      "backward_entropy": 0.010241714119911195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4710687398910522,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05006018280982971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05181817213694254,
      "backward_entropy": 0.010248247534036636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4271067380905151,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050075843930244446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05180409550666809,
      "backward_entropy": 0.01024966835975647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.861355185508728,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05009130761027336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051790197690327965,
      "backward_entropy": 0.010259109735488891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.416896939277649,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05010699853301048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051775639255841575,
      "backward_entropy": 0.010276771336793899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7213265895843506,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05012219399213791,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051762208342552185,
      "backward_entropy": 0.01029011532664299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9499635100364685,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05013815313577652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05174722274144491,
      "backward_entropy": 0.01030290573835373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3596118688583374,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05015316233038902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05173427859942118,
      "backward_entropy": 0.010310135781764984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48153576254844666,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.05016782879829407,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051721940437952675,
      "backward_entropy": 0.010317937284708024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.325628638267517,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050181541591882706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.05171133577823639,
      "backward_entropy": 0.010330223292112351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2979687452316284,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050195079296827316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.051700969537099205,
      "backward_entropy": 0.010344602167606354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2935513257980347,
      "terminal_state_reached": true,
      "terminal_reward": 90,
      "log_Z": -0.050208620727062225,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.0516903301080068,
      "backward_entropy": 0.010367047041654587,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.4356839065253735,
    "avg_log_Z": -0.04944020032882691,
    "success_rate": 1.0,
    "avg_reward": 85.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.02,
      "1": 0.04,
      "2": 0.94
    },
    "avg_forward_entropy": 0.05238386044899622,
    "avg_backward_entropy": 0.01232348735630512,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}